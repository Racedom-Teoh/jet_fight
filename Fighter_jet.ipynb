{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code by Swati Kar\n",
    "# email: swati.cse.ruet@gmail.com\n",
    "\n",
    "#necessary packages\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import pygame\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStoppingCallback(BaseCallback):\n",
    "    def __init__(self, patience: int, min_delta: float = 0.0, verbose: int = 0):\n",
    "        \"\"\"\n",
    "        Early stopping callback to stop training when a monitored metric stops improving.\n",
    "\n",
    "        :param patience: Number of steps to wait for improvement before stopping.\n",
    "        :param min_delta: Minimum change to qualify as an improvement.\n",
    "        :param verbose: Verbosity level (0: no output, 1: output when stopping).\n",
    "        \"\"\"\n",
    "        super(EarlyStoppingCallback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.best_reward = -np.inf\n",
    "        self.wait = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Access the latest reward from the training environment\n",
    "        if \"episode\" in self.locals[\"infos\"][0]:\n",
    "            episode_reward = self.locals[\"infos\"][0][\"episode\"][\"r\"]\n",
    "            if episode_reward > self.best_reward + self.min_delta:\n",
    "                self.best_reward = episode_reward\n",
    "                self.wait = 0  # Reset the patience counter\n",
    "            else:\n",
    "                self.wait += 1\n",
    "\n",
    "            if self.wait >= self.patience:\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Early stopping triggered. Best reward: {self.best_reward}\")\n",
    "                return False  # Stop training\n",
    "\n",
    "        return True  # Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# environment code\n",
    "class FighterJetEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(FighterJetEnv, self).__init__()\n",
    "\n",
    "        # Initialize Pygame\n",
    "        pygame.init()\n",
    "        self.width = 800\n",
    "        self.height = 800\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"V14_exp_extend Fighter Jet Game\")\n",
    "\n",
    "\n",
    "        # Initialize font for text rendering\n",
    "        self.font = pygame.font.Font(None, 20)\n",
    "\n",
    "        # Add a semi-transparent surface for text background\n",
    "        self.text_surface = pygame.Surface((200, 100))\n",
    "        self.text_surface.set_alpha(128)\n",
    "        self.text_surface.fill((0, 0, 0))\n",
    "        self.dot_spacing = 2  # Adjust this value to change the spacing between dots\n",
    "\n",
    "        # Update colors\n",
    "        self.WHITE = (255, 255, 255)\n",
    "        self.RED = (255, 0, 0)\n",
    "        self.BLUE = (0, 0, 255)\n",
    "        self.LIGHT_BLUE = (100, 100, 255)  # Darker shade of light blue for better visibility\n",
    "\n",
    "        \n",
    "\n",
    "        # New colors\n",
    "        self.LIGHT_GREEN = (200, 255, 200)  # Very light green for background\n",
    "        self.DARK_GREEN = (0, 100, 0)  # Dark green for agent and bullets\n",
    "\n",
    "        \n",
    "\n",
    "        # Update background color\n",
    "        self.background = pygame.Surface((self.width, self.height))\n",
    "        self.background.fill(self.LIGHT_GREEN)\n",
    "\n",
    "        # Game parameters\n",
    "        # self.jet_speed = 3\n",
    "        self.bullet_speed = 7\n",
    "        self.targeting_zone_radius = 200\n",
    "        self.enemy_observation_radius = 250\n",
    "        self.agent_observation_radius = self.targeting_zone_radius\n",
    "        self.max_speed = 3\n",
    "        self.min_speed = 0\n",
    "        self.acceleration = 0.25\n",
    "        self.turn_rate = 0.05\n",
    "        self.current_speed = self.min_speed\n",
    "        self.good_shooting_distance_threshold = 50\n",
    "\n",
    "        # Update enemy parameters\n",
    "        self.enemy_speed = 4\n",
    "        self.enemy_bullet_speed = 7\n",
    "        self.enemy_shoot_interval = 5 \n",
    "        self.enemy_max_bullets = 1000\n",
    "\n",
    "\n",
    "        # Define action and observation space\n",
    "        # Actions: 0: do nothing, 1: turn left, 2: turn right, 3: accelerate, 4: decelerate, 5: shoot\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "\n",
    "        self.obs_ranges = {\n",
    "            'jet_pos_x': (0, self.width),\n",
    "            'jet_pos_y': (0, self.height),\n",
    "            'jet_orientation': (-math.pi, math.pi),\n",
    "            'jet_velocity_x': (-self.max_speed, self.max_speed),\n",
    "            'jet_velocity_y': (-self.max_speed, self.max_speed),\n",
    "            'angle_to_target': (-math.pi, math.pi),\n",
    "            'dist_to_target': (0, math.sqrt(self.width**2 + self.height**2)),\n",
    "            'enemy_visible': (0, 1),\n",
    "            'angle_to_enemy': (-math.pi, math.pi),\n",
    "            'dist_to_enemy': (0, math.sqrt(self.width**2 + self.height**2)),\n",
    "            'bullet_visible': (0, 1),\n",
    "            'dist_to_bullet': (0, math.sqrt(self.width**2 + self.height**2)),\n",
    "            'in_target_zone': (0, 1)\n",
    "        }\n",
    "\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(13,), dtype=np.float32)\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.edge_buffer = 20\n",
    "\n",
    "        self.in_target_zone = False\n",
    "        self.enemy_visible = False\n",
    "\n",
    "        # attributes for episode limit and bullet optimization\n",
    "        self.max_steps = 2000\n",
    "        self.current_step = 0\n",
    "        self.max_bullets = 50\n",
    "        self.bullet_count = 0\n",
    "\n",
    "        self.current_reward = 0\n",
    "        self.episode_reward = 0\n",
    "        self.episode = 0\n",
    "        \n",
    "        self.agent_status = \"Game started\"\n",
    "\n",
    "        self.action_counts = [0] * 6\n",
    "        self.action_rewards = [0] * 6\n",
    "        self.last_action = None\n",
    "        self.last_state = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        print(\"Reset environment\")\n",
    "        self.episode += 1\n",
    "        # Reset jet, enemy, target positions and other game states\n",
    "        self.jet_pos = np.array([self.width // 2, self.height - 50], dtype=np.float32)\n",
    "        self.jet_orientation = -math.pi / 2 \n",
    "        self.current_speed = self.min_speed\n",
    "        self.jet_velocity = self.current_speed * np.array([math.cos(self.jet_orientation), math.sin(self.jet_orientation)])\n",
    "        self.enemy_pos = np.array([self.width // 2, 50], dtype=np.float32)\n",
    "        self.target_pos = np.array([random.randint(50, self.width-50), random.randint(50, self.height-50)], dtype=np.float32)\n",
    "        self.jet_bullets = []\n",
    "        self.enemy_bullets = []\n",
    "        self.enemy_shoot_counter = 0\n",
    "        self.enemy_bullet_count = 0\n",
    "        self.in_target_zone = False\n",
    "        self.enemy_visible = False\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.bullet_count = 0\n",
    "\n",
    "        self.action_counts = [0] * 6\n",
    "        self.action_rewards = [0] * 6\n",
    "        self.last_action = None\n",
    "        self.last_state = None\n",
    "\n",
    "        self.current_reward = 0\n",
    "        self.episode_reward = 0\n",
    "        self.agent_status = \"Game started\"\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        return obs, {} \n",
    "\n",
    "    def step(self, action):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                return self._get_obs(), 0, True, False, {}\n",
    "            \n",
    "        prev_jet_pos = self.jet_pos.copy()\n",
    "            \n",
    "        # Process action\n",
    "        if action == 0:  # Do nothing\n",
    "            pass\n",
    "        elif action == 1:  # Turn left\n",
    "            self.jet_orientation -= self.turn_rate\n",
    "        elif action == 2:  # Turn right\n",
    "            self.jet_orientation += self.turn_rate\n",
    "        elif action == 3:  # Accelerate\n",
    "            self.current_speed = min(self.current_speed + self.acceleration, self.max_speed)\n",
    "        elif action == 4:  # Decelerate\n",
    "            self.current_speed = max(self.current_speed - self.acceleration, self.min_speed)\n",
    "        if action == 5:  # Shoot\n",
    "            self.bullet_count += 1\n",
    "            bullet_velocity = self.bullet_speed * np.array([math.cos(self.jet_orientation), math.sin(self.jet_orientation)])\n",
    "            self.jet_bullets.append([self.jet_pos.copy(), bullet_velocity])\n",
    "\n",
    "        # Move jet forward in the direction it's facing\n",
    "        self.jet_velocity = self.current_speed * np.array([math.cos(self.jet_orientation), math.sin(self.jet_orientation)])\n",
    "        new_pos = self.jet_pos + self.jet_velocity\n",
    "\n",
    "        \n",
    "\n",
    "        # Check for out-of-bounds\n",
    "        if new_pos[0] < self.edge_buffer or new_pos[0] > self.width - self.edge_buffer:\n",
    "            self.jet_orientation = math.pi - self.jet_orientation\n",
    "            self.jet_orientation = (self.jet_orientation + math.pi) % (2 * math.pi) - math.pi\n",
    "            new_pos[0] = max(min(new_pos[0], self.width - self.edge_buffer - 1), self.edge_buffer + 1)\n",
    "\n",
    "        if new_pos[1] < self.edge_buffer or new_pos[1] > self.height - self.edge_buffer:\n",
    "            self.jet_orientation = -self.jet_orientation\n",
    "            self.jet_orientation = (self.jet_orientation + math.pi) % (2 * math.pi) - math.pi\n",
    "            new_pos[1] = max(min(new_pos[1], self.height - self.edge_buffer - 1), self.edge_buffer + 1)\n",
    "\n",
    "        self.jet_pos = new_pos\n",
    "\n",
    "\n",
    "       # Update in_target_zone and enemy_visible status\n",
    "        self.in_target_zone = np.linalg.norm(self.jet_pos - self.target_pos) <= self.targeting_zone_radius\n",
    "        self.enemy_visible = self.enemy_pos is not None and np.linalg.norm(self.jet_pos - self.enemy_pos) <= self.enemy_observation_radius\n",
    "\n",
    "        # Move bullets\n",
    "        for bullet in self.jet_bullets:\n",
    "            bullet[0] += bullet[1]\n",
    "        self.jet_bullets = [bullet for bullet in self.jet_bullets if 0 <= bullet[0][0] <= self.width and 0 <= bullet[0][1] <= self.height]\n",
    "\n",
    "        for bullet in self.enemy_bullets:\n",
    "            bullet[0] += bullet[1]\n",
    "        self.enemy_bullets = [bullet for bullet in self.enemy_bullets if 0 <= bullet[0][0] <= self.width and 0 <= bullet[0][1] <= self.height]\n",
    "\n",
    "        \n",
    "\n",
    "        # enemy behavior\n",
    "        if self.enemy_pos is not None:\n",
    "            dist_to_jet = np.linalg.norm(self.jet_pos - self.enemy_pos)\n",
    "            direction = (self.jet_pos - self.enemy_pos) / dist_to_jet\n",
    "            \n",
    "            if dist_to_jet > 100:\n",
    "                self.enemy_pos += direction * self.enemy_speed\n",
    "            elif dist_to_jet < 50:\n",
    "                self.enemy_pos -= direction * self.enemy_speed\n",
    "            else:\n",
    "                self.enemy_pos += np.random.uniform(-0.5, 0.5, 2) * self.enemy_speed\n",
    "\n",
    "            self.enemy_pos = np.clip(self.enemy_pos, self.edge_buffer, [self.width - self.edge_buffer, self.height - self.edge_buffer])\n",
    "\n",
    "            self.enemy_shoot_counter += 1\n",
    "            if self.enemy_shoot_counter >= self.enemy_shoot_interval and self.enemy_bullet_count < self.enemy_max_bullets:\n",
    "                bullet_velocity = self.enemy_bullet_speed * direction\n",
    "                self.enemy_bullets.append([self.enemy_pos.copy(), bullet_velocity])\n",
    "                self.enemy_bullet_count += 1\n",
    "                self.enemy_shoot_counter = 0\n",
    "\n",
    "        done = False\n",
    "        reward = 0\n",
    "        \n",
    "        # Small negative reward for each step to encourage efficiency\n",
    "        reward -= 0.1\n",
    "\n",
    "        # Calculate distances\n",
    "        prev_dist_to_target = np.linalg.norm(self.target_pos - prev_jet_pos)\n",
    "        current_dist_to_target = np.linalg.norm(self.target_pos - self.jet_pos)\n",
    "        # print(f\"prev_dist_to_target: {prev_dist_to_target} |current_dist_to_target: {current_dist_to_target} \")\n",
    "        \n",
    "        # Calculate reward\n",
    "        distance_change = prev_dist_to_target - current_dist_to_target\n",
    "        distance_weight = 10  # Increased from 5 to 10\n",
    "        reward += distance_change * distance_weight\n",
    "\n",
    "        # Add an additional penalty for moving away from the target\n",
    "        if distance_change < 0:\n",
    "            moving_away_penalty = abs(distance_change) * 15  # Additional penalty\n",
    "            reward -= moving_away_penalty\n",
    "\n",
    "        \n",
    "        if self.in_target_zone:\n",
    "            reward += 2\n",
    "            self.agent_status = \"Agent in target zone\"\n",
    "        else:\n",
    "            reward += -1\n",
    "            self.agent_status = \"Agent out of target zone\"\n",
    "\n",
    "        if self.enemy_visible:\n",
    "            reward += 1\n",
    "            self.agent_status = \"Enemy visible\"\n",
    "        else:\n",
    "            reward -= 0.5\n",
    "\n",
    "        if self.bullet_count > self.max_bullets:\n",
    "            reward -= 0.5\n",
    "            self.agent_status = \"Excessive bullet usage\"\n",
    "\n",
    "\n",
    "        if self.in_target_zone and any(np.linalg.norm(bullet[0] - self.target_pos) < 15 for bullet in self.jet_bullets):\n",
    "            reward += 200\n",
    "            done = True\n",
    "            self.agent_status = \"Agent hit target within target zone\"\n",
    "\n",
    "        if self.enemy_visible and self.enemy_pos is not None and any(np.linalg.norm(bullet[0] - self.enemy_pos) < 15 for bullet in self.jet_bullets):\n",
    "            reward += 100\n",
    "            self.agent_status = \"Agent hit enemy\"\n",
    "            self.enemy_pos = None\n",
    "            self.enemy_visible = False\n",
    "            self.enemy_bullets = []\n",
    "\n",
    "        if self.enemy_visible and any(np.linalg.norm(bullet[0] - self.jet_pos) < 15 for bullet in self.enemy_bullets):\n",
    "            reward += -500\n",
    "            done = True\n",
    "            self.agent_status = \"Enemy hit agent\"\n",
    "\n",
    "        # Check if max steps reached\n",
    "        if self.current_step >= self.max_steps:\n",
    "            reward -= 1000 \n",
    "            done = True\n",
    "            self.agent_status = \"Max steps reached without hitting target\"\n",
    "\n",
    "        self.last_state = self._get_obs()\n",
    "        self.last_action = action\n",
    "        self.action_counts[action] += 1\n",
    "        self.action_rewards[action] += reward\n",
    "\n",
    "        self.current_step += 1\n",
    "        self.episode_reward += reward\n",
    "        self.current_reward = reward\n",
    "        self.render()\n",
    "        return self._get_obs(), reward, done, False, {\"status\": self.agent_status, \"episode_reward\": self.episode_reward}\n",
    "      \n",
    "\n",
    "    def _get_obs(self):\n",
    "        jet_to_target = self.target_pos - self.jet_pos\n",
    "        \n",
    "        angle_to_target = math.atan2(jet_to_target[1], jet_to_target[0])\n",
    "        dist_to_target = np.linalg.norm(jet_to_target)\n",
    "        \n",
    "        if self.enemy_pos is not None and self.enemy_visible:\n",
    "            jet_to_enemy = self.enemy_pos - self.jet_pos\n",
    "            angle_to_enemy = math.atan2(jet_to_enemy[1], jet_to_enemy[0])\n",
    "            dist_to_enemy = np.linalg.norm(jet_to_enemy)\n",
    "        else:\n",
    "            angle_to_enemy = 0\n",
    "            dist_to_enemy = self.enemy_observation_radius\n",
    "\n",
    "        closest_enemy_bullet = min(self.enemy_bullets, key=lambda bullet: np.linalg.norm(bullet[0] - self.jet_pos)) if self.enemy_bullets else [self.jet_pos, np.zeros(2)]\n",
    "        jet_to_bullet = closest_enemy_bullet[0] - self.jet_pos\n",
    "        angle_to_bullet = math.atan2(jet_to_bullet[1], jet_to_bullet[0])\n",
    "        dist_to_bullet = np.linalg.norm(jet_to_bullet)\n",
    "        bullet_visible = int(len(self.enemy_bullets) > 0)\n",
    "\n",
    "        obs = [\n",
    "            self.jet_pos[0],\n",
    "            self.jet_pos[1],\n",
    "            self.jet_orientation,\n",
    "            self.jet_velocity[0],\n",
    "            self.jet_velocity[1],\n",
    "            angle_to_target,\n",
    "            dist_to_target,\n",
    "            int(self.enemy_pos is not None and self.enemy_visible),\n",
    "            angle_to_enemy,\n",
    "            dist_to_enemy,\n",
    "            bullet_visible,\n",
    "            dist_to_bullet,\n",
    "            int(self.in_target_zone)\n",
    "        ]\n",
    "\n",
    "        # Normalize observations\n",
    "        normalized_obs = [\n",
    "            (obs[i] - self.obs_ranges[key][0]) / (self.obs_ranges[key][1] - self.obs_ranges[key][0])\n",
    "            for i, key in enumerate(self.obs_ranges.keys())\n",
    "        ]\n",
    "\n",
    "        return np.array(normalized_obs, dtype=np.float32)\n",
    "    \n",
    "    def draw_dotted_circle(self, surface, color, center, radius, width=1):\n",
    "\n",
    "        for i in range(0, 360, self.dot_spacing):\n",
    "\n",
    "            angle = i * math.pi / 180\n",
    "\n",
    "            start_pos = (center[0] + int(radius * math.cos(angle)),\n",
    "\n",
    "                        center[1] + int(radius * math.sin(angle)))\n",
    "\n",
    "            end_pos = (center[0] + int(radius * math.cos(angle + math.pi / 180)),\n",
    "\n",
    "                    center[1] + int(radius * math.sin(angle + math.pi / 180)))\n",
    "\n",
    "            pygame.draw.line(surface, color, start_pos, end_pos, width)\n",
    "\n",
    "    def render(self):\n",
    "        # Fill the background with light green\n",
    "        self.screen.blit(self.background, (0, 0))\n",
    "        \n",
    "        # Draw targeting zone\n",
    "        self.draw_dotted_circle(self.screen, self.LIGHT_BLUE, self.target_pos.astype(int), self.targeting_zone_radius, 2)\n",
    "        \n",
    "        # Draw observation ranges\n",
    "        self.draw_dotted_circle(self.screen, self.DARK_GREEN, self.jet_pos.astype(int), self.agent_observation_radius, 1)        \n",
    "       \n",
    "        # Draw jet\n",
    "        jet_direction = np.array([math.cos(self.jet_orientation), math.sin(self.jet_orientation)])\n",
    "        jet_nose = self.jet_pos + 20 * jet_direction\n",
    "        jet_left = self.jet_pos + 10 * np.array([-jet_direction[1], jet_direction[0]])\n",
    "        jet_right = self.jet_pos + 10 * np.array([jet_direction[1], -jet_direction[0]])\n",
    "        pygame.draw.polygon(self.screen, self.DARK_GREEN, [jet_nose, jet_left, jet_right])\n",
    "\n",
    "        if self.enemy_pos is not None:\n",
    "            self.draw_dotted_circle(self.screen, self.RED, self.enemy_pos.astype(int), self.enemy_observation_radius, 1)\n",
    "            enemy_direction = (self.jet_pos - self.enemy_pos) / np.linalg.norm(self.jet_pos - self.enemy_pos)\n",
    "            enemy_nose = self.enemy_pos + 20 * enemy_direction\n",
    "            enemy_left = self.enemy_pos + 10 * np.array([-enemy_direction[1], enemy_direction[0]])\n",
    "            enemy_right = self.enemy_pos + 10 * np.array([enemy_direction[1], -enemy_direction[0]])\n",
    "            pygame.draw.polygon(self.screen, self.RED, [enemy_nose, enemy_left, enemy_right])\n",
    "        \n",
    "        pygame.draw.circle(self.screen, self.BLUE, self.target_pos.astype(int), 15)\n",
    "        \n",
    "        for bullet in self.jet_bullets:\n",
    "            pygame.draw.circle(self.screen, self.DARK_GREEN, bullet[0].astype(int), 3)\n",
    "        for bullet in self.enemy_bullets:\n",
    "            pygame.draw.circle(self.screen, self.RED, bullet[0].astype(int), 3)\n",
    "\n",
    "        text_color = (0, 0, 0)  # Black text\n",
    "\n",
    "        status_text = self.font.render(f\"Episode: {self.episode}\", True, text_color)\n",
    "        self.screen.blit(status_text, (15, 15))\n",
    "\n",
    "\n",
    "        reward_text = self.font.render(f\"Reward: {self.episode_reward:.2f}\", True, text_color)\n",
    "        self.screen.blit(reward_text, (15, 35))\n",
    "\n",
    "\n",
    "        step_text = self.font.render(f\"Steps: {self.current_step}/{self.max_steps}\", True, text_color)\n",
    "        self.screen.blit(step_text, (15, 55))\n",
    "\n",
    "\n",
    "        bullet_text = self.font.render(f\"Bullets: {self.bullet_count}/{self.max_bullets}\", True, text_color)\n",
    "        self.screen.blit(bullet_text, (15, 75))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(60)\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "# from stable_baselines3.dqn import DDQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_reward = 0\n",
    "        self.q_values = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Access the VecEnv\n",
    "        env = self.training_env.envs[0]  # Extract the original environment\n",
    "        if isinstance(env, Monitor):\n",
    "            env = env.env  # Unwrap the Monitor to access the original FighterJetEnv\n",
    "\n",
    "        self.episode_reward += self.locals['rewards'][0]\n",
    "\n",
    "        # Log epsilon value\n",
    "        epsilon = self.model.exploration_rate\n",
    "        self.logger.record(\"exploration/epsilon\", epsilon)\n",
    "\n",
    "        # Log Q-values\n",
    "        obs = self.locals['new_obs']\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model.q_net(torch.as_tensor(obs).to(self.model.device))\n",
    "        q_values = q_values.cpu().numpy()\n",
    "        self.q_values.append(q_values)\n",
    "\n",
    "        if self.locals['dones']:\n",
    "            self.episode_lengths.append(self.locals['infos'][0]['episode']['l'])\n",
    "            self.logger.record('main/ep_rew_total', self.episode_reward)\n",
    "            self.logger.record('main/ep_len_mean', sum(self.episode_lengths) / len(self.episode_lengths))\n",
    "\n",
    "            # Log Q-values\n",
    "            mean_q_values = np.mean(self.q_values, axis=0)\n",
    "            for i, q_value in enumerate(mean_q_values[0]):\n",
    "                self.logger.record(f'q_values/action_{i}', q_value)\n",
    "            self.logger.record('q_values/max', np.max(mean_q_values))\n",
    "            self.logger.record('q_values/min', np.min(mean_q_values))\n",
    "            self.logger.record('q_values/mean', np.mean(mean_q_values))\n",
    "\n",
    "            # Print debug information\n",
    "            print(\"Episode reward:\", self.episode_reward)\n",
    "            print(\"Total Steps:\", self.episode_lengths[-1])\n",
    "            print(\"Agent status:\", env.agent_status)  # Access the original environment's attribute\n",
    "            print(\"Mean Q-values:\", mean_q_values[0])\n",
    "\n",
    "            self.episode_reward = 0\n",
    "        return True\n",
    "    \n",
    "\n",
    "# Create the callback\n",
    "callback = TensorboardCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hyperparameters(model):\n",
    "    print(\"\\nDQN Hyperparameters:\")\n",
    "    print(f\"Learning rate: {model.learning_rate}\")\n",
    "    print(f\"Gamma (discount factor): {model.gamma}\")\n",
    "    print(f\"Tau (soft update coefficient): {model.tau}\")\n",
    "    print(f\"Train frequency: {model.train_freq}\")\n",
    "    print(f\"Gradient steps: {model.gradient_steps}\")\n",
    "    print(f\"Batch size: {model.batch_size}\")\n",
    "    print(f\"Learning starts: {model.learning_starts}\")\n",
    "    print(f\"Buffer size: {model.buffer_size}\")\n",
    "    print(f\"Target update interval: {model.target_update_interval}\")\n",
    "    print(f\"Exploration initial epsilon: {model.exploration_initial_eps}\")\n",
    "    print(f\"Exploration final epsilon: {model.exploration_final_eps}\")\n",
    "    print(f\"Exploration fraction: {model.exploration_fraction}\")\n",
    "    print(f\"Max gradient norm: {model.max_grad_norm}\")\n",
    "    print(\"\\nPolicy network architecture:\")\n",
    "    print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "No existing model found. Creating a new DQN agent.\n",
      "\n",
      "DQN Hyperparameters:\n",
      "Learning rate: 5e-05\n",
      "Gamma (discount factor): 0.99\n",
      "Tau (soft update coefficient): 0.001\n",
      "Train frequency: TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: 'step'>)\n",
      "Gradient steps: 1\n",
      "Batch size: 256\n",
      "Learning starts: 50000\n",
      "Buffer size: 500000\n",
      "Target update interval: 5000\n",
      "Exploration initial epsilon: 1.0\n",
      "Exploration final epsilon: 0.1\n",
      "Exploration fraction: 0.7\n",
      "Max gradient norm: 10\n",
      "\n",
      "Policy network architecture:\n",
      "DQNPolicy(\n",
      "  (q_net): QNetwork(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=13, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (q_net_target): QNetwork(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=13, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Reset environment\n",
      "Reset environment\n",
      "Episode reward: 2876.0142\n",
      "Total Steps: 973\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01576454  0.01142806 -0.0305754  -0.01792675 -0.03297333 -0.06576564]\n",
      "Reset environment\n",
      "Episode reward: 353.74396\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01575491  0.01214376 -0.02984929 -0.01797968 -0.03306414 -0.06717265]\n",
      "Reset environment\n",
      "Episode reward: 733.28204\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01585316  0.01265237 -0.02919873 -0.01826926 -0.03293303 -0.06869775]\n",
      "Reset environment\n",
      "Episode reward: 60.32657\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01586672  0.01316687 -0.02861329 -0.01822629 -0.03305271 -0.06954736]\n",
      "Reset environment\n",
      "Episode reward: -9646.945\n",
      "Total Steps: 237\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0176254   0.01336675 -0.02860209 -0.01835288 -0.03381068 -0.0696764 ]\n",
      "Reset environment\n",
      "Episode reward: -14199.867\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02170668  0.01232642 -0.03353407 -0.01288454 -0.03357547 -0.06240417]\n",
      "Reset environment\n",
      "Episode reward: -3016.0332\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02170168  0.01248198 -0.03330952 -0.01315229 -0.03360988 -0.06291545]\n",
      "Reset environment\n",
      "Episode reward: -428.36734\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02158771  0.01268575 -0.03286413 -0.01338701 -0.0334891  -0.06345994]\n",
      "Reset environment\n",
      "Episode reward: -1110.4747\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02153693  0.01287829 -0.03260371 -0.01353052 -0.03343    -0.06384592]\n",
      "Reset environment\n",
      "Episode reward: 99.54648\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02142678  0.01303991 -0.0322945  -0.01365777 -0.03344962 -0.06427225]\n",
      "Reset environment\n",
      "Episode reward: -751.91754\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02137034  0.01322086 -0.03191696 -0.01384441 -0.03334286 -0.06469246]\n",
      "Reset environment\n",
      "Episode reward: 72.653564\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02108987  0.013152   -0.03181282 -0.01417233 -0.03323516 -0.06531158]\n",
      "Reset environment\n",
      "Episode reward: -713.7341\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02100892  0.01332405 -0.03158396 -0.01439469 -0.03320601 -0.06571709]\n",
      "Reset environment\n",
      "Episode reward: -24884.412\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02310909  0.01300522 -0.03322255 -0.01210971 -0.03344138 -0.06230153]\n",
      "Reset environment\n",
      "Episode reward: -214.41614\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02300272  0.01310806 -0.0330382  -0.01224706 -0.03344931 -0.06259057]\n",
      "Reset environment\n",
      "Episode reward: 256.02576\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02290774  0.01318406 -0.03289805 -0.01239879 -0.0334042  -0.06292988]\n",
      "Reset environment\n",
      "Episode reward: -455.97397\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02281673  0.01329955 -0.03265634 -0.01254641 -0.03336095 -0.06324311]\n",
      "Reset environment\n",
      "Episode reward: -378.3403\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02271808  0.0134063  -0.03249104 -0.01269716 -0.03334375 -0.06353847]\n",
      "Reset environment\n",
      "Episode reward: 243.7243\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02263959  0.0134868  -0.03232408 -0.01279525 -0.03335389 -0.06379196]\n",
      "Reset environment\n",
      "Episode reward: 849.9367\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02256159  0.01360628 -0.03203173 -0.01299566 -0.03332108 -0.06411885]\n",
      "Reset environment\n",
      "Episode reward: 182.06335\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0224704   0.01368772 -0.03192328 -0.0130881  -0.03331813 -0.06436329]\n",
      "Reset environment\n",
      "Episode reward: -199.57773\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02239053  0.01377956 -0.03174287 -0.01318849 -0.03331577 -0.06460872]\n",
      "Reset environment\n",
      "Episode reward: -18448.268\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02300732  0.01356052 -0.03219615 -0.01234572 -0.03352454 -0.06309808]\n",
      "Reset environment\n",
      "Episode reward: -592.5399\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0229457   0.01363555 -0.032008   -0.01246526 -0.03348051 -0.06332421]\n",
      "Reset environment\n",
      "Episode reward: -364.90692\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02287858  0.01370868 -0.03186555 -0.01257026 -0.03346325 -0.06353474]\n",
      "Reset environment\n",
      "Episode reward: 464.17947\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02279405  0.01378539 -0.03171787 -0.01263902 -0.03342688 -0.06376241]\n",
      "Reset environment\n",
      "Episode reward: -351.81232\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02274535  0.01384224 -0.0315729  -0.0127242  -0.03338228 -0.0639612 ]\n",
      "Reset environment\n",
      "Episode reward: 232.97357\n",
      "Total Steps: 20\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02271921  0.0138249  -0.03156313 -0.01275328 -0.03337695 -0.06400339]\n",
      "Reset environment\n",
      "Episode reward: -301.4984\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02255663  0.01379531 -0.03147241 -0.0129054  -0.03335612 -0.06427812]\n",
      "Reset environment\n",
      "Episode reward: 132.45602\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02249972  0.01384844 -0.03136703 -0.01297805 -0.03335107 -0.06445774]\n",
      "Reset environment\n",
      "Episode reward: -96.516785\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02243518  0.01391472 -0.03125605 -0.01303962 -0.03335406 -0.06462596]\n",
      "Reset environment\n",
      "Episode reward: 256.63297\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02237876  0.013967   -0.03116123 -0.01309138 -0.03335742 -0.06478975]\n",
      "Reset environment\n",
      "Episode reward: -6253.7676\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02250782  0.01405114 -0.03109505 -0.0131122  -0.0334185  -0.06491822]\n",
      "Reset environment\n",
      "Episode reward: -344.69122\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02245492  0.01411082 -0.03097354 -0.01321032 -0.03338391 -0.06510431]\n",
      "Reset environment\n",
      "Episode reward: 62.07257\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02241068  0.01415984 -0.03087605 -0.01330476 -0.03334816 -0.06528573]\n",
      "Reset environment\n",
      "Episode reward: 222.0804\n",
      "Total Steps: 7\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02240316  0.01415181 -0.0308772  -0.013312   -0.03334543 -0.06528995]\n",
      "Reset environment\n",
      "Episode reward: 474.6305\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02231863  0.01417051 -0.03079095 -0.0134084  -0.03332024 -0.06549857]\n",
      "Reset environment\n",
      "Episode reward: 293.37408\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02225551  0.01423158 -0.03066952 -0.01345434 -0.03329768 -0.06567345]\n",
      "Reset environment\n",
      "Episode reward: -623.55707\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0222134   0.01429122 -0.03057512 -0.01356248 -0.03327508 -0.06584767]\n",
      "Reset environment\n",
      "Episode reward: 445.34845\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02217983  0.01434304 -0.03045001 -0.01362603 -0.03328749 -0.06598369]\n",
      "Reset environment\n",
      "Episode reward: 22.238403\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02214458  0.01438845 -0.03034466 -0.01371382 -0.03329431 -0.06611615]\n",
      "Reset environment\n",
      "Episode reward: -208.26965\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02209533  0.01444068 -0.03025229 -0.01378817 -0.03327416 -0.06627075]\n",
      "Reset environment\n",
      "Episode reward: -701.8782\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02204982  0.01449432 -0.03017564 -0.0138817  -0.03326518 -0.06641736]\n",
      "Reset environment\n",
      "Episode reward: -241.18973\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02200445  0.01454154 -0.03010335 -0.01396303 -0.03324739 -0.06657079]\n",
      "Reset environment\n",
      "Episode reward: -505.58572\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02196445  0.01459128 -0.0299818  -0.01403702 -0.03320899 -0.06671851]\n",
      "Reset environment\n",
      "Episode reward: -411.00577\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02191733  0.01463993 -0.0298904  -0.0141077  -0.03321027 -0.06684628]\n",
      "Reset environment\n",
      "Episode reward: 166.81088\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02186866  0.01468341 -0.02982546 -0.01416113 -0.03320509 -0.06697798]\n",
      "Reset environment\n",
      "Episode reward: 18.33728\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02181798  0.01473057 -0.02975382 -0.01420436 -0.03320947 -0.06710063]\n",
      "Reset environment\n",
      "Episode reward: -519.7753\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02165367  0.01469432 -0.02966148 -0.01431032 -0.03320811 -0.06732401]\n",
      "Reset environment\n",
      "Episode reward: -675.6292\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02161617  0.01473907 -0.02960179 -0.01439    -0.03320035 -0.06745058]\n",
      "Reset environment\n",
      "Episode reward: 513.6667\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02158394  0.01477366 -0.02954561 -0.01444301 -0.03318186 -0.0675787 ]\n",
      "Reset environment\n",
      "Episode reward: -349.55194\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02153974  0.01482485 -0.02945932 -0.01449742 -0.03316952 -0.06770676]\n",
      "Reset environment\n",
      "Episode reward: 170.33246\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02151153  0.01485887 -0.02937501 -0.01456686 -0.03315602 -0.06782477]\n",
      "Reset environment\n",
      "Episode reward: 888.1666\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02148756  0.01490377 -0.02927821 -0.01459839 -0.03316847 -0.06792991]\n",
      "Reset environment\n",
      "Episode reward: -234.60359\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02145729  0.01494224 -0.02919844 -0.01466907 -0.03313624 -0.0680591 ]\n",
      "Reset environment\n",
      "Episode reward: -488.8919\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02142584  0.01498007 -0.02913796 -0.0147436  -0.03312454 -0.06817934]\n",
      "Reset environment\n",
      "Episode reward: -78.392914\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0213918   0.01501739 -0.0290648  -0.01479114 -0.0331088  -0.06829415]\n",
      "Reset environment\n",
      "Episode reward: -83.39444\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02135208  0.01505477 -0.02901529 -0.01484719 -0.03309816 -0.068412  ]\n",
      "Reset environment\n",
      "Episode reward: -159.09656\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02125694  0.01501187 -0.02900089 -0.01495416 -0.03306305 -0.06859662]\n",
      "Reset environment\n",
      "Episode reward: -212.34494\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0212232   0.01504963 -0.02895179 -0.01501068 -0.03305128 -0.06870957]\n",
      "Reset environment\n",
      "Episode reward: -496.52957\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02118798  0.01508813 -0.02888019 -0.01505531 -0.03305895 -0.06879762]\n",
      "Reset environment\n",
      "Episode reward: -10293.28\n",
      "Total Steps: 1717\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02085928  0.01423894 -0.02951458 -0.01484281 -0.03298676 -0.06796382]\n",
      "Reset environment\n",
      "Episode reward: -477.6151\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02083459  0.01427658 -0.02946079 -0.01490499 -0.03297821 -0.0680666 ]\n",
      "Reset environment\n",
      "Episode reward: -648.0349\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02081465  0.01431961 -0.02940361 -0.01497283 -0.03296412 -0.06817447]\n",
      "Reset environment\n",
      "Episode reward: 399.71112\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02078902  0.01430344 -0.02939868 -0.0149954  -0.03296023 -0.06821442]\n",
      "Reset environment\n",
      "Episode reward: -39.027344\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02075726  0.01433902 -0.029364   -0.01503351 -0.03295648 -0.06830869]\n",
      "Reset environment\n",
      "Episode reward: -267.21048\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02073206  0.01437866 -0.02929717 -0.01507154 -0.03295488 -0.06839781]\n",
      "Reset environment\n",
      "Episode reward: -532.43524\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02070256  0.01441864 -0.02922727 -0.01509315 -0.0329621  -0.06847338]\n",
      "Reset environment\n",
      "Episode reward: 293.03934\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02067415  0.01440044 -0.02922053 -0.01512171 -0.03295728 -0.06852061]\n",
      "Reset environment\n",
      "Episode reward: -21421.09\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02089842  0.01404079 -0.02998902 -0.01478315 -0.03309045 -0.06705601]\n",
      "Reset environment\n",
      "Episode reward: -411.58292\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02087099  0.0140788  -0.02993373 -0.01481901 -0.03309116 -0.06713908]\n",
      "Reset environment\n",
      "Episode reward: -521.1319\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02085173  0.01411403 -0.02986476 -0.01487109 -0.03307127 -0.06723476]\n",
      "Reset environment\n",
      "Episode reward: -179.05579\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02082731  0.01414859 -0.02980637 -0.01489824 -0.03307546 -0.0673148 ]\n",
      "Reset environment\n",
      "Episode reward: -230.84573\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02080284  0.0141819  -0.02975455 -0.01493946 -0.03306364 -0.06740482]\n",
      "Reset environment\n",
      "Episode reward: -402.03076\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02078335  0.01421655 -0.02970602 -0.01498818 -0.03305146 -0.06749765]\n",
      "Reset environment\n",
      "Episode reward: -824.2628\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02077064  0.01424597 -0.0296536  -0.01500836 -0.03303425 -0.0675737 ]\n",
      "Reset environment\n",
      "Episode reward: -19603.049\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02122194  0.01386035 -0.03025843 -0.01460053 -0.03309428 -0.066462  ]\n",
      "Reset environment\n",
      "Episode reward: -183.8685\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02116105  0.01383925 -0.03024169 -0.01466893 -0.03307342 -0.06658969]\n",
      "Reset environment\n",
      "Episode reward: -304.38623\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02113713  0.0138721  -0.03019345 -0.01470335 -0.03307119 -0.06666663]\n",
      "Reset environment\n",
      "Episode reward: -209.4668\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02111141  0.01390146 -0.03014739 -0.01472703 -0.03307628 -0.06673435]\n",
      "Reset environment\n",
      "Episode reward: 90.80362\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02109536  0.01393219 -0.03008054 -0.01476326 -0.03307356 -0.06680807]\n",
      "Reset environment\n",
      "Episode reward: -14397.992\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02100111  0.01360962 -0.03057833 -0.01478889 -0.03308674 -0.06619988]\n",
      "Reset environment\n",
      "Episode reward: -1427.9517\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02098996  0.01363268 -0.0305543  -0.01482847 -0.03308742 -0.06627516]\n",
      "Reset environment\n",
      "Episode reward: 66.715454\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02096954  0.01365856 -0.03051374 -0.01485296 -0.0330795  -0.06634836]\n",
      "Reset environment\n",
      "Episode reward: 140.85068\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02095399  0.01368058 -0.03047348 -0.01487137 -0.03307332 -0.06641819]\n",
      "Reset environment\n",
      "Episode reward: -4193.1772\n",
      "Total Steps: 247\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02100799  0.01369979 -0.03044538 -0.01490002 -0.0331185  -0.06647859]\n",
      "Reset environment\n",
      "Episode reward: -1160.081\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0209801   0.01368265 -0.03043814 -0.01495383 -0.03308322 -0.06656666]\n",
      "Reset environment\n",
      "Episode reward: -334.30707\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02096075  0.01370981 -0.03039904 -0.01498459 -0.03308216 -0.06663222]\n",
      "Reset environment\n",
      "Episode reward: -513.23224\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02094301  0.01373906 -0.03035325 -0.01502165 -0.03307415 -0.06670504]\n",
      "Reset environment\n",
      "Episode reward: 147.56393\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.020902    0.01372677 -0.03034546 -0.01506329 -0.0330587  -0.0667937 ]\n",
      "Reset environment\n",
      "Episode reward: -18737.393\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0212015   0.01340558 -0.03085186 -0.01461787 -0.03299289 -0.06595957]\n",
      "Reset environment\n",
      "Episode reward: -1563.6184\n",
      "Total Steps: 217\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02124413  0.01341306 -0.03080034 -0.01462197 -0.03301695 -0.06606711]\n",
      "Reset environment\n",
      "Episode reward: -465.03094\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02122798  0.01343965 -0.03075127 -0.01465511 -0.03301123 -0.06613219]\n",
      "Reset environment\n",
      "Episode reward: -180.67435\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02120866  0.01346264 -0.03072179 -0.01468323 -0.0330102  -0.0661935 ]\n",
      "Reset environment\n",
      "Episode reward: -503.7991\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02117196  0.01347093 -0.030687   -0.01471734 -0.03300111 -0.06627525]\n",
      "Reset environment\n",
      "Episode reward: -117.469025\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02115672  0.01349422 -0.0306439  -0.014744   -0.03299546 -0.06633847]\n",
      "Reset environment\n",
      "Episode reward: -208.10916\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02114112  0.01351877 -0.03059981 -0.01476908 -0.03299694 -0.06639688]\n",
      "Reset environment\n",
      "Episode reward: -12048.224\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02124502  0.01328508 -0.03095456 -0.0148027  -0.03298837 -0.06565702]\n",
      "Reset environment\n",
      "Episode reward: -540.3505\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02123237  0.01330941 -0.03091525 -0.01483915 -0.03297898 -0.06572431]\n",
      "Reset environment\n",
      "Episode reward: -308.16852\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.021219    0.01333277 -0.03087007 -0.01486789 -0.03296784 -0.06578664]\n",
      "Reset environment\n",
      "Episode reward: -1068.9517\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02119151  0.01331568 -0.03085962 -0.01491639 -0.03294399 -0.06586317]\n",
      "Reset environment\n",
      "Episode reward: -452.37396\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02117802  0.01334133 -0.03082478 -0.01494774 -0.03293711 -0.06592724]\n",
      "Reset environment\n",
      "Episode reward: -59.566193\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02115865  0.01336964 -0.03076873 -0.01497382 -0.03292033 -0.06599502]\n",
      "Reset environment\n",
      "Episode reward: -542.0382\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02115177  0.01338868 -0.03073562 -0.01498831 -0.03291212 -0.06604533]\n",
      "Reset environment\n",
      "Episode reward: -7577.1885\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02107516  0.0130921  -0.03090136 -0.014953   -0.03291716 -0.06562299]\n",
      "Reset environment\n",
      "Episode reward: -6906.947\n",
      "Total Steps: 237\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0211117   0.01309811 -0.03087402 -0.01500015 -0.03294741 -0.06567612]\n",
      "Reset environment\n",
      "Episode reward: 1553.7839\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02109032  0.01310824 -0.03085198 -0.01502328 -0.03293907 -0.06573413]\n",
      "Reset environment\n",
      "Episode reward: -480.44382\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02107687  0.01313151 -0.03081299 -0.01504282 -0.03294146 -0.06578261]\n",
      "Reset environment\n",
      "Episode reward: -208.50839\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02106214  0.0131549  -0.03077609 -0.01505494 -0.03294417 -0.06583147]\n",
      "Reset environment\n",
      "Episode reward: -481.80826\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02104945  0.01317795 -0.03074732 -0.01508249 -0.03293995 -0.06588797]\n",
      "Reset environment\n",
      "Episode reward: -9451.769\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02096074  0.0129643  -0.03088597 -0.01500952 -0.03293082 -0.06555574]\n",
      "Reset environment\n",
      "Episode reward: -614.28143\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02094895  0.01298762 -0.03085277 -0.01503685 -0.03292653 -0.06561026]\n",
      "Reset environment\n",
      "Episode reward: -412.7616\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02093629  0.01301035 -0.03081569 -0.01505233 -0.03292925 -0.06565643]\n",
      "Reset environment\n",
      "Episode reward: -16700.24\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02094047  0.01266716 -0.03099216 -0.01491156 -0.03291018 -0.06531756]\n",
      "Reset environment\n",
      "Episode reward: 52.585724\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02092838  0.01268589 -0.03096581 -0.01492744 -0.0329119  -0.06536205]\n",
      "Reset environment\n",
      "Episode reward: -3417.1042\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0209197   0.01269089 -0.03095866 -0.01494293 -0.03291497 -0.06540556]\n",
      "Reset environment\n",
      "Episode reward: -591.7406\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02091343  0.01270909 -0.03093369 -0.01496968 -0.03291031 -0.06545442]\n",
      "Reset environment\n",
      "Episode reward: 1012.7993\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02090735  0.01273082 -0.03089637 -0.01498388 -0.03291352 -0.06550027]\n",
      "Reset environment\n",
      "Episode reward: 748.14355\n",
      "Total Steps: 259\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02093967  0.01275607 -0.03084508 -0.01500756 -0.03293617 -0.0655453 ]\n",
      "Reset environment\n",
      "Episode reward: -20349.645\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0213298   0.0128041  -0.03114333 -0.01443667 -0.03300508 -0.06485107]\n",
      "Reset environment\n",
      "Episode reward: -62.034058\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02131914  0.01282143 -0.03111721 -0.0144539  -0.03300555 -0.06489354]\n",
      "Reset environment\n",
      "Episode reward: -479.75647\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02130926  0.0128407  -0.03107918 -0.01447729 -0.0329949  -0.06494331]\n",
      "Reset environment\n",
      "Episode reward: -734.81213\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02130513  0.0128575  -0.03105044 -0.01449321 -0.03298553 -0.06498522]\n",
      "Reset environment\n",
      "Episode reward: 34.621216\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02129495  0.01287394 -0.03102468 -0.0145136  -0.03298071 -0.06503079]\n",
      "Reset environment\n",
      "Episode reward: 604.54126\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02127889  0.01289606 -0.03098926 -0.01453057 -0.03297273 -0.0650827 ]\n",
      "Reset environment\n",
      "Episode reward: -231.97247\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02126596  0.01291343 -0.03096445 -0.01454631 -0.03297553 -0.06512259]\n",
      "Reset environment\n",
      "Episode reward: 561.30676\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02125366  0.01293067 -0.03094188 -0.01456551 -0.03297576 -0.06516821]\n",
      "Reset environment\n",
      "Episode reward: -8464.043\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02115398  0.01259965 -0.03099756 -0.01445759 -0.0329631  -0.06492229]\n",
      "Reset environment\n",
      "Episode reward: -165.5\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02114431  0.01261656 -0.03097542 -0.01447831 -0.03296014 -0.06496628]\n",
      "Reset environment\n",
      "Episode reward: 1407.9624\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02113438  0.01263097 -0.03095159 -0.01449605 -0.03295559 -0.0650131 ]\n",
      "Reset environment\n",
      "Episode reward: -166.01727\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02112258  0.01264798 -0.03092918 -0.0145101  -0.03295816 -0.06505063]\n",
      "Reset environment\n",
      "Episode reward: 87.816925\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02111341  0.0126631  -0.03091113 -0.01452787 -0.0329523  -0.06509615]\n",
      "Reset environment\n",
      "Episode reward: 155.81735\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02110366  0.0126781  -0.03088728 -0.01453973 -0.03295434 -0.06513418]\n",
      "Reset environment\n",
      "Episode reward: 87.86557\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02109226  0.01269462 -0.03086716 -0.01455571 -0.03295156 -0.06517641]\n",
      "Reset environment\n",
      "Episode reward: -191.8544\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02108144  0.01271797 -0.03083025 -0.01456555 -0.03295244 -0.06521676]\n",
      "Reset environment\n",
      "Episode reward: -22824.848\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02103355  0.01242109 -0.03098823 -0.014576   -0.03288836 -0.06498325]\n",
      "Reset environment\n",
      "Episode reward: -18627.162\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02110428  0.01229755 -0.03109912 -0.01444372 -0.03289592 -0.06472633]\n",
      "Reset environment\n",
      "Episode reward: 42.497406\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02109697  0.01231183 -0.03107532 -0.01445752 -0.03289181 -0.06476515]\n",
      "Reset environment\n",
      "Episode reward: -456.54138\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02108754  0.01232917 -0.03105257 -0.01447737 -0.03288938 -0.0648057 ]\n",
      "Reset environment\n",
      "Episode reward: 710.4998\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0210759   0.01234898 -0.03102701 -0.01448314 -0.03288934 -0.06484558]\n",
      "Reset environment\n",
      "Episode reward: -55.096497\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02106977  0.01236438 -0.03100841 -0.01450189 -0.0328909  -0.06488232]\n",
      "Reset environment\n",
      "Episode reward: -157.20285\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02106295  0.0123807  -0.03098997 -0.01451965 -0.03288563 -0.06492308]\n",
      "Reset environment\n",
      "Episode reward: -12076.05\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02110893  0.01238664 -0.03099935 -0.01437115 -0.03292226 -0.06473085]\n",
      "Reset environment\n",
      "Episode reward: -13593.448\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02071114  0.01176499 -0.03127329 -0.01396821 -0.03426343 -0.06488124]\n",
      "Reset environment\n",
      "Episode reward: 146.97253\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02258598  0.01313481 -0.02967199 -0.00960845 -0.03487888 -0.06295853]\n",
      "Reset environment\n",
      "Episode reward: 948.25305\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02619268  0.01646384 -0.02620688 -0.00215193 -0.03420271 -0.05912332]\n",
      "Reset environment\n",
      "Episode reward: -43.334442\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02860934  0.01894074 -0.02363399  0.00301524 -0.033597   -0.0563814 ]\n",
      "Reset environment\n",
      "Episode reward: 98.967865\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.03347166  0.02351166 -0.01904077  0.01107455 -0.03144116 -0.05136884]\n",
      "Reset environment\n",
      "Episode reward: 655.8496\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.03918951  0.02904542 -0.0135836   0.02031799 -0.02834606 -0.04502713]\n",
      "Reset environment\n",
      "Episode reward: 135.44736\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.04471165  0.03472849 -0.00805823  0.02972042 -0.02564546 -0.03860569]\n",
      "Reset environment\n",
      "Episode reward: -601.5193\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.05118373  0.04164207 -0.00158706  0.04056446 -0.02228706 -0.03156001]\n",
      "Reset environment\n",
      "Episode reward: -489.5165\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.05446778  0.04517486  0.00169707  0.04771496 -0.02166551 -0.0275896 ]\n",
      "Reset environment\n",
      "Episode reward: -244.5073\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.06230399  0.05319387  0.0093729   0.0599148  -0.01686725 -0.01943275]\n",
      "Reset environment\n",
      "Episode reward: -2.4518738\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.07052225  0.06143887  0.01745519  0.07235139 -0.01192277 -0.01086056]\n",
      "Reset environment\n",
      "Episode reward: 194.66461\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.08032865  0.07110374  0.02699475  0.0861527  -0.0056778  -0.00097199]\n",
      "Reset environment\n",
      "Episode reward: -348.9474\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0843078   0.07524754  0.03098508  0.09342975 -0.004062    0.00320621]\n",
      "Reset environment\n",
      "Episode reward: 117.931\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [0.09611121 0.08699901 0.04269753 0.11052531 0.00317467 0.01507099]\n",
      "Reset environment\n",
      "Episode reward: -187.51645\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [0.10375299 0.0945669  0.0504227  0.12180083 0.00755046 0.02283821]\n",
      "Reset environment\n",
      "Episode reward: -141.97604\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [0.11192612 0.10270621 0.05860844 0.13390604 0.0124398  0.03105354]\n",
      "Reset environment\n",
      "Episode reward: 627.2434\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [0.12687919 0.11716902 0.0731506  0.15221189 0.02334088 0.0453559 ]\n",
      "Reset environment\n",
      "Episode reward: -6489.84\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.10268489 -0.11049035 -0.1496636  -0.07962194 -0.17625672 -0.17214365]\n",
      "Reset environment\n",
      "Episode reward: 82.47476\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.09312695 -0.10083278 -0.1399558  -0.06654954 -0.16951655 -0.162512  ]\n",
      "Reset environment\n",
      "Episode reward: -828.9684\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.09704212 -0.10508849 -0.14373958 -0.06806369 -0.1745018  -0.16635591]\n",
      "Reset environment\n",
      "Episode reward: -1403.6055\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.11982424 -0.12822527 -0.16628438 -0.09168334 -0.19423164 -0.18910243]\n",
      "Reset environment\n",
      "Episode reward: -86.0773\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.11279993 -0.12108392 -0.15899828 -0.08075169 -0.1901107  -0.1819216 ]\n",
      "Reset environment\n",
      "Episode reward: -496.6432\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.10835069 -0.11685169 -0.1543345  -0.07415752 -0.18729824 -0.17747603]\n",
      "Reset environment\n",
      "Episode reward: 233.04762\n",
      "Total Steps: 7\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.10795925 -0.11646485 -0.15393798 -0.07366206 -0.1870012  -0.17707728]\n",
      "Reset environment\n",
      "Episode reward: -64.19125\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.10023648 -0.10880103 -0.14602788 -0.06208609 -0.18219069 -0.16920309]\n",
      "Reset environment\n",
      "Episode reward: -379.24805\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.07894088 -0.08739874 -0.12435336 -0.03419067 -0.16631444 -0.14759102]\n",
      "Reset environment\n",
      "Episode reward: 1006.678\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.0538909  -0.06208311 -0.09899    -0.00350301 -0.14676042 -0.12232807]\n",
      "Reset environment\n",
      "Episode reward: 191.56754\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04158752 -0.04968739 -0.08662475  0.01305519 -0.1380689  -0.10988209]\n",
      "Reset environment\n",
      "Episode reward: -1551.3984\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.05172539 -0.06000484 -0.09638078  0.00497113 -0.1483339  -0.11979426]\n",
      "Reset environment\n",
      "Episode reward: 1233.1976\n",
      "Total Steps: 262\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03183101 -0.03970466 -0.07623907  0.03366855 -0.13505192 -0.09931284]\n",
      "Reset environment\n",
      "Episode reward: 261.65707\n",
      "Total Steps: 21\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03068269 -0.03858717 -0.07507055  0.03526204 -0.1342325  -0.098131  ]\n",
      "Reset environment\n",
      "Episode reward: -499.46585\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03059674 -0.03858659 -0.07475877  0.03820614 -0.13586442 -0.09800228]\n",
      "Reset environment\n",
      "Episode reward: -265.4134\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02586167 -0.03382033 -0.06982771  0.04638984 -0.13359153 -0.0931314 ]\n",
      "Reset environment\n",
      "Episode reward: 233.24973\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.01295423 -0.02081374 -0.05675924  0.06346285 -0.12412677 -0.08002918]\n",
      "Reset environment\n",
      "Episode reward: -3.4649963\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00409694 -0.01176019 -0.0476955   0.07620444 -0.11810707 -0.07089613]\n",
      "Reset environment\n",
      "Episode reward: -655.7258\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00691101 -0.01474246 -0.05028965  0.07573076 -0.12187509 -0.0735453 ]\n",
      "Reset environment\n",
      "Episode reward: 312.01157\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.00845853  0.00073749 -0.03485182  0.09570573 -0.11061618 -0.05808528]\n",
      "Reset environment\n",
      "Episode reward: 1413.4412\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.03380952  0.02631747 -0.00921962  0.12685327 -0.09085394 -0.03266365]\n",
      "Reset environment\n",
      "Episode reward: 365.59955\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.04564175  0.0380625   0.00278143  0.1423081  -0.08222125 -0.02077172]\n",
      "Reset environment\n",
      "Episode reward: -841.24915\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.05334847  0.04534923  0.01082145  0.15209301 -0.07614764 -0.01325696]\n",
      "Reset environment\n",
      "Episode reward: -352.529\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.05529496  0.04747482  0.01276482  0.15695821 -0.07588572 -0.01115534]\n",
      "Reset environment\n",
      "Episode reward: -5267.635\n",
      "Total Steps: 1130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04987508 -0.0580834  -0.09266306  0.04651817 -0.16779225 -0.11531422]\n",
      "Reset environment\n",
      "Episode reward: -142.9805\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04331913 -0.05149556 -0.086023    0.05629743 -0.1636743  -0.10874303]\n",
      "Reset environment\n",
      "Episode reward: 1116.8367\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.01896415 -0.02711796 -0.06134222  0.08583902 -0.14451382 -0.08414654]\n",
      "Reset environment\n",
      "Episode reward: -2694.4824\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04165016 -0.05045661 -0.08399275  0.06242855 -0.16552138 -0.10711054]\n",
      "Reset environment\n",
      "Episode reward: 269.9424\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.0289455  -0.03760546 -0.07112137  0.07909454 -0.1560963  -0.09423116]\n",
      "Reset environment\n",
      "Episode reward: 48.151947\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.0197346  -0.0282482  -0.0617137   0.09173544 -0.14944123 -0.08480904]\n",
      "Reset environment\n",
      "Episode reward: 49.35971\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.01063088 -0.01911484 -0.05235859  0.1045914  -0.14325653 -0.0754391 ]\n",
      "Reset environment\n",
      "Episode reward: 30.929413\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00026493 -0.00854656 -0.04193383  0.11841108 -0.13559598 -0.06488169]\n",
      "Reset environment\n",
      "Episode reward: 60.328552\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.00856824 -0.00014016 -0.03283435  0.12916426 -0.12846601 -0.05620381]\n",
      "Reset environment\n",
      "Episode reward: 84.453125\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01707083  0.00818199 -0.02416273  0.14073911 -0.12250397 -0.04766982]\n",
      "Reset environment\n",
      "Episode reward: -1916.9805\n",
      "Total Steps: 582\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02661778 -0.0366247  -0.06685085  0.09457684 -0.16129431 -0.09106399]\n",
      "Reset environment\n",
      "Episode reward: 245.4585\n",
      "Total Steps: 15\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02598164 -0.03600845 -0.06613959  0.09547202 -0.16078359 -0.09041467]\n",
      "Reset environment\n",
      "Episode reward: 927.0392\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00312961 -0.01302857 -0.04315289  0.12295766 -0.1423553  -0.06745636]\n",
      "Reset environment\n",
      "Episode reward: -208.57227\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.00176588 -0.00818777 -0.03806579  0.13125366 -0.13978246 -0.06234624]\n",
      "Reset environment\n",
      "Episode reward: -581.25244\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00568121 -0.01601204 -0.04542477  0.12239313 -0.1458589  -0.07005851]\n",
      "Reset environment\n",
      "Episode reward: -8272.662\n",
      "Total Steps: 1194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.14676364 -0.15777074 -0.18704686 -0.03904727 -0.26254064 -0.20952103]\n",
      "Reset environment\n",
      "Episode reward: -598.80725\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.14885059 -0.1601896  -0.18879463 -0.03954855 -0.26528475 -0.21144533]\n",
      "Reset environment\n",
      "Episode reward: 1636.917\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.11905127 -0.13029368 -0.15873015 -0.00431791 -0.24082834 -0.18153979]\n",
      "Reset environment\n",
      "Episode reward: -52.457367\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.11229858 -0.12387218 -0.15155509  0.00412707 -0.23517367 -0.17489284]\n",
      "Reset environment\n",
      "Episode reward: 233.6568\n",
      "Total Steps: 15\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.11215654 -0.12374903 -0.15141821  0.0043641  -0.23510614 -0.17474163]\n",
      "Reset environment\n",
      "Episode reward: -594.7306\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.1141548  -0.12600294 -0.15313253  0.00452542 -0.23822121 -0.17659287]\n",
      "Reset environment\n",
      "Episode reward: -9410.811\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21881388 -0.23335032 -0.25965926 -0.12529294 -0.32241794 -0.28017566]\n",
      "Reset environment\n",
      "Episode reward: -303.94946\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21513888 -0.22934546 -0.25590006 -0.11846064 -0.3208764  -0.27626526]\n",
      "Reset environment\n",
      "Episode reward: -403.50845\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.2134789  -0.2279054  -0.2539532  -0.11423963 -0.3208465  -0.27437884]\n",
      "Reset environment\n",
      "Episode reward: 1157.1365\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.18834904 -0.20260353 -0.2287446  -0.08423513 -0.30024856 -0.24905467]\n",
      "Reset environment\n",
      "Episode reward: -18648.857\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.39206418 -0.40650487 -0.42973986 -0.32357743 -0.47087353 -0.45006508]\n",
      "Reset environment\n",
      "Episode reward: -506.5315\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.39217576 -0.40678552 -0.42950737 -0.32116443 -0.47245502 -0.45000684]\n",
      "Reset environment\n",
      "Episode reward: -266.13416\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.38753456 -0.4023725  -0.42454338 -0.31422633 -0.4695353  -0.44523832]\n",
      "Reset environment\n",
      "Episode reward: -90.97647\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.38110685 -0.39629877 -0.41770655 -0.30558136 -0.46490896 -0.4388349 ]\n",
      "Reset environment\n",
      "Episode reward: -10513.611\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4752151  -0.4846653  -0.518746   -0.42725423 -0.5398976  -0.5305859 ]\n",
      "Reset environment\n",
      "Episode reward: 1016.4846\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.45307997 -0.46255356 -0.49639037 -0.40119836 -0.52162766 -0.5084125 ]\n",
      "Reset environment\n",
      "Episode reward: -490.5119\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4521502  -0.461581   -0.49534595 -0.39727852 -0.5225595  -0.5072687 ]\n",
      "Reset environment\n",
      "Episode reward: 3438.192\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4073023  -0.41673392 -0.4503635  -0.34597573 -0.48474935 -0.46233892]\n",
      "Reset environment\n",
      "Episode reward: -545.9138\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.40772045 -0.41752055 -0.45034105 -0.34526962 -0.48583922 -0.46265423]\n",
      "Reset environment\n",
      "Episode reward: -6423.7495\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.48725513 -0.49699247 -0.5292879  -0.4347878  -0.55438817 -0.54191387]\n",
      "Reset environment\n",
      "Episode reward: -20539.49\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7030181  -0.7149628  -0.74035174 -0.6835455  -0.7376649  -0.75595397]\n",
      "Reset environment\n",
      "Episode reward: 378.8888\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.69049436 -0.70277375 -0.727504   -0.66829836 -0.72774917 -0.74341565]\n",
      "Reset environment\n",
      "Episode reward: 45.782715\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.68178654 -0.6939002  -0.7188586  -0.656475   -0.72145224 -0.73466307]\n",
      "Reset environment\n",
      "Episode reward: -435.06622\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.67951435 -0.6913965  -0.71662104 -0.65139776 -0.7208968  -0.7323151 ]\n",
      "Reset environment\n",
      "Episode reward: -363.0902\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.67663187 -0.6881992  -0.713819   -0.6455008  -0.71987164 -0.7292372 ]\n",
      "Reset environment\n",
      "Episode reward: -1520.2736\n",
      "Total Steps: 787\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.70219356 -0.71456754 -0.7371979  -0.67731225 -0.7400671  -0.7539606 ]\n",
      "Reset environment\n",
      "Episode reward: 381.93546\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6888342  -0.70143586 -0.72338337 -0.66025877 -0.7299269  -0.74044573]\n",
      "Reset environment\n",
      "Episode reward: 838.7175\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.67184174 -0.6846654  -0.7061566  -0.6404927  -0.7157261  -0.72355986]\n",
      "Reset environment\n",
      "Episode reward: 750.9228\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.656816   -0.6694042  -0.6912643  -0.62239844 -0.7034646  -0.7085231 ]\n",
      "Reset environment\n",
      "Episode reward: 233.62021\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6463546  -0.6588466  -0.68082404 -0.6087693  -0.69566786 -0.69795376]\n",
      "Reset environment\n",
      "Episode reward: -153.78726\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.64088494 -0.65356845 -0.67511016 -0.6005621  -0.69217455 -0.69236004]\n",
      "Reset environment\n",
      "Episode reward: -106.11716\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6345734 -0.6474533 -0.6684918 -0.5915658 -0.6878746 -0.6859698]\n",
      "Reset environment\n",
      "Episode reward: 1838.0312\n",
      "Total Steps: 542\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6143739  -0.6255465  -0.64934105 -0.57229704 -0.66874087 -0.66534615]\n",
      "Reset environment\n",
      "Episode reward: 179.8493\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.60413045 -0.61544555 -0.63897586 -0.55900085 -0.661013   -0.65502745]\n",
      "Reset environment\n",
      "Episode reward: 1775.5638\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5729214  -0.5844908  -0.6074883  -0.52281404 -0.63519603 -0.62375206]\n",
      "Reset environment\n",
      "Episode reward: -320.77393\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5757033  -0.5866938  -0.6102826  -0.5273321  -0.6360163  -0.62635636]\n",
      "Reset environment\n",
      "Episode reward: 1605.9116\n",
      "Total Steps: 227\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5557355  -0.56650084 -0.59032893 -0.5052072  -0.61867183 -0.60599554]\n",
      "Reset environment\n",
      "Episode reward: 156.77567\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.54635125 -0.557008   -0.5809527  -0.49278274 -0.61173993 -0.5965171 ]\n",
      "Reset environment\n",
      "Episode reward: -167.48517\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5412244  -0.5516013  -0.5759568  -0.4848824  -0.60861063 -0.59126776]\n",
      "Reset environment\n",
      "Episode reward: -379.14236\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5396967  -0.5498909  -0.5744744  -0.48044765 -0.60886663 -0.5896488 ]\n",
      "Reset environment\n",
      "Episode reward: 937.0226\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.51905495 -0.5294873  -0.5534042  -0.455807   -0.5920836  -0.56885296]\n",
      "Reset environment\n",
      "Episode reward: -14545.327\n",
      "Total Steps: 1971\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.70895594 -0.7155675  -0.741425   -0.68056643 -0.7501994  -0.7575322 ]\n",
      "Reset environment\n",
      "Episode reward: -329.7069\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.70584124 -0.7126532  -0.7381067  -0.675143   -0.7486959  -0.75440913]\n",
      "Reset environment\n",
      "Episode reward: -12780.848\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.900662   -0.89921534 -0.93870574 -0.9091725  -0.9067078  -0.9475032 ]\n",
      "Reset environment\n",
      "Episode reward: 1873.1567\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8697693  -0.869184   -0.9069935  -0.874113   -0.8806252  -0.91652167]\n",
      "Reset environment\n",
      "Episode reward: 198.32144\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.859254   -0.8586921  -0.89642435 -0.8606454  -0.8725437  -0.9059604 ]\n",
      "Reset environment\n",
      "Episode reward: 299.90863\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8480853  -0.8473539  -0.8854615  -0.8468462  -0.8637607  -0.89475524]\n",
      "Reset environment\n",
      "Episode reward: -14447.311\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0174578 -1.0143054 -1.0523309 -1.0446854 -1.0033802 -1.0623069]\n",
      "Reset environment\n",
      "Episode reward: -499.0708\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0204521 -1.0165433 -1.0555909 -1.04872   -1.0051671 -1.0651021]\n",
      "Reset environment\n",
      "Episode reward: -541.074\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0194303 -1.0148104 -1.055199  -1.0458177 -1.0052133 -1.0640633]\n",
      "Reset environment\n",
      "Episode reward: 1106.2283\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9983931  -0.9942272  -1.0337424  -1.0212061  -0.98787856 -1.0429488 ]\n",
      "Reset environment\n",
      "Episode reward: -8631.034\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0748912 -1.0661507 -1.1127517 -1.1229804 -1.0453854 -1.1177378]\n",
      "Reset environment\n",
      "Episode reward: -1.2194824\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0686992 -1.0604764 -1.1059245 -1.1143217 -1.0409914 -1.111397 ]\n",
      "Reset environment\n",
      "Episode reward: 192.27618\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0589331 -1.0506825 -1.096123  -1.1016997 -1.0336374 -1.1015902]\n",
      "Reset environment\n",
      "Episode reward: -336.71796\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0554188 -1.047038  -1.0925741 -1.0952663 -1.0320213 -1.0979445]\n",
      "Reset environment\n",
      "Episode reward: -493.63504\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0546175 -1.0453691 -1.0924932 -1.0932584 -1.0319911 -1.0971067]\n",
      "Reset environment\n",
      "Episode reward: -435.9874\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0523884 -1.0429078 -1.0904361 -1.0882119 -1.0315726 -1.094843 ]\n",
      "Reset environment\n",
      "Episode reward: 1273.8318\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0301855 -1.0212681 -1.0676869 -1.0624385 -1.0131803 -1.0726144]\n",
      "Reset environment\n",
      "Episode reward: -354.9457\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0268239 -1.017207  -1.0648712 -1.0575136 -1.0109773 -1.0692637]\n",
      "Reset environment\n",
      "Episode reward: -232.80972\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0224524 -1.0128111 -1.06047   -1.0503199 -1.0085694 -1.0648391]\n",
      "Reset environment\n",
      "Episode reward: -18645.54\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1788082 -1.1606119 -1.2238541 -1.2343832 -1.1354264 -1.2193935]\n",
      "Reset environment\n",
      "Episode reward: 943.6266\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1605383 -1.1422753 -1.2055656 -1.2130194 -1.1203047 -1.2010823]\n",
      "Reset environment\n",
      "Episode reward: 812.96924\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1433223 -1.1249967 -1.18841   -1.1923894 -1.1063939 -1.183866 ]\n",
      "Reset environment\n",
      "Episode reward: 1020.611\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1268306 -1.1091608 -1.1712165 -1.1740098 -1.0922189 -1.1673013]\n",
      "Reset environment\n",
      "Episode reward: -275.47806\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1226726 -1.1053752 -1.1667196 -1.1677821 -1.0895798 -1.1631559]\n",
      "Reset environment\n",
      "Episode reward: 1221.5944\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1017029 -1.0843145 -1.145835  -1.1439332 -1.0718822 -1.1421996]\n",
      "Reset environment\n",
      "Episode reward: -6157.3306\n",
      "Total Steps: 1539\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1674803 -1.1507257 -1.2097842 -1.2323977 -1.1230516 -1.2065387]\n",
      "Reset environment\n",
      "Episode reward: 277.82886\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1576158 -1.1408165 -1.1999658 -1.2199565 -1.1154151 -1.1966691]\n",
      "Reset environment\n",
      "Episode reward: 740.2959\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1443908 -1.1283635 -1.1860931 -1.2047482 -1.104392  -1.1834944]\n",
      "Reset environment\n",
      "Episode reward: 414.0902\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1326576 -1.1166692 -1.1743529 -1.1903639 -1.0951308 -1.1717942]\n",
      "Reset environment\n",
      "Episode reward: 238.77673\n",
      "Total Steps: 17\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1319662 -1.1159835 -1.1736555 -1.189337  -1.0946382 -1.171085 ]\n",
      "Reset environment\n",
      "Episode reward: -553.8062\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1315844 -1.1162416 -1.1726359 -1.1882279 -1.0948195 -1.1706996]\n",
      "Reset environment\n",
      "Episode reward: -776.574\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1330327 -1.1168479 -1.1746955 -1.1902561 -1.0956808 -1.1720707]\n",
      "Reset environment\n",
      "Episode reward: -324.61816\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1297535 -1.1140429 -1.1708606 -1.185469  -1.0934638 -1.1687526]\n",
      "Reset environment\n",
      "Episode reward: 208.71634\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1205693 -1.105186  -1.1613119 -1.1738139 -1.0864713 -1.1595472]\n",
      "Reset environment\n",
      "Episode reward: -2414.294\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1377959 -1.1229749 -1.1778057 -1.1926898 -1.1016953 -1.1766284]\n",
      "Reset environment\n",
      "Episode reward: 665.2688\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1228749 -1.1080952 -1.1628215 -1.1748888 -1.0895491 -1.1616933]\n",
      "Reset environment\n",
      "Episode reward: 228.71094\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1138619 -1.0988944 -1.1539687 -1.1636441 -1.0824981 -1.1526897]\n",
      "Reset environment\n",
      "Episode reward: -161.51523\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1103212 -1.0960966 -1.1496989 -1.1591618 -1.079528  -1.1491385]\n",
      "Reset environment\n",
      "Episode reward: -6219.0015\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1574789 -1.1406382 -1.1986035 -1.2319293 -1.1057633 -1.19553  ]\n",
      "Reset environment\n",
      "Episode reward: -13.046722\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1509305 -1.1339031 -1.1921167 -1.2228446 -1.1011823 -1.1889288]\n",
      "Reset environment\n",
      "Episode reward: 891.9298\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.134467  -1.1176502 -1.1754283 -1.203059  -1.0879613 -1.1724077]\n",
      "Reset environment\n",
      "Episode reward: -12431.909\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2436697 -1.2167423 -1.2925557 -1.3353232 -1.1738623 -1.2805637]\n",
      "Reset environment\n",
      "Episode reward: 931.6964\n",
      "Total Steps: 249\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2265202 -1.1988502 -1.2758052 -1.3151445 -1.1600003 -1.2631023]\n",
      "Reset environment\n",
      "Episode reward: -104.11099\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2208471 -1.1930085 -1.2702552 -1.3069447 -1.1562521 -1.2573161]\n",
      "Reset environment\n",
      "Episode reward: -506.75854\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2198874 -1.1926651 -1.2687181 -1.3053048 -1.1557796 -1.2563616]\n",
      "Reset environment\n",
      "Episode reward: -782.23047\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2220852 -1.1939237 -1.271614  -1.3083912 -1.1572295 -1.2584252]\n",
      "Reset environment\n",
      "Episode reward: -155.95242\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2173249 -1.1887597 -1.2672051 -1.3016388 -1.1540015 -1.2535838]\n",
      "Reset environment\n",
      "Episode reward: -236.74487\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.213459  -1.1852014 -1.2630621 -1.2954502 -1.1516641 -1.2496314]\n",
      "Reset environment\n",
      "Episode reward: -505.81412\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2122952 -1.1844953 -1.2614529 -1.2931147 -1.1511849 -1.2484637]\n",
      "Reset environment\n",
      "Episode reward: -20611.826\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3852966 -1.3543566 -1.433687  -1.5020065 -1.2918478 -1.4192194]\n",
      "Reset environment\n",
      "Episode reward: -832.45374\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.387939  -1.3576432 -1.4357355 -1.504388  -1.2945848 -1.4218898]\n",
      "Reset environment\n",
      "Episode reward: 737.56775\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3733479 -1.3434123 -1.4207195 -1.4867272 -1.2828802 -1.407252 ]\n",
      "Reset environment\n",
      "Episode reward: -87.87314\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3679043 -1.3376433 -1.4155834 -1.479168  -1.2790867 -1.4017869]\n",
      "Reset environment\n",
      "Episode reward: 410.449\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3573712 -1.3275096 -1.4047239 -1.4666623 -1.2705696 -1.391261 ]\n",
      "Reset environment\n",
      "Episode reward: 885.64667\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3407975 -1.3113565 -1.3877329 -1.4468033 -1.2572298 -1.374631 ]\n",
      "Reset environment\n",
      "Episode reward: 1107.231\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3227886 -1.2931031 -1.3700427 -1.4266242 -1.2419083 -1.3566082]\n",
      "Reset environment\n",
      "Episode reward: 1660.6431\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2989599 -1.2694007 -1.3461179 -1.3997782 -1.2215984 -1.3327757]\n",
      "Reset environment\n",
      "Episode reward: -9104.33\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3495303 -1.3234607 -1.3924977 -1.4851209 -1.2505845 -1.3813553]\n",
      "Reset environment\n",
      "Episode reward: -3995.7214\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4002656 -1.3805205 -1.436073  -1.5343899 -1.2984487 -1.4310169]\n",
      "Reset environment\n",
      "Episode reward: 1416.686\n",
      "Total Steps: 235\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.376235  -1.3584796 -1.4102049 -1.5069765 -1.2788439 -1.4068894]\n",
      "Reset environment\n",
      "Episode reward: -224.30292\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.372079  -1.3547392 -1.4056374 -1.5011735 -1.2759746 -1.4027001]\n",
      "Reset environment\n",
      "Episode reward: -7490.595\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.423847  -1.3997799 -1.4624819 -1.5913507 -1.2999542 -1.4530901]\n",
      "Reset environment\n",
      "Episode reward: -420.60184\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4217924 -1.3977265 -1.4602805 -1.586583  -1.2995614 -1.4509445]\n",
      "Reset environment\n",
      "Episode reward: -345.98535\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4189066 -1.3951273 -1.4570438 -1.5817679 -1.2979264 -1.447959 ]\n",
      "Reset environment\n",
      "Episode reward: 485.35938\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4082474 -1.3842556 -1.4465855 -1.5692968 -1.2891058 -1.4372389]\n",
      "Reset environment\n",
      "Episode reward: 2670.3015\n",
      "Total Steps: 224\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3729275 -1.3498546 -1.4104624 -1.529212  -1.259372  -1.4018236]\n",
      "Reset environment\n",
      "Episode reward: -5407.8022\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3939809 -1.3585612 -1.4426371 -1.575085  -1.2616154 -1.4219244]\n",
      "Reset environment\n",
      "Episode reward: -424.52875\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3919332 -1.3559484 -1.4410962 -1.5716857 -1.2605208 -1.4198256]\n",
      "Reset environment\n",
      "Episode reward: 67.10925\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3853364 -1.349081  -1.4347188 -1.5632409 -1.2555163 -1.413187 ]\n",
      "Reset environment\n",
      "Episode reward: -20.431152\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3795873 -1.3431956 -1.4290217 -1.555155  -1.2515951 -1.4073607]\n",
      "Reset environment\n",
      "Episode reward: -299.29178\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3770485 -1.3417362 -1.4254751 -1.5515878 -1.2501034 -1.4048764]\n",
      "Reset environment\n",
      "Episode reward: -12556.582\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4621718 -1.4367677 -1.5007888 -1.6639795 -1.3160762 -1.4897267]\n",
      "Reset environment\n",
      "Episode reward: -510.52374\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4611083 -1.4361315 -1.499289  -1.6619182 -1.3156753 -1.4886798]\n",
      "Reset environment\n",
      "Episode reward: -299.9183\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.458524  -1.4329625 -1.4973723 -1.6586045 -1.3138134 -1.4860771]\n",
      "Reset environment\n",
      "Episode reward: 19.85498\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4523356 -1.4266243 -1.4913497 -1.6503043 -1.3093739 -1.4798661]\n",
      "Reset environment\n",
      "Episode reward: 754.36804\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4395902 -1.4143168 -1.4781623 -1.6348671 -1.2992162 -1.4670644]\n",
      "Reset environment\n",
      "Episode reward: 376.17706\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4306405 -1.4050324 -1.4696001 -1.6245246 -1.291813  -1.4580812]\n",
      "Reset environment\n",
      "Episode reward: -12362.498\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5053691 -1.4875773 -1.536261  -1.7270409 -1.3482431 -1.5330694]\n",
      "Reset environment\n",
      "Episode reward: -26.818756\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4995761 -1.48191   -1.530267  -1.7188524 -1.3442392 -1.5272137]\n",
      "Reset environment\n",
      "Episode reward: -12003.586\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5902784 -1.5782119 -1.6163126 -1.842356  -1.412584  -1.6176196]\n",
      "Reset environment\n",
      "Episode reward: 366.68173\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5813292 -1.5697567 -1.6068219 -1.8313296 -1.405553  -1.6086454]\n",
      "Reset environment\n",
      "Episode reward: -579.5465\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5808336 -1.5697867 -1.6058859 -1.8303854 -1.4054463 -1.6082104]\n",
      "Reset environment\n",
      "Episode reward: 262.40915\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5731577 -1.5623214 -1.5979499 -1.8207958 -1.3994768 -1.600512 ]\n",
      "Reset environment\n",
      "Episode reward: 4512.5474\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5325676 -1.5218514 -1.5574145 -1.77583   -1.3643098 -1.5598886]\n",
      "Reset environment\n",
      "Episode reward: -410.8883\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5303205 -1.5195792 -1.5551238 -1.7710178 -1.3636974 -1.5575593]\n",
      "Reset environment\n",
      "Episode reward: 677.0478\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5180191 -1.5079513 -1.5421215 -1.7567819 -1.3535081 -1.5451896]\n",
      "Reset environment\n",
      "Episode reward: -12735.258\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6301184 -1.6173373 -1.6566942 -1.8860443 -1.449744  -1.6567513]\n",
      "Reset environment\n",
      "Episode reward: 2326.8232\n",
      "Total Steps: 259\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6032091 -1.5927497 -1.6273563 -1.8563256 -1.4268924 -1.6296517]\n",
      "Reset environment\n",
      "Episode reward: 833.04803\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5966773 -1.5862513 -1.6207674 -1.8478851 -1.4219114 -1.6230487]\n",
      "Reset environment\n",
      "Episode reward: 310.2923\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5954617 -1.5850728 -1.6195447 -1.8461685 -1.4210451 -1.6218047]\n",
      "Reset environment\n",
      "Episode reward: 78.24481\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5892267 -1.5787492 -1.6133822 -1.8377486 -1.4166089 -1.6155479]\n",
      "Reset environment\n",
      "Episode reward: -54.55606\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5833123 -1.5728616 -1.6073853 -1.8297293 -1.4121901 -1.6095616]\n",
      "Reset environment\n",
      "Episode reward: -11037.553\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6501975 -1.643637  -1.6708913 -1.923662  -1.4595462 -1.6767853]\n",
      "Reset environment\n",
      "Episode reward: 761.6294\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6383654 -1.6318206 -1.6590738 -1.9100119 -1.4496981 -1.6649411]\n",
      "Reset environment\n",
      "Episode reward: -224.8446\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6361034 -1.6306143 -1.6557932 -1.907061  -1.4482505 -1.6626637]\n",
      "Reset environment\n",
      "Episode reward: -261.17148\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6324887 -1.62717   -1.6520133 -1.9013767 -1.4460529 -1.6590055]\n",
      "Reset environment\n",
      "Episode reward: -65.43161\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.632651  -1.6263285 -1.6531664 -1.9004995 -1.4469082 -1.6590875]\n",
      "Reset environment\n",
      "Episode reward: -191.25235\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6288269 -1.6223944 -1.6493084 -1.8942555 -1.4447365 -1.6551577]\n",
      "Reset environment\n",
      "Episode reward: -17083.734\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7593111 -1.7566653 -1.7764529 -2.0759294 -1.5401763 -1.7856125]\n",
      "Reset environment\n",
      "Episode reward: -415.80908\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7569857 -1.7542113 -1.7741851 -2.0710955 -1.5394905 -1.7832228]\n",
      "Reset environment\n",
      "Episode reward: -15296.179\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8470138 -1.8491672 -1.8597482 -2.194081  -1.606717  -1.8733791]\n",
      "Reset environment\n",
      "Episode reward: 3026.2178\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8142618 -1.815795  -1.8278503 -2.158709  -1.5778505 -1.8405738]\n",
      "Reset environment\n",
      "Episode reward: 4166.344\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7789227 -1.7806431 -1.792183  -2.118569  -1.547853  -1.8049896]\n",
      "Reset environment\n",
      "Episode reward: 1912.4486\n",
      "Total Steps: 269\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.757061  -1.7610208 -1.7680467 -2.0938094 -1.529717  -1.782963 ]\n",
      "Reset environment\n",
      "Episode reward: 282.18204\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7496976 -1.7532753 -1.7610554 -2.0850403 -1.5238223 -1.7755569]\n",
      "Reset environment\n",
      "Episode reward: -162.89029\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7456386 -1.7489761 -1.757185  -2.0792418 -1.5211635 -1.7714671]\n",
      "Reset environment\n",
      "Episode reward: 582.5449\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7357651 -1.7392275 -1.7471733 -2.0675898 -1.5130655 -1.7615634]\n",
      "Reset environment\n",
      "Episode reward: -6826.8237\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7547538 -1.7562401 -1.7683265 -2.1168041 -1.5150157 -1.7802614]\n",
      "Reset environment\n",
      "Episode reward: -266.5819\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7514204 -1.7528139 -1.7650517 -2.1111531 -1.5133553 -1.7768861]\n",
      "Reset environment\n",
      "Episode reward: -17207.11\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8612264 -1.8613026 -1.8750485 -2.257017  -1.5984185 -1.8863014]\n",
      "Reset environment\n",
      "Episode reward: -3.7008057\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.855932  -1.8563675 -1.8694193 -2.2505443 -1.5942292 -1.8810141]\n",
      "Reset environment\n",
      "Episode reward: 568.4955\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8464205 -1.8469228 -1.859857  -2.239089  -1.5865437 -1.8714556]\n",
      "Reset environment\n",
      "Episode reward: 127.867584\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8402973 -1.8410885 -1.8534342 -2.2316089 -1.5817034 -1.8653244]\n",
      "Reset environment\n",
      "Episode reward: -301.3963\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8373195 -1.8380182 -1.8504909 -2.2262354 -1.5802792 -1.8622686]\n",
      "Reset environment\n",
      "Episode reward: 482.05832\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8287706 -1.8293892 -1.8420522 -2.216222  -1.5732247 -1.8536777]\n",
      "Reset environment\n",
      "Episode reward: -9868.88\n",
      "Total Steps: 1071\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8993986 -1.8962257 -1.9160004 -2.2879603 -1.6399516 -1.9238399]\n",
      "Reset environment\n",
      "Episode reward: 345.06833\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8919411 -1.8882804 -1.9090958 -2.2795491 -1.6336185 -1.9163731]\n",
      "Reset environment\n",
      "Episode reward: -2.512024\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8867829 -1.883182  -1.903867  -2.2722614 -1.6300964 -1.9111737]\n",
      "Reset environment\n",
      "Episode reward: -238.29865\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.88338   -1.8802646 -1.8999606 -2.2685332 -1.627025  -1.9077872]\n",
      "Reset environment\n",
      "Episode reward: -275.44955\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8801665 -1.877248  -1.8965365 -2.2635634 -1.6250123 -1.9045563]\n",
      "Reset environment\n",
      "Episode reward: 3436.1729\n",
      "Total Steps: 250\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.840961  -1.8375832 -1.8580102 -2.2206933 -1.5908605 -1.8653305]\n",
      "Reset environment\n",
      "Episode reward: -41.160797\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8356328 -1.8333821 -1.851447  -2.2146542 -1.586166  -1.8599381]\n",
      "Reset environment\n",
      "Episode reward: -11214.605\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8795193 -1.8820415 -1.8901863 -2.2888293 -1.6101612 -1.9038928]\n",
      "Reset environment\n",
      "Episode reward: -60.509735\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8752259 -1.8773609 -1.8862829 -2.2837412 -1.6066594 -1.899578 ]\n",
      "Reset environment\n",
      "Episode reward: -233.59601\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8721513 -1.8745972 -1.8829166 -2.2792501 -1.604629  -1.8964655]\n",
      "Reset environment\n",
      "Episode reward: -16289.355\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9642098 -1.9621134 -1.9793974 -2.406427  -1.6719913 -1.9882294]\n",
      "Reset environment\n",
      "Episode reward: 644.8898\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9547275 -1.9526438 -1.9699482 -2.3952212 -1.6642138 -1.9787287]\n",
      "Reset environment\n",
      "Episode reward: 291.75616\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9475243 -1.9456246 -1.9624863 -2.386488  -1.658431  -1.9714977]\n",
      "Reset environment\n",
      "Episode reward: -55.63919\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9422711 -1.941046  -1.9565581 -2.3800976 -1.6540456 -1.9662535]\n",
      "Reset environment\n",
      "Episode reward: -96.41495\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9380364 -1.9365541 -1.9526044 -2.374479  -1.6509639 -1.9619691]\n",
      "Reset environment\n",
      "Episode reward: 169.1037\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9317906 -1.9300236 -1.9466218 -2.3670862 -1.6459048 -1.9556768]\n",
      "Reset environment\n",
      "Episode reward: 54.235535\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9259287 -1.9247475 -1.9401842 -2.3597217 -1.6413956 -1.9498056]\n",
      "Reset environment\n",
      "Episode reward: -9186.533\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9586614 -1.958149  -1.9726025 -2.417902  -1.6580992 -1.9821277]\n",
      "Reset environment\n",
      "Episode reward: -667.44214\n",
      "Total Steps: 214\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9556003 -1.9562775 -1.968195  -2.4142156 -1.6553173 -1.9789908]\n",
      "Reset environment\n",
      "Episode reward: 746.5928\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9452997 -1.9460716 -1.9577975 -2.4023323 -1.6466864 -1.9686803]\n",
      "Reset environment\n",
      "Episode reward: 738.094\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.934849  -1.9357862 -1.9471824 -2.3898063 -1.638192  -1.958156 ]\n",
      "Reset environment\n",
      "Episode reward: 164.5672\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9290813 -1.9297837 -1.9416708 -2.3828394 -1.6336124 -1.9523687]\n",
      "Reset environment\n",
      "Episode reward: -729.24084\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9296296 -1.9307308 -1.9417692 -2.3833177 -1.6341252 -1.952915 ]\n",
      "Reset environment\n",
      "Episode reward: -239.26483\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9263352 -1.9271595 -1.9387739 -2.378733  -1.6319212 -1.9496043]\n",
      "Reset environment\n",
      "Episode reward: -172.5734\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9225467 -1.923299  -1.9350072 -2.3727882 -1.629715  -1.9457802]\n",
      "Reset environment\n",
      "Episode reward: 2011.6146\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9079537 -1.9088806 -1.9203143 -2.3555474 -1.6177351 -1.9311733]\n",
      "Reset environment\n",
      "Episode reward: 69.78793\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9027921 -1.9034154 -1.915437  -2.34927   -1.6136012 -1.9260111]\n",
      "Reset environment\n",
      "Episode reward: 1442.3683\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8874142 -1.8881711 -1.8999106 -2.3321116 -1.600352  -1.9105846]\n",
      "Reset environment\n",
      "Episode reward: -16026.982\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9755057 -1.9830263 -1.9815582 -2.448638  -1.6663672 -1.9987857]\n",
      "Reset environment\n",
      "Episode reward: 170.34885\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9693907 -1.9768336 -1.9754999 -2.4406388 -1.6618358 -1.9926478]\n",
      "Reset environment\n",
      "Episode reward: 390.14224\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9619919 -1.9693694 -1.9681586 -2.4316447 -1.6558251 -1.9852318]\n",
      "Reset environment\n",
      "Episode reward: 187.44446\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9560566 -1.9633664 -1.9622748 -2.4237916 -1.6514978 -1.9792786]\n",
      "Reset environment\n",
      "Episode reward: 657.5609\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9467484 -1.9538842 -1.9531084 -2.4131293 -1.6436805 -1.9699467]\n",
      "Reset environment\n",
      "Episode reward: -279.7014\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9437582 -1.9507182 -1.9502431 -2.4081852 -1.6420877 -1.9669216]\n",
      "Reset environment\n",
      "Episode reward: -1026.5133\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9483358 -1.9547111 -1.9553955 -2.4126987 -1.64632   -1.9714792]\n",
      "Reset environment\n",
      "Episode reward: -12693.783\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-2.0060678 -2.0131528 -2.0130424 -2.5050235 -1.682186  -2.0288863]\n",
      "Reset environment\n",
      "Episode reward: -525.7573\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-2.0047488 -2.011109  -2.0124085 -2.5034313 -1.6810837 -2.0275316]\n",
      "Reset environment\n",
      "Episode reward: -9507.105\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-2.047264  -2.0589957 -2.0507355 -2.5831065 -1.7020358 -2.0700028]\n",
      "Reset environment\n",
      "Episode reward: 3739.9233\n",
      "Total Steps: 216\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-2.0138407 -2.0265536 -2.0165186 -2.546331  -1.6730353 -2.0365736]\n",
      "Reset environment\n",
      "Episode reward: 506.8334\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-2.0050936 -2.017929  -2.007574  -2.535058  -1.6663625 -2.02777  ]\n",
      "Reset environment\n",
      "Episode reward: 445.02316\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-2.0029638 -2.0157766 -2.0054617 -2.5322726 -1.6647294 -2.0256364]\n",
      "Reset environment\n",
      "Episode reward: 780.3843\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9924889 -2.0050073 -1.9952984 -2.5200577 -1.6560221 -2.0151277]\n",
      "Reset environment\n",
      "Episode reward: 453.59314\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9847286 -1.9971812 -1.9875563 -2.510541  -1.6498427 -2.0073538]\n",
      "Reset environment\n",
      "Episode reward: 995.713\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9725388 -1.9847198 -1.9756918 -2.4964783 -1.6396312 -1.9951484]\n",
      "Reset environment\n",
      "Episode reward: 377.79028\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9653621 -1.977399  -1.9686594 -2.487633  -1.633948  -1.9879379]\n",
      "Reset environment\n",
      "Episode reward: 1911.1931\n",
      "Total Steps: 233\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9469355 -1.9609065 -1.9484755 -2.4671116 -1.6183906 -1.9694993]\n",
      "Reset environment\n",
      "Episode reward: 158.65533\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9410654 -1.9548972 -1.9426893 -2.4594398 -1.6139797 -1.9635826]\n",
      "Reset environment\n",
      "Episode reward: 1225.0907\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9280723 -1.9415667 -1.9300067 -2.4445019 -1.6029975 -1.9505163]\n",
      "Reset environment\n",
      "Episode reward: 18.983185\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9227729 -1.9361216 -1.9249072 -2.437892  -1.5988052 -1.9452262]\n",
      "Reset environment\n",
      "Episode reward: 394.57697\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9206654 -1.9339664 -1.9228386 -2.4344933 -1.5976424 -1.9431096]\n",
      "Reset environment\n",
      "Episode reward: 552.7761\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9124391 -1.9255279 -1.9148499 -2.4251602 -1.5906659 -1.9348929]\n",
      "Reset environment\n",
      "Episode reward: -235.57187\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9094222 -1.9226307 -1.9117374 -2.4203362 -1.5888959 -1.931874 ]\n",
      "Reset environment\n",
      "Episode reward: -54.99066\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9053284 -1.9184073 -1.9077686 -2.4145393 -1.5861508 -1.9277633]\n",
      "Reset environment\n",
      "Episode reward: 735.84265\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8943341 -1.9068029 -1.8973745 -2.4011765 -1.5773196 -1.916703 ]\n",
      "Reset environment\n",
      "Episode reward: 2039.9368\n",
      "Total Steps: 235\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8730907 -1.887168  -1.8746401 -2.377006  -1.5594074 -1.8954065]\n",
      "Reset environment\n",
      "Episode reward: 251.26645\n",
      "Total Steps: 17\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8725783 -1.8866495 -1.874136  -2.3762076 -1.5590768 -1.8948925]\n",
      "Reset environment\n",
      "Episode reward: -1033.1997\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8747646 -1.8894244 -1.8757396 -2.3782108 -1.56123   -1.8970752]\n",
      "Reset environment\n",
      "Episode reward: 3523.8005\n",
      "Total Steps: 252\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8494971 -1.8639079 -1.8509232 -2.350066  -1.5394626 -1.8717537]\n",
      "Reset environment\n",
      "Episode reward: 44.157684\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8446528 -1.8589145 -1.8462389 -2.3436007 -1.5359678 -1.866901 ]\n",
      "Reset environment\n",
      "Episode reward: 978.3732\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8328785 -1.8471885 -1.8344544 -2.3295023 -1.5264007 -1.8551295]\n",
      "Reset environment\n",
      "Episode reward: -227.452\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8298464 -1.8445029 -1.8310927 -2.3255737 -1.5241467 -1.8521023]\n",
      "Reset environment\n",
      "Episode reward: -274.3586\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8271399 -1.8414671 -1.8287383 -2.3222692 -1.5219126 -1.8493619]\n",
      "Reset environment\n",
      "Episode reward: -172.65756\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8240262 -1.838758  -1.8251771 -2.318427  -1.5192865 -1.8462597]\n",
      "Reset environment\n",
      "Episode reward: -103.072845\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8209927 -1.8362622 -1.821582  -2.3148165 -1.5168225 -1.8431828]\n",
      "Reset environment\n",
      "Episode reward: 1748.793\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8037736 -1.8200998 -1.8033733 -2.2953176 -1.5022717 -1.8259243]\n",
      "Reset environment\n",
      "Episode reward: -519.4227\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8026658 -1.8192116 -1.8019813 -2.2934563 -1.5016268 -1.8247799]\n",
      "Reset environment\n",
      "Episode reward: -392.39676\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8009864 -1.8169521 -1.8008286 -2.2922192 -1.4997455 -1.8230764]\n",
      "Reset environment\n",
      "Episode reward: 389.77945\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.793583  -1.8097899 -1.7931699 -2.282652  -1.4941211 -1.8156512]\n",
      "Reset environment\n",
      "Episode reward: 347.633\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7863582 -1.8022926 -1.78625   -2.2740514 -1.4881521 -1.8084046]\n",
      "Reset environment\n",
      "Episode reward: 4576.755\n",
      "Total Steps: 262\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7474762 -1.7643402 -1.7466227 -2.230724  -1.4546667 -1.7694644]\n",
      "Reset environment\n",
      "Episode reward: -9.900665\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7430977 -1.7598574 -1.7422863 -2.2245438 -1.4516398 -1.7650518]\n",
      "Reset environment\n",
      "Episode reward: -11957.766\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7881233 -1.8009261 -1.791335  -2.2937222 -1.4825282 -1.8098656]\n",
      "Reset environment\n",
      "Episode reward: 63.580017\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7830807 -1.7962593 -1.7859204 -2.2876868 -1.4783236 -1.8047931]\n",
      "Reset environment\n",
      "Episode reward: -290.59772\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7804798 -1.7932912 -1.7836703 -2.2844632 -1.4762775 -1.8021668]\n",
      "Reset environment\n",
      "Episode reward: 584.0968\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7722213 -1.7845393 -1.7759241 -2.2748485 -1.4694135 -1.7938861]\n",
      "Reset environment\n",
      "Episode reward: -72.37186\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7682498 -1.7805015 -1.7719586 -2.2688575 -1.4669229 -1.7898778]\n",
      "Reset environment\n",
      "Episode reward: -10177.316\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8114004 -1.8269757 -1.8115433 -2.3255491 -1.5001925 -1.8330112]\n",
      "Reset environment\n",
      "Episode reward: 1062.9086\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8000299 -1.8151237 -1.8006469 -2.3127992 -1.4904044 -1.8216046]\n",
      "Reset environment\n",
      "Episode reward: -10209.295\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8465447 -1.8589351 -1.8501462 -2.3813999 -1.5228931 -1.8681377]\n",
      "Reset environment\n",
      "Episode reward: -88.64725\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8422363 -1.8545301 -1.8458852 -2.3753827 -1.5198352 -1.8638004]\n",
      "Reset environment\n",
      "Episode reward: 975.57983\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8312607 -1.8431873 -1.8353399 -2.3631737 -1.510328  -1.852831 ]\n",
      "Reset environment\n",
      "Episode reward: 51.384216\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8266941 -1.8390869 -1.8302798 -2.3577545 -1.5065647 -1.8482243]\n",
      "Reset environment\n",
      "Episode reward: -6150.6143\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8341322 -1.8408865 -1.8433146 -2.377865  -1.5071609 -1.8552524]\n",
      "Reset environment\n",
      "Episode reward: 312.2516\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8279601 -1.8346577 -1.8371944 -2.3699837 -1.5024725 -1.8490647]\n",
      "Reset environment\n",
      "Episode reward: -11.136749\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8237777 -1.8305354 -1.8329278 -2.363949  -1.4996753 -1.8448567]\n",
      "Reset environment\n",
      "Episode reward: 769.8374\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8152409 -1.8218951 -1.8244478 -2.3539267 -1.4925294 -1.8362843]\n",
      "Reset environment\n",
      "Episode reward: 585.3353\n",
      "Total Steps: 227\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8146704 -1.8223267 -1.8226883 -2.3529384 -1.4920949 -1.8355943]\n",
      "Reset environment\n",
      "Episode reward: -1673.6774\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8240254 -1.8297318 -1.8338135 -2.3612106 -1.5015441 -1.8448433]\n",
      "Reset environment\n",
      "Episode reward: 162.52463\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8187643 -1.8244959 -1.8285092 -2.3541636 -1.4977055 -1.8395617]\n",
      "Reset environment\n",
      "Episode reward: 1115.9331\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8075395 -1.8129476 -1.8176421 -2.3416164 -1.4880477 -1.8283162]\n",
      "Reset environment\n",
      "Episode reward: 68.68176\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.8027742 -1.8081865 -1.8128359 -2.3349388 -1.4847581 -1.8235208]\n",
      "Reset environment\n",
      "Episode reward: 725.20667\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.794275  -1.7996972 -1.8043045 -2.324994  -1.4777124 -1.8150012]\n",
      "Reset environment\n",
      "Episode reward: 131.82788\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.789125  -1.7949954 -1.7987202 -2.3190753 -1.4733452 -1.8098528]\n",
      "Reset environment\n",
      "Episode reward: 205.59998\n",
      "Total Steps: 4\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7890414 -1.7949067 -1.7986416 -2.3189282 -1.4733003 -1.8097665]\n",
      "Reset environment\n",
      "Episode reward: 1977.7552\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7776092 -1.78342   -1.7872952 -2.3057551 -1.46366   -1.7983298]\n",
      "Reset environment\n",
      "Episode reward: 3.8459473\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7733295 -1.7791009 -1.7830491 -2.2996259 -1.4608002 -1.794015 ]\n",
      "Reset environment\n",
      "Episode reward: 462.44608\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7702559 -1.7744814 -1.7814264 -2.2953076 -1.4586476 -1.7909124]\n",
      "Reset environment\n",
      "Episode reward: 292.40952\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7641858 -1.7684878 -1.7753023 -2.2875834 -1.4540353 -1.7848322]\n",
      "Reset environment\n",
      "Episode reward: 537.7611\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7617186 -1.7660121 -1.7728369 -2.2842414 -1.4522667 -1.7823502]\n",
      "Reset environment\n",
      "Episode reward: 202.88113\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7564553 -1.7606764 -1.7676607 -2.2773578 -1.4483578 -1.7770761]\n",
      "Reset environment\n",
      "Episode reward: 647.2341\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7484381 -1.7525454 -1.7597227 -2.267826  -1.4417696 -1.7690291]\n",
      "Reset environment\n",
      "Episode reward: 364.49094\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.742569  -1.7463741 -1.7541702 -2.2612133 -1.4366525 -1.763139 ]\n",
      "Reset environment\n",
      "Episode reward: 888.0938\n",
      "Total Steps: 216\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.73294   -1.7357262 -1.7455606 -2.2495692 -1.4287918 -1.7534641]\n",
      "Reset environment\n",
      "Episode reward: -324.03662\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7305883 -1.7335643 -1.7429993 -2.246187  -1.4271684 -1.7510917]\n",
      "Reset environment\n",
      "Episode reward: -408.91858\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7288959 -1.7316418 -1.7415364 -2.2430813 -1.4264399 -1.7493762]\n",
      "Reset environment\n",
      "Episode reward: 94.00934\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.723996  -1.7270974 -1.7362483 -2.2367117 -1.4227464 -1.744445 ]\n",
      "Reset environment\n",
      "Episode reward: 374.8417\n",
      "Total Steps: 26\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7227151 -1.7258081 -1.7349609 -2.234954  -1.4217905 -1.7431544]\n",
      "Reset environment\n",
      "Episode reward: 280.85513\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.7162329 -1.719249  -1.7285175 -2.2261553 -1.4171486 -1.73661  ]\n",
      "Reset environment\n",
      "Episode reward: 4933.2236\n",
      "Total Steps: 258\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6841509 -1.6869833 -1.6966329 -2.1890087 -1.3903788 -1.7044257]\n",
      "Reset environment\n",
      "Episode reward: 1720.9333\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6699026 -1.6717669 -1.6833832 -2.172509  -1.3783253 -1.6901892]\n",
      "Reset environment\n",
      "Episode reward: 222.03143\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6646874 -1.666392  -1.6783502 -2.166113  -1.3741863 -1.6849576]\n",
      "Reset environment\n",
      "Episode reward: -460.84998\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6632755 -1.6648935 -1.6770369 -2.1629033 -1.3739941 -1.6835344]\n",
      "Reset environment\n",
      "Episode reward: 97.689575\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6585643 -1.6602081 -1.6723183 -2.1563113 -1.370755  -1.6788154]\n",
      "Reset environment\n",
      "Episode reward: -74.87894\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6549585 -1.6566446 -1.6686538 -2.1510193 -1.3684056 -1.6751856]\n",
      "Reset environment\n",
      "Episode reward: -9712.982\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6877629 -1.6888728 -1.7017342 -2.1967547 -1.3912517 -1.7079512]\n",
      "Reset environment\n",
      "Episode reward: 423.15775\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6812534 -1.6823797 -1.6951915 -2.1885922 -1.3862104 -1.7014071]\n",
      "Reset environment\n",
      "Episode reward: 472.70395\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6741043 -1.6755626 -1.6877278 -2.1799996 -1.380428  -1.69423  ]\n",
      "Reset environment\n",
      "Episode reward: 1134.271\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.662883  -1.6640944 -1.6767803 -2.1675546 -1.37065   -1.6830107]\n",
      "Reset environment\n",
      "Episode reward: 3310.1448\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6417372 -1.6431366 -1.655535  -2.1437628 -1.3524919 -1.6618981]\n",
      "Reset environment\n",
      "Episode reward: -175.3847\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6388963 -1.6406025 -1.6523536 -2.1401746 -1.3501102 -1.6590483]\n",
      "Reset environment\n",
      "Episode reward: 520.721\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6313177 -1.6326382 -1.6451046 -2.1309059 -1.3440562 -1.6514239]\n",
      "Reset environment\n",
      "Episode reward: 1443.4794\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6185957 -1.6200427 -1.6322991 -2.1163974 -1.3332855 -1.6386981]\n",
      "Reset environment\n",
      "Episode reward: 4.3420105\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6146725 -1.6160933 -1.6283678 -2.11064   -1.3307196 -1.6347334]\n",
      "Reset environment\n",
      "Episode reward: 550.1589\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6076751 -1.6090183 -1.6214281 -2.1023145 -1.3250202 -1.627713 ]\n",
      "Reset environment\n",
      "Episode reward: 1016.6616\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5975871 -1.599511  -1.6108565 -2.091029  -1.3163874 -1.6176414]\n",
      "Reset environment\n",
      "Episode reward: 695.99927\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5891027 -1.5905838 -1.602828  -2.0813487 -1.3091769 -1.6091324]\n",
      "Reset environment\n",
      "Episode reward: -735.0248\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5894834 -1.5906885 -1.6034203 -2.0814028 -1.3097211 -1.6094825]\n",
      "Reset environment\n",
      "Episode reward: 400.03595\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5834385 -1.5849143 -1.5971483 -2.0743344 -1.3047526 -1.6034312]\n",
      "Reset environment\n",
      "Episode reward: -32.35211\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5785213 -1.5792434 -1.5929254 -2.0685616 -1.300682  -1.5984809]\n",
      "Reset environment\n",
      "Episode reward: 419.99396\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5720706 -1.572578  -1.5866767 -2.0611863 -1.2952105 -1.592002 ]\n",
      "Reset environment\n",
      "Episode reward: -22.16568\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5679744 -1.5687544 -1.5822939 -2.0559373 -1.2919041 -1.5878824]\n",
      "Reset environment\n",
      "Episode reward: 386.71124\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5619104 -1.5628302 -1.5760953 -2.0484092 -1.2870187 -1.5818012]\n",
      "Reset environment\n",
      "Episode reward: -505.50153\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5612682 -1.5618775 -1.5757549 -2.0469804 -1.2869097 -1.5811412]\n",
      "Reset environment\n",
      "Episode reward: 571.20276\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5547128 -1.556287  -1.568153  -2.03957   -1.2812587 -1.5744978]\n",
      "Reset environment\n",
      "Episode reward: 966.6072\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5448754 -1.5462837 -1.558548  -2.028204  -1.2729428 -1.5646293]\n",
      "Reset environment\n",
      "Episode reward: 7.585388\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5381991 -1.5378809 -1.5535465 -2.0213628 -1.2668407 -1.5579137]\n",
      "Reset environment\n",
      "Episode reward: 3151.21\n",
      "Total Steps: 226\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5128201 -1.511466  -1.529212  -1.9932345 -1.2446792 -1.5324538]\n",
      "Reset environment\n",
      "Episode reward: -16471.709\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5968628 -1.5954896 -1.6129957 -2.121325  -1.2979889 -1.6166704]\n",
      "Reset environment\n",
      "Episode reward: -8675.747\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6283448 -1.6257514 -1.6453912 -2.1837034 -1.31162   -1.6477175]\n",
      "Reset environment\n",
      "Episode reward: -368.61182\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6268488 -1.6245836 -1.6435691 -2.1815138 -1.3104804 -1.6462247]\n",
      "Reset environment\n",
      "Episode reward: 3290.986\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.6025345 -1.6001621 -1.6193863 -2.1533904 -1.2901074 -1.621874 ]\n",
      "Reset environment\n",
      "Episode reward: 2909.478\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5803293 -1.5778527 -1.5973493 -2.128371  -1.2710987 -1.5996289]\n",
      "Reset environment\n",
      "Episode reward: -503.2507\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5794039 -1.5775639 -1.595802  -2.127052  -1.2705312 -1.5986893]\n",
      "Reset environment\n",
      "Episode reward: 260.13614\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5742418 -1.5726947 -1.5904053 -2.1209168 -1.2663354 -1.5935271]\n",
      "Reset environment\n",
      "Episode reward: -419.45728\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5726342 -1.5708156 -1.5890331 -2.1184642 -1.2653023 -1.5918957]\n",
      "Reset environment\n",
      "Episode reward: 341.01373\n",
      "Total Steps: 26\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5716558 -1.5698295 -1.5880669 -2.1170685 -1.2646074 -1.5909209]\n",
      "Reset environment\n",
      "Episode reward: 1074.929\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5611744 -1.5595654 -1.5774252 -2.10479   -1.255924  -1.5804498]\n",
      "Reset environment\n",
      "Episode reward: 51.912903\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5572491 -1.5554245 -1.5737158 -2.099859  -1.2528826 -1.5765034]\n",
      "Reset environment\n",
      "Episode reward: -180.07501\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5545475 -1.5527353 -1.570958  -2.095378  -1.2514064 -1.5737646]\n",
      "Reset environment\n",
      "Episode reward: 589.4608\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5474714 -1.5455061 -1.5640495 -2.087199  -1.2454841 -1.56668  ]\n",
      "Reset environment\n",
      "Episode reward: 754.4797\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5394901 -1.5373468 -1.5562506 -2.0782673 -1.2385894 -1.5586925]\n",
      "Reset environment\n",
      "Episode reward: 4369.3696\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5103513 -1.5084363 -1.5269012 -2.0454543 -1.213687  -1.5294732]\n",
      "Reset environment\n",
      "Episode reward: 438.76767\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5040488 -1.5027101 -1.520087  -2.0384939 -1.2082561 -1.5231785]\n",
      "Reset environment\n",
      "Episode reward: -164.67651\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5013486 -1.4999878 -1.5173889 -2.0340116 -1.2068233 -1.5204567]\n",
      "Reset environment\n",
      "Episode reward: -1471.0698\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5067779 -1.50622   -1.5220696 -2.039514  -1.2119225 -1.5258957]\n",
      "Reset environment\n",
      "Episode reward: 814.17816\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4986212 -1.4982703 -1.5137287 -2.0303085 -1.2049253 -1.5177448]\n",
      "Reset environment\n",
      "Episode reward: 2121.2012\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4873408 -1.486984  -1.5024675 -2.017438  -1.1953566 -1.506446 ]\n",
      "Reset environment\n",
      "Episode reward: 1784.8733\n",
      "Total Steps: 249\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4728633 -1.4710934 -1.4893806 -2.0004869 -1.1831493 -1.4919103]\n",
      "Reset environment\n",
      "Episode reward: 505.07465\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.466343  -1.4644036 -1.4830272 -1.9928564 -1.1777306 -1.4853745]\n",
      "Reset environment\n",
      "Episode reward: -141.47275\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4636483 -1.4616919 -1.4803332 -1.9884832 -1.176263  -1.4826559]\n",
      "Reset environment\n",
      "Episode reward: -398.46417\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4623567 -1.4600959 -1.4793109 -1.986394  -1.1755233 -1.4813459]\n",
      "Reset environment\n",
      "Episode reward: -12807.036\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.519655  -1.5209719 -1.5326959 -2.0608587 -1.2190531 -1.5387318]\n",
      "Reset environment\n",
      "Episode reward: -88.71277\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5165553 -1.5178492 -1.5296135 -2.0561132 -1.2172021 -1.5356183]\n",
      "Reset environment\n",
      "Episode reward: 653.77856\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.5092632 -1.5102013 -1.5226536 -2.047839  -1.2109507 -1.5283146]\n",
      "Reset environment\n",
      "Episode reward: 1300.3356\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.497971  -1.4989367 -1.5114008 -2.0349479 -1.201385  -1.517021 ]\n",
      "Reset environment\n",
      "Episode reward: 953.0153\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4891442 -1.4901546 -1.5025889 -2.0249813 -1.1938838 -1.5082035]\n",
      "Reset environment\n",
      "Episode reward: 356.1422\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4836632 -1.4849116 -1.4969162 -2.018495  -1.189423  -1.5027313]\n",
      "Reset environment\n",
      "Episode reward: -31.959625\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4803189 -1.4815158 -1.4936465 -2.0134044 -1.1874286 -1.4993658]\n",
      "Reset environment\n",
      "Episode reward: 952.48517\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4715117 -1.4726385 -1.4849066 -2.0030568 -1.1801499 -1.4905381]\n",
      "Reset environment\n",
      "Episode reward: -46.916565\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4681271 -1.4692729 -1.4815005 -1.9980084 -1.1779983 -1.4871273]\n",
      "Reset environment\n",
      "Episode reward: 1319.6978\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4569346 -1.4583753 -1.4700832 -1.9854939 -1.168377  -1.4759454]\n",
      "Reset environment\n",
      "Episode reward: -431.5262\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4558905 -1.4569422 -1.4693991 -1.9842737 -1.1674771 -1.4748827]\n",
      "Reset environment\n",
      "Episode reward: 322.45517\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4505165 -1.4515978 -1.4640337 -1.9773552 -1.1634729 -1.469511 ]\n",
      "Reset environment\n",
      "Episode reward: -577.2101\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4499241 -1.4511997 -1.4632388 -1.9764118 -1.1630931 -1.4689057]\n",
      "Reset environment\n",
      "Episode reward: 457.67828\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4439449 -1.4453135 -1.4571726 -1.9688879 -1.1583359 -1.4629017]\n",
      "Reset environment\n",
      "Episode reward: 463.39078\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4377842 -1.43899   -1.4511622 -1.9616828 -1.153168  -1.4567147]\n",
      "Reset environment\n",
      "Episode reward: -48.88159\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4346997 -1.4352146 -1.4487453 -1.9577073 -1.1507945 -1.4535968]\n",
      "Reset environment\n",
      "Episode reward: 2100.2974\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.424073  -1.4244647 -1.438256  -1.945636  -1.1417507 -1.4429477]\n",
      "Reset environment\n",
      "Episode reward: 3475.814\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.4034895 -1.4040905 -1.4175524 -1.9224559 -1.1240631 -1.422382 ]\n",
      "Reset environment\n",
      "Episode reward: 1504.2491\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3914857 -1.3920903 -1.4055574 -1.9088669 -1.1138484 -1.4103543]\n",
      "Reset environment\n",
      "Episode reward: 2901.3635\n",
      "Total Steps: 317\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3709186 -1.3696755 -1.3867767 -1.8853991 -1.0962694 -1.3896967]\n",
      "Reset environment\n",
      "Episode reward: -401.58652\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3697072 -1.3687978 -1.3852552 -1.8835764 -1.0955125 -1.3884802]\n",
      "Reset environment\n",
      "Episode reward: 824.1981\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3617948 -1.3608223 -1.3773798 -1.8744404 -1.0888668 -1.3805386]\n",
      "Reset environment\n",
      "Episode reward: 327.9024\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.356481  -1.355646  -1.3719213 -1.8679073 -1.0846511 -1.3752218]\n",
      "Reset environment\n",
      "Episode reward: -273.20984\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3544722 -1.3535709 -1.3699672 -1.8644147 -1.0837156 -1.3732028]\n",
      "Reset environment\n",
      "Episode reward: -264.17535\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3539053 -1.353424  -1.3690068 -1.8632996 -1.0834428 -1.372631 ]\n",
      "Reset environment\n",
      "Episode reward: 447.7237\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3485863 -1.3473696 -1.3643897 -1.8567222 -1.0791664 -1.3672912]\n",
      "Reset environment\n",
      "Episode reward: -1020.33435\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3500309 -1.3500379 -1.3646039 -1.8574393 -1.0809246 -1.3686926]\n",
      "Reset environment\n",
      "Episode reward: 37.358948\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.346289  -1.3464489 -1.360684  -1.852622  -1.078072  -1.3649154]\n",
      "Reset environment\n",
      "Episode reward: 856.3148\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3376038 -1.3378901 -1.3518832 -1.8420929 -1.071062  -1.3562062]\n",
      "Reset environment\n",
      "Episode reward: 1391.4344\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3262107 -1.326423  -1.3405665 -1.8288096 -1.0615644 -1.3447685]\n",
      "Reset environment\n",
      "Episode reward: -4839.591\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3430151 -1.3416328 -1.3588526 -1.8677202 -1.064695  -1.3611294]\n",
      "Reset environment\n",
      "Episode reward: 2576.8835\n",
      "Total Steps: 391\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3279349 -1.3288438 -1.3416303 -1.8507068 -1.0520103 -1.3460665]\n",
      "Reset environment\n",
      "Episode reward: 1411.9526\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3165771 -1.3174682 -1.3303005 -1.8375818 -1.0425234 -1.3346767]\n",
      "Reset environment\n",
      "Episode reward: -3423.7927\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3191066 -1.3192511 -1.3340133 -1.8682954 -1.0286194 -1.3372962]\n",
      "Reset environment\n",
      "Episode reward: 233.46979\n",
      "Total Steps: 10\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3189061 -1.3190418 -1.3338181 -1.8679625 -1.028501  -1.3370966]\n",
      "Reset environment\n",
      "Episode reward: 601.06085\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3123746 -1.3124201 -1.3273749 -1.8603096 -1.0231117 -1.3305638]\n",
      "Reset environment\n",
      "Episode reward: -115.824066\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3098983 -1.3096665 -1.3251737 -1.8573344 -1.0210869 -1.3280714]\n",
      "Reset environment\n",
      "Episode reward: -295.37405\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3075473 -1.3075325 -1.3225884 -1.8532561 -1.0199068 -1.3256919]\n",
      "Reset environment\n",
      "Episode reward: -87.138916\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3046173 -1.3045536 -1.3196944 -1.8487521 -1.0181496 -1.3227488]\n",
      "Reset environment\n",
      "Episode reward: -157.86688\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3016095 -1.3009372 -1.3173025 -1.8447548 -1.0159886 -1.3197163]\n",
      "Reset environment\n",
      "Episode reward: 621.4011\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2949848 -1.2942392 -1.3107712 -1.8369623 -1.0105455 -1.3130879]\n",
      "Reset environment\n",
      "Episode reward: -17559.105\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3735918 -1.3704515 -1.3915871 -1.9610668 -1.058137  -1.391501 ]\n",
      "Reset environment\n",
      "Episode reward: 3106.9604\n",
      "Total Steps: 260\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3545153 -1.3528004 -1.3712351 -1.9398578 -1.0415868 -1.3724401]\n",
      "Reset environment\n",
      "Episode reward: 654.8905\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3475494 -1.3457028 -1.3643664 -1.9310467 -1.0362048 -1.365444 ]\n",
      "Reset environment\n",
      "Episode reward: 1104.3346\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3382956 -1.3363508 -1.3552235 -1.920569  -1.0283215 -1.3561938]\n",
      "Reset environment\n",
      "Episode reward: -7654.8594\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3692609 -1.3679224 -1.3861592 -1.966711  -1.0500493 -1.3870522]\n",
      "Reset environment\n",
      "Episode reward: 859.50146\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3614811 -1.3600037 -1.3785447 -1.9579456 -1.0434002 -1.3792745]\n",
      "Reset environment\n",
      "Episode reward: 547.76086\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3554299 -1.3541099 -1.372377  -1.9508172 -1.0384151 -1.3732173]\n",
      "Reset environment\n",
      "Episode reward: 657.76\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3484358 -1.347627  -1.364937  -1.9428111 -1.032566  -1.3662407]\n",
      "Reset environment\n",
      "Episode reward: 490.19348\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3424004 -1.3418398 -1.3586977 -1.9353625 -1.027833  -1.360198 ]\n",
      "Reset environment\n",
      "Episode reward: -10645.83\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3770561 -1.3774228 -1.3926204 -1.9951732 -1.0464597 -1.3946021]\n",
      "Reset environment\n",
      "Episode reward: 938.0628\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3686244 -1.3687971 -1.3844321 -1.985196  -1.0394753 -1.3861738]\n",
      "Reset environment\n",
      "Episode reward: 54.29535\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3649325 -1.3662655 -1.3795801 -1.980803  -1.0364264 -1.3824588]\n",
      "Reset environment\n",
      "Episode reward: 1270.3307\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3551229 -1.3566848 -1.3696086 -1.9698826 -1.0279719 -1.372652 ]\n",
      "Reset environment\n",
      "Episode reward: -42.20218\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3520873 -1.353844  -1.3664116 -1.9657346 -1.0258394 -1.3696221]\n",
      "Reset environment\n",
      "Episode reward: 1425.7909\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3411889 -1.3430032 -1.3554798 -1.9533    -1.0165557 -1.3587223]\n",
      "Reset environment\n",
      "Episode reward: 463.82147\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3354065 -1.3370572 -1.3498185 -1.9457793 -1.012185  -1.3529128]\n",
      "Reset environment\n",
      "Episode reward: -46.400665\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3325647 -1.3339442 -1.3472534 -1.9424039 -1.0098318 -1.3500806]\n",
      "Reset environment\n",
      "Episode reward: 1049.1676\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3280997 -1.3294723 -1.3428245 -1.9371704 -1.0060588 -1.3456107]\n",
      "Reset environment\n",
      "Episode reward: -579.1052\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3288637 -1.3306772 -1.3431852 -1.9378784 -1.0067427 -1.3463833]\n",
      "Reset environment\n",
      "Episode reward: -370.757\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.32742   -1.3295097 -1.3414813 -1.9359843 -1.0055438 -1.3449453]\n",
      "Reset environment\n",
      "Episode reward: 194.6051\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3231392 -1.3255038 -1.3369548 -1.9309019 -1.0020397 -1.3406652]\n",
      "Reset environment\n",
      "Episode reward: 1296.4839\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3130113  -1.3152622  -1.3269598  -1.9189602  -0.99370575 -1.3305292 ]\n",
      "Reset environment\n",
      "Episode reward: 239.13449\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.308601   -1.310805   -1.3225833  -1.9130136  -0.99051183 -1.3260909 ]\n",
      "Reset environment\n",
      "Episode reward: -914.80664\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.3108488  -1.312822   -1.3250408  -1.9162112  -0.99190867 -1.3283243 ]\n",
      "Reset environment\n",
      "Episode reward: 346.04816\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.305876  -1.3077275 -1.3201873 -1.910094  -0.9879731 -1.3233459]\n",
      "Reset environment\n",
      "Episode reward: 908.36316\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.297885  -1.2996389 -1.3122741 -1.9004077 -0.981586  -1.3153212]\n",
      "Reset environment\n",
      "Episode reward: 807.59937\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2905     -1.2920852  -1.3050679  -1.8920318  -0.97530955 -1.3079252 ]\n",
      "Reset environment\n",
      "Episode reward: -7.4897156\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2874497 -1.2888683 -1.3021874 -1.8880614 -0.9730573 -1.3048811]\n",
      "Reset environment\n",
      "Episode reward: 391.93707\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2823836 -1.2839855 -1.2969595 -1.8818966 -0.9690083 -1.2998073]\n",
      "Reset environment\n",
      "Episode reward: 460.4106\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.276971   -1.2788785  -1.2912495  -1.8757269  -0.96436137 -1.2943869 ]\n",
      "Reset environment\n",
      "Episode reward: 3436.3245\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2553666 -1.257907  -1.2690583 -1.851734  -0.9456939 -1.2727281]\n",
      "Reset environment\n",
      "Episode reward: 827.99786\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2480956 -1.2505994 -1.2618344 -1.843373  -0.9396029 -1.2654535]\n",
      "Reset environment\n",
      "Episode reward: -337.37207\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2466946 -1.2490538 -1.260526  -1.8406415 -0.9390563 -1.2640194]\n",
      "Reset environment\n",
      "Episode reward: -179.84705\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2445347 -1.2465966 -1.2586782 -1.8380458 -0.937277  -1.2618529]\n",
      "Reset environment\n",
      "Episode reward: 476.37158\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2389776 -1.2411997 -1.2529869 -1.8314196 -0.932784  -1.2562991]\n",
      "Reset environment\n",
      "Episode reward: -163.46082\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2363222 -1.2381526 -1.2507596 -1.8273702 -0.9311404 -1.2536379]\n",
      "Reset environment\n",
      "Episode reward: 386.46954\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2311624  -1.2328537  -1.2457601  -1.8211983  -0.92695427 -1.2484802 ]\n",
      "Reset environment\n",
      "Episode reward: 1063.3978\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2224257  -1.2240218  -1.2371346  -1.8106506  -0.91992325 -1.2397096 ]\n",
      "Reset environment\n",
      "Episode reward: -445.16525\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2215205 -1.2233319 -1.2360214 -1.8091204 -0.919438  -1.2388046]\n",
      "Reset environment\n",
      "Episode reward: -176.49478\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2193305 -1.2212332 -1.233717  -1.8055792 -0.9182238 -1.2365878]\n",
      "Reset environment\n",
      "Episode reward: 857.84235\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2118679 -1.2136352 -1.2264062 -1.79718   -0.9118385 -1.2291157]\n",
      "Reset environment\n",
      "Episode reward: 3507.2942\n",
      "Total Steps: 241\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1901275 -1.1914032 -1.2051541 -1.771854  -0.8936894 -1.2072576]\n",
      "Reset environment\n",
      "Episode reward: -10787.443\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2294762 -1.2331357 -1.2414969 -1.8318973 -0.9190471 -1.2466946]\n",
      "Reset environment\n",
      "Episode reward: -3017.3423\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.225974  -1.2284113 -1.2394489 -1.8476245 -0.9053606 -1.2431637]\n",
      "Reset environment\n",
      "Episode reward: 979.41125\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2176425 -1.2190119 -1.2322106 -1.8383238 -0.8981562 -1.2348659]\n",
      "Reset environment\n",
      "Episode reward: -586.18805\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2175895 -1.2193941 -1.2317762 -1.8378726 -0.8983491 -1.2348421]\n",
      "Reset environment\n",
      "Episode reward: -0.25463867\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2144183  -1.2162945  -1.228533   -1.8334929  -0.89611536 -1.2316648 ]\n",
      "Reset environment\n",
      "Episode reward: -528.97845\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2143569 -1.216029  -1.22862   -1.8336666 -0.895776  -1.2315756]\n",
      "Reset environment\n",
      "Episode reward: 128.87573\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2108861  -1.212084   -1.2256659  -1.8296688  -0.89281744 -1.2281058 ]\n",
      "Reset environment\n",
      "Episode reward: 616.8314\n",
      "Total Steps: 241\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2035137 -1.2064993 -1.2166467 -1.8213139 -0.8867275 -1.2207407]\n",
      "Reset environment\n",
      "Episode reward: -768.70276\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.2045951 -1.2072048 -1.2180638 -1.8220916 -0.8878957 -1.2218088]\n",
      "Reset environment\n",
      "Episode reward: 1243.2395\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1949538 -1.1971945 -1.20881   -1.811253  -0.8796111 -1.2121512]\n",
      "Reset environment\n",
      "Episode reward: 1592.3307\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1874574 -1.1897165 -1.2013125 -1.802612  -0.8732899 -1.2046492]\n",
      "Reset environment\n",
      "Episode reward: -205.61166\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1854612  -1.1877742  -1.1992582  -1.7994785  -0.87210196 -1.202628  ]\n",
      "Reset environment\n",
      "Episode reward: 73.380066\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1820807 -1.184419  -1.1958557 -1.7946486 -0.8698269 -1.1992314]\n",
      "Reset environment\n",
      "Episode reward: -376.20633\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1808419 -1.1831598 -1.194625  -1.7917842 -0.8696678 -1.1979768]\n",
      "Reset environment\n",
      "Episode reward: -3954.7078\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1838601 -1.1871165 -1.196787  -1.8115262 -0.8642175 -1.2009491]\n",
      "Reset environment\n",
      "Episode reward: 797.0241\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1768867  -1.180145   -1.1898     -1.8034834  -0.85834736 -1.1939576 ]\n",
      "Reset environment\n",
      "Episode reward: -1632.1146\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1817176 -1.184763  -1.1948234 -1.8092812 -0.8621292 -1.1987997]\n",
      "Reset environment\n",
      "Episode reward: 325.13168\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1771727 -1.1803411 -1.1901734 -1.8035777 -0.8586045 -1.194244 ]\n",
      "Reset environment\n",
      "Episode reward: 202.40146\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1730739 -1.1770701 -1.1852427 -1.7989274 -0.8548673 -1.1901231]\n",
      "Reset environment\n",
      "Episode reward: 30.104279\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1699495 -1.174415  -1.1816515 -1.7947758 -0.852417  -1.1869972]\n",
      "Reset environment\n",
      "Episode reward: 525.6986\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1644835 -1.16915   -1.1760039 -1.788453  -0.847824  -1.1815224]\n",
      "Reset environment\n",
      "Episode reward: 345.49658\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1597943 -1.1644095 -1.1713759 -1.7825013 -0.8442312 -1.1768389]\n",
      "Reset environment\n",
      "Episode reward: 1204.5984\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1509113 -1.1560347 -1.1620716 -1.7722893 -0.8367776 -1.1679803]\n",
      "Reset environment\n",
      "Episode reward: 67.80725\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1476161  -1.1529686  -1.1585544  -1.7681218  -0.83413106 -1.1646793 ]\n",
      "Reset environment\n",
      "Episode reward: -134.75858\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1452066  -1.1506586  -1.1560434  -1.7645476  -0.83260566 -1.1622581 ]\n",
      "Reset environment\n",
      "Episode reward: -2542.6753\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.152311  -1.1578306 -1.1637604 -1.7963573 -0.8257095 -1.169681 ]\n",
      "Reset environment\n",
      "Episode reward: 421.1244\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.1473871 -1.153085  -1.1586741 -1.790482  -0.8217028 -1.1647532]\n",
      "Reset environment\n",
      "Episode reward: 2454.5833\n",
      "Total Steps: 297\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.131035  -1.1385982 -1.1406207 -1.7720691 -0.8077805 -1.1484191]\n",
      "Reset environment\n",
      "Episode reward: -6012.9634\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.096413   -1.1023921  -1.1072861  -1.7512846  -0.76809424 -1.1138835 ]\n",
      "Reset environment\n",
      "Episode reward: -3632.9602\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0978181 -1.1052536 -1.1076044 -1.7834353 -0.7521505 -1.1151814]\n",
      "Reset environment\n",
      "Episode reward: 3850.7012\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0764476 -1.0839756 -1.0862216 -1.7600759 -0.7333182 -1.093856 ]\n",
      "Reset environment\n",
      "Episode reward: -517.63873\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0760992  -1.0840218  -1.0855132  -1.7590721  -0.73336774 -1.0935333 ]\n",
      "Reset environment\n",
      "Episode reward: 676.1549\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.070105  -1.078265  -1.0792948 -1.7519085 -0.7284808 -1.087531 ]\n",
      "Reset environment\n",
      "Episode reward: 105.70053\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0660676 -1.0749254 -1.0745778 -1.7473682 -0.7249571 -1.0834956]\n",
      "Reset environment\n",
      "Episode reward: 557.4863\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0605983 -1.0692514 -1.069305  -1.741129  -0.7203216 -1.0780169]\n",
      "Reset environment\n",
      "Episode reward: 1239.8096\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0518295 -1.0605714 -1.0604787 -1.7311734 -0.71288   -1.069254 ]\n",
      "Reset environment\n",
      "Episode reward: -8544.224\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0762283  -1.0854691  -1.0842701  -1.7735956  -0.72632414 -1.0932947 ]\n",
      "Reset environment\n",
      "Episode reward: 1163.4747\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.071615   -1.0808372  -1.0796932  -1.7682233  -0.72241336 -1.088687  ]\n",
      "Reset environment\n",
      "Episode reward: -646.8052\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0710111  -1.080851   -1.078463   -1.7672433  -0.72199696 -1.0880847 ]\n",
      "Reset environment\n",
      "Episode reward: 715.7666\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0649556  -1.074782   -1.0724245  -1.7600458  -0.71703273 -1.0820217 ]\n",
      "Reset environment\n",
      "Episode reward: 1450.2397\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.055422   -1.0649776  -1.0631797  -1.7493974  -0.70870364 -1.0724756 ]\n",
      "Reset environment\n",
      "Episode reward: 2993.3481\n",
      "Total Steps: 215\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0375586 -1.0464903 -1.0460277 -1.7296635 -0.6930163 -1.0546391]\n",
      "Reset environment\n",
      "Episode reward: -789.6147\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0388184 -1.047218  -1.0478035 -1.7305855 -0.694354  -1.0558641]\n",
      "Reset environment\n",
      "Episode reward: 549.1312\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.033577   -1.0419258  -1.0426171  -1.7242017  -0.69014806 -1.0506257 ]\n",
      "Reset environment\n",
      "Episode reward: 379.60452\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0290824  -1.0375075  -1.038061   -1.7185494  -0.68665284 -1.04612   ]\n",
      "Reset environment\n",
      "Episode reward: 1247.8306\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0203624 -1.0284367 -1.0297056 -1.70836   -0.6793932 -1.037368 ]\n",
      "Reset environment\n",
      "Episode reward: 916.2842\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0131714  -1.0212827  -1.0224944  -1.6997024  -0.67358494 -1.0301592 ]\n",
      "Reset environment\n",
      "Episode reward: 2694.2832\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0015509  -1.0095409  -1.0110167  -1.686673   -0.66361374 -1.0185193 ]\n",
      "Reset environment\n",
      "Episode reward: 740.4149\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9951552  -1.0034844  -1.0043086  -1.679185   -0.65828454 -1.0121199 ]\n",
      "Reset environment\n",
      "Episode reward: 769.61597\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.98833656 -0.99759597 -0.99656117 -1.6716137  -0.65232354 -1.005266  ]\n",
      "Reset environment\n",
      "Episode reward: 941.48065\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9812783  -0.99049026 -0.98956126 -1.6636057  -0.64629704 -0.9982116 ]\n",
      "Reset environment\n",
      "Episode reward: 345.5478\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9769743  -0.9863483  -0.9850976  -1.6583387  -0.64284086 -0.993906  ]\n",
      "Reset environment\n",
      "Episode reward: 634.8268\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9712539  -0.98053163 -0.9794788  -1.651548   -0.63813925 -0.98816544]\n",
      "Reset environment\n",
      "Episode reward: -19429.37\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0499364  -1.0591956  -1.0577768  -1.7715505  -0.68791026 -1.0665916 ]\n",
      "Reset environment\n",
      "Episode reward: 900.7999\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0428302  -1.0519106  -1.050851   -1.7629902  -0.68214685 -1.0594656 ]\n",
      "Reset environment\n",
      "Episode reward: -9168.564\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0724399 -1.0816984 -1.079875  -1.8156602 -0.6973662 -1.0888534]\n",
      "Reset environment\n",
      "Episode reward: -826.2554\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0737892 -1.0829453 -1.0812882 -1.8171606 -0.6985389 -1.0901818]\n",
      "Reset environment\n",
      "Episode reward: 351.14813\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0728294 -1.0819459 -1.0803528 -1.8154033 -0.6981064 -1.0892158]\n",
      "Reset environment\n",
      "Episode reward: 510.1095\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0678169 -1.0768371 -1.0754409 -1.8093439 -0.6940691 -1.084191 ]\n",
      "Reset environment\n",
      "Episode reward: 2752.665\n",
      "Total Steps: 232\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0509968  -1.0608819  -1.057862   -1.7903035  -0.67968166 -1.0673734 ]\n",
      "Reset environment\n",
      "Episode reward: 999.78125\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0438483  -1.0538284  -1.0506322  -1.7823296  -0.67351645 -1.0602258 ]\n",
      "Reset environment\n",
      "Episode reward: -136.99619\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0415454  -1.0519158  -1.0479584  -1.7795101  -0.67155814 -1.0579233 ]\n",
      "Reset environment\n",
      "Episode reward: -370.00143\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0400493  -1.0498986  -1.0469574  -1.7771723  -0.67072386 -1.0563974 ]\n",
      "Reset environment\n",
      "Episode reward: 195.17587\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0362422 -1.0456017 -1.0436585 -1.772331  -0.6677477 -1.0525846]\n",
      "Reset environment\n",
      "Episode reward: 631.1354\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0306039 -1.0398511 -1.0381397 -1.7649846 -0.6635019 -1.0469121]\n",
      "Reset environment\n",
      "Episode reward: 938.0814\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0235887 -1.0331342 -1.0308815 -1.7566628 -0.6577608 -1.0398908]\n",
      "Reset environment\n",
      "Episode reward: -136.71805\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0215448 -1.0311315 -1.0288126 -1.753276  -0.6566774 -1.0378389]\n",
      "Reset environment\n",
      "Episode reward: 163.79562\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0173279 -1.0274143 -1.0241239 -1.7483411 -0.6531453 -1.0336324]\n",
      "Reset environment\n",
      "Episode reward: 430.30545\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0128733 -1.0231537 -1.0194966 -1.7430439 -0.6494465 -1.0291774]\n",
      "Reset environment\n",
      "Episode reward: -147.47998\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.011099   -1.0210919  -1.0179714  -1.7407385  -0.64797866 -1.0273701 ]\n",
      "Reset environment\n",
      "Episode reward: 2726.6633\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.99569863 -1.0066026  -1.0017644  -1.7235242  -0.6347545  -1.0119699 ]\n",
      "Reset environment\n",
      "Episode reward: 119.95657\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9925102 -1.0035033 -0.9984896 -1.7191367 -0.6325051 -1.0087708]\n",
      "Reset environment\n",
      "Episode reward: 138.81879\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.98927474 -1.0002375  -0.9952525  -1.7144873  -0.63034    -1.0055116 ]\n",
      "Reset environment\n",
      "Episode reward: 752.9942\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9831634  -0.99381626 -0.98943734 -1.7072494  -0.62521964 -0.9993837 ]\n",
      "Reset environment\n",
      "Episode reward: 1377.932\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.973952  -0.9852175 -0.9796361 -1.6969541 -0.6172771 -0.9901551]\n",
      "Reset environment\n",
      "Episode reward: -79.25235\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9719385  -0.98256385 -0.97825027 -1.6951292  -0.6152319  -0.9881297 ]\n",
      "Reset environment\n",
      "Episode reward: 438.41193\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9673965  -0.9779064  -0.9738397  -1.6895739  -0.61158675 -0.98359   ]\n",
      "Reset environment\n",
      "Episode reward: 1098.6987\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9596865  -0.96995467 -0.9663685  -1.6806692  -0.6049725  -0.9758699 ]\n",
      "Reset environment\n",
      "Episode reward: -543.77515\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.95910895 -0.9694823  -0.9656939  -1.6796727  -0.6046845  -0.97529274]\n",
      "Reset environment\n",
      "Episode reward: 2058.3274\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.94690275 -0.9581423  -0.952721   -1.6657977  -0.59429455 -0.9631055 ]\n",
      "Reset environment\n",
      "Episode reward: -14708.874\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.0008081 -1.0133498 -1.0052414 -1.740985  -0.6343877 -1.0169959]\n",
      "Reset environment\n",
      "Episode reward: 54.673218\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.99791324 -1.010473   -1.0023054  -1.7366648  -0.6325468  -1.0140827 ]\n",
      "Reset environment\n",
      "Episode reward: 875.5653\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9908293 -1.0027415 -0.9958669 -1.7288659 -0.6263636 -1.0069937]\n",
      "Reset environment\n",
      "Episode reward: -297.90515\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.98976547 -1.0013951  -0.99506414 -1.7276021  -0.625423   -1.0058974 ]\n",
      "Reset environment\n",
      "Episode reward: -52.95993\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.98737866 -0.99913913 -0.99254334 -1.7242656  -0.6237794  -1.0035014 ]\n",
      "Reset environment\n",
      "Episode reward: 719.31586\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9813454  -0.9934144  -0.9862529  -1.7171288  -0.61886054 -0.9974676 ]\n",
      "Reset environment\n",
      "Episode reward: 535.62305\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9763208  -0.98821235 -0.98140323 -1.7105862  -0.6150412  -0.9924156 ]\n",
      "Reset environment\n",
      "Episode reward: 384.5916\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.97188634 -0.9841437  -0.97668165 -1.7051481  -0.61152756 -0.9880066 ]\n",
      "Reset environment\n",
      "Episode reward: 131.03867\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9686771  -0.9809109  -0.9735186  -1.7006489  -0.60933274 -0.9847805 ]\n",
      "Reset environment\n",
      "Episode reward: 1404.7952\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9588541  -0.970125   -0.9647137  -1.6897573  -0.60074157 -0.97498703]\n",
      "Reset environment\n",
      "Episode reward: 163.35226\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.95560044 -0.96677905 -0.9615312  -1.6853873  -0.5983641  -0.97172177]\n",
      "Reset environment\n",
      "Episode reward: -4826.6753\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.96994203 -0.97787553 -0.97942775 -1.7172191  -0.6028546  -0.98591506]\n",
      "Reset environment\n",
      "Episode reward: -184.95895\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9683291  -0.9765267  -0.97753245 -1.715      -0.6015966  -0.9842887 ]\n",
      "Reset environment\n",
      "Episode reward: -1249.0472\n",
      "Total Steps: 1662\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.97750384 -0.9844124  -0.9874642  -1.740773   -0.601964   -0.993445  ]\n",
      "Reset environment\n",
      "Episode reward: 59.687744\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9747389  -0.98146176 -0.98486996 -1.7370957  -0.599907   -0.9906659 ]\n",
      "Reset environment\n",
      "Episode reward: 1652.3953\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9649628  -0.97153324 -0.97528625 -1.7260945  -0.59154475 -0.98088413]\n",
      "Reset environment\n",
      "Episode reward: 224.98349\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.96139765 -0.9679204  -0.97177804 -1.7214242  -0.5888889  -0.9773328 ]\n",
      "Reset environment\n",
      "Episode reward: -965.36755\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9654272  -0.97074956 -0.97699773 -1.7243177  -0.59330654 -0.9813548 ]\n",
      "Reset environment\n",
      "Episode reward: -403.37515\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9648293  -0.9698482  -0.9767134  -1.7233827  -0.5929143  -0.98075575]\n",
      "Reset environment\n",
      "Episode reward: -129.02698\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9662671  -0.97016954 -0.9792537  -1.7238665  -0.59480846 -0.98217094]\n",
      "Reset environment\n",
      "Episode reward: 50.120117\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.96349406 -0.9674356  -0.9764529  -1.7198726  -0.59296405 -0.9793869 ]\n",
      "Reset environment\n",
      "Episode reward: 3306.3235\n",
      "Total Steps: 240\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.94594723 -0.9507866  -0.9581369  -1.7001051  -0.5779379  -0.9618735 ]\n",
      "Reset environment\n",
      "Episode reward: 3265.6348\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9290002  -0.9335173  -0.9415787  -1.6805654  -0.56367475 -0.9448979 ]\n",
      "Reset environment\n",
      "Episode reward: -633.21185\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.9292948 -0.9335149 -0.9421243 -1.6805291 -0.5641459 -0.9451519]\n",
      "Reset environment\n",
      "Episode reward: 3381.6917\n",
      "Total Steps: 337\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.91037625 -0.91589844 -0.92205536 -1.6581483  -0.548588   -0.926241  ]\n",
      "Reset environment\n",
      "Episode reward: 1018.0863\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.90343976 -0.9091755  -0.9149521  -1.6502415  -0.54270667 -0.9193276 ]\n",
      "Reset environment\n",
      "Episode reward: 861.25745\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.89724857 -0.9030271  -0.9087553  -1.6431026  -0.53752375 -0.9131429 ]\n",
      "Reset environment\n",
      "Episode reward: 509.6296\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8926153  -0.89868003 -0.9038633  -1.6376603  -0.5336786  -0.9085142 ]\n",
      "Reset environment\n",
      "Episode reward: -1104.8844\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.87781256 -0.88473904 -0.88864005 -1.6459943  -0.5097236  -0.8937079 ]\n",
      "Reset environment\n",
      "Episode reward: 198.76913\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8745302  -0.88138527 -0.8854186  -1.6415921  -0.5073033  -0.89042205]\n",
      "Reset environment\n",
      "Episode reward: 499.68173\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.86991024 -0.8766968  -0.880847   -1.6358593  -0.5036484  -0.8857839 ]\n",
      "Reset environment\n",
      "Episode reward: 28.419739\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.86737394 -0.87393296 -0.8785405  -1.6326678  -0.50163287 -0.88324505]\n",
      "Reset environment\n",
      "Episode reward: -776.77295\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.86837864 -0.8745687  -0.8798984  -1.6334885  -0.50262225 -0.88423705]\n",
      "Reset environment\n",
      "Episode reward: -394.1855\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8678093  -0.8737569  -0.87953514 -1.6325458  -0.50219756 -0.8836401 ]\n",
      "Reset environment\n",
      "Episode reward: 2513.5789\n",
      "Total Steps: 229\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85469466 -0.86013734 -0.86694205 -1.6175247  -0.49104548 -0.87048805]\n",
      "Reset environment\n",
      "Episode reward: 319.94275\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85094726 -0.8564977  -0.8630981  -1.6126969  -0.48821658 -0.8667365 ]\n",
      "Reset environment\n",
      "Episode reward: 1116.6046\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.84375817 -0.8492214  -0.85601276 -1.6047384  -0.48196366 -0.8595553 ]\n",
      "Reset environment\n",
      "Episode reward: 42.57724\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.84115463 -0.8464163  -0.85363764 -1.6014909  -0.47991452 -0.8569503 ]\n",
      "Reset environment\n",
      "Episode reward: 159.55075\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8379117  -0.84346515 -0.85010815 -1.59741    -0.47738352 -0.8537047 ]\n",
      "Reset environment\n",
      "Episode reward: 423.26492\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8336834  -0.83930516 -0.8458227  -1.5921338  -0.47409037 -0.84946805]\n",
      "Reset environment\n",
      "Episode reward: -4072.2642\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8426693  -0.8507047  -0.85193545 -1.6182313  -0.4737718  -0.8583784 ]\n",
      "Reset environment\n",
      "Episode reward: -7728.2876\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.86517906 -0.8716513  -0.8758094  -1.6588795  -0.4871437  -0.8808377 ]\n",
      "Reset environment\n",
      "Episode reward: 516.8684\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8606316  -0.867032   -0.87133133 -1.65327    -0.48351654 -0.8762685 ]\n",
      "Reset environment\n",
      "Episode reward: 330.74768\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85678416 -0.86322445 -0.8674586  -1.6482117  -0.48067048 -0.872424  ]\n",
      "Reset environment\n",
      "Episode reward: 817.3841\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85102487 -0.8573063  -0.86182076 -1.6416891  -0.47570285 -0.86664474]\n",
      "Reset environment\n",
      "Episode reward: 5557.276\n",
      "Total Steps: 279\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.82533836 -0.8322355  -0.8356344  -1.6133174  -0.4532247  -0.8410106 ]\n",
      "Reset environment\n",
      "Episode reward: -333.72437\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8241229  -0.8313994  -0.83405256 -1.611559   -0.4524171  -0.8397941 ]\n",
      "Reset environment\n",
      "Episode reward: 605.08704\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8188943  -0.8253349  -0.8296741  -1.604769   -0.44854015 -0.83454984]\n",
      "Reset environment\n",
      "Episode reward: 614.7022\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.81396157 -0.8203086  -0.8248237  -1.5988854  -0.44448945 -0.8296028 ]\n",
      "Reset environment\n",
      "Episode reward: -9760.324\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8397981  -0.84614265 -0.8500364  -1.6458405  -0.45527852 -0.8551381 ]\n",
      "Reset environment\n",
      "Episode reward: -5376.2563\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85867274 -0.86443037 -0.86945695 -1.6648474  -0.47263056 -0.8740105 ]\n",
      "Reset environment\n",
      "Episode reward: -44.744293\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85641193 -0.86232305 -0.86706716 -1.6616582  -0.47108895 -0.87174   ]\n",
      "Reset environment\n",
      "Episode reward: -8895.123\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8855754  -0.893431   -0.89396054 -1.7201931  -0.4831248  -0.9008629 ]\n",
      "Reset environment\n",
      "Episode reward: 476.28616\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8811897  -0.88904816 -0.8895625  -1.7146094  -0.47975966 -0.8964625 ]\n",
      "Reset environment\n",
      "Episode reward: 1487.6182\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8725925  -0.8805055  -0.8809227  -1.7048084  -0.47247735 -0.88784766]\n",
      "Reset environment\n",
      "Episode reward: 1871.9851\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8625448  -0.87041706 -0.87093806 -1.6936945  -0.46368903 -0.8777951 ]\n",
      "Reset environment\n",
      "Episode reward: 705.14453\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85737014 -0.8653346  -0.865673   -1.6876842  -0.45939296 -0.87262946]\n",
      "Reset environment\n",
      "Episode reward: 809.52264\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8517502  -0.8596951  -0.8600548  -1.6810608  -0.45475334 -0.8669908 ]\n",
      "Reset environment\n",
      "Episode reward: 1386.8746\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8432544  -0.8520883  -0.8507668  -1.6713134  -0.44767055 -0.85848445]\n",
      "Reset environment\n",
      "Episode reward: 39.22583\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.84114057 -0.8496857  -0.84894514 -1.6684134  -0.4460887  -0.8563636 ]\n",
      "Reset environment\n",
      "Episode reward: 955.44965\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8349414  -0.84351265 -0.8427351  -1.6613247  -0.44083333 -0.8501543 ]\n",
      "Reset environment\n",
      "Episode reward: -9240.837\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.86412656 -0.8735041  -0.8713173  -1.7197247  -0.45243892 -0.87932724]\n",
      "Reset environment\n",
      "Episode reward: -1877.4663\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8688147  -0.877223   -0.87695104 -1.7245944  -0.4566097  -0.8839987 ]\n",
      "Reset environment\n",
      "Episode reward: 362.96152\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.86513424 -0.8736725  -0.87315154 -1.7200235  -0.45372078 -0.88031644]\n",
      "Reset environment\n",
      "Episode reward: 1317.4873\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8571946  -0.8655011  -0.8655115  -1.7110225  -0.44689685 -0.8724004 ]\n",
      "Reset environment\n",
      "Episode reward: 825.5432\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.85143334 -0.8598913  -0.85963887 -1.7039127  -0.44234285 -0.8666439 ]\n",
      "Reset environment\n",
      "Episode reward: -647.36865\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8517582  -0.8600672  -0.86004657 -1.7037824  -0.44290662 -0.86694485]\n",
      "Reset environment\n",
      "Episode reward: -5631.977\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.86740035 -0.876302   -0.87483805 -1.7339109  -0.45089862 -0.88230205]\n",
      "Reset environment\n",
      "Episode reward: 3385.7651\n",
      "Total Steps: 261\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8498639  -0.8580988  -0.858054   -1.7142739  -0.43569773 -0.86476207]\n",
      "Reset environment\n",
      "Episode reward: 1368.9148\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8419439  -0.84995717 -0.8503753  -1.7053572  -0.42887253 -0.85684836]\n",
      "Reset environment\n",
      "Episode reward: 801.43384\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.836503   -0.8446295  -0.8448238  -1.6991208  -0.42425558 -0.85140586]\n",
      "Reset environment\n",
      "Episode reward: 1418.4948\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.82831377 -0.8363786  -0.8367316  -1.6896904  -0.41736436 -0.8432251 ]\n",
      "Reset environment\n",
      "Episode reward: 567.85706\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8267231  -0.8347628  -0.8351635  -1.6875308  -0.41616538 -0.84162086]\n",
      "Reset environment\n",
      "Episode reward: 930.1035\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8206613  -0.8290494  -0.82877076 -1.6805308  -0.41104993 -0.83556736]\n",
      "Reset environment\n",
      "Episode reward: -12496.8955\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8608405  -0.86723405 -0.870285   -1.7489203  -0.43449637 -0.8753524 ]\n",
      "Reset environment\n",
      "Episode reward: 668.9762\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8559254  -0.8624026  -0.8652846  -1.7430563  -0.43047756 -0.8704326 ]\n",
      "Reset environment\n",
      "Episode reward: 561.93164\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8505851 -0.8564299 -0.8605763 -1.7364398 -0.4263394 -0.8650766]\n",
      "Reset environment\n",
      "Episode reward: -372.13174\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.84989864 -0.8560484  -0.8596133  -1.7351431  -0.4260378  -0.86439794]\n",
      "Reset environment\n",
      "Episode reward: 215.1565\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.84673744 -0.85269535 -0.8566444  -1.7313039  -0.42346933 -0.8612303 ]\n",
      "Reset environment\n",
      "Episode reward: 1307.7935\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8393096  -0.84512854 -0.8493483  -1.7227694  -0.41714332 -0.85378104]\n",
      "Reset environment\n",
      "Episode reward: 3458.1172\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.82264775 -0.82826596 -0.83294225 -1.7042783  -0.4025636  -0.8371296 ]\n",
      "Reset environment\n",
      "Episode reward: 1394.3715\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.81493247 -0.8205863  -0.82520443 -1.6956573  -0.3958827  -0.8294113 ]\n",
      "Reset environment\n",
      "Episode reward: 828.83325\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.8094093  -0.8151585  -0.8195809  -1.6887457  -0.39144486 -0.8238645 ]\n",
      "Reset environment\n",
      "Episode reward: 2782.509\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7989489  -0.80468464 -0.809172   -1.6768289  -0.38257864 -0.8134221 ]\n",
      "Reset environment\n",
      "Episode reward: 211.77542\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7958752  -0.8016503  -0.8060678  -1.6726644  -0.3803485  -0.81034243]\n",
      "Reset environment\n",
      "Episode reward: 43.181213\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7934819  -0.7997891  -0.80320024 -1.6695445  -0.3785568  -0.8079598 ]\n",
      "Reset environment\n",
      "Episode reward: 487.5782\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.78921777 -0.79586786 -0.79865384 -1.6643032  -0.37517413 -0.8037039 ]\n",
      "Reset environment\n",
      "Episode reward: 473.09753\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.78510976 -0.7915716  -0.79472876 -1.6595079  -0.3717219  -0.7995966 ]\n",
      "Reset environment\n",
      "Episode reward: 824.1846\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7795044  -0.7856938  -0.7894469  -1.6527933  -0.36711624 -0.7939859 ]\n",
      "Reset environment\n",
      "Episode reward: 953.7181\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.77302563 -0.7800585  -0.78221977 -1.6453195  -0.36165294 -0.78752893]\n",
      "Reset environment\n",
      "Episode reward: 4291.0244\n",
      "Total Steps: 263\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.75307214 -0.76083463 -0.7616254  -1.6229949  -0.34443933 -0.7675734 ]\n",
      "Reset environment\n",
      "Episode reward: 643.5232\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7481888  -0.75597215 -0.7567334  -1.6171008  -0.3405155  -0.7626909 ]\n",
      "Reset environment\n",
      "Episode reward: -5389.0156\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7760603  -0.7804472  -0.78772205 -1.67045    -0.35097426 -0.7906845 ]\n",
      "Reset environment\n",
      "Episode reward: 731.6471\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7710462  -0.77540326 -0.7827271  -1.6644356  -0.34690648 -0.7856622 ]\n",
      "Reset environment\n",
      "Episode reward: 1615.7015\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7624841  -0.7669548  -0.77411216 -1.6548965  -0.3395099  -0.777115  ]\n",
      "Reset environment\n",
      "Episode reward: 382.05936\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.758878   -0.7635559  -0.7703259  -1.6505214  -0.3365994  -0.77350885]\n",
      "Reset environment\n",
      "Episode reward: 20.271454\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7565158 -0.7615109 -0.7676974 -1.6476141 -0.3346965 -0.7711633]\n",
      "Reset environment\n",
      "Episode reward: -6417.5674\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.77644557 -0.7829621  -0.7863043  -1.6922168  -0.34093735 -0.7909964 ]\n",
      "Reset environment\n",
      "Episode reward: -2219.8394\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7820472 -0.7898982 -0.7905881 -1.7227055 -0.3336022 -0.7963003]\n",
      "Reset environment\n",
      "Episode reward: 365.29657\n",
      "Total Steps: 20\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7814061  -0.78926224 -0.78994286 -1.7217872  -0.3331453  -0.7956577 ]\n",
      "Reset environment\n",
      "Episode reward: 200.39777\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7723095  -0.7796243  -0.7809926  -1.7316602  -0.31598136 -0.7864394 ]\n",
      "Reset environment\n",
      "Episode reward: 1569.814\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.76404643 -0.7714447  -0.7726595  -1.7224001  -0.30889407 -0.77817154]\n",
      "Reset environment\n",
      "Episode reward: 1403.831\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7564842  -0.7638802  -0.765103   -1.7138948  -0.3024009  -0.77059203]\n",
      "Reset environment\n",
      "Episode reward: 1179.3452\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7499154  -0.7572034  -0.75864804 -1.7065666  -0.2967148  -0.76401156]\n",
      "Reset environment\n",
      "Episode reward: 2163.4563\n",
      "Total Steps: 376\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.74213547 -0.74819535 -0.7521038  -1.6972066  -0.2905737  -0.7562129 ]\n",
      "Reset environment\n",
      "Episode reward: 222.83731\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.73909736 -0.7450585  -0.7491681  -1.6931568  -0.28833514 -0.7531632 ]\n",
      "Reset environment\n",
      "Episode reward: 1347.8999\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.731291   -0.73655355 -0.7420698  -1.6840696  -0.28189445 -0.74536055]\n",
      "Reset environment\n",
      "Episode reward: 659.70984\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7266405  -0.7318109  -0.73753    -1.678497   -0.27809078 -0.74071336]\n",
      "Reset environment\n",
      "Episode reward: -469.23212\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7263762  -0.7313162  -0.73747337 -1.678586   -0.27758703 -0.7404238 ]\n",
      "Reset environment\n",
      "Episode reward: 757.1907\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.72406626 -0.72902846 -0.7351534  -1.6753702  -0.2759987  -0.73811775]\n",
      "Reset environment\n",
      "Episode reward: -4542.5083\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7325627  -0.73968476 -0.74139297 -1.7013949  -0.27615985 -0.7464508 ]\n",
      "Reset environment\n",
      "Episode reward: -385.98215\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7318098  -0.73930794 -0.74029875 -1.6997193  -0.27596068 -0.7457018 ]\n",
      "Reset environment\n",
      "Episode reward: 567.5995\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7276027  -0.73499376 -0.736197   -1.6946102  -0.2725637  -0.7414987 ]\n",
      "Reset environment\n",
      "Episode reward: -4774.304\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.73428017 -0.74303323 -0.7413702  -1.7261034  -0.26821667 -0.7480726 ]\n",
      "Reset environment\n",
      "Episode reward: 268.23737\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.73123944 -0.7401591  -0.738185   -1.7222675  -0.2658446  -0.74502134]\n",
      "Reset environment\n",
      "Episode reward: -366.6391\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7305224  -0.7396057  -0.73729044 -1.7212783  -0.2653192  -0.744295  ]\n",
      "Reset environment\n",
      "Episode reward: -7128.085\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.75052845 -0.7604289  -0.75658405 -1.7597865  -0.27599064 -0.76426727]\n",
      "Reset environment\n",
      "Episode reward: 4782.956\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7337046  -0.7433748  -0.73999137 -1.7412468  -0.26144934 -0.7474292 ]\n",
      "Reset environment\n",
      "Episode reward: 464.47964\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.72994787 -0.7395678  -0.7362721  -1.7364092  -0.25859267 -0.74365723]\n",
      "Reset environment\n",
      "Episode reward: -575.72076\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7302219  -0.7394768  -0.73688734 -1.7368705  -0.2585584  -0.7439137 ]\n",
      "Reset environment\n",
      "Episode reward: 980.9634\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.72443384 -0.7333866  -0.73143655 -1.7301941  -0.25360614 -0.73812985]\n",
      "Reset environment\n",
      "Episode reward: 494.64862\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7204052  -0.7289411  -0.72781086 -1.7253312  -0.25020117 -0.7340858 ]\n",
      "Reset environment\n",
      "Episode reward: 372.15256\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7170014 -0.7254825 -0.7244446 -1.7208604 -0.2476643 -0.7306676]\n",
      "Reset environment\n",
      "Episode reward: 1333.7566\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7099449  -0.71868545 -0.71717477 -1.7128383  -0.24162705 -0.7236237 ]\n",
      "Reset environment\n",
      "Episode reward: 1034.351\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7040804  -0.71269125 -0.71144235 -1.7062922  -0.23656034 -0.7177486 ]\n",
      "Reset environment\n",
      "Episode reward: 917.44086\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.69863087 -0.707116   -0.7061361  -1.7001392  -0.23187806 -0.71230346]\n",
      "Reset environment\n",
      "Episode reward: 54.74176\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6963394  -0.705015   -0.7036725  -1.6970804  -0.230177   -0.71001226]\n",
      "Reset environment\n",
      "Episode reward: 645.97455\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.69189364 -0.7004964  -0.699309   -1.6916922  -0.22655983 -0.70556164]\n",
      "Reset environment\n",
      "Episode reward: 1307.7227\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.68490666 -0.6933772  -0.6924602  -1.6837963  -0.22054881 -0.6985729 ]\n",
      "Reset environment\n",
      "Episode reward: -9748.776\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.71469176 -0.7240644  -0.7209451  -1.73027    -0.24164192 -0.7281637 ]\n",
      "Reset environment\n",
      "Episode reward: -3994.773\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7193009  -0.72789526 -0.7262801  -1.7523867  -0.23758186 -0.73260665]\n",
      "Reset environment\n",
      "Episode reward: 193.53064\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.71658677 -0.7248142  -0.72389406 -1.749004   -0.23530114 -0.7298761 ]\n",
      "Reset environment\n",
      "Episode reward: -515.92615\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7164229 -0.7248519 -0.7235291 -1.7485563 -0.2352741 -0.72971  ]\n",
      "Reset environment\n",
      "Episode reward: 101.09613\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.71410346 -0.72249436 -0.72121584 -1.7449764  -0.23384513 -0.7273646 ]\n",
      "Reset environment\n",
      "Episode reward: 1855.3025\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7081524  -0.71656287 -0.715251   -1.7379563  -0.22897056 -0.7214084 ]\n",
      "Reset environment\n",
      "Episode reward: -148.93057\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.70670336 -0.7149145  -0.7139966  -1.7358996  -0.22792241 -0.7199607 ]\n",
      "Reset environment\n",
      "Episode reward: -383.68652\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.7060507  -0.7144263  -0.71320766 -1.734513   -0.22774369 -0.71930397]\n",
      "Reset environment\n",
      "Episode reward: 2959.5032\n",
      "Total Steps: 353\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6950677  -0.70458996 -0.70105827 -1.7216105  -0.21870625 -0.70828456]\n",
      "Reset environment\n",
      "Episode reward: 4277.4985\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.68018335 -0.68957585 -0.6863422  -1.7051492  -0.20582134 -0.69340575]\n",
      "Reset environment\n",
      "Episode reward: -254.03926\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.67912024 -0.6886809  -0.68511    -1.7035966  -0.20510304 -0.6923405 ]\n",
      "Reset environment\n",
      "Episode reward: 5912.268\n",
      "Total Steps: 233\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.65844584 -0.6678002  -0.6646877  -1.6808298  -0.1872768  -0.6716434 ]\n",
      "Reset environment\n",
      "Episode reward: 2998.0796\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.64567333 -0.6554482  -0.6515762  -1.6663277  -0.17648609 -0.65886885]\n",
      "Reset environment\n",
      "Episode reward: 208.18683\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6429617  -0.65293634 -0.6486708  -1.6630213  -0.17425676 -0.65615475]\n",
      "Reset environment\n",
      "Episode reward: 1181.0316\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6365351  -0.6465317  -0.6422427  -1.6551692  -0.16909713 -0.64971477]\n",
      "Reset environment\n",
      "Episode reward: -4968.98\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6542304  -0.66529477 -0.6589094  -1.6985477  -0.17285383 -0.6672684 ]\n",
      "Reset environment\n",
      "Episode reward: 908.3512\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6490512  -0.66013527 -0.6537175  -1.6925018  -0.16851075 -0.6620845 ]\n",
      "Reset environment\n",
      "Episode reward: 1720.7249\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6407775  -0.6518631  -0.64547473 -1.6831231  -0.16140446 -0.6538036 ]\n",
      "Reset environment\n",
      "Episode reward: 385.35187\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6374205  -0.6485382  -0.64208436 -1.678705   -0.15891515 -0.6504441 ]\n",
      "Reset environment\n",
      "Episode reward: -1345.2877\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.64000976 -0.65058523 -0.64518046 -1.6809536  -0.16136065 -0.6530326 ]\n",
      "Reset environment\n",
      "Episode reward: 841.53845\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6350458  -0.6455396  -0.64030164 -1.6751903  -0.1571839  -0.6480542 ]\n",
      "Reset environment\n",
      "Episode reward: 570.95154\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6310556  -0.641619   -0.6362415  -1.6702676  -0.15401983 -0.6440611 ]\n",
      "Reset environment\n",
      "Episode reward: 730.37524\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.62630624 -0.63688767 -0.6315016  -1.6639878  -0.15051877 -0.6393072 ]\n",
      "Reset environment\n",
      "Episode reward: -5484.7285\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.64292026 -0.6529824  -0.64878535 -1.698235   -0.15763965 -0.65577936]\n",
      "Reset environment\n",
      "Episode reward: 376.19223\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6396283  -0.6498743  -0.6453321  -1.6941793  -0.15499574 -0.6524884 ]\n",
      "Reset environment\n",
      "Episode reward: -180.70383\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6382707  -0.64868563 -0.6438155  -1.6921222  -0.15410538 -0.6511289 ]\n",
      "Reset environment\n",
      "Episode reward: 905.9096\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6330212  -0.643535   -0.63848275 -1.6859844  -0.14972904 -0.6458708 ]\n",
      "Reset environment\n",
      "Episode reward: 1423.481\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6260639  -0.6365566  -0.6315786  -1.6781904  -0.14373493 -0.6389036 ]\n",
      "Reset environment\n",
      "Episode reward: 3854.9048\n",
      "Total Steps: 298\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.60978544 -0.62110597 -0.6145909  -1.6592416  -0.13007678 -0.62263834]\n",
      "Reset environment\n",
      "Episode reward: 548.5323\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6059006  -0.6172198  -0.6107126  -1.654267   -0.12710878 -0.61874574]\n",
      "Reset environment\n",
      "Episode reward: 648.9932\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6017127  -0.61299515 -0.6065572  -1.6491041  -0.12376384 -0.6145402 ]\n",
      "Reset environment\n",
      "Episode reward: 1044.0109\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.59599453 -0.6075037  -0.60064816 -1.6422344  -0.1190609  -0.6088197 ]\n",
      "Reset environment\n",
      "Episode reward: -250.70334\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5950704  -0.60637397 -0.59990203 -1.6410215  -0.11823641 -0.6078713 ]\n",
      "Reset environment\n",
      "Episode reward: 269.0492\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5922578  -0.60356545 -0.597095   -1.6370864  -0.11627992 -0.6050552 ]\n",
      "Reset environment\n",
      "Episode reward: 676.7632\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5879553  -0.5991774  -0.5928637  -1.6319227  -0.11276902 -0.6007414 ]\n",
      "Reset environment\n",
      "Episode reward: 575.0271\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5840122  -0.5951078  -0.5890488  -1.6272585  -0.10952015 -0.59679186]\n",
      "Reset environment\n",
      "Episode reward: -287.91293\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.58302903 -0.59436655 -0.5878359  -1.6257098  -0.10887592 -0.59581023]\n",
      "Reset environment\n",
      "Episode reward: 106.89151\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.58073545 -0.59192127 -0.58568865 -1.6226693  -0.1071373  -0.59350485]\n",
      "Reset environment\n",
      "Episode reward: 1269.7898\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5742172 -0.5855099 -0.5790975 -1.6152152 -0.1016172 -0.5869812]\n",
      "Reset environment\n",
      "Episode reward: -8426.498\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.60842174 -0.61953247 -0.61286616 -1.6736689  -0.12131492 -0.62099075]\n",
      "Reset environment\n",
      "Episode reward: 908.80896\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6058458  -0.616945   -0.6103009  -1.6700749  -0.11942044 -0.61840373]\n",
      "Reset environment\n",
      "Episode reward: 305.03833\n",
      "Total Steps: 20\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6054563  -0.61655426 -0.6099132  -1.6694554  -0.11917052 -0.61801046]\n",
      "Reset environment\n",
      "Episode reward: -233.50769\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6044974  -0.6153341  -0.6092146  -1.668003   -0.11848187 -0.61704946]\n",
      "Reset environment\n",
      "Episode reward: 51.45813\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.60241395 -0.6130502  -0.60735583 -1.6653417  -0.11684807 -0.6149725 ]\n",
      "Reset environment\n",
      "Episode reward: -10723.436\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6341136  -0.6456166  -0.6376899  -1.7211286  -0.13609575 -0.6464632 ]\n",
      "Reset environment\n",
      "Episode reward: -109.90869\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.63251173 -0.64330506 -0.6367723  -1.7190042  -0.13477455 -0.6448587 ]\n",
      "Reset environment\n",
      "Episode reward: 4029.4446\n",
      "Total Steps: 471\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6195537  -0.62920064 -0.6250038  -1.7046447  -0.12398556 -0.63187444]\n",
      "Reset environment\n",
      "Episode reward: 310.13727\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6165894  -0.62615556 -0.6221367  -1.7007954  -0.12170628 -0.6289172 ]\n",
      "Reset environment\n",
      "Episode reward: 786.05457\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6119985  -0.6215247  -0.6175829  -1.6952986  -0.11795209 -0.6243272 ]\n",
      "Reset environment\n",
      "Episode reward: 1023.26685\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6064816  -0.61578566 -0.61228144 -1.6889637  -0.11322881 -0.6188076 ]\n",
      "Reset environment\n",
      "Episode reward: -10.830688\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.604557   -0.6139619  -0.61027545 -1.6861918  -0.11193664 -0.6168809 ]\n",
      "Reset environment\n",
      "Episode reward: 3633.591\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.58960766 -0.59880924 -0.5955855  -1.6698347  -0.09878763 -0.6019439 ]\n",
      "Reset environment\n",
      "Episode reward: -5070.596\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6039341  -0.61056805 -0.61230165 -1.699209   -0.10656702 -0.6161521 ]\n",
      "Reset environment\n",
      "Episode reward: 623.7313\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.59996146 -0.60668683 -0.60823435 -1.6944529  -0.10329258 -0.6121714 ]\n",
      "Reset environment\n",
      "Episode reward: 530.62115\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.596335   -0.60318947 -0.6044653  -1.6899832  -0.10032628 -0.60853744]\n",
      "Reset environment\n",
      "Episode reward: 502.92505\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5927246  -0.5996649  -0.60078615 -1.685495   -0.09744965 -0.60491884]\n",
      "Reset environment\n",
      "Episode reward: -7679.645\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.62653935 -0.63278323 -0.63483137 -1.7318877  -0.12445518 -0.63860583]\n",
      "Reset environment\n",
      "Episode reward: 2675.3784\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6149579  -0.6209261  -0.6235488  -1.7188005  -0.11451819 -0.6270146 ]\n",
      "Reset environment\n",
      "Episode reward: 865.9557\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6101225  -0.6161569  -0.6186671  -1.7132004  -0.11043832 -0.6221786 ]\n",
      "Reset environment\n",
      "Episode reward: 994.4488\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.60488045 -0.6109406  -0.61341894 -1.7072046  -0.10597584 -0.6169395 ]\n",
      "Reset environment\n",
      "Episode reward: 294.79248\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.60449195 -0.61054397 -0.6130281  -1.7063271  -0.10590708 -0.61654437]\n",
      "Reset environment\n",
      "Episode reward: -234.3183\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6033952  -0.60972714 -0.611674   -1.7046854  -0.10510127 -0.6154654 ]\n",
      "Reset environment\n",
      "Episode reward: 874.7258\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5984274  -0.60448736 -0.6070094  -1.6986161  -0.1009864  -0.61048746]\n",
      "Reset environment\n",
      "Episode reward: 3473.139\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.58734304 -0.59332925 -0.59604657 -1.6861918  -0.09152801 -0.59940094]\n",
      "Reset environment\n",
      "Episode reward: 2171.1099\n",
      "Total Steps: 256\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5768706  -0.5819784  -0.5865148  -1.674038   -0.08265791 -0.5889643 ]\n",
      "Reset environment\n",
      "Episode reward: -2606.6096\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6276393  -0.63232833 -0.63753223 -1.7278036  -0.1286548  -0.63970816]\n",
      "Reset environment\n",
      "Episode reward: 224.28217\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.62505704 -0.6296485  -0.63504976 -1.7243383  -0.12673251 -0.63711745]\n",
      "Reset environment\n",
      "Episode reward: 553.0536\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6213002  -0.62593883 -0.6312499  -1.7197441  -0.12372313 -0.6333553 ]\n",
      "Reset environment\n",
      "Episode reward: 581.9379\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6199589  -0.624588   -0.6299006  -1.7177973  -0.12276217 -0.631998  ]\n",
      "Reset environment\n",
      "Episode reward: -90.20433\n",
      "Total Steps: 1774\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.61924213 -0.6243024  -0.62859905 -1.7331406  -0.11715542 -0.6312196 ]\n",
      "Reset environment\n",
      "Episode reward: -303.8106\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.61852795 -0.62323934 -0.62822825 -1.7316824  -0.11676183 -0.63048553]\n",
      "Reset environment\n",
      "Episode reward: -5811.5654\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.62335795 -0.6249856  -0.6358046  -1.7444305  -0.11952148 -0.63504106]\n",
      "Reset environment\n",
      "Episode reward: 409.6365\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6201801  -0.62170887 -0.6327415  -1.7404085  -0.11701963 -0.63185745]\n",
      "Reset environment\n",
      "Episode reward: 1305.3982\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6139997  -0.6155121  -0.6266089  -1.7333753  -0.11176265 -0.6256792 ]\n",
      "Reset environment\n",
      "Episode reward: -6655.248\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6253689  -0.62797105 -0.6368487  -1.7710284  -0.11356304 -0.6369649 ]\n",
      "Reset environment\n",
      "Episode reward: -9013.292\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6480455  -0.6507218  -0.6594636  -1.7977203  -0.13186067 -0.6596349 ]\n",
      "Reset environment\n",
      "Episode reward: 1065.5767\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.64264345 -0.64532447 -0.65405864 -1.7911247  -0.1275115  -0.6542307 ]\n",
      "Reset environment\n",
      "Episode reward: -6060.9946\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.65644765 -0.6595229  -0.6674179  -1.8221308  -0.13317637 -0.66793346]\n",
      "Reset environment\n",
      "Episode reward: -2447.656\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.65889037 -0.6624852  -0.6695771  -1.8342197  -0.13042895 -0.670366  ]\n",
      "Reset environment\n",
      "Episode reward: 1185.4047\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.65321577 -0.6568518  -0.66387004 -1.8276732  -0.12559554 -0.66469043]\n",
      "Reset environment\n",
      "Episode reward: 1329.4644\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.64679295 -0.65074    -0.65714777 -1.8204076  -0.12005493 -0.65826595]\n",
      "Reset environment\n",
      "Episode reward: -487.00668\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6466044  -0.6503715  -0.6571568  -1.8196297  -0.12009213 -0.6580867 ]\n",
      "Reset environment\n",
      "Episode reward: 4680.872\n",
      "Total Steps: 281\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.628689   -0.63170505 -0.640092   -1.799843   -0.10436754 -0.6402093 ]\n",
      "Reset environment\n",
      "Episode reward: -305.9282\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6279076  -0.630756   -0.63947994 -1.798878   -0.10361265 -0.63941985]\n",
      "Reset environment\n",
      "Episode reward: 188.75403\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.62550974 -0.6281603  -0.63726354 -1.7958397  -0.10160839 -0.6370106 ]\n",
      "Reset environment\n",
      "Episode reward: -824.7829\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6264682  -0.6295849  -0.63777256 -1.7964723  -0.10261834 -0.6379638 ]\n",
      "Reset environment\n",
      "Episode reward: 578.05457\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6228775  -0.62581235 -0.6343597  -1.7923383  -0.09953843 -0.6343777 ]\n",
      "Reset environment\n",
      "Episode reward: -2324.9126\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6231168  -0.62408966 -0.63665605 -1.8073531  -0.09401973 -0.6345984 ]\n",
      "Reset environment\n",
      "Episode reward: 866.4373\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6209541  -0.6219039  -0.6345178  -1.8047361  -0.09225224 -0.6324395 ]\n",
      "Reset environment\n",
      "Episode reward: -707.7532\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6209852  -0.6213353  -0.63518304 -1.8042507  -0.09239205 -0.63248783]\n",
      "Reset environment\n",
      "Episode reward: 1276.05\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.615108   -0.6156293  -0.6291546  -1.7973921  -0.08739003 -0.6266058 ]\n",
      "Reset environment\n",
      "Episode reward: 396.8897\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6120779  -0.6124316  -0.6263031  -1.7937785  -0.08485905 -0.6235728 ]\n",
      "Reset environment\n",
      "Episode reward: -1186.5327\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.614169   -0.61372817 -0.6291813  -1.7955773  -0.08680945 -0.62566453]\n",
      "Reset environment\n",
      "Episode reward: -316.64386\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.6134241  -0.61284286 -0.6285687  -1.7940937  -0.08647653 -0.624918  ]\n",
      "Reset environment\n",
      "Episode reward: 4429.8726\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.59680855 -0.5963978  -0.6118587  -1.7754829  -0.07218724 -0.60828555]\n",
      "Reset environment\n",
      "Episode reward: 1080.1187\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5915795  -0.5913986  -0.60642827 -1.7691827  -0.06785707 -0.6030504 ]\n",
      "Reset environment\n",
      "Episode reward: -3022.657\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.59529203 -0.5957467  -0.610098   -1.7802905  -0.06872437 -0.60695547]\n",
      "Reset environment\n",
      "Episode reward: 1435.9192\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.58892787 -0.58938    -0.6037324  -1.7728051  -0.06337763 -0.60059077]\n",
      "Reset environment\n",
      "Episode reward: 3798.8994\n",
      "Total Steps: 648\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5790796  -0.5804264  -0.5929455  -1.7630212  -0.05441205 -0.5907208 ]\n",
      "Reset environment\n",
      "Episode reward: 3971.268\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5667058  -0.5680039  -0.58068794 -1.7492965  -0.04378167 -0.5783646 ]\n",
      "Reset environment\n",
      "Episode reward: 1519.3237\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5601119  -0.5615466  -0.57399553 -1.7416837  -0.0381305  -0.5717684 ]\n",
      "Reset environment\n",
      "Episode reward: 673.57513\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5563306  -0.55771846 -0.57025045 -1.737035   -0.03510575 -0.5679744 ]\n",
      "Reset environment\n",
      "Episode reward: -429.4603\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5561447  -0.55685705 -0.5707751  -1.7363452  -0.03487338 -0.5678099 ]\n",
      "Reset environment\n",
      "Episode reward: -18.26706\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5544082  -0.55537945 -0.5687854  -1.7337648  -0.03367573 -0.5660684 ]\n",
      "Reset environment\n",
      "Episode reward: 372.58252\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.55138916 -0.5528015  -0.56535035 -1.7300354  -0.0313356  -0.56306165]\n",
      "Reset environment\n",
      "Episode reward: 3055.0947\n",
      "Total Steps: 260\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5393812  -0.5414217  -0.55279166 -1.7166435  -0.02079524 -0.55108804]\n",
      "Reset environment\n",
      "Episode reward: 1014.66425\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.53448963 -0.53659    -0.54786134 -1.7110531  -0.01656072 -0.5462018 ]\n",
      "Reset environment\n",
      "Episode reward: 2976.896\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-5.2004391e-01 -5.2037513e-01 -5.3568918e-01 -1.6999736e+00\n",
      " -1.3211415e-03 -5.3204238e-01]\n",
      "Reset environment\n",
      "Episode reward: -10184.844\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5452079  -0.5455524  -0.560629   -1.7458012  -0.01867697 -0.5569987 ]\n",
      "Reset environment\n",
      "Episode reward: 2860.2961\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5344114  -0.5344288  -0.550214   -1.7333052  -0.00940694 -0.5462183 ]\n",
      "Reset environment\n",
      "Episode reward: -5.0669556\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.53271693 -0.5325587  -0.5486793  -1.7310313  -0.00811331 -0.5445264 ]\n",
      "Reset environment\n",
      "Episode reward: -9554.455\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.56252086 -0.5621071  -0.57827055 -1.7754933  -0.02816612 -0.57414776]\n",
      "Reset environment\n",
      "Episode reward: 790.69653\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5584152  -0.55825025 -0.5739519  -1.7705938  -0.0247328  -0.5700617 ]\n",
      "Reset environment\n",
      "Episode reward: 1829.9445\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5509956  -0.5507077  -0.566663   -1.7623212  -0.01824892 -0.5626279 ]\n",
      "Reset environment\n",
      "Episode reward: 1080.1367\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.54822123 -0.547922   -0.56389266 -1.7589204  -0.01600462 -0.5598526 ]\n",
      "Reset environment\n",
      "Episode reward: 3240.1382\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5390202  -0.5387029  -0.55471784 -1.7487022  -0.00796168 -0.55064595]\n",
      "Reset environment\n",
      "Episode reward: 898.2062\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5345934  -0.5342262  -0.55032057 -1.7435355  -0.004231   -0.5462155 ]\n",
      "Reset environment\n",
      "Episode reward: 403.6837\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.53171676 -0.53147477 -0.5473285  -1.7399175  -0.00193268 -0.5433359 ]\n",
      "Reset environment\n",
      "Episode reward: 630.1007\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-5.2808559e-01 -5.2774805e-01 -5.4381096e-01 -1.7355841e+00\n",
      "  1.0778939e-03 -5.3971428e-01]\n",
      "Reset environment\n",
      "Episode reward: 430.43237\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.52504504 -0.52452916 -0.54095614 -1.7315187   0.00343082 -0.5366743 ]\n",
      "Reset environment\n",
      "Episode reward: 1098.3208\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.52007914 -0.51942354 -0.53611976 -1.7258186   0.00768685 -0.53169656]\n",
      "Reset environment\n",
      "Episode reward: 927.6397\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5156054  -0.5151667  -0.53143215 -1.7205565   0.01147939 -0.5272161 ]\n",
      "Reset environment\n",
      "Episode reward: -4716.6216\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5253392  -0.52559036 -0.5406918  -1.7491992   0.00639728 -0.53699994]\n",
      "Reset environment\n",
      "Episode reward: 1712.9603\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.52060723 -0.5208297  -0.535982   -1.7437493   0.01043079 -0.5322567 ]\n",
      "Reset environment\n",
      "Episode reward: -4592.195\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5293331  -0.53143585 -0.5429404  -1.7652708   0.005456   -0.5409709 ]\n",
      "Reset environment\n",
      "Episode reward: 1000.23865\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5246444  -0.526683   -0.53831226 -1.7599053   0.00950092 -0.53627986]\n",
      "Reset environment\n",
      "Episode reward: 491.46964\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.521421   -0.52324766 -0.53531295 -1.7559137   0.01218305 -0.5330536 ]\n",
      "Reset environment\n",
      "Episode reward: 737.20935\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5175485  -0.5192675  -0.5315511  -1.7513754   0.01544092 -0.52917403]\n",
      "Reset environment\n",
      "Episode reward: 596.4346\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5140586  -0.51570773 -0.52814186 -1.7470167   0.01819724 -0.52568877]\n",
      "Reset environment\n",
      "Episode reward: 747.91614\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.51014215 -0.5118193  -0.5241859  -1.7422892   0.02142277 -0.5217573 ]\n",
      "Reset environment\n",
      "Episode reward: 367.83292\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.5073523  -0.5088517  -0.5215682  -1.7389383   0.02375569 -0.51896954]\n",
      "Reset environment\n",
      "Episode reward: 611.1612\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.504      -0.50494105 -0.5187961  -1.7346935   0.02641314 -0.515626  ]\n",
      "Reset environment\n",
      "Episode reward: 258.6736\n",
      "Total Steps: 8\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.50382483 -0.50476784 -0.5186195  -1.7344307   0.02653148 -0.5154495 ]\n",
      "Reset environment\n",
      "Episode reward: 1279.7029\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.498247   -0.49902788 -0.5132232  -1.7280749   0.03134163 -0.50987244]\n",
      "Reset environment\n",
      "Episode reward: 909.22534\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.49373826 -0.4943171  -0.5089123  -1.7226387   0.03513499 -0.5053689 ]\n",
      "Reset environment\n",
      "Episode reward: 448.1233\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4907785  -0.49117634 -0.50613    -1.7191267   0.03765956 -0.5024029 ]\n",
      "Reset environment\n",
      "Episode reward: 4238.133\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.48017812 -0.48247954 -0.49466553 -1.7186174   0.04815164 -0.49207363]\n",
      "Reset environment\n",
      "Episode reward: -639.5149\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4804308  -0.48253083 -0.49511525 -1.7183033   0.04765692 -0.49231356]\n",
      "Reset environment\n",
      "Episode reward: 2953.459\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.47224757 -0.4742959  -0.48698747 -1.7090522   0.05470935 -0.4841151 ]\n",
      "Reset environment\n",
      "Episode reward: -2205.3162\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.47685313 -0.48014697 -0.48997644 -1.7229087   0.05498287 -0.4885755 ]\n",
      "Reset environment\n",
      "Episode reward: 3471.1792\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4601392  -0.4604293  -0.4765425  -1.7090154   0.07120217 -0.47197446]\n",
      "Reset environment\n",
      "Episode reward: 1508.2971\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.45397258 -0.454331   -0.47032672 -1.7017967   0.07637508 -0.46580356]\n",
      "Reset environment\n",
      "Episode reward: 70.02255\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.45217717 -0.45233494 -0.46873072 -1.6994647   0.0778553  -0.4640056 ]\n",
      "Reset environment\n",
      "Episode reward: -110.62027\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.45091572 -0.45131862 -0.46724218 -1.6976563   0.07878389 -0.46274596]\n",
      "Reset environment\n",
      "Episode reward: 1966.6709\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.44338846 -0.44377914 -0.45973384 -1.6891627   0.08535326 -0.4552214 ]\n",
      "Reset environment\n",
      "Episode reward: -5788.592\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.45507574 -0.45599946 -0.4706306  -1.7261548   0.08299056 -0.46680352]\n",
      "Reset environment\n",
      "Episode reward: 982.9353\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4505868  -0.45147476 -0.4661898  -1.7209717   0.086835   -0.4623179 ]\n",
      "Reset environment\n",
      "Episode reward: 891.53284\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.44633818 -0.4471237  -0.46205294 -1.7161463   0.09047415 -0.45807147]\n",
      "Reset environment\n",
      "Episode reward: 722.1251\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.44480383 -0.44558737 -0.46052456 -1.714104    0.09163868 -0.45653832]\n",
      "Reset environment\n",
      "Episode reward: -1458.55\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4470611  -0.44719076 -0.46343523 -1.7156518   0.08926681 -0.4587868 ]\n",
      "Reset environment\n",
      "Episode reward: 1432.4751\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.44119805 -0.44128603 -0.4576341  -1.7090076   0.09435304 -0.45293447]\n",
      "Reset environment\n",
      "Episode reward: 659.857\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4376513  -0.43763348 -0.454194   -1.7047653   0.09729419 -0.4493857 ]\n",
      "Reset environment\n",
      "Episode reward: 1039.6493\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.43295336 -0.43302527 -0.44941214 -1.6988795   0.10102812 -0.44468424]\n",
      "Reset environment\n",
      "Episode reward: 531.15576\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.42984083 -0.42984575 -0.446373   -1.6949527   0.10347559 -0.4415822 ]\n",
      "Reset environment\n",
      "Episode reward: 2826.3667\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.42220116 -0.4221258  -0.43883318 -1.6865082   0.11012372 -0.43394792]\n",
      "Reset environment\n",
      "Episode reward: 1108.3491\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.41733944 -0.4171596  -0.43409422 -1.6805152   0.11405636 -0.42909515]\n",
      "Reset environment\n",
      "Episode reward: 457.14505\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.41503686 -0.41429496 -0.43240017 -1.6772264   0.11583006 -0.42681378]\n",
      "Reset environment\n",
      "Episode reward: -44.15692\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.41359964 -0.4131032  -0.4307227  -1.6752745   0.11693667 -0.42537946]\n",
      "Reset environment\n",
      "Episode reward: -1146.7432\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4127469  -0.4145326  -0.42767587 -1.6892962   0.12199229 -0.4246023 ]\n",
      "Reset environment\n",
      "Episode reward: -1125.2822\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.41461852 -0.41585228 -0.4300849  -1.6908275   0.12019527 -0.42647156]\n",
      "Reset environment\n",
      "Episode reward: -2900.271\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.41822544 -0.4201191  -0.4331314  -1.708551    0.12141066 -0.43010134]\n",
      "Reset environment\n",
      "Episode reward: 301.8278\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4161538  -0.41869792 -0.43041423 -1.7058748   0.12316652 -0.4280356 ]\n",
      "Reset environment\n",
      "Episode reward: 311.29227\n",
      "Total Steps: 26\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.41581264 -0.41835955 -0.43007275 -1.7052385   0.12333732 -0.42769256]\n",
      "Reset environment\n",
      "Episode reward: 811.54126\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4119216  -0.41440415 -0.42623603 -1.70059     0.12660168 -0.4237948 ]\n",
      "Reset environment\n",
      "Episode reward: -392.1181\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4076703  -0.40934107 -0.42284822 -1.7108476   0.13303848 -0.41938826]\n",
      "Reset environment\n",
      "Episode reward: 1920.9624\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.40290484 -0.40454483 -0.41810715 -1.7053112   0.13706453 -0.4146164 ]\n",
      "Reset environment\n",
      "Episode reward: 51.44342\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.4021005  -0.40395015 -0.41688555 -1.713278    0.13967095 -0.4136306 ]\n",
      "Reset environment\n",
      "Episode reward: -295.31738\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.40301666 -0.40561005 -0.41707626 -1.7136889   0.13854666 -0.41455755]\n",
      "Reset environment\n",
      "Episode reward: 327.6661\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.40056667 -0.40308917 -0.41469684 -1.7103977   0.14038472 -0.41210145]\n",
      "Reset environment\n",
      "Episode reward: 584.1388\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.39749473 -0.40030822 -0.4113464  -1.7064608   0.14284036 -0.40902555]\n",
      "Reset environment\n",
      "Episode reward: 1442.1605\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.39385036 -0.39666247 -0.40770543 -1.7020457   0.14580588 -0.40537563]\n",
      "Reset environment\n",
      "Episode reward: 664.0886\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3904134  -0.39315686 -0.40434596 -1.6978693   0.14860372 -0.40194288]\n",
      "Reset environment\n",
      "Episode reward: 334.731\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3880286  -0.39118403 -0.40156353 -1.6947938   0.15049967 -0.3995539 ]\n",
      "Reset environment\n",
      "Episode reward: 1504.9309\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.38221836 -0.38527855 -0.39586765 -1.688122    0.15550801 -0.3937439 ]\n",
      "Reset environment\n",
      "Episode reward: 1081.2256\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.37758172 -0.38081917 -0.39107788 -1.6826376   0.15939173 -0.3891068 ]\n",
      "Reset environment\n",
      "Episode reward: -1045.1101\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3792244  -0.38226795 -0.39289358 -1.6844571   0.15802786 -0.3907492 ]\n",
      "Reset environment\n",
      "Episode reward: 1119.1992\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3745009  -0.37747952 -0.38824156 -1.6791737   0.16214608 -0.38603324]\n",
      "Reset environment\n",
      "Episode reward: 712.9946\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.37050617 -0.37376657 -0.38399258 -1.6742909   0.16514191 -0.38202897]\n",
      "Reset environment\n",
      "Episode reward: 678.7989\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3670367  -0.37024206 -0.38056183 -1.6700492   0.16795266 -0.3785517 ]\n",
      "Reset environment\n",
      "Episode reward: -1821.0256\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.37010455 -0.37345004 -0.38358244 -1.6847452   0.17091194 -0.38149458]\n",
      "Reset environment\n",
      "Episode reward: -1130.023\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3718351  -0.3755495  -0.3849315  -1.6863176   0.16930963 -0.3832252 ]\n",
      "Reset environment\n",
      "Episode reward: 968.0564\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.36754927 -0.3713637  -0.3805626  -1.6811736   0.17284086 -0.37893492]\n",
      "Reset environment\n",
      "Episode reward: -1085.5875\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.36418325 -0.3681519  -0.37704602 -1.6864476   0.17952262 -0.37555832]\n",
      "Reset environment\n",
      "Episode reward: 3814.92\n",
      "Total Steps: 231\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.35196772 -0.3555863  -0.36523294 -1.672883    0.19030862 -0.3633482 ]\n",
      "Reset environment\n",
      "Episode reward: 979.39276\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.34766054 -0.35110635 -0.36110026 -1.6677495   0.193938   -0.35903606]\n",
      "Reset environment\n",
      "Episode reward: 804.79553\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3439497  -0.34754688 -0.3572438  -1.6634984   0.197149   -0.35532442]\n",
      "Reset environment\n",
      "Episode reward: 888.3522\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.33988544 -0.3433193  -0.35336038 -1.6587088   0.2006175  -0.35125697]\n",
      "Reset environment\n",
      "Episode reward: 4908.053\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.32690936 -0.33036035 -0.34041    -1.6442343   0.21200785 -0.33827236]\n",
      "Reset environment\n",
      "Episode reward: -193.65433\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3260367  -0.3293636  -0.33966067 -1.6426281   0.21240388 -0.3373965 ]\n",
      "Reset environment\n",
      "Episode reward: 4841.3076\n",
      "Total Steps: 239\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.31063902 -0.314229   -0.32407895 -1.6254923   0.22589238 -0.32201117]\n",
      "Reset environment\n",
      "Episode reward: 2146.293\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.30329213 -0.30719164 -0.31644526 -1.6172159   0.23205312 -0.31466302]\n",
      "Reset environment\n",
      "Episode reward: -257.92267\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.30247545 -0.3064727  -0.31551507 -1.6159402   0.23262616 -0.3138299 ]\n",
      "Reset environment\n",
      "Episode reward: 1133.8274\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29782823 -0.3017765  -0.3109175  -1.6106482   0.23661114 -0.30918238]\n",
      "Reset environment\n",
      "Episode reward: 275.89923\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29558933 -0.2993942  -0.30881035 -1.6077667   0.2384052  -0.30693957]\n",
      "Reset environment\n",
      "Episode reward: -3398.7915\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3041374  -0.31005913 -0.3153508  -1.6253507   0.23128638 -0.31532636]\n",
      "Reset environment\n",
      "Episode reward: -1730.1482\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.30564103 -0.31098852 -0.31760782 -1.640539    0.23454875 -0.31680483]\n",
      "Reset environment\n",
      "Episode reward: 845.61914\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3017974  -0.30696145 -0.31396213 -1.6359991   0.23781279 -0.31296897]\n",
      "Reset environment\n",
      "Episode reward: -6638.708\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.31794766 -0.32279164 -0.33043033 -1.6718014   0.22879711 -0.32902288]\n",
      "Reset environment\n",
      "Episode reward: -8013.138\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.336167   -0.340955   -0.3486148  -1.7109733   0.21878494 -0.34709695]\n",
      "Reset environment\n",
      "Episode reward: -7159.7773\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.37321058 -0.37715223 -0.38659585 -1.7455788   0.18592216 -0.38409305]\n",
      "Reset environment\n",
      "Episode reward: -299.5647\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.37247854 -0.37629002 -0.38599584 -1.7446071   0.18656665 -0.3833609 ]\n",
      "Reset environment\n",
      "Episode reward: -5220.2427\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.38300774 -0.38639116 -0.39699128 -1.7740377   0.1822794  -0.3938564 ]\n",
      "Reset environment\n",
      "Episode reward: 368.87988\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3805801  -0.38405433 -0.39447471 -1.7709087   0.18416329 -0.39142454]\n",
      "Reset environment\n",
      "Episode reward: 1378.255\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3754151  -0.37892804 -0.3892906  -1.7649626   0.18857862 -0.38626087]\n",
      "Reset environment\n",
      "Episode reward: -343.07016\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.37497157 -0.37871596 -0.38863057 -1.7640543   0.18878089 -0.38582253]\n",
      "Reset environment\n",
      "Episode reward: 1199.2146\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.37027162 -0.37392503 -0.38402614 -1.7586439   0.1928336  -0.38111606]\n",
      "Reset environment\n",
      "Episode reward: 1951.6475\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3634848  -0.36649537 -0.37789294 -1.7506728   0.19857773 -0.37434226]\n",
      "Reset environment\n",
      "Episode reward: 1832.4087\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.35897788 -0.36197487 -0.37340516 -1.7453036   0.20233329 -0.3698426 ]\n",
      "Reset environment\n",
      "Episode reward: 830.5702\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.35529226 -0.35832044 -0.36968687 -1.7408838   0.20537324 -0.3661504 ]\n",
      "Reset environment\n",
      "Episode reward: 803.86194\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3516542  -0.3549431  -0.3657974  -1.7364999   0.20840408 -0.3625097 ]\n",
      "Reset environment\n",
      "Episode reward: 1227.5032\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.34668508 -0.34941465 -0.36141595 -1.7304872   0.21257941 -0.35754585]\n",
      "Reset environment\n",
      "Episode reward: 229.64368\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3446489  -0.34731025 -0.35944736 -1.7276891   0.21407971 -0.3555157 ]\n",
      "Reset environment\n",
      "Episode reward: 987.45337\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3405557  -0.3432127  -0.3553758  -1.7228757   0.21752317 -0.35143107]\n",
      "Reset environment\n",
      "Episode reward: 400.6761\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.33804867 -0.3406788  -0.35290703 -1.719451    0.21935484 -0.34893066]\n",
      "Reset environment\n",
      "Episode reward: 1016.30774\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.335803   -0.33842158 -0.35067162 -1.7166331   0.22114605 -0.34668362]\n",
      "Reset environment\n",
      "Episode reward: 745.10706\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.33237302 -0.3351118  -0.3471412  -1.7126262   0.22405338 -0.34325454]\n",
      "Reset environment\n",
      "Episode reward: -129.24237\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.32995328 -0.3315927  -0.3457966  -1.7238668   0.23077975 -0.34073   ]\n",
      "Reset environment\n",
      "Episode reward: 175.21335\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3281008  -0.32958007 -0.34410107 -1.7214859   0.23229323 -0.3388743 ]\n",
      "Reset environment\n",
      "Episode reward: -1242.8048\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.33031857 -0.33114117 -0.34695914 -1.7232391   0.23007514 -0.34108415]\n",
      "Reset environment\n",
      "Episode reward: -1753.927\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.33264935 -0.33469528 -0.34809822 -1.7347778   0.23171547 -0.34340385]\n",
      "Reset environment\n",
      "Episode reward: 442.36447\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.33008593 -0.33224547 -0.34541014 -1.7314996   0.23377421 -0.34082693]\n",
      "Reset environment\n",
      "Episode reward: -367.64996\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.32968244 -0.33204988 -0.34480348 -1.7305835   0.23391734 -0.34042042]\n",
      "Reset environment\n",
      "Episode reward: 1332.7512\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.32471594 -0.3269725  -0.33995593 -1.724721    0.23809552 -0.33545858]\n",
      "Reset environment\n",
      "Episode reward: -1121.074\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3217089  -0.32312828 -0.33771676 -1.739332    0.24501595 -0.3324254 ]\n",
      "Reset environment\n",
      "Episode reward: -927.48645\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.3224415  -0.32598114 -0.33639207 -1.7437403   0.24531655 -0.33310816]\n",
      "Reset environment\n",
      "Episode reward: 1224.4885\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.31781402 -0.32131994 -0.33178738 -1.73854     0.24934159 -0.3284693 ]\n",
      "Reset environment\n",
      "Episode reward: 4740.918\n",
      "Total Steps: 296\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.30361876 -0.3075779  -0.31720832 -1.7222732   0.26154897 -0.3142713 ]\n",
      "Reset environment\n",
      "Episode reward: 890.5482\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29985505 -0.30385095 -0.3134122  -1.7177247   0.26467896 -0.31049857]\n",
      "Reset environment\n",
      "Episode reward: 1658.8773\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29405043 -0.29808432 -0.3075844  -1.7110068   0.26960286 -0.30469787]\n",
      "Reset environment\n",
      "Episode reward: 255.10727\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29198474 -0.2962227  -0.3053228  -1.7081537   0.27111557 -0.3026242 ]\n",
      "Reset environment\n",
      "Episode reward: -746.0695\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29252344 -0.29671052 -0.30592796 -1.7084559   0.27064255 -0.30316743]\n",
      "Reset environment\n",
      "Episode reward: -332.6027\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29211962 -0.29611304 -0.30572823 -1.7075461   0.27081865 -0.30276677]\n",
      "Reset environment\n",
      "Episode reward: -15.379089\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29082283 -0.2946562  -0.3045877  -1.7057055   0.27177796 -0.30147737]\n",
      "Reset environment\n",
      "Episode reward: -2129.5544\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29654932 -0.3022752  -0.30845544 -1.7199075   0.26966676 -0.30716455]\n",
      "Reset environment\n",
      "Episode reward: 1595.7134\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29093662 -0.29666206 -0.30286032 -1.7134285   0.27446398 -0.30154356]\n",
      "Reset environment\n",
      "Episode reward: -381.5509\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.29083443 -0.29717472 -0.3021189  -1.7127866   0.274476   -0.3014313 ]\n",
      "Reset environment\n",
      "Episode reward: 1630.0459\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.28530952 -0.29204023 -0.2962059  -1.7060454   0.2789839  -0.29589674]\n",
      "Reset environment\n",
      "Episode reward: 2417.123\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.27753934 -0.28461158 -0.28811842 -1.6972157   0.28561538 -0.2881118 ]\n",
      "Reset environment\n",
      "Episode reward: 1085.7006\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.27277175 -0.27863276 -0.28475866 -1.703571    0.29468027 -0.28338873]\n",
      "Reset environment\n",
      "Episode reward: 1637.3269\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.26713327 -0.27293915 -0.2791734  -1.6971675   0.2995685  -0.27774134]\n",
      "Reset environment\n",
      "Episode reward: 970.59644\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.2632085  -0.26895422 -0.2753132  -1.6926035   0.30290478 -0.27381647]\n",
      "Reset environment\n",
      "Episode reward: 543.6822\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.26050258 -0.26637113 -0.27249792 -1.6892879   0.30510288 -0.27111405]\n",
      "Reset environment\n",
      "Episode reward: 522.10657\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.25779352 -0.26356706 -0.26988158 -1.6859796   0.3073242  -0.26840377]\n",
      "Reset environment\n",
      "Episode reward: 784.0864\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.25443977 -0.2601543  -0.2665806  -1.6819638   0.31012    -0.26504627]\n",
      "Reset environment\n",
      "Episode reward: 4865.967\n",
      "Total Steps: 215\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.23999229 -0.24596408 -0.25192314 -1.6659511   0.32281053 -0.25059107]\n",
      "Reset environment\n",
      "Episode reward: 1226.844\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.23555577 -0.24183695 -0.2472014  -1.6606575   0.32612848 -0.246161  ]\n",
      "Reset environment\n",
      "Episode reward: -16.217651\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.236587   -0.2415531  -0.24972512 -1.6605052   0.32622313 -0.24728847]\n",
      "Reset environment\n",
      "Episode reward: 852.9098\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.23303722 -0.23789273 -0.2462887  -1.656211    0.32915723 -0.24373281]\n",
      "Reset environment\n",
      "Episode reward: 1444.7177\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22782046 -0.23225322 -0.24149933 -1.6500736   0.33361784 -0.23851137]\n",
      "Reset environment\n",
      "Episode reward: 3657.0305\n",
      "Total Steps: 282\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21626414 -0.22140928 -0.22928832 -1.6367897   0.34350324 -0.22693406]\n",
      "Reset environment\n",
      "Episode reward: 1342.5876\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21145378 -0.21661107 -0.224464   -1.6311948   0.34758997 -0.22212163]\n",
      "Reset environment\n",
      "Episode reward: 470.79248\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.2080759  -0.2134191  -0.22091134 -1.626838    0.35026556 -0.21874565]\n",
      "Reset environment\n",
      "Episode reward: 1834.1499\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.20182912 -0.20748663 -0.21439403 -1.6193556   0.35536176 -0.21248704]\n",
      "Reset environment\n",
      "Episode reward: -4230.4595\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21056244 -0.21595672 -0.22343712 -1.6483111   0.3533368  -0.2212512 ]\n",
      "Reset environment\n",
      "Episode reward: 779.2158\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.20721054 -0.21263455 -0.22005954 -1.644316    0.35613042 -0.21790695]\n",
      "Reset environment\n",
      "Episode reward: -9361.814\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22879845 -0.23460591 -0.2411277  -1.6878234   0.34176946 -0.2393967 ]\n",
      "Reset environment\n",
      "Episode reward: 391.31522\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22647376 -0.23215657 -0.23892626 -1.6848599   0.34368548 -0.23706777]\n",
      "Reset environment\n",
      "Episode reward: 868.08936\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22289474 -0.22862914 -0.23529853 -1.6806542   0.3467144  -0.23348467]\n",
      "Reset environment\n",
      "Episode reward: 1132.104\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21871419 -0.22442336 -0.23115106 -1.6758701   0.35031283 -0.22930203]\n",
      "Reset environment\n",
      "Episode reward: -8443.682\n",
      "Total Steps: 1917\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22688766 -0.23319875 -0.23882261 -1.6786298   0.33700848 -0.23748739]\n",
      "Reset environment\n",
      "Episode reward: -234.17511\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22624134 -0.23238476 -0.23832944 -1.6774423   0.33737946 -0.23683995]\n",
      "Reset environment\n",
      "Episode reward: 5257.33\n",
      "Total Steps: 335\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21345109 -0.21878998 -0.22637537 -1.662792    0.34822756 -0.22404416]\n",
      "Reset environment\n",
      "Episode reward: 601.5125\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.2106137  -0.21598421 -0.22351952 -1.6592442   0.35048652 -0.22120391]\n",
      "Reset environment\n",
      "Episode reward: 989.6063\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.2069585  -0.21268317 -0.21953313 -1.6548445   0.3533079  -0.21754368]\n",
      "Reset environment\n",
      "Episode reward: 3090.6304\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22848372 -0.2337225  -0.2415128  -1.678589    0.3325473  -0.23909047]\n",
      "Reset environment\n",
      "Episode reward: 3926.7805\n",
      "Total Steps: 343\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.2148957  -0.22087763 -0.2272125  -1.6633978   0.34466568 -0.22549722]\n",
      "Reset environment\n",
      "Episode reward: -2657.419\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21927547 -0.22567843 -0.23103052 -1.6789271   0.34311303 -0.22981225]\n",
      "Reset environment\n",
      "Episode reward: 1369.5521\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21453027 -0.22107886 -0.22615562 -1.6733676   0.3471506  -0.22506283]\n",
      "Reset environment\n",
      "Episode reward: -2094.3174\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21686563 -0.22502367 -0.22675571 -1.6885269   0.34937087 -0.22725788]\n",
      "Reset environment\n",
      "Episode reward: 325.15262\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21471228 -0.22337    -0.22411671 -1.6854353   0.35087913 -0.22510584]\n",
      "Reset environment\n",
      "Episode reward: 1002.3834\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.21092531 -0.21945556 -0.220457   -1.6809782   0.3540977  -0.22131419]\n",
      "Reset environment\n",
      "Episode reward: 1503.0002\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.2058952  -0.21447764 -0.2153743  -1.6751976   0.35842624 -0.21628629]\n",
      "Reset environment\n",
      "Episode reward: 1015.8195\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.20207593 -0.21060339 -0.21161793 -1.670748    0.36167246 -0.2124692 ]\n",
      "Reset environment\n",
      "Episode reward: -620.661\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.20365556 -0.21313961 -0.21223752 -1.6858096   0.36343914 -0.2139425 ]\n",
      "Reset environment\n",
      "Episode reward: -8105.5894\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.22543257 -0.23534968 -0.23368613 -1.719521    0.35004196 -0.23587406]\n",
      "Reset environment\n",
      "Episode reward: 6244.066\n",
      "Total Steps: 357\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.20920327 -0.2195606  -0.21702515 -1.7011894   0.3640538  -0.2196408 ]\n",
      "Reset environment\n",
      "Episode reward: 2628.936\n",
      "Total Steps: 1356\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.20391236 -0.21329002 -0.21283357 -1.7002449   0.3703614  -0.21436882]\n",
      "Reset environment\n",
      "Episode reward: 1539.1643\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.20060751 -0.20997538 -0.20953001 -1.6962479   0.37311348 -0.2110563 ]\n",
      "Reset environment\n",
      "Episode reward: 6608.997\n",
      "Total Steps: 316\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.18495665 -0.1948749  -0.19337322 -1.6786908   0.3867892  -0.1953942 ]\n",
      "Reset environment\n",
      "Episode reward: 941.2781\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.18136625 -0.19135927 -0.18970802 -1.6745342   0.38986468 -0.1917944 ]\n",
      "Reset environment\n",
      "Episode reward: 1364.8063\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.17674895 -0.18663372 -0.18520856 -1.6691755   0.3938025  -0.18718192]\n",
      "Reset environment\n",
      "Episode reward: -1283.8674\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.17767328 -0.18981585 -0.18394235 -1.6715511   0.39359888 -0.18805267]\n",
      "Reset environment\n",
      "Episode reward: 534.76324\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.1749691  -0.18741165 -0.18094523 -1.667924    0.39555547 -0.18534799]\n",
      "Reset environment\n",
      "Episode reward: 852.17114\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.17159909 -0.18444425 -0.1771907  -1.6636685   0.39808837 -0.18197489]\n",
      "Reset environment\n",
      "Episode reward: 977.30316\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.16799757 -0.1807771  -0.17365293 -1.6594113   0.40113965 -0.17836963]\n",
      "Reset environment\n",
      "Episode reward: 2019.4911\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.16151269 -0.17282623 -0.1687763  -1.6604362   0.41041577 -0.1719251 ]\n",
      "Reset environment\n",
      "Episode reward: -8371.934\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.1803318  -0.19194213 -0.1873071  -1.69424     0.39669463 -0.19070564]\n",
      "Reset environment\n",
      "Episode reward: 866.467\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.178758   -0.19036119 -0.18574448 -1.6922483   0.39797238 -0.18913193]\n",
      "Reset environment\n",
      "Episode reward: 2670.0808\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.17113969 -0.1830358  -0.17786525 -1.6834679   0.4045021  -0.18150191]\n",
      "Reset environment\n",
      "Episode reward: -533.249\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.16827652 -0.18030202 -0.1750923  -1.6925111   0.41030097 -0.17875329]\n",
      "Reset environment\n",
      "Episode reward: 579.682\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.16677387 -0.17850561 -0.1737193  -1.6970471   0.41315416 -0.17718579]\n",
      "Reset environment\n",
      "Episode reward: 31.791199\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.16541962 -0.17694171 -0.17259634 -1.6950905   0.41423017 -0.17582136]\n",
      "Reset environment\n",
      "Episode reward: -2245.7405\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.1673943  -0.18089657 -0.17247973 -1.7040603   0.41439167 -0.17771016]\n",
      "Reset environment\n",
      "Episode reward: 1195.7437\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.1632957  -0.1766633  -0.16851354 -1.6993918   0.4179886  -0.17360486]\n",
      "Reset environment\n",
      "Episode reward: 789.4441\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.16020644 -0.1734918  -0.16551135 -1.6957637   0.4206078  -0.17051183]\n",
      "Reset environment\n",
      "Episode reward: 2911.999\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.15360148 -0.16701439 -0.15896732 -1.7004676   0.4295358  -0.16375169]\n",
      "Reset environment\n",
      "Episode reward: 1223.53\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.14972177 -0.16340718 -0.15482897 -1.6957972   0.43242714 -0.1598684 ]\n",
      "Reset environment\n",
      "Episode reward: 2250.9683\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.1451223  -0.15879184 -0.15024662 -1.6905345   0.43640602 -0.15526696]\n",
      "Reset environment\n",
      "Episode reward: -6323.192\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.15751292 -0.17119594 -0.16252096 -1.7231802   0.42930338 -0.16757098]\n",
      "Reset environment\n",
      "Episode reward: -3465.6475\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.16174097 -0.17533693 -0.16672027 -1.739109    0.4269542  -0.17171474]\n",
      "Reset environment\n",
      "Episode reward: 583.50024\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.15922731 -0.17295472 -0.1640814  -1.7360551   0.42904875 -0.16919614]\n",
      "Reset environment\n",
      "Episode reward: 1178.8403\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.15523922 -0.16891292 -0.16015339 -1.7309954   0.4322088  -0.16520612]\n",
      "Reset environment\n",
      "Episode reward: 1223.683\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.15114693 -0.16441865 -0.15646957 -1.726056    0.43556285 -0.16112196]\n",
      "Reset environment\n",
      "Episode reward: 455.3603\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.15069753 -0.16484527 -0.15511294 -1.7293946   0.4363981  -0.16061984]\n",
      "Reset environment\n",
      "Episode reward: 246.27551\n",
      "Total Steps: 7\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.15060486 -0.16475052 -0.15502158 -1.7292376   0.43646258 -0.16052663]\n",
      "Reset environment\n",
      "Episode reward: 629.0805\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.14963418 -0.16378148 -0.15404947 -1.7278914   0.43721047 -0.15955319]\n",
      "Reset environment\n",
      "Episode reward: 3606.826\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.14165471 -0.15581909 -0.14608644 -1.7186773   0.4440275  -0.15156457]\n",
      "Reset environment\n",
      "Episode reward: -109.7074\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.13989925 -0.15333258 -0.14514603 -1.7283715   0.44861344 -0.14982477]\n",
      "Reset environment\n",
      "Episode reward: 1738.4948\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.13466658 -0.14808561 -0.13994288 -1.7224141   0.45315337 -0.14459307]\n",
      "Reset environment\n",
      "Episode reward: 947.2732\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.13132218 -0.14470366 -0.1366306  -1.7183794   0.45595613 -0.1412416 ]\n",
      "Reset environment\n",
      "Episode reward: 823.5381\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.12823617 -0.14167951 -0.13350101 -1.7147027   0.45852983 -0.13815258]\n",
      "Reset environment\n",
      "Episode reward: 818.8447\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.12512921 -0.13842003 -0.13054684 -1.7109863   0.46116868 -0.13504459]\n",
      "Reset environment\n",
      "Episode reward: -2566.5264\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.12975706 -0.14325938 -0.13474333 -1.725977    0.4625007  -0.13957544]\n",
      "Reset environment\n",
      "Episode reward: -1331.2493\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.13072573 -0.14559467 -0.13428271 -1.7376723   0.4639589  -0.14049457]\n",
      "Reset environment\n",
      "Episode reward: 2941.8926\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.12277536 -0.1379323  -0.12607856 -1.7286168   0.47093418 -0.13254265]\n",
      "Reset environment\n",
      "Episode reward: 791.4066\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.11981672 -0.13489935 -0.12318168 -1.7250855   0.47344404 -0.12957609]\n",
      "Reset environment\n",
      "Episode reward: 1701.0604\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.11476459 -0.12988296 -0.11811402 -1.7193357   0.47783932 -0.12452515]\n",
      "Reset environment\n",
      "Episode reward: 3489.0046\n",
      "Total Steps: 632\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.10775504 -0.12282833 -0.11118962 -1.7099441   0.48310792 -0.11747409]\n",
      "Reset environment\n",
      "Episode reward: 1991.0151\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.10207512 -0.11721105 -0.1054578  -1.7035034   0.4880884  -0.11178873]\n",
      "Reset environment\n",
      "Episode reward: 4168.128\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.09163912 -0.10698891 -0.0948507  -1.6916461   0.4971428  -0.10135082]\n",
      "Reset environment\n",
      "Episode reward: 1513.1819\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.08715336 -0.10282523 -0.09005231 -1.6862693   0.5007706  -0.09686308]\n",
      "Reset environment\n",
      "Episode reward: 1819.2314\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.0820455  -0.09729183 -0.08537053 -1.680101    0.50496    -0.09176288]\n",
      "Reset environment\n",
      "Episode reward: 717.4043\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.07925601 -0.094451   -0.08263718 -1.6766634   0.50722456 -0.08897728]\n",
      "Reset environment\n",
      "Episode reward: 1319.8047\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.07509382 -0.09017295 -0.07859734 -1.6718309   0.5108261  -0.08481166]\n",
      "Reset environment\n",
      "Episode reward: -578.62695\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.07522251 -0.09041072 -0.07862496 -1.6715496   0.5105244  -0.0849444 ]\n",
      "Reset environment\n",
      "Episode reward: 991.76605\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.07182125 -0.0869694  -0.07526676 -1.6675713   0.5134171  -0.08154041]\n",
      "Reset environment\n",
      "Episode reward: 1624.6653\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.06688169 -0.08208319 -0.07029701 -1.6618296   0.51764816 -0.07660402]\n",
      "Reset environment\n",
      "Episode reward: 3848.2305\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.05703023 -0.07243285 -0.06026107 -1.6508538   0.52642095 -0.06674191]\n",
      "Reset environment\n",
      "Episode reward: 1589.6298\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.05224601 -0.06752127 -0.05560312 -1.6454195   0.53059757 -0.06195249]\n",
      "Reset environment\n",
      "Episode reward: 1231.1959\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04842225 -0.06393284 -0.05155927 -1.6408039   0.53352296 -0.05813413]\n",
      "Reset environment\n",
      "Episode reward: 764.28143\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04554734 -0.06112434 -0.04862894 -1.6373643   0.5359185  -0.05525656]\n",
      "Reset environment\n",
      "Episode reward: 1248.7954\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04193571 -0.0578845  -0.04465286 -1.6330373   0.5387042  -0.05165134]\n",
      "Reset environment\n",
      "Episode reward: 753.2429\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.04072251 -0.05665753 -0.04346564 -1.6314951   0.5396683  -0.05044018]\n",
      "Reset environment\n",
      "Episode reward: 1458.3516\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03617827 -0.05245367 -0.03861254 -1.6261941   0.54334533 -0.04590272]\n",
      "Reset environment\n",
      "Episode reward: 394.5505\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03412221 -0.0502656  -0.03667779 -1.6236311   0.54504985 -0.04383871]\n",
      "Reset environment\n",
      "Episode reward: -531.9079\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03425106 -0.0500277  -0.03717487 -1.6233338   0.54472554 -0.04396357]\n",
      "Reset environment\n",
      "Episode reward: 1589.4717\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02951188 -0.04535661 -0.03238355 -1.6177987   0.54876673 -0.03922937]\n",
      "Reset environment\n",
      "Episode reward: 1724.6394\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02452972 -0.03998519 -0.02778764 -1.6118886   0.5529041  -0.0342451 ]\n",
      "Reset environment\n",
      "Episode reward: -5135.7617\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03524929 -0.05071063 -0.03837541 -1.6358267   0.547323   -0.04492183]\n",
      "Reset environment\n",
      "Episode reward: 1047.5769\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03171549 -0.04754834 -0.03450068 -1.6313158   0.5501048  -0.04138959]\n",
      "Reset environment\n",
      "Episode reward: 979.55786\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02834966 -0.04426409 -0.03105985 -1.6274369   0.55302036 -0.03802454]\n",
      "Reset environment\n",
      "Episode reward: -648.86536\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02793814 -0.04399189 -0.03051764 -1.6359748   0.55566895 -0.03759396]\n",
      "Reset environment\n",
      "Episode reward: 1252.2161\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02397783 -0.04012169 -0.02648302 -1.6312602   0.5590099  -0.03362977]\n",
      "Reset environment\n",
      "Episode reward: 3906.3445\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.01580474 -0.0318683  -0.01839592 -1.6220793   0.56615806 -0.0254411 ]\n",
      "Reset environment\n",
      "Episode reward: -3460.109\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02212739 -0.03853078 -0.0242111  -1.6408422   0.56493336 -0.03171755]\n",
      "Reset environment\n",
      "Episode reward: -7784.8276\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03929252 -0.05597572 -0.04097514 -1.6734165   0.5528985  -0.0487792 ]\n",
      "Reset environment\n",
      "Episode reward: 617.0969\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03681467 -0.05342666 -0.038567   -1.6703203   0.55489814 -0.0463015 ]\n",
      "Reset environment\n",
      "Episode reward: 900.52234\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03367252 -0.05034589 -0.03537636 -1.6665761   0.5575484  -0.04316355]\n",
      "Reset environment\n",
      "Episode reward: 621.05554\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03125321 -0.04814086 -0.03276112 -1.6635665   0.55953777 -0.04074129]\n",
      "Reset environment\n",
      "Episode reward: -330.4782\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03089665 -0.04765443 -0.03253129 -1.6630058   0.55990726 -0.04038015]\n",
      "Reset environment\n",
      "Episode reward: 645.08105\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02834355 -0.04502612 -0.03004195 -1.6598611   0.5620181  -0.03782393]\n",
      "Reset environment\n",
      "Episode reward: 230.65027\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02673556 -0.04356216 -0.02830499 -1.6577406   0.5632386  -0.0362169 ]\n",
      "Reset environment\n",
      "Episode reward: 2285.192\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02768713 -0.04504583 -0.0288362  -1.6583841   0.56383467 -0.03727217]\n",
      "Reset environment\n",
      "Episode reward: 659.53735\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02511893 -0.04258856 -0.02617262 -1.6553112   0.5659923  -0.03470312]\n",
      "Reset environment\n",
      "Episode reward: -1689.2134\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02537292 -0.04326711 -0.02575159 -1.6703506   0.5688354  -0.03481972]\n",
      "Reset environment\n",
      "Episode reward: -625.8882\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02507368 -0.04311657 -0.02516035 -1.6779472   0.5708707  -0.03439286]\n",
      "Reset environment\n",
      "Episode reward: -3647.8838\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.03098984 -0.05150233 -0.02851036 -1.6884785   0.56641614 -0.04021977]\n",
      "Reset environment\n",
      "Episode reward: 1073.4501\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02773806 -0.04703674 -0.02663745 -1.695261    0.5720578  -0.03700845]\n",
      "Reset environment\n",
      "Episode reward: 862.1473\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02478465 -0.04400366 -0.02377248 -1.6917907   0.5745631  -0.034054  ]\n",
      "Reset environment\n",
      "Episode reward: -409.41275\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02473353 -0.04399103 -0.02367163 -1.6914726   0.57465845 -0.03399505]\n",
      "Reset environment\n",
      "Episode reward: 802.91534\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02190919 -0.04114161 -0.02087344 -1.6880323   0.5770082  -0.03116952]\n",
      "Reset environment\n",
      "Episode reward: -1948.1863\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02438396 -0.04345424 -0.02349817 -1.708933    0.5793339  -0.03361593]\n",
      "Reset environment\n",
      "Episode reward: 1095.8652\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.02091883 -0.03995387 -0.02007169 -1.7049108   0.5823106  -0.03015111]\n",
      "Reset environment\n",
      "Episode reward: 252.48138\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.01929162 -0.03860605 -0.01817102 -1.7028008   0.5836416  -0.02852035]\n",
      "Reset environment\n",
      "Episode reward: 3964.6338\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.0095585  -0.02909054 -0.0082641  -1.6918026   0.59215057 -0.01878568]\n",
      "Reset environment\n",
      "Episode reward: 285.5891\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00742668 -0.0274239  -0.00566659 -1.6890903   0.5939643  -0.01666003]\n",
      "Reset environment\n",
      "Episode reward: 713.233\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00632447 -0.02631487 -0.00457276 -1.6874931   0.5947504  -0.01555535]\n",
      "Reset environment\n",
      "Episode reward: 64.69876\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-0.00517423 -0.02505061 -0.00353239 -1.6861691   0.5958288  -0.01440321]\n",
      "Reset environment\n",
      "Episode reward: 1014.7001\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [-1.9040842e-03 -2.1795355e-02 -2.5960858e-04 -1.6823169e+00\n",
      "  5.9860688e-01 -1.1133460e-02]\n",
      "Reset environment\n",
      "Episode reward: 2341.4548\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.00423887 -0.0159666   0.00617924 -1.6752076   0.6039414  -0.00498876]\n",
      "Reset environment\n",
      "Episode reward: -3703.5186\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 9.0214983e-03 -1.1564649e-02  1.1099779e-02 -1.6712065e+00\n",
      "  6.0762620e-01 -2.8276441e-04]\n",
      "Reset environment\n",
      "Episode reward: -320.2381\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0778863e-02 -9.6445782e-03  1.2648618e-02 -1.6805520e+00\n",
      "  6.1053294e-01  1.5334531e-03]\n",
      "Reset environment\n",
      "Episode reward: 280.38846\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01239826 -0.00764028  0.0138663  -1.6782745   0.61176044  0.00315974]\n",
      "Reset environment\n",
      "Episode reward: 1792.9967\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01729598 -0.00291468  0.01891671 -1.6726868   0.61601204  0.00806165]\n",
      "Reset environment\n",
      "Episode reward: 510.86768\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.01708592 -0.00324608  0.01884089 -1.6775092   0.61750793  0.00789719]\n",
      "Reset environment\n",
      "Episode reward: 851.2363\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9952597e-02 -4.3867281e-04  2.1761656e-02 -1.6741207e+00\n",
      "  6.1993003e-01  1.0763657e-02]\n",
      "Reset environment\n",
      "Episode reward: 3420.567\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.02813283  0.00776412  0.02983431 -1.6776233   0.6310781   0.01902961]\n",
      "Reset environment\n",
      "Episode reward: 993.51215\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0313078   0.01102155  0.03292673 -1.6739546   0.63382345  0.02221406]\n",
      "Reset environment\n",
      "Episode reward: 4780.147\n",
      "Total Steps: 216\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.04262369  0.02222659  0.04434553 -1.6611508   0.6437582   0.03353549]\n",
      "Reset environment\n",
      "Episode reward: 943.67993\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.04568153  0.02523573  0.0474475  -1.6575596   0.6463768   0.03659635]\n",
      "Reset environment\n",
      "Episode reward: 878.9481\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.04858044  0.02820911  0.05027433 -1.6541404   0.6488304   0.03949386]\n",
      "Reset environment\n",
      "Episode reward: 1252.0923\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.05229306  0.03201777  0.05388414 -1.6497397   0.6519661   0.04320633]\n",
      "Reset environment\n",
      "Episode reward: 629.80383\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0546749   0.03446202  0.05620252 -1.6467911   0.65389335  0.04559182]\n",
      "Reset environment\n",
      "Episode reward: 823.0829\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.05745833  0.03733223  0.05889754 -1.6435142   0.65627193  0.04837703]\n",
      "Reset environment\n",
      "Episode reward: 2394.9263\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.06299593  0.04376643  0.06353837 -1.6378207   0.66259104  0.05400164]\n",
      "Reset environment\n",
      "Episode reward: 527.72424\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0651467   0.0458598   0.06574143 -1.6350574   0.6642973   0.05615267]\n",
      "Reset environment\n",
      "Episode reward: 334.53152\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.06690276  0.04800096  0.06707613 -1.6325725   0.6655824   0.05790926]\n",
      "Reset environment\n",
      "Episode reward: 552.02075\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.06737003  0.04802211  0.06792863 -1.6411245   0.66887164  0.05835324]\n",
      "Reset environment\n",
      "Episode reward: 791.45386\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.07004962  0.05075292  0.07055315 -1.6378682   0.6710951   0.06103271]\n",
      "Reset environment\n",
      "Episode reward: 1357.204\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.07398027  0.05455766  0.07460185 -1.6331414   0.6744278   0.06496512]\n",
      "Reset environment\n",
      "Episode reward: 1328.5159\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.07779133  0.05836562  0.07840195 -1.628852    0.67778796  0.06877243]\n",
      "Reset environment\n",
      "Episode reward: 856.55237\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.08063745  0.06129336  0.08116848 -1.6255541   0.68023086  0.0716227 ]\n",
      "Reset environment\n",
      "Episode reward: -998.459\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.07952659  0.06031254  0.07993661 -1.6268271   0.67940265  0.07051689]\n",
      "Reset environment\n",
      "Episode reward: 4986.322\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.09104473  0.07171097  0.09155122 -1.6139429   0.6896085   0.08204044]\n",
      "Reset environment\n",
      "Episode reward: 869.46545\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.09390329  0.07448232  0.09449141 -1.6105392   0.6920346   0.08490502]\n",
      "Reset environment\n",
      "Episode reward: 527.4181\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.09602483  0.07671665  0.09649885 -1.607927    0.6937953   0.08702922]\n",
      "Reset environment\n",
      "Episode reward: 2313.693\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.1020646   0.08243739  0.10281803 -1.6009133   0.6989139   0.09306345]\n",
      "Reset environment\n",
      "Episode reward: 999.5051\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.10515588  0.08538225  0.10604546 -1.5972441   0.701555    0.09615544]\n",
      "Reset environment\n",
      "Episode reward: 1260.487\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.10850509  0.0890872   0.10901961 -1.5929427   0.7041705   0.09951286]\n",
      "Reset environment\n",
      "Episode reward: -311.094\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.10546448  0.08550724  0.10640718 -1.6039445   0.7057086   0.09640316]\n",
      "Reset environment\n",
      "Episode reward: -4086.4\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.0992038   0.07912774  0.10033085 -1.6269541   0.7025108   0.09016256]\n",
      "Reset environment\n",
      "Episode reward: 935.3463\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.10214454  0.08206183  0.10327458 -1.6234388   0.7049902   0.09310598]\n",
      "Reset environment\n",
      "Episode reward: 6814.412\n",
      "Total Steps: 282\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11539585  0.09502549  0.11679786 -1.6084591   0.7165791   0.10637502]\n",
      "Reset environment\n",
      "Episode reward: 547.69867\n",
      "Total Steps: 25\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11608476  0.09571771  0.11748459 -1.6075376   0.7171268   0.10706705]\n",
      "Reset environment\n",
      "Episode reward: 883.42773\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.1060316   0.08599343  0.1070528  -1.6186194   0.7083022   0.09703072]\n",
      "Reset environment\n",
      "Episode reward: 1027.2014\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.10918627  0.08888087  0.11046124 -1.6146058   0.7108204   0.10019097]\n",
      "Reset environment\n",
      "Episode reward: -484.37692\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.1091328   0.08902778  0.11019927 -1.6142018   0.71063215  0.1001334 ]\n",
      "Reset environment\n",
      "Episode reward: -302.672\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.10967675  0.09002414  0.11028485 -1.6130503   0.7108473   0.10068555]\n",
      "Reset environment\n",
      "Episode reward: 892.807\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11254422  0.09298787  0.11305294 -1.6097517   0.71333474  0.10355207]\n",
      "Reset environment\n",
      "Episode reward: 234.62308\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.1135771   0.09443334  0.11366825 -1.6080533   0.7139258   0.10459344]\n",
      "Reset environment\n",
      "Episode reward: -213.39719\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11384964  0.09459692  0.1140485  -1.6078421   0.7143643   0.10487019]\n",
      "Reset environment\n",
      "Episode reward: 630.194\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11634077  0.09743503  0.11607163 -1.6186175   0.7195458   0.10731576]\n",
      "Reset environment\n",
      "Episode reward: 242.45724\n",
      "Total Steps: 9\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11642057  0.09751635  0.1161488  -1.6184632   0.7195903   0.10739578]\n",
      "Reset environment\n",
      "Episode reward: -1335.7698\n",
      "Total Steps: 1398\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11266082  0.09310896  0.11320481 -1.6290438   0.7174659   0.10369971]\n",
      "Reset environment\n",
      "Episode reward: 2792.893\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11938703  0.10008084  0.11968132 -1.6212962   0.7232776   0.11043251]\n",
      "Reset environment\n",
      "Episode reward: 610.49066\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.12134255  0.10243425  0.12122242 -1.6186182   0.7247818   0.11238931]\n",
      "Reset environment\n",
      "Episode reward: 1172.8921\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.12474929  0.10584334  0.12462397 -1.6147035   0.7277452   0.11579322]\n",
      "Reset environment\n",
      "Episode reward: -2573.9167\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11976243  0.10048702  0.11990485 -1.6273147   0.72485936  0.11086038]\n",
      "Reset environment\n",
      "Episode reward: 1007.9458\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.12281811  0.1035492   0.12294763 -1.6236839   0.72744673  0.1139126 ]\n",
      "Reset environment\n",
      "Episode reward: 966.2355\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.12577547  0.10657088  0.12584269 -1.6202396   0.7299778   0.11686668]\n",
      "Reset environment\n",
      "Episode reward: 1181.5359\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.12882642  0.10922952  0.12925401 -1.6164254   0.7325872   0.11991153]\n",
      "Reset environment\n",
      "Episode reward: -672.20355\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.09047683  0.07122131  0.09028207 -1.6589934   0.703473    0.08115763]\n",
      "Reset environment\n",
      "Episode reward: 681.05615\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.09286606  0.0735535   0.09271745 -1.655969    0.705431    0.0835521 ]\n",
      "Reset environment\n",
      "Episode reward: 696.71985\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.09518015  0.07557047  0.09533804 -1.6528714   0.70718     0.08587971]\n",
      "Reset environment\n",
      "Episode reward: 5116.874\n",
      "Total Steps: 258\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.10652057  0.08668141  0.10688109 -1.6401616   0.7171984   0.09721835]\n",
      "Reset environment\n",
      "Episode reward: 1638.5554\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11092681  0.09100641  0.11135195 -1.6350074   0.7209833   0.1016296 ]\n",
      "Reset environment\n",
      "Episode reward: -497.7819\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11070558  0.0907036   0.11121499 -1.6351067   0.7209044   0.1014175 ]\n",
      "Reset environment\n",
      "Episode reward: 911.5923\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.1135672   0.09365731  0.11397271 -1.6317918   0.7233582   0.10427902]\n",
      "Reset environment\n",
      "Episode reward: 735.2407\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.11605484  0.09626509  0.11633508 -1.6288549   0.72547776  0.10676221]\n",
      "Reset environment\n",
      "Episode reward: 1941.4642\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.1209293   0.10113413  0.12122087 -1.623286    0.72973716  0.11164   ]\n",
      "Reset environment\n",
      "Episode reward: 949.47314\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.12384982  0.10401859  0.12417227 -1.6198286   0.73223114  0.11456241]\n",
      "Reset environment\n",
      "Episode reward: 4348.236\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.13532482  0.11607993  0.13481124 -1.6090257   0.7440191   0.12579839]\n",
      "Reset environment\n",
      "Episode reward: 974.0267\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.13822171  0.11903286  0.13764338 -1.6055946   0.74652153  0.12870178]\n",
      "Reset environment\n",
      "Episode reward: 526.4048\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.14026378  0.12099914  0.13975072 -1.6029829   0.7481501   0.13074869]\n",
      "Reset environment\n",
      "Episode reward: 943.40344\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.14313136  0.12382215  0.14265244 -1.5995952   0.7505857   0.13361225]\n",
      "Reset environment\n",
      "Episode reward: -420.76013\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.14346014  0.12458388  0.14253566 -1.5987138   0.75057536  0.13395181]\n",
      "Reset environment\n",
      "Episode reward: 1533.9783\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.14756255  0.12877187  0.1465483  -1.5939258   0.7540801   0.13805383]\n",
      "Reset environment\n",
      "Episode reward: -244.82593\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.14691472  0.12899508  0.14494431 -1.6017419   0.7591938   0.1374415 ]\n",
      "Reset environment\n",
      "Episode reward: 1938.2373\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.15189382  0.13363127  0.15022732 -1.5958884   0.763373    0.1424177 ]\n",
      "Reset environment\n",
      "Episode reward: -1039.4238\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.15036745  0.13063285  0.1502999  -1.6057391   0.76313204  0.14103599]\n",
      "Reset environment\n",
      "Episode reward: 2544.4314\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.15648824  0.13708726  0.1560849  -1.5987241   0.7684258   0.14715445]\n",
      "Reset environment\n",
      "Episode reward: 662.2821\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.15878919  0.13943234  0.15834011 -1.5958866   0.77032423  0.1494547 ]\n",
      "Reset environment\n",
      "Episode reward: 1041.9102\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.16184394  0.14255579  0.16132669 -1.5923553   0.7729633   0.15251535]\n",
      "Reset environment\n",
      "Episode reward: 4256.185\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.16956493  0.15015352  0.16917367 -1.5835887   0.7796819   0.16025594]\n",
      "Reset environment\n",
      "Episode reward: 543.5554\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.17162795  0.15233196  0.1711225  -1.5810909   0.7814175   0.16232234]\n",
      "Reset environment\n",
      "Episode reward: 1108.5964\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.17479761  0.15547232  0.17430414 -1.5774285   0.7841539   0.16549064]\n",
      "Reset environment\n",
      "Episode reward: 5702.4707\n",
      "Total Steps: 310\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.185221    0.16544613  0.18510456 -1.5653554   0.7930233   0.17591412]\n",
      "Reset environment\n",
      "Episode reward: 690.29694\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.1875618   0.16788352  0.18735047 -1.5626014   0.7950161   0.17825285]\n",
      "Reset environment\n",
      "Episode reward: 1465.8417\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.19134653  0.17143048  0.19136763 -1.5580876   0.7981139   0.18203849]\n",
      "Reset environment\n",
      "Episode reward: 3304.7568\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2003828   0.18092822  0.19962014 -1.5533844   0.80675936  0.19076747]\n",
      "Reset environment\n",
      "Episode reward: 931.67566\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.20315462  0.18360381  0.2024916  -1.5501571   0.80915636  0.19354616]\n",
      "Reset environment\n",
      "Episode reward: -3794.1982\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.19675845  0.17739995  0.19586118 -1.5729135   0.8049512   0.18715474]\n",
      "Reset environment\n",
      "Episode reward: 1084.1931\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.19984582  0.18045804  0.19897975 -1.5693126   0.8076146   0.19024253]\n",
      "Reset environment\n",
      "Episode reward: 1250.1885\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.20187917  0.18250673  0.20099214 -1.5669149   0.80935454  0.19227654]\n",
      "Reset environment\n",
      "Episode reward: 1145.5625\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.20510343  0.18569207  0.204248   -1.5631837   0.81215507  0.19549991]\n",
      "Reset environment\n",
      "Episode reward: 3817.3677\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.21337554  0.19468494  0.21165742 -1.5570196   0.8192409   0.2037887 ]\n",
      "Reset environment\n",
      "Episode reward: 2524.2234\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.21917674  0.20075545  0.21716356 -1.5503418   0.8241901   0.2095898 ]\n",
      "Reset environment\n",
      "Episode reward: 1729.6399\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.22351749  0.2051284   0.22146311 -1.5453755   0.827962    0.21393141]\n",
      "Reset environment\n",
      "Episode reward: 1001.7378\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.22641826  0.20791589  0.22446035 -1.5418204   0.8303633   0.21683453]\n",
      "Reset environment\n",
      "Episode reward: 888.70325\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.22908498  0.21066144  0.22704141 -1.5387062   0.83265203  0.21950522]\n",
      "Reset environment\n",
      "Episode reward: -21.934387\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.22977835  0.21170592  0.22736695 -1.5374247   0.8330585   0.22020568]\n",
      "Reset environment\n",
      "Episode reward: 811.9147\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2323083   0.21420482  0.22992298 -1.5343224   0.835151    0.2227354 ]\n",
      "Reset environment\n",
      "Episode reward: 2512.1826\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.238469    0.22059645  0.23586619 -1.5375732   0.84286135  0.22894311]\n",
      "Reset environment\n",
      "Episode reward: -239.15656\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2389139   0.22116771  0.23619011 -1.5366689   0.8430726   0.22938952]\n",
      "Reset environment\n",
      "Episode reward: 1737.7404\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.24319784  0.22581013  0.24010436 -1.5314866   0.8466434   0.23368098]\n",
      "Reset environment\n",
      "Episode reward: 5034.288\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.25460038  0.23771945  0.25106227 -1.5304418   0.85716313  0.24510412]\n",
      "Reset environment\n",
      "Episode reward: 1004.6911\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.25749516  0.24069192  0.25388023 -1.5271134   0.8596756   0.24799882]\n",
      "Reset environment\n",
      "Episode reward: 187.19443\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2587724   0.24207658  0.2550467  -1.5253638   0.8606636   0.24927813]\n",
      "Reset environment\n",
      "Episode reward: -379.64215\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2588426   0.24222706  0.25503287 -1.5252331   0.8607943   0.24935628]\n",
      "Reset environment\n",
      "Episode reward: 731.17395\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2612236   0.24469583  0.25731745 -1.5221632   0.86267227  0.2517313 ]\n",
      "Reset environment\n",
      "Episode reward: -320.85052\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.260422    0.24382335  0.25653067 -1.5323507   0.8648986   0.25096264]\n",
      "Reset environment\n",
      "Episode reward: 356.69144\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.26189533  0.24546663  0.257833   -1.5305018   0.8661269   0.2524403 ]\n",
      "Reset environment\n",
      "Episode reward: 1337.9052\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.26530612  0.24859019  0.26153272 -1.5262967   0.8689001   0.25586012]\n",
      "Reset environment\n",
      "Episode reward: 1030.4056\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.26688117  0.250164    0.2631079  -1.5243921   0.8702204   0.25743595]\n",
      "Reset environment\n",
      "Episode reward: 1839.6532\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2704274   0.25326127  0.2671984  -1.5292263   0.87499994  0.26107758]\n",
      "Reset environment\n",
      "Episode reward: 785.2362\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.27286345  0.25560567  0.26971853 -1.5263119   0.8770652   0.26351517]\n",
      "Reset environment\n",
      "Episode reward: 1352.9408\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2761455   0.25859937  0.27327976 -1.5222898   0.8798795   0.26680273]\n",
      "Reset environment\n",
      "Episode reward: 890.76984\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.27879605  0.26149422  0.27568266 -1.5189289   0.8820303   0.26946327]\n",
      "Reset environment\n",
      "Episode reward: 878.1825\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.28141746  0.26406923  0.27834824 -1.5157974   0.8842508   0.27209017]\n",
      "Reset environment\n",
      "Episode reward: 2364.2607\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.28594804  0.26918337  0.2823132  -1.5209637   0.89114326  0.27661708]\n",
      "Reset environment\n",
      "Episode reward: 46.020355\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.2868846   0.27044407  0.28292653 -1.5195673   0.89183164  0.27755907]\n",
      "Reset environment\n",
      "Episode reward: 2077.438\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.29165798  0.2755523   0.28735492 -1.5138075   0.8957907   0.28233132]\n",
      "Reset environment\n",
      "Episode reward: 2191.227\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.29600468  0.2797079   0.29179147 -1.5131363   0.90011525  0.2865805 ]\n",
      "Reset environment\n",
      "Episode reward: 595.6748\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.29805917  0.28183126  0.29377076 -1.5106068   0.9017928   0.28863338]\n",
      "Reset environment\n",
      "Episode reward: 3761.127\n",
      "Total Steps: 265\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.30433276  0.28864986  0.2995072  -1.503003    0.9069652   0.29490846]\n",
      "Reset environment\n",
      "Episode reward: 1590.0232\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.30828     0.29268584  0.30336443 -1.4984858   0.91038394  0.29885262]\n",
      "Reset environment\n",
      "Episode reward: 1157.2543\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3112603   0.29602772  0.30597067 -1.4943593   0.912591    0.30184   ]\n",
      "Reset environment\n",
      "Episode reward: 316.27625\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.31267726  0.29768363  0.3071646  -1.5048051   0.9159392   0.30336094]\n",
      "Reset environment\n",
      "Episode reward: -25.111877\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3096122   0.29418835  0.30424866 -1.511789    0.9136425   0.30019417]\n",
      "Reset environment\n",
      "Episode reward: 426.9821\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.31118158  0.29613572  0.30544797 -1.5097136   0.91492593  0.3017715 ]\n",
      "Reset environment\n",
      "Episode reward: 1599.8037\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.31510523  0.29993415  0.30948433 -1.5051165   0.91830444  0.30569732]\n",
      "Reset environment\n",
      "Episode reward: 57.021423\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.31604567  0.30132592  0.30997938 -1.5035901   0.9189096   0.30664316]\n",
      "Reset environment\n",
      "Episode reward: 1352.65\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3195077   0.30476782  0.31345662 -1.4996086   0.9219291   0.3101049 ]\n",
      "Reset environment\n",
      "Episode reward: 7273.635\n",
      "Total Steps: 312\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.33290538  0.31850368  0.3265011  -1.4845866   0.93352515  0.32349876]\n",
      "Reset environment\n",
      "Episode reward: 1331.4413\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.336291    0.3218141   0.32996398 -1.4805263   0.936408    0.32688788]\n",
      "Reset environment\n",
      "Episode reward: 4233.255\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3435266   0.32922736  0.33701265 -1.4724168   0.94271016  0.33412153]\n",
      "Reset environment\n",
      "Episode reward: 944.4302\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3461981   0.33195853  0.33962387 -1.4692981   0.94499713  0.3367931 ]\n",
      "Reset environment\n",
      "Episode reward: 389.0852\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.34825757  0.33301488  0.34268865 -1.4746169   0.9478609   0.33884877]\n",
      "Reset environment\n",
      "Episode reward: 2158.3298\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.35320595  0.33785173  0.34774178 -1.468923    0.9521778   0.3437939 ]\n",
      "Reset environment\n",
      "Episode reward: 902.86664\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.35554197  0.340518    0.34973776 -1.4658824   0.9540139   0.346132  ]\n",
      "Reset environment\n",
      "Episode reward: 915.6232\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.35816687  0.3432141   0.3522913  -1.4628052   0.956252    0.3487576 ]\n",
      "Reset environment\n",
      "Episode reward: 1683.3903\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.36124432  0.34596935  0.3557629  -1.4700885   0.9611024   0.35186478]\n",
      "Reset environment\n",
      "Episode reward: -1023.8314\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.35995993  0.34439528  0.3547666  -1.4712787   0.95992297  0.35058233]\n",
      "Reset environment\n",
      "Episode reward: 839.0383\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.36240453  0.3469062   0.3571481  -1.4683772   0.9620072   0.35303137]\n",
      "Reset environment\n",
      "Episode reward: 1271.4102\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.36541882  0.3502535   0.3598153  -1.464602    0.96443707  0.35604477]\n",
      "Reset environment\n",
      "Episode reward: -3204.0317\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3595417   0.34409177  0.35441    -1.4845233   0.9616879   0.35023963]\n",
      "Reset environment\n",
      "Episode reward: 1100.3057\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.36242124  0.34727204  0.35697603 -1.4808007   0.9639355   0.3531148 ]\n",
      "Reset environment\n",
      "Episode reward: 1844.5774\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3667115   0.35127637  0.36153668 -1.4756873   0.9675569   0.35741356]\n",
      "Reset environment\n",
      "Episode reward: 57.451538\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.36801434  0.3523525   0.36309907 -1.4811713   0.9691706   0.35876328]\n",
      "Reset environment\n",
      "Episode reward: 1252.9307\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.37121922  0.35551375  0.36632988 -1.4773517   0.971874    0.3619697 ]\n",
      "Reset environment\n",
      "Episode reward: 2776.6687\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.37716523  0.36123118  0.37246144 -1.470511    0.97700316  0.36791056]\n",
      "Reset environment\n",
      "Episode reward: 161.7019\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.3762051   0.36007702  0.37161428 -1.4832056   0.9782521   0.36691985]\n",
      "Reset environment\n",
      "Episode reward: 887.83514\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.37870294  0.36261803  0.37406835 -1.480204    0.98033607  0.3694138 ]\n",
      "Reset environment\n",
      "Episode reward: 3378.4463\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.38583693  0.36999503  0.38093942 -1.4721507   0.9865931   0.3765442 ]\n",
      "Reset environment\n",
      "Episode reward: 2054.0144\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.39046937  0.37433937  0.38584673 -1.4667218   0.9905862   0.3811806 ]\n",
      "Reset environment\n",
      "Episode reward: 3400.3887\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.396313    0.38019708  0.3916422  -1.4600946   0.9957137   0.38701186]\n",
      "Reset environment\n",
      "Episode reward: 3098.8633\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.40097728  0.3848229   0.39640817 -1.4609909   1.0018542   0.3917492 ]\n",
      "Reset environment\n",
      "Episode reward: -289.84286\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.4012122   0.38493675  0.39676157 -1.4603406   1.0019897   0.39198795]\n",
      "Reset environment\n",
      "Episode reward: 5245.0327\n",
      "Total Steps: 223\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.41165656  0.39541748  0.4071396  -1.4485935   1.011179    0.40243572]\n",
      "Reset environment\n",
      "Episode reward: 3520.125\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.417712    0.40262574  0.41189674 -1.4458394   1.0168346   0.40848935]\n",
      "Reset environment\n",
      "Episode reward: 829.1051\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.42009363  0.40491992  0.41435054 -1.443012    1.0188577   0.41086784]\n",
      "Reset environment\n",
      "Episode reward: 1671.7041\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.42387265  0.40897438  0.41784412 -1.4385194   1.0220299   0.41464743]\n",
      "Reset environment\n",
      "Episode reward: 2829.4133\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.4284565   0.41357583  0.42239594 -1.4333355   1.0260688   0.41922858]\n",
      "Reset environment\n",
      "Episode reward: 3648.034\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.43594533  0.4212993   0.42964143 -1.4248353   1.0326619   0.4267201 ]\n",
      "Reset environment\n",
      "Episode reward: 2397.3213\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.44035462  0.42551062  0.43434685 -1.4333268   1.0397823   0.43114856]\n",
      "Reset environment\n",
      "Episode reward: -709.6535\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.43925145  0.42465988  0.43300265 -1.4490157   1.0396856   0.43005076]\n",
      "Reset environment\n",
      "Episode reward: 456.11694\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.44091663  0.42626876  0.43472338 -1.4468      1.0410004   0.43171823]\n",
      "Reset environment\n",
      "Episode reward: 950.71985\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.44348583  0.4289111   0.43722588 -1.4437922   1.0432122   0.43429175]\n",
      "Reset environment\n",
      "Episode reward: 1125.9753\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.44513416  0.43056086  0.43886393 -1.4417821   1.0446016   0.43594152]\n",
      "Reset environment\n",
      "Episode reward: 421.11615\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.44669816  0.43173382  0.4408274  -1.4395719   1.0458483   0.43751925]\n",
      "Reset environment\n",
      "Episode reward: 6422.106\n",
      "Total Steps: 402\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.4574409   0.4426317   0.45140538 -1.4276651   1.0554197   0.44827148]\n",
      "Reset environment\n",
      "Episode reward: 1805.791\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.46031198  0.44551465  0.45425925 -1.4243703   1.0579153   0.45114103]\n",
      "Reset environment\n",
      "Episode reward: 2062.2837\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.464217    0.44959247  0.45795968 -1.4309742   1.0635037   0.455045  ]\n",
      "Reset environment\n",
      "Episode reward: 5675.4375\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.4764899   0.46168995  0.4703641  -1.4198111   1.0756315   0.46734062]\n",
      "Reset environment\n",
      "Episode reward: -1083.2064\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.47527167  0.4603188   0.46929997 -1.4210261   1.074532    0.46612492]\n",
      "Reset environment\n",
      "Episode reward: 311.77478\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.4753768   0.46040943  0.46937025 -1.4284502   1.0761751   0.46629247]\n",
      "Reset environment\n",
      "Episode reward: 4075.7617\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.4817049   0.46685374  0.47566673 -1.4309579   1.083503    0.47262597]\n",
      "Reset environment\n",
      "Episode reward: 5564.975\n",
      "Total Steps: 263\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.49077818  0.47558126  0.48504964 -1.4206731   1.0914356   0.48170462]\n",
      "Reset environment\n",
      "Episode reward: 6616.3657\n",
      "Total Steps: 271\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5020651   0.48711875  0.49608138 -1.4079993   1.1013327   0.49299338]\n",
      "Reset environment\n",
      "Episode reward: 1950.4991\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.50626236  0.4916005   0.49999446 -1.402989    1.1048732   0.49719107]\n",
      "Reset environment\n",
      "Episode reward: 173.18591\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5044092   0.4891132   0.49843615 -1.4080011   1.1034248   0.4951544 ]\n",
      "Reset environment\n",
      "Episode reward: 293.2276\n",
      "Total Steps: 15\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5045442   0.4892494   0.4985678  -1.4077455   1.1035024   0.49528903]\n",
      "Reset environment\n",
      "Episode reward: 850.59204\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.50689924  0.49169946  0.5008343  -1.4049652   1.10553     0.49764588]\n",
      "Reset environment\n",
      "Episode reward: 544.63336\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5086229   0.49372086  0.5022519  -1.4026393   1.1068662   0.499371  ]\n",
      "Reset environment\n",
      "Episode reward: 4175.362\n",
      "Total Steps: 404\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.51492834  0.49963966  0.50893193 -1.3960525   1.1124991   0.5056936 ]\n",
      "Reset environment\n",
      "Episode reward: 5066.1973\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.52349377  0.50773185  0.51794827 -1.3935072   1.1218266   0.5143796 ]\n",
      "Reset environment\n",
      "Episode reward: 2247.5151\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5281922   0.51218486  0.52287614 -1.3879961   1.1259098   0.519084  ]\n",
      "Reset environment\n",
      "Episode reward: 1986.3767\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5302142   0.5139408   0.52501744 -1.3957831   1.1300777   0.5209543 ]\n",
      "Reset environment\n",
      "Episode reward: 327.71268\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.53141063  0.51483643  0.5265197  -1.3941159   1.1310278   0.52215916]\n",
      "Reset environment\n",
      "Episode reward: 1715.7753\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5352471   0.51874375  0.53028446 -1.3896906   1.134359    0.5259977 ]\n",
      "Reset environment\n",
      "Episode reward: 1048.9609\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.537859    0.5210267   0.5332303  -1.38638     1.136443    0.52861995]\n",
      "Reset environment\n",
      "Episode reward: 738.41296\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5398041   0.52335167  0.53478736 -1.3836799   1.1379496   0.5305695 ]\n",
      "Reset environment\n",
      "Episode reward: 1689.042\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5435911   0.52705234  0.53863895 -1.3793072   1.1412274   0.5343582 ]\n",
      "Reset environment\n",
      "Episode reward: 3789.4153\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.55105686  0.5343692   0.5462335  -1.3708736   1.1477954   0.54182804]\n",
      "Reset environment\n",
      "Episode reward: 216.07446\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.55026364  0.53263104  0.5462973  -1.3770673   1.1477813   0.54103625]\n",
      "Reset environment\n",
      "Episode reward: 601.0167\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.55180705  0.5344942   0.54751366 -1.374921    1.1489327   0.5425812 ]\n",
      "Reset environment\n",
      "Episode reward: 1727.8564\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.554024    0.5362838   0.5501104  -1.3744553   1.1508588   0.54485285]\n",
      "Reset environment\n",
      "Episode reward: 4062.4702\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5619368   0.54438126  0.5578348  -1.3655659   1.1578562   0.5527624 ]\n",
      "Reset environment\n",
      "Episode reward: 1141.3174\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5647368   0.54723793  0.5605705  -1.3623456   1.1602839   0.5555571 ]\n",
      "Reset environment\n",
      "Episode reward: 1031.0469\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5671513   0.54938     0.56324667 -1.3593998   1.1623693   0.55796653]\n",
      "Reset environment\n",
      "Episode reward: 2745.4534\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.57264966  0.5551672   0.56843644 -1.3528461   1.1669279   0.56346154]\n",
      "Reset environment\n",
      "Episode reward: 1437.7859\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.57592815  0.5583493   0.5718122  -1.3489563   1.169729    0.56674576]\n",
      "Reset environment\n",
      "Episode reward: -32.094177\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5765765  0.559111   0.5723523 -1.3481791  1.1703534  0.5673927]\n",
      "Reset environment\n",
      "Episode reward: 993.4015\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5770729   0.5586909   0.5736815  -1.352241    1.1710638   0.56790155]\n",
      "Reset environment\n",
      "Episode reward: 3509.796\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5839868   0.5658189   0.58037287 -1.344455    1.1771752   0.57481986]\n",
      "Reset environment\n",
      "Episode reward: 64.69876\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.58467424  0.56629574  0.5812704  -1.343571    1.1777537   0.57550603]\n",
      "Reset environment\n",
      "Episode reward: 15.547333\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5854941   0.567237    0.58197314 -1.3423384   1.178333    0.57632864]\n",
      "Reset environment\n",
      "Episode reward: 2879.378\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.59115237  0.5731459   0.5873637  -1.3358308   1.183233    0.5819845 ]\n",
      "Reset environment\n",
      "Episode reward: 601.9452\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.59300476  0.575322    0.5888835  -1.3334111   1.1846783   0.5838387 ]\n",
      "Reset environment\n",
      "Episode reward: 682.423\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.59378874  0.5761122   0.589661   -1.3323579   1.1852847   0.58462465]\n",
      "Reset environment\n",
      "Episode reward: 1138.017\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.59655154  0.5788974   0.5923933  -1.3291433   1.1876606   0.58738637]\n",
      "Reset environment\n",
      "Episode reward: 1302.3859\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.5996002   0.58199286  0.59539217 -1.3255564   1.1902541   0.590433  ]\n",
      "Reset environment\n",
      "Episode reward: 459.40268\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.60115737  0.5835136   0.5969821  -1.323443    1.191441    0.5919914 ]\n",
      "Reset environment\n",
      "Episode reward: 828.8032\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6034159  0.5858463  0.5991647 -1.3207668  1.1933619  0.5942511]\n",
      "Reset environment\n",
      "Episode reward: 1781.8889\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6072708   0.58962893  0.6030733  -1.3162566   1.1966788   0.5981007 ]\n",
      "Reset environment\n",
      "Episode reward: 1426.4583\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6105336  0.5929599  0.6062608 -1.3124942  1.1995026  0.6013612]\n",
      "Reset environment\n",
      "Episode reward: -991.5612\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6093979   0.59197515  0.6049859  -1.313557    1.1985254   0.6002238 ]\n",
      "Reset environment\n",
      "Episode reward: 4152.8315\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6159601   0.59870505  0.6113772  -1.3061472   1.2042475   0.60678947]\n",
      "Reset environment\n",
      "Episode reward: 1300.8086\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6188018   0.6013653   0.61438984 -1.3027486   1.2066804   0.6096268 ]\n",
      "Reset environment\n",
      "Episode reward: 1422.7283\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.62188464  0.6042439   0.6176696  -1.2989414   1.2091961   0.6127188 ]\n",
      "Reset environment\n",
      "Episode reward: 3488.7817\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6285175  0.6111115  0.6240598 -1.2914389  1.2149862  0.619349 ]\n",
      "Reset environment\n",
      "Episode reward: 3397.127\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.63374203  0.6163721   0.629245   -1.2855749   1.2196153   0.62457126]\n",
      "Reset environment\n",
      "Episode reward: 1124.1567\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6364447  0.6189932  0.6320163 -1.2822616  1.2218474  0.6272705]\n",
      "Reset environment\n",
      "Episode reward: 5997.498\n",
      "Total Steps: 222\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.64617854  0.6288018   0.64166385 -1.2712773   1.2303878   0.6370096 ]\n",
      "Reset environment\n",
      "Episode reward: 1380.4465\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.64454967  0.6272047   0.6399494  -1.2760067   1.2296406   0.63533133]\n",
      "Reset environment\n",
      "Episode reward: -1491.7238\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.64140964  0.62351906  0.63721323 -1.2849349   1.227102    0.63204175]\n",
      "Reset environment\n",
      "Episode reward: 1682.4497\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6450693   0.6271544   0.64088404 -1.2806348   1.2302262   0.6357009 ]\n",
      "Reset environment\n",
      "Episode reward: 2549.7234\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6501394  0.6319599  0.646182  -1.2747475  1.2345746  0.6407638]\n",
      "Reset environment\n",
      "Episode reward: 557.6634\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.649919   0.631473   0.6462673 -1.2816801  1.2350502  0.6405664]\n",
      "Reset environment\n",
      "Episode reward: -265.6748\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.64845335  0.6292905   0.645541   -1.2931805   1.235128    0.639093  ]\n",
      "Reset environment\n",
      "Episode reward: 1387.8198\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6515335   0.63225985  0.648727   -1.2895114   1.23776     0.64217645]\n",
      "Reset environment\n",
      "Episode reward: 856.09814\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6537501   0.6344388   0.65097475 -1.2868083   1.2396146   0.6443908 ]\n",
      "Reset environment\n",
      "Episode reward: -249.64178\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6539799  0.6347872  0.6510875 -1.2863132  1.239821   0.644625 ]\n",
      "Reset environment\n",
      "Episode reward: 789.48126\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.65611595  0.63685215  0.6532932  -1.2837569   1.2416373   0.64676446]\n",
      "Reset environment\n",
      "Episode reward: 4576.703\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6646877   0.6455716   0.66173047 -1.2741827   1.2492545   0.6553444 ]\n",
      "Reset environment\n",
      "Episode reward: 1237.231\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6674792   0.64854103  0.66434854 -1.2708821   1.2516878   0.6581388 ]\n",
      "Reset environment\n",
      "Episode reward: 1631.4357\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6710227   0.6520244   0.66794735 -1.2667239   1.2547292   0.6616824 ]\n",
      "Reset environment\n",
      "Episode reward: -267.9659\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6713307  0.6524056  0.6681696 -1.2661035  1.2548743  0.6619877]\n",
      "Reset environment\n",
      "Episode reward: 915.432\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.67365664  0.6546755   0.6705475  -1.2633499   1.2568735   0.66432047]\n",
      "Reset environment\n",
      "Episode reward: 2996.4487\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.67952764  0.6607063   0.6762538  -1.256722    1.2620608   0.67020047]\n",
      "Reset environment\n",
      "Episode reward: -945.6874\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6786002   0.65943474  0.6756685  -1.2572712   1.261083    0.66927445]\n",
      "Reset environment\n",
      "Episode reward: 3621.9714\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6855041  0.6665613  0.6823414 -1.2494731  1.2671607  0.6761829]\n",
      "Reset environment\n",
      "Episode reward: 1765.8726\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.68905914  0.6697844   0.68621755 -1.2451833   1.2701622   0.67974097]\n",
      "Reset environment\n",
      "Episode reward: 1151.3652\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.69180715  0.6725848   0.68890786 -1.2420015   1.2725292   0.6824912 ]\n",
      "Reset environment\n",
      "Episode reward: 1735.3706\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6955193   0.67636544  0.6925478  -1.2377349   1.2757509   0.6862033 ]\n",
      "Reset environment\n",
      "Episode reward: 1298.6945\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.6983581  0.679478   0.6951033 -1.2342032  1.2780886  0.6890465]\n",
      "Reset environment\n",
      "Episode reward: 1104.4528\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7008987  0.6823043  0.6973464 -1.2309282  1.2801315  0.6915897]\n",
      "Reset environment\n",
      "Episode reward: 5408.37\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.70944893  0.6909928   0.70575255 -1.2214559   1.2876903   0.7001408 ]\n",
      "Reset environment\n",
      "Episode reward: 1604.7161\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7127962   0.69462514  0.70879525 -1.2174072   1.2904677   0.7034879 ]\n",
      "Reset environment\n",
      "Episode reward: -1005.1017\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.70982945  0.69120646  0.70627004 -1.2301999   1.2887658   0.70053124]\n",
      "Reset environment\n",
      "Episode reward: 866.6807\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.71206164  0.69338894  0.7085449  -1.2275244   1.2906508   0.70276815]\n",
      "Reset environment\n",
      "Episode reward: -2858.207\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7062364   0.688009    0.7023891  -1.2442409   1.2876934   0.69699883]\n",
      "Reset environment\n",
      "Episode reward: 2196.1294\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7105663   0.6921078   0.70693356 -1.2392427   1.2914485   0.70133317]\n",
      "Reset environment\n",
      "Episode reward: 999.55774\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.71301824  0.6945185   0.70942384 -1.2362967   1.2935228   0.70378286]\n",
      "Reset environment\n",
      "Episode reward: 1207.6603\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7155771   0.6973551   0.71169645 -1.2329992   1.2955807   0.7063463 ]\n",
      "Reset environment\n",
      "Episode reward: 1464.2737\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7186349  0.7006834  0.7144734 -1.2292184  1.2980813  0.7094087]\n",
      "Reset environment\n",
      "Episode reward: -302.48938\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7166633   0.69839656  0.7128452  -1.2394818   1.297094    0.70745456]\n",
      "Reset environment\n",
      "Episode reward: 1438.9423\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7198345  0.7015841  0.7160006 -1.2358046  1.2998369  0.7106274]\n",
      "Reset environment\n",
      "Episode reward: 23.382751\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.72044224  0.70234203  0.71646243 -1.234929    1.3003842   0.7112352 ]\n",
      "Reset environment\n",
      "Episode reward: 1546.9656\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.72361064  0.7052274   0.7199043  -1.231166    1.3031721   0.7144024 ]\n",
      "Reset environment\n",
      "Episode reward: 2002.3999\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7275567   0.7094311   0.72357965 -1.2264566   1.306469    0.7183533 ]\n",
      "Reset environment\n",
      "Episode reward: 3546.4854\n",
      "Total Steps: 785\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7311114   0.7123883   0.7277175  -1.225031    1.3101184   0.72189707]\n",
      "Reset environment\n",
      "Episode reward: 534.9937\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.73259515  0.71410465  0.72896117 -1.2231907   1.3114238   0.72338235]\n",
      "Reset environment\n",
      "Episode reward: 2157.339\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.736699    0.718046    0.73321015 -1.2184144   1.3149794   0.7274877 ]\n",
      "Reset environment\n",
      "Episode reward: 1134.0232\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7393442   0.72073627  0.73580563 -1.2153577   1.3172716   0.73013383]\n",
      "Reset environment\n",
      "Episode reward: 2075.3691\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.74356645  0.7249755   0.7400033  -1.2105658   1.320974    0.7343546 ]\n",
      "Reset environment\n",
      "Episode reward: 3076.936\n",
      "Total Steps: 228\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7477788   0.7288117   0.74456835 -1.205319    1.3244119   0.7385686 ]\n",
      "Reset environment\n",
      "Episode reward: -702.97076\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.74727947  0.728174    0.744207   -1.2058058   1.3239801   0.73806643]\n",
      "Reset environment\n",
      "Episode reward: 995.1591\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7496995  0.7306264  0.7465833 -1.202931   1.3260237  0.7404825]\n",
      "Reset environment\n",
      "Episode reward: 412.91196\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7511158   0.73211336  0.7479337  -1.2010325   1.327116    0.7418986 ]\n",
      "Reset environment\n",
      "Episode reward: 1054.664\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7494744   0.73086596  0.7458814  -1.2087054   1.3266768   0.74024945]\n",
      "Reset environment\n",
      "Episode reward: 1165.1057\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.75210124  0.73379105  0.7482165  -1.2054121   1.328853    0.74288625]\n",
      "Reset environment\n",
      "Episode reward: -749.4097\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7502877   0.7318579   0.74657226 -1.2174535   1.3280181   0.7410847 ]\n",
      "Reset environment\n",
      "Episode reward: 809.3739\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7500653  0.7328263  0.7451787 -1.2242651  1.328619   0.740879 ]\n",
      "Reset environment\n",
      "Episode reward: 2278.5544\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7532439  0.7360189  0.7483436 -1.2206248  1.3313918  0.7440606]\n",
      "Reset environment\n",
      "Episode reward: 1026.5837\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.75552094  0.73808116  0.7508264  -1.2176555   1.3331971   0.74633896]\n",
      "Reset environment\n",
      "Episode reward: 1847.0461\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.75654155  0.7392611   0.7517291  -1.2223092   1.3353925   0.74740005]\n",
      "Reset environment\n",
      "Episode reward: 841.25635\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.758664    0.7414354   0.7537958  -1.2197503   1.3371607   0.74952304]\n",
      "Reset environment\n",
      "Episode reward: 194.8934\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.75954443  0.7425336   0.7544566  -1.2185112   1.3379011   0.7504045 ]\n",
      "Reset environment\n",
      "Episode reward: 909.7728\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.76179355  0.7447241   0.7567583  -1.2158629   1.3398426   0.75265473]\n",
      "Reset environment\n",
      "Episode reward: 239.0817\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7624718   0.7452205   0.757612   -1.2150466   1.3404554   0.75333565]\n",
      "Reset environment\n",
      "Episode reward: 482.85712\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.76374555  0.74613833  0.7592314  -1.2131883   1.3414626   0.75460994]\n",
      "Reset environment\n",
      "Episode reward: 2351.0405\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.76605725  0.74814576  0.76190114 -1.2200929   1.3447788   0.7569799 ]\n",
      "Reset environment\n",
      "Episode reward: 258.20715\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7657178   0.7476076   0.76184976 -1.2314284   1.3455718   0.7566858 ]\n",
      "Reset environment\n",
      "Episode reward: -298.68607\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.76571465  0.74789923  0.76154387 -1.2310555   1.3454468   0.7566839 ]\n",
      "Reset environment\n",
      "Episode reward: -398.6054\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.76347506  0.74530923  0.7596696  -1.242664    1.3445907   0.7544811 ]\n",
      "Reset environment\n",
      "Episode reward: 1975.0629\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7673876   0.74934083  0.76345414 -1.2381063   1.3479637   0.758395  ]\n",
      "Reset environment\n",
      "Episode reward: 2665.9253\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7711532   0.7531289   0.76718867 -1.2338021   1.3512466   0.76215965]\n",
      "Reset environment\n",
      "Episode reward: -791.08826\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7689006  0.7505105  0.7652856 -1.247128   1.3508214  0.7599227]\n",
      "Reset environment\n",
      "Episode reward: 1141.186\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.77145714  0.7529767   0.76791495 -1.2441344   1.3530294   0.7624773 ]\n",
      "Reset environment\n",
      "Episode reward: 1721.3694\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.77326775  0.75568813  0.7687922  -1.2484319   1.3546522   0.76428986]\n",
      "Reset environment\n",
      "Episode reward: 963.1982\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7755461  0.7580046  0.7710251 -1.2456982  1.356564   0.7665675]\n",
      "Reset environment\n",
      "Episode reward: 768.6649\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.775656    0.75778437  0.7715415  -1.255478    1.3579595   0.76674163]\n",
      "Reset environment\n",
      "Episode reward: 1678.0813\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7790671   0.761189    0.77494055 -1.2515548   1.3609264   0.770148  ]\n",
      "Reset environment\n",
      "Episode reward: 1996.4062\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7828961   0.7648149   0.77895355 -1.2470466   1.3642118   0.7739746 ]\n",
      "Reset environment\n",
      "Episode reward: 4704.7275\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7911581   0.77336496  0.7867721  -1.242552    1.3713639   0.7822215 ]\n",
      "Reset environment\n",
      "Episode reward: 32.83731\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7918022  0.7738933  0.7875331 -1.2417814  1.37191    0.7828679]\n",
      "Reset environment\n",
      "Episode reward: 4147.0645\n",
      "Total Steps: 230\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.7975463  0.7799722  0.7929513 -1.2350659  1.3768728  0.7886165]\n",
      "Reset environment\n",
      "Episode reward: 291.93076\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.79848975  0.7807504   0.7940519  -1.2339199   1.3777033   0.78956205]\n",
      "Reset environment\n",
      "Episode reward: 2003.6433\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8022353   0.7843184   0.79796755 -1.2295259   1.3808738   0.79331416]\n",
      "Reset environment\n",
      "Episode reward: 855.7588\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8041465   0.78651077  0.7995962  -1.2269758   1.382399    0.7952302 ]\n",
      "Reset environment\n",
      "Episode reward: 907.88885\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.80631787  0.7886113   0.80182767 -1.2244158   1.3842704   0.79740125]\n",
      "Reset environment\n",
      "Episode reward: -379.47107\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8062044   0.788623    0.8015873  -1.2244267   1.3842332   0.79728615]\n",
      "Reset environment\n",
      "Episode reward: 1017.75543\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8085424  0.7909417  0.8039344 -1.2216462  1.3862215  0.7996213]\n",
      "Reset environment\n",
      "Episode reward: 14.823242\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8077923   0.7907918   0.80254835 -1.2313558   1.3861411   0.7988237 ]\n",
      "Reset environment\n",
      "Episode reward: 5201.434\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.81556314  0.7987574   0.8101231  -1.222635    1.392969    0.80660003]\n",
      "Reset environment\n",
      "Episode reward: 2885.1033\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8192149   0.80227906  0.8138842  -1.218436    1.396166    0.8102554 ]\n",
      "Reset environment\n",
      "Episode reward: -511.43045\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.81899226  0.801958    0.8137575  -1.2185371   1.3960557   0.81003445]\n",
      "Reset environment\n",
      "Episode reward: 2902.192\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8239392   0.8071337   0.818464   -1.212802    1.4002917   0.81498015]\n",
      "Reset environment\n",
      "Episode reward: 2352.2197\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8283758   0.81157243  0.8228828  -1.2077819   1.4041883   0.81941265]\n",
      "Reset environment\n",
      "Episode reward: 112.12479\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8291549   0.81223476  0.8237787  -1.2066832   1.4048779   0.8201938 ]\n",
      "Reset environment\n",
      "Episode reward: 5085.639\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.83583826  0.81921965  0.8302284  -1.2047688   1.4113841   0.8269115 ]\n",
      "Reset environment\n",
      "Episode reward: 738.4856\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8377163   0.8211594   0.8320416  -1.2024778   1.4129452   0.82878816]\n",
      "Reset environment\n",
      "Episode reward: 1271.7927\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.84044904  0.8239193   0.83475006 -1.1993592   1.4153439   0.831522  ]\n",
      "Reset environment\n",
      "Episode reward: 1453.088\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8434386   0.8268997   0.8377393  -1.1958704   1.4179255   0.83450913]\n",
      "Reset environment\n",
      "Episode reward: 1136.0538\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.84595513  0.82947385  0.8401994  -1.1929903   1.4201213   0.8370268 ]\n",
      "Reset environment\n",
      "Episode reward: -4690.6704\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8467748  0.8311695  0.8400501 -1.1903203  1.416033   0.8378349]\n",
      "Reset environment\n",
      "Episode reward: 3426.5945\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8528063   0.83743113  0.8458413  -1.1833847   1.4212584   0.8438693 ]\n",
      "Reset environment\n",
      "Episode reward: 1544.7803\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8559224   0.8404963   0.84900683 -1.1797547   1.4239614   0.84698886]\n",
      "Reset environment\n",
      "Episode reward: 346.57367\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8571611  0.8418135  0.8501643 -1.178095   1.4249196  0.848228 ]\n",
      "Reset environment\n",
      "Episode reward: 1197.8835\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8597682   0.84438473  0.8527952  -1.1750541   1.4271836   0.85082877]\n",
      "Reset environment\n",
      "Episode reward: 1938.322\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8623608  0.8471314  0.8552389 -1.1741303  1.4294204  0.8534551]\n",
      "Reset environment\n",
      "Episode reward: -479.5448\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8607237   0.8449561   0.85414785 -1.1854274   1.429221    0.8518375 ]\n",
      "Reset environment\n",
      "Episode reward: 1908.361\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.86423165  0.8481969   0.8579137  -1.1812546   1.432251    0.85534334]\n",
      "Reset environment\n",
      "Episode reward: 1712.718\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.86757076  0.85145164  0.86133313 -1.1774064   1.4351732   0.8586861 ]\n",
      "Reset environment\n",
      "Episode reward: -327.12924\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8676294   0.8514684   0.86143285 -1.1772166   1.4352278   0.85875   ]\n",
      "Reset environment\n",
      "Episode reward: -688.5863\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8655852   0.8496258   0.85932744 -1.1885346   1.434236    0.8567898 ]\n",
      "Reset environment\n",
      "Episode reward: 1101.4802\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8680021  0.8520039  0.8617733 -1.1857305  1.4363341  0.8592044]\n",
      "Reset environment\n",
      "Episode reward: 2149.4138\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8718389   0.8560785   0.86536205 -1.1811469   1.4395932   0.86304474]\n",
      "Reset environment\n",
      "Episode reward: 3503.896\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.87572926  0.85928667  0.86992013 -1.183917    1.4436176   0.866924  ]\n",
      "Reset environment\n",
      "Episode reward: -687.0625\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8752153   0.85875124  0.8694233  -1.1841006   1.4431112   0.86640894]\n",
      "Reset environment\n",
      "Episode reward: 2288.2722\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.87936556  0.8631314   0.87333333 -1.1792387   1.4466825   0.870561  ]\n",
      "Reset environment\n",
      "Episode reward: 1535.9711\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8824641   0.86614954  0.8765059  -1.1755694   1.4493488   0.873659  ]\n",
      "Reset environment\n",
      "Episode reward: 4570.1694\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.88899595  0.87278277  0.8829268  -1.168284    1.4550962   0.88019204]\n",
      "Reset environment\n",
      "Episode reward: 1058.3545\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.89133424  0.87517214  0.8852119  -1.1655644   1.4571128   0.88253045]\n",
      "Reset environment\n",
      "Episode reward: 192.01208\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.89226824  0.87598467  0.8862614  -1.1642838   1.4578406   0.8834638 ]\n",
      "Reset environment\n",
      "Episode reward: 3419.2405\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.8982495   0.88214976  0.8920392  -1.1574849   1.4630445   0.88943875]\n",
      "Reset environment\n",
      "Episode reward: 3696.2222\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.90456337  0.8882871   0.89849263 -1.1503259   1.4686075   0.8957435 ]\n",
      "Reset environment\n",
      "Episode reward: 1142.5033\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9070267   0.8907355   0.90096027 -1.1473867   1.4706975   0.89820564]\n",
      "Reset environment\n",
      "Episode reward: 736.72034\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.90850466  0.8920487   0.90259856 -1.1457007   1.4721346   0.89968437]\n",
      "Reset environment\n",
      "Episode reward: 2020.1846\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9121288   0.89542127  0.90645313 -1.1414145   1.4752815   0.90330994]\n",
      "Reset environment\n",
      "Episode reward: 3675.3972\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9184706   0.901578    0.91295713 -1.1342573   1.4808923   0.9096476 ]\n",
      "Reset environment\n",
      "Episode reward: -1531.9619\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9166694   0.8999157   0.91101784 -1.136142    1.4794532   0.907845  ]\n",
      "Reset environment\n",
      "Episode reward: 5988.966\n",
      "Total Steps: 225\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9252575   0.90862155  0.919489   -1.1265361   1.4870108   0.9164366 ]\n",
      "Reset environment\n",
      "Episode reward: 1722.1785\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9284398  0.9120426  0.9224131 -1.1226186  1.4896623  0.9196175]\n",
      "Reset environment\n",
      "Episode reward: 1085.2717\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9308218   0.9144741   0.9247416  -1.1198679   1.4917225   0.92199826]\n",
      "Reset environment\n",
      "Episode reward: 949.5785\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9329836   0.91669124  0.9268454  -1.1173228   1.4935738   0.9241584 ]\n",
      "Reset environment\n",
      "Episode reward: 1525.5767\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9358208   0.9197774   0.92943    -1.1138546   1.4959774   0.92699975]\n",
      "Reset environment\n",
      "Episode reward: 1373.5544\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9385684   0.92241716  0.9322637  -1.1106308   1.498389    0.92974114]\n",
      "Reset environment\n",
      "Episode reward: -3149.166\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.93467534  0.9170774   0.9297016  -1.1087132   1.4914058   0.9257821 ]\n",
      "Reset environment\n",
      "Episode reward: 814.20544\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.93661565  0.91908324  0.93157387 -1.10641     1.4930562   0.9277245 ]\n",
      "Reset environment\n",
      "Episode reward: 1192.8628\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.93894506  0.9216848   0.93361956 -1.1034715   1.4949691   0.93006074]\n",
      "Reset environment\n",
      "Episode reward: 1457.8916\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.94179064  0.92476773  0.9362059  -1.0999461   1.4973594   0.93290347]\n",
      "Reset environment\n",
      "Episode reward: 361.55115\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.94291055  0.92573327  0.9374699  -1.098557    1.4983656   0.934018  ]\n",
      "Reset environment\n",
      "Episode reward: 3793.7498\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.94935066  0.93199086  0.9440563  -1.0912503   1.5040425   0.94044334]\n",
      "Reset environment\n",
      "Episode reward: 4802.727\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.95615625  0.9388655   0.95077467 -1.0836394   1.5100547   0.9472362 ]\n",
      "Reset environment\n",
      "Episode reward: 4074.1165\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.96179223  0.9446665   0.9562358  -1.0773      1.514987    0.952872  ]\n",
      "Reset environment\n",
      "Episode reward: 1786.8444\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.96323264  0.94583744  0.9579987  -1.0858542   1.517092    0.95434815]\n",
      "Reset environment\n",
      "Episode reward: 4601.0425\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.96637297  0.9497896   0.9603063  -1.0845115   1.5234294   0.9574499 ]\n",
      "Reset environment\n",
      "Episode reward: 3367.7554\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9720365   0.9552528   0.9661394  -1.0780439   1.528406    0.96310323]\n",
      "Reset environment\n",
      "Episode reward: 3310.1375\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.97763383  0.96064985  0.9719075  -1.0716234   1.533306    0.96869653]\n",
      "Reset environment\n",
      "Episode reward: 4568.092\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9840586   0.96710384  0.97828966 -1.0644109   1.5389632   0.97511595]\n",
      "Reset environment\n",
      "Episode reward: 1908.8552\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.98754585  0.9703483   0.9820004  -1.0603011   1.5419853   0.97860295]\n",
      "Reset environment\n",
      "Episode reward: 4926.7134\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9939741   0.97736603  0.98789066 -1.0548959   1.548323    0.9850538 ]\n",
      "Reset environment\n",
      "Episode reward: 1073.2036\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 0.9962945   0.97974265  0.9901515  -1.052215    1.5503293   0.9873735 ]\n",
      "Reset environment\n",
      "Episode reward: 3259.3127\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0018048   0.98505867  0.99582213 -1.0458801   1.5551378   0.99287736]\n",
      "Reset environment\n",
      "Episode reward: 324.78796\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0027318   0.98627853  0.996446   -1.0444202   1.555769    0.9938002 ]\n",
      "Reset environment\n",
      "Episode reward: 1179.2809\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0051993   0.9887375   0.99890876 -1.0415541   1.5579042   0.99626565]\n",
      "Reset environment\n",
      "Episode reward: 1051.4612\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0074716  0.9909632  1.0012177 -1.038899   1.5598711  0.9985384]\n",
      "Reset environment\n",
      "Episode reward: 2544.8706\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.011903   0.995168   1.0058469 -1.033742   1.5637399  1.0029585]\n",
      "Reset environment\n",
      "Episode reward: -219.33948\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.009087   0.9918635  1.0034776 -1.0398531  1.5619484  1.000143 ]\n",
      "Reset environment\n",
      "Episode reward: 880.8616\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0110921  0.9938112  1.0055349 -1.0374475  1.5636559  1.0021495]\n",
      "Reset environment\n",
      "Episode reward: 1519.8702\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0140373   0.99665123  1.0085641  -1.0340043   1.5662007   1.0050906 ]\n",
      "Reset environment\n",
      "Episode reward: 3944.6628\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0194201  1.0019966  1.0139619 -1.0279253  1.5709488  1.0104699]\n",
      "Reset environment\n",
      "Episode reward: 3435.32\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0240229  1.0067061  1.0184435 -1.0226424  1.5749156  1.0150723]\n",
      "Reset environment\n",
      "Episode reward: 1634.6936\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0269874  1.0099126  1.0211453 -1.0189736  1.5774025  1.0180383]\n",
      "Reset environment\n",
      "Episode reward: 5064.2373\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0318729  1.0158838  1.0249678 -1.0183831  1.584781   1.0229368]\n",
      "Reset environment\n",
      "Episode reward: 1575.0146\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0349001  1.0188763  1.0280178 -1.0149099  1.58743    1.0259606]\n",
      "Reset environment\n",
      "Episode reward: 1855.9807\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0383377  1.0222529  1.0315031 -1.0110042  1.5904517  1.0293953]\n",
      "Reset environment\n",
      "Episode reward: 1883.0049\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0414516  1.0255909  1.0343596 -1.0071877  1.5930426  1.032503 ]\n",
      "Reset environment\n",
      "Episode reward: 692.8969\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0431483  1.0272112  1.036124  -1.0050997  1.5944598  1.0342001]\n",
      "Reset environment\n",
      "Episode reward: 809.09393\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0450233  1.029038   1.038046  -1.0027878  1.5960242  1.0360776]\n",
      "Reset environment\n",
      "Episode reward: 1936.3278\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0484318  1.0321629  1.0417178 -0.9986817  1.5989431  1.0394816]\n",
      "Reset environment\n",
      "Episode reward: 4892.6206\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0564363   1.0401022   1.0497731  -0.98971546  1.6060326   1.0474893 ]\n",
      "Reset environment\n",
      "Episode reward: 2114.7505\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0601456   1.043575    1.0536908  -0.98532987  1.609224    1.0512011 ]\n",
      "Reset environment\n",
      "Episode reward: -282.04077\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0577719  1.0411696  1.051378  -0.9974683  1.6079324  1.0488973]\n",
      "Reset environment\n",
      "Episode reward: 624.71594\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0557679  1.0392659  1.0493464 -1.005831   1.6071337  1.0469542]\n",
      "Reset environment\n",
      "Episode reward: 1819.6273\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0590143  1.0422515  1.0528262 -1.0019492  1.6099541  1.0501963]\n",
      "Reset environment\n",
      "Episode reward: 1338.1897\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0616704  1.0448993  1.0554832 -0.9989113  1.6122831  1.0528511]\n",
      "Reset environment\n",
      "Episode reward: 1230.6108\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0640261  1.0470418  1.0580307 -0.9959322  1.6142441  1.0552064]\n",
      "Reset environment\n",
      "Episode reward: 2105.5583\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0676967  1.0504956  1.0618929 -0.9916697  1.6174648  1.0588714]\n",
      "Reset environment\n",
      "Episode reward: 221.20963\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0685436   1.0516516   1.0624093  -0.99033356  1.6180276   1.0597184 ]\n",
      "Reset environment\n",
      "Episode reward: 3180.0176\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0738163   1.0567186   1.0678595  -0.98424804  1.6226565   1.0649828 ]\n",
      "Reset environment\n",
      "Episode reward: 1796.8068\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0770229  1.059715   1.0712582 -0.9804671  1.6254352  1.0681899]\n",
      "Reset environment\n",
      "Episode reward: 6749.755\n",
      "Total Steps: 1182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.08381    1.0666904  1.0778662 -0.9772258  1.6320297  1.0749856]\n",
      "Reset environment\n",
      "Episode reward: 1608.362\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0868577   1.0697708   1.0808756  -0.97373974  1.634688    1.0780303 ]\n",
      "Reset environment\n",
      "Episode reward: 587.3572\n",
      "Total Steps: 24\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0873742   1.0702904   1.0813851  -0.97306883  1.6351095   1.0785456 ]\n",
      "Reset environment\n",
      "Episode reward: 2049.9019\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0910878   1.0740035   1.0850874  -0.96885866  1.6383616   1.0822574 ]\n",
      "Reset environment\n",
      "Episode reward: 1191.7761\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.0934201  1.0765615  1.0871803 -0.9659548  1.6403222  1.0845891]\n",
      "Reset environment\n",
      "Episode reward: 4658.5522\n",
      "Total Steps: 241\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1007822  1.0838153  1.0946397 -0.9577511  1.646928   1.0919514]\n",
      "Reset environment\n",
      "Episode reward: 4031.1067\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1038914   1.0869555   1.0977429  -0.95822346  1.6513615   1.0950465 ]\n",
      "Reset environment\n",
      "Episode reward: 1521.6183\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1063575  1.0896567  1.0999416 -0.9550851  1.6533691  1.0975085]\n",
      "Reset environment\n",
      "Episode reward: 2499.4575\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.110617   1.0941321  1.1039767 -0.9500802  1.6570355  1.1017725]\n",
      "Reset environment\n",
      "Episode reward: 2016.9307\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1141329   1.0974411   1.1076752  -0.94593906  1.6600668   1.1052834 ]\n",
      "Reset environment\n",
      "Episode reward: 6663.657\n",
      "Total Steps: 244\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1233858  1.1065714  1.1170193 -0.9356373  1.6682581  1.1145344]\n",
      "Reset environment\n",
      "Episode reward: 4101.5215\n",
      "Total Steps: 232\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1299615   1.1133004   1.1234373  -0.92831576  1.6741631   1.1211145 ]\n",
      "Reset environment\n",
      "Episode reward: 1087.749\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1322219   1.1155622   1.1256905  -0.92564654  1.6760982   1.123377  ]\n",
      "Reset environment\n",
      "Episode reward: 639.88403\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1311544   1.1142508   1.1249231  -0.93639386  1.6763425   1.122337  ]\n",
      "Reset environment\n",
      "Episode reward: -39.30255\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.131355   1.1146138  1.1249546 -0.9359093  1.6765201  1.1225375]\n",
      "Reset environment\n",
      "Episode reward: 770.312\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.13312     1.1163061   1.1267835  -0.93377465  1.6780131   1.124306  ]\n",
      "Reset environment\n",
      "Episode reward: -759.1381\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1295763  1.1126822  1.123299  -0.9460641  1.6756214  1.1207741]\n",
      "Reset environment\n",
      "Episode reward: 4001.3564\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1347947  1.118042   1.1283643 -0.9401135  1.6801494  1.125995 ]\n",
      "Reset environment\n",
      "Episode reward: 692.2151\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1364417   1.1196586   1.1300379  -0.93801343  1.6814753   1.1276426 ]\n",
      "Reset environment\n",
      "Episode reward: 5395.006\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1437975  1.127127   1.1372486 -0.9298701  1.6879936  1.134998 ]\n",
      "Reset environment\n",
      "Episode reward: 3917.7793\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1501645  1.1336567  1.143426  -0.9227295  1.6936007  1.1413685]\n",
      "Reset environment\n",
      "Episode reward: 1022.3519\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1523358  1.1358857  1.1455355 -0.9201755  1.6954503  1.1435394]\n",
      "Reset environment\n",
      "Episode reward: 1924.8156\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.155626    1.1389287   1.1490465  -0.91614807  1.698218    1.1468297 ]\n",
      "Reset environment\n",
      "Episode reward: -548.6414\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1556321  1.1385771  1.1493994 -0.9158335  1.698201   1.146837 ]\n",
      "Reset environment\n",
      "Episode reward: 1930.4772\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1590729  1.1420164  1.152837  -0.9118287  1.7011671  1.1502838]\n",
      "Reset environment\n",
      "Episode reward: 3038.178\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1641412   1.1472399   1.157734   -0.90607893  1.7056065   1.1553502 ]\n",
      "Reset environment\n",
      "Episode reward: 1168.5842\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1664953  1.149576   1.1600969 -0.903328   1.7076379  1.157701 ]\n",
      "Reset environment\n",
      "Episode reward: 164.11523\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.162423    1.1446909   1.1569408  -0.90875846  1.7050959   1.1536012 ]\n",
      "Reset environment\n",
      "Episode reward: 1503.6516\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1652626   1.1475297   1.1597731  -0.90549946  1.7075737   1.1564415 ]\n",
      "Reset environment\n",
      "Episode reward: 881.9607\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1671011   1.14927     1.1616974  -0.90335757  1.7091396   1.158277  ]\n",
      "Reset environment\n",
      "Episode reward: -529.741\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.166901    1.1491358   1.1614288  -0.90320534  1.7088474   1.1580782 ]\n",
      "Reset environment\n",
      "Episode reward: 4740.9062\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1732805   1.1555631   1.1677641  -0.89603686  1.7144608   1.164467  ]\n",
      "Reset environment\n",
      "Episode reward: 3267.467\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1786041  1.1606956  1.1732517 -0.8899029  1.7191272  1.169786 ]\n",
      "Reset environment\n",
      "Episode reward: 91.66318\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1791269   1.1610337   1.1739525  -0.88919574  1.719623    1.1703054 ]\n",
      "Reset environment\n",
      "Episode reward: 1098.5914\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.181374    1.1633291   1.1761466  -0.88659084  1.7215713   1.1725501 ]\n",
      "Reset environment\n",
      "Episode reward: 2325.5205\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1852455  1.1674097  1.1797799 -0.8820005  1.7248629  1.1764224]\n",
      "Reset environment\n",
      "Episode reward: 6018.9253\n",
      "Total Steps: 216\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1934645  1.1756926  1.1879101 -0.872822   1.7321078  1.1846353]\n",
      "Reset environment\n",
      "Episode reward: 2606.7666\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.1976863   1.1801436   1.1918886  -0.86789274  1.7357391   1.1888667 ]\n",
      "Reset environment\n",
      "Episode reward: 3729.7705\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2035894   1.1862372   1.1975843  -0.86118823  1.7408884   1.1947819 ]\n",
      "Reset environment\n",
      "Episode reward: 4925.6333\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2102339   1.1929504   1.2041371  -0.85373336  1.7467264   1.2014214 ]\n",
      "Reset environment\n",
      "Episode reward: -935.3517\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2092392   1.1921368   1.2029566  -0.85453993  1.7458248   1.2004299 ]\n",
      "Reset environment\n",
      "Episode reward: 4639.886\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2153957  1.1983994  1.2089951 -0.8476321  1.7512386  1.2065927]\n",
      "Reset environment\n",
      "Episode reward: 2892.062\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2200794  1.2028694  1.2138661 -0.8421132  1.7552788  1.211266 ]\n",
      "Reset environment\n",
      "Episode reward: 1230.127\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2224243   1.2049981   1.2164052  -0.83920527  1.7572062   1.2136061 ]\n",
      "Reset environment\n",
      "Episode reward: 1797.4414\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2256595  1.2082942  1.2195841 -0.8354663  1.7600106  1.2168477]\n",
      "Reset environment\n",
      "Episode reward: 743.2779\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2273676  1.2099411  1.2213503 -0.8333525  1.761428   1.2185583]\n",
      "Reset environment\n",
      "Episode reward: 583.68567\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2287221   1.2111588   1.2228277  -0.83179903  1.7625979   1.2199086 ]\n",
      "Reset environment\n",
      "Episode reward: -147.5333\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2290581  1.2118077  1.2228441 -0.8309999  1.7627096  1.2202493]\n",
      "Reset environment\n",
      "Episode reward: 793.8076\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2273654  1.2094144  1.2218974 -0.8347616  1.7612542  1.2185106]\n",
      "Reset environment\n",
      "Episode reward: 2746.1702\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2319275   1.2138102   1.226603   -0.82954836  1.7652862   1.2230681 ]\n",
      "Reset environment\n",
      "Episode reward: 4.4628906\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2308007   1.2128228   1.2252908  -0.84231824  1.7647856   1.2219428 ]\n",
      "Reset environment\n",
      "Episode reward: 3602.1763\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2354785  1.2175713  1.2298864 -0.8370709  1.7688857  1.2266259]\n",
      "Reset environment\n",
      "Episode reward: 1174.5184\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2368008  1.2188908  1.2312013 -0.8354317  1.7699859  1.2279464]\n",
      "Reset environment\n",
      "Episode reward: 270.2694\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2376982  1.2195299  1.2323424 -0.8340132  1.7706412  1.2288474]\n",
      "Reset environment\n",
      "Episode reward: 1968.7386\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2409931  1.2230375  1.2354091 -0.8300334  1.7734452  1.2321445]\n",
      "Reset environment\n",
      "Episode reward: 747.9066\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2427084  1.2248272  1.2370502 -0.8279804  1.7748977  1.2338622]\n",
      "Reset environment\n",
      "Episode reward: 4432.0566\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2497151  1.2319282  1.2439559 -0.8201913  1.7811236  1.2408799]\n",
      "Reset environment\n",
      "Episode reward: 2796.5054\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2543135  1.2363565  1.248701  -0.8148444  1.78516    1.2454711]\n",
      "Reset environment\n",
      "Episode reward: 1238.0764\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2567362   1.2388114   1.251087   -0.81207186  1.7872739   1.2478929 ]\n",
      "Reset environment\n",
      "Episode reward: 1011.136\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.258794   1.2408323  1.253173  -0.8095907  1.7890152  1.2499497]\n",
      "Reset environment\n",
      "Episode reward: 3061.3499\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2637357  1.2459722  1.2579018 -0.8039604  1.7933241  1.254892 ]\n",
      "Reset environment\n",
      "Episode reward: 4208.966\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2692378   1.2515479   1.2633151  -0.79782915  1.7981703   1.2603925 ]\n",
      "Reset environment\n",
      "Episode reward: 1364.3004\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2714998  1.2536165  1.2657481 -0.7951127  1.8001808  1.2626535]\n",
      "Reset environment\n",
      "Episode reward: 1599.3585\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2744045   1.2565117   1.2686555  -0.79177684  1.8027139   1.2655594 ]\n",
      "Reset environment\n",
      "Episode reward: 1174.0131\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2767283  1.2588891  1.2709233 -0.7890382  1.8047101  1.2678812]\n",
      "Reset environment\n",
      "Episode reward: 1248.3809\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.278856   1.2612447  1.2727983 -0.7862662  1.8064221  1.2700089]\n",
      "Reset environment\n",
      "Episode reward: 1840.9362\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2790072   1.2612704   1.2730961  -0.79229325  1.8070449   1.2701881 ]\n",
      "Reset environment\n",
      "Episode reward: 860.69836\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.278144    1.2590413   1.2735764  -0.79503995  1.8050929   1.2693177 ]\n",
      "Reset environment\n",
      "Episode reward: 2184.6033\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2817256   1.2628425   1.2769272  -0.79083437  1.8082049   1.2729017 ]\n",
      "Reset environment\n",
      "Episode reward: 2945.3467\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2864146  1.2673322  1.281783  -0.785406   1.8122919  1.2775836]\n",
      "Reset environment\n",
      "Episode reward: 340.6415\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.287113    1.268262    1.2822341  -0.78421134  1.812775    1.2782828 ]\n",
      "Reset environment\n",
      "Episode reward: 2469.8276\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2879798  1.2689848  1.283306  -0.7927633  1.8142327  1.2791481]\n",
      "Reset environment\n",
      "Episode reward: 519.35815\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2854875   1.2657847   1.2815357  -0.80109143  1.8124455   1.2766554 ]\n",
      "Reset environment\n",
      "Episode reward: 1225.3646\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2878385  1.2681084  1.283903  -0.7983836  1.814497   1.2790042]\n",
      "Reset environment\n",
      "Episode reward: 87.48776\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2881249  1.2685742  1.2840098 -0.7978627  1.8148046  1.279296 ]\n",
      "Reset environment\n",
      "Episode reward: 2831.011\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2916092  1.272109   1.2874368 -0.7939368  1.8178866  1.2827808]\n",
      "Reset environment\n",
      "Episode reward: 1572.1427\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2944239  1.2749393  1.2902342 -0.790607   1.8202955  1.285598 ]\n",
      "Reset environment\n",
      "Episode reward: 992.7675\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2964387   1.2769067   1.2922949  -0.78824306  1.8220439   1.2876128 ]\n",
      "Reset environment\n",
      "Episode reward: 382.4582\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.2973768   1.2776734   1.2933927  -0.78710943  1.822915    1.2885462 ]\n",
      "Reset environment\n",
      "Episode reward: 1741.4277\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3002383   1.2807283   1.2960374  -0.78360426  1.8253397   1.2914082 ]\n",
      "Reset environment\n",
      "Episode reward: 3711.8877\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3059771   1.2866452   1.3015898  -0.77707475  1.8303634   1.2971545 ]\n",
      "Reset environment\n",
      "Episode reward: 2113.7183\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3095642  1.2902306  1.3051716 -0.772994   1.8335065  1.3007454]\n",
      "Reset environment\n",
      "Episode reward: -925.1718\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3055073  1.2856847  1.3016064 -0.7798394  1.8296605  1.2966958]\n",
      "Reset environment\n",
      "Episode reward: 1018.676\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.305261   1.2854325  1.3013273 -0.7869529  1.8300414  1.2964853]\n",
      "Reset environment\n",
      "Episode reward: 4056.0913\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3077723   1.287588    1.3041918  -0.79077446  1.8334192   1.2990406 ]\n",
      "Reset environment\n",
      "Episode reward: 214.42166\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3085214  1.2884282  1.3048425 -0.7898281  1.8340989  1.2997851]\n",
      "Reset environment\n",
      "Episode reward: 1562.5168\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3113348  1.2912811  1.3076031 -0.7866032  1.8365523  1.3025919]\n",
      "Reset environment\n",
      "Episode reward: 3562.3167\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3168408   1.2966536   1.3132206  -0.78027844  1.8413891   1.3080921 ]\n",
      "Reset environment\n",
      "Episode reward: 1252.9766\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3192164  1.2990297  1.3155916 -0.777551   1.8434587  1.3104683]\n",
      "Reset environment\n",
      "Episode reward: 1926.8815\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3223847   1.3023661   1.3185873  -0.77387196  1.8462306   1.3136398 ]\n",
      "Reset environment\n",
      "Episode reward: 1263.1064\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.324779    1.3047873   1.3209472  -0.77113307  1.8483229   1.3160318 ]\n",
      "Reset environment\n",
      "Episode reward: -4398.2656\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3168048  1.2956965  1.314026  -0.778803   1.8381722  1.3080198]\n",
      "Reset environment\n",
      "Episode reward: 4300.3223\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3223618  1.3012009  1.3196114 -0.7725781  1.8430834  1.3135766]\n",
      "Reset environment\n",
      "Episode reward: 1859.0938\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3255463   1.3043418   1.3228233  -0.76886606  1.8458285   1.3167605 ]\n",
      "Reset environment\n",
      "Episode reward: 1927.2224\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3288275  1.3075932  1.3261222 -0.7651049  1.8486886  1.3200402]\n",
      "Reset environment\n",
      "Episode reward: 6495.2505\n",
      "Total Steps: 233\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3374077  1.3161857  1.3346709 -0.7555995  1.8563234  1.3286184]\n",
      "Reset environment\n",
      "Episode reward: 558.3135\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.338618    1.3176289   1.3356397  -0.75387156  1.8572583   1.3298302 ]\n",
      "Reset environment\n",
      "Episode reward: -436.51935\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.338369    1.3170797   1.3356807  -0.75393677  1.8570265   1.3295803 ]\n",
      "Reset environment\n",
      "Episode reward: 2616.7417\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3394986   1.317597    1.3374122  -0.75802827  1.857746    1.3306817 ]\n",
      "Reset environment\n",
      "Episode reward: -368.3248\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3394344   1.3175209   1.3373573  -0.75776213  1.8576269   1.3306209 ]\n",
      "Reset environment\n",
      "Episode reward: 1336.688\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3418946   1.3199733   1.3398225  -0.75495917  1.859794    1.3330779 ]\n",
      "Reset environment\n",
      "Episode reward: 6198.864\n",
      "Total Steps: 234\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3498721  1.3280362  1.3477092 -0.7460448  1.866824   1.3410647]\n",
      "Reset environment\n",
      "Episode reward: 4297.202\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3553388   1.3335674   1.353114   -0.73994786  1.8716558   1.3465364 ]\n",
      "Reset environment\n",
      "Episode reward: 5879.463\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3629322   1.3410802   1.3607796  -0.73147285  1.8783841   1.3541341 ]\n",
      "Reset environment\n",
      "Episode reward: 4532.7056\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3685764  1.3466307  1.3665022 -0.7249264  1.883255   1.3597788]\n",
      "Reset environment\n",
      "Episode reward: 1533.1785\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3713089   1.3493221   1.3692644  -0.72178066  1.8856424   1.3625102 ]\n",
      "Reset environment\n",
      "Episode reward: 4986.445\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3778372  1.3559278  1.3757045 -0.7144251  1.8913788  1.3690522]\n",
      "Reset environment\n",
      "Episode reward: 2312.3555\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3814883   1.3597986   1.3791265  -0.71014154  1.894523    1.3727025 ]\n",
      "Reset environment\n",
      "Episode reward: -259.86713\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3815219   1.3596917   1.3792871  -0.70990276  1.8945682   1.3727351 ]\n",
      "Reset environment\n",
      "Episode reward: 1697.7971\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3842735  1.3622622  1.3821967 -0.7065249  1.8969073  1.3754855]\n",
      "Reset environment\n",
      "Episode reward: 1946.2853\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3785607   1.3559048   1.3771949  -0.71289307  1.8921688   1.3697021 ]\n",
      "Reset environment\n",
      "Episode reward: 1292.3318\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3809603   1.3582788   1.3796124  -0.71013886  1.894265    1.372098  ]\n",
      "Reset environment\n",
      "Episode reward: 1374.4\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3834766   1.3608383   1.3820807  -0.70728576  1.8964872   1.3746142 ]\n",
      "Reset environment\n",
      "Episode reward: 4328.7505\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3890717  1.3665484  1.3875425 -0.7010327  1.9014068  1.3802117]\n",
      "Reset environment\n",
      "Episode reward: 1167.4746\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.3912884  1.3688065  1.3897195 -0.6984694  1.9033294  1.3824319]\n",
      "Reset environment\n",
      "Episode reward: 2054.1123\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.39469     1.3722187   1.3931061  -0.69459116  1.9063098   1.3858329 ]\n",
      "Reset environment\n",
      "Episode reward: 6106.1587\n",
      "Total Steps: 235\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4025522  1.379964   1.401076  -0.6856884  1.9132255  1.3936968]\n",
      "Reset environment\n",
      "Episode reward: 4492.9507\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4082394   1.3855836   1.4068139  -0.67920256  1.9181961   1.3993841 ]\n",
      "Reset environment\n",
      "Episode reward: -855.23846\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4073578   1.3845658   1.4060571  -0.68016803  1.9174601   1.3985007 ]\n",
      "Reset environment\n",
      "Episode reward: 1563.3164\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4099456  1.3873569  1.4084376 -0.6770551  1.9196755  1.4010941]\n",
      "Reset environment\n",
      "Episode reward: 6151.0513\n",
      "Total Steps: 223\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4178538  1.3951868  1.4164076 -0.6682422  1.9266841  1.4090042]\n",
      "Reset environment\n",
      "Episode reward: 3987.096\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4229072  1.4002401  1.4214523 -0.6625539  1.9311335  1.4140627]\n",
      "Reset environment\n",
      "Episode reward: 891.31433\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4242228  1.4017876  1.4225131 -0.6607373  1.9321553  1.415372 ]\n",
      "Reset environment\n",
      "Episode reward: 1081.3525\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4263226  1.4038647  1.4246327 -0.6582591  1.9339565  1.4174703]\n",
      "Reset environment\n",
      "Episode reward: 1344.5803\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.428485   1.4060605  1.4267588 -0.6556975  1.9358215  1.419632 ]\n",
      "Reset environment\n",
      "Episode reward: 3603.3\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.432956    1.4105942   1.4311666  -0.65068597  1.9397733   1.4241103 ]\n",
      "Reset environment\n",
      "Episode reward: 4453.8945\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4395721  1.4170775  1.4379008 -0.6432206  1.9456135  1.4307191]\n",
      "Reset environment\n",
      "Episode reward: 1829.946\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4425031  1.4197948  1.4410228 -0.6397551  1.9481729  1.4336443]\n",
      "Reset environment\n",
      "Episode reward: 3652.9307\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4471356   1.4245024   1.4455503  -0.63457173  1.9522583   1.4382697 ]\n",
      "Reset environment\n",
      "Episode reward: 2257.6284\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4473659   1.4244776   1.4461006  -0.63431895  1.9521632   1.4384837 ]\n",
      "Reset environment\n",
      "Episode reward: 1122.2241\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4485445  1.425654   1.4472803 -0.6329066  1.9531682  1.4396648]\n",
      "Reset environment\n",
      "Episode reward: 5798.105\n",
      "Total Steps: 217\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4559207   1.433119    1.4545504  -0.62471783  1.9597003   1.4470493 ]\n",
      "Reset environment\n",
      "Episode reward: 1743.3044\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4587631  1.435765   1.4575671 -0.6213562  1.9621797  1.4498905]\n",
      "Reset environment\n",
      "Episode reward: 928.4232\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4585202  1.4357562  1.4570985 -0.6276164  1.9618627  1.4496644]\n",
      "Reset environment\n",
      "Episode reward: 1769.6447\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4615071  1.4386833  1.4601278 -0.6241929  1.96446    1.4526486]\n",
      "Reset environment\n",
      "Episode reward: 152.6449\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4583955  1.4354401  1.4572121 -0.6351837  1.9626312  1.4495665]\n",
      "Reset environment\n",
      "Episode reward: 1869.1807\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4575948  1.4343138  1.4567221 -0.6391431  1.9619461  1.4488207]\n",
      "Reset environment\n",
      "Episode reward: 1286.0239\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4599274   1.4366826   1.4590193  -0.63648134  1.9639916   1.4511576 ]\n",
      "Reset environment\n",
      "Episode reward: 1036.4369\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4619192  1.4387246  1.4609665 -0.6341445  1.9657102  1.4531538]\n",
      "Reset environment\n",
      "Episode reward: 1502.3022\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4644635   1.4411681   1.4636042  -0.63115317  1.9679456   1.4556979 ]\n",
      "Reset environment\n",
      "Episode reward: 1272.6183\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4664391  1.4433451  1.4653505 -0.6286491  1.9695956  1.4576697]\n",
      "Reset environment\n",
      "Episode reward: 1633.744\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4692262   1.4461381   1.4681308  -0.62542886  1.9720142   1.4604586 ]\n",
      "Reset environment\n",
      "Episode reward: 5716.7734\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4764001  1.4532781  1.4753239 -0.6174532  1.9783767  1.4676286]\n",
      "Reset environment\n",
      "Episode reward: 1869.4661\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4794873   1.4563506   1.4784224  -0.61388236  1.9810375   1.4707173 ]\n",
      "Reset environment\n",
      "Episode reward: 4620.8394\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4862976  1.4630499  1.485331  -0.6062781  1.9870957  1.4775308]\n",
      "Reset environment\n",
      "Episode reward: 1414.5435\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4884826  1.4650588  1.4876701 -0.6035781  1.9889859  1.4797091]\n",
      "Reset environment\n",
      "Episode reward: 1083.9866\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4905281  1.4671314  1.4896892 -0.6011722  1.9907392  1.4817567]\n",
      "Reset environment\n",
      "Episode reward: 2252.7341\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4930905  1.4697003  1.492231  -0.5982596  1.9929777  1.4843122]\n",
      "Reset environment\n",
      "Episode reward: 413.18378\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4940801  1.4708583  1.4930304 -0.5967193  1.9937128  1.485295 ]\n",
      "Reset environment\n",
      "Episode reward: 1183.4363\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4962716  1.4730585  1.4952029 -0.5941379  1.9955809  1.4874836]\n",
      "Reset environment\n",
      "Episode reward: 2099.3403\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.4995319   1.4761167   1.498631   -0.59024584  1.9983852   1.4907401 ]\n",
      "Reset environment\n",
      "Episode reward: 2221.2856\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5029501  1.479344   1.5022051 -0.5862076  2.0013554  1.494153 ]\n",
      "Reset environment\n",
      "Episode reward: 5531.0073\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5071522  1.4835889  1.5063535 -0.5861364  2.0050638  1.4983678]\n",
      "Reset environment\n",
      "Episode reward: 3450.5042\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5114347   1.4879245   1.5105709  -0.58132225  2.0088284   1.502655  ]\n",
      "Reset environment\n",
      "Episode reward: 1078.459\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5134677  1.4899098  1.5126421 -0.5789707  2.0105999  1.5046865]\n",
      "Reset environment\n",
      "Episode reward: 2571.6118\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5173587  1.4940037  1.5163132 -0.5744602  2.0139751  1.5085804]\n",
      "Reset environment\n",
      "Episode reward: 2455.8784\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5210829  1.4975685  1.5201635 -0.5701724  2.0172756  1.5123038]\n",
      "Reset environment\n",
      "Episode reward: 7009.169\n",
      "Total Steps: 251\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5299044  1.5064644  1.5288988 -0.5604397  2.0251133  1.5211251]\n",
      "Reset environment\n",
      "Episode reward: 1481.5095\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5315615   1.508127    1.5305383  -0.55852675  2.0265596   1.5227796 ]\n",
      "Reset environment\n",
      "Episode reward: 4085.524\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5330453  1.5097218  1.5320318 -0.5658255  2.0295963  1.5242633]\n",
      "Reset environment\n",
      "Episode reward: 1297.267\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5353754  1.5120609  1.5343499 -0.5631776  2.0316405  1.5265934]\n",
      "Reset environment\n",
      "Episode reward: 5728.2666\n",
      "Total Steps: 214\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5425016  1.5192822  1.5413744 -0.5552481  2.0379484  1.5337191]\n",
      "Reset environment\n",
      "Episode reward: 4417.776\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5490168  1.5258771  1.5478132 -0.5479715  2.043722   1.5402462]\n",
      "Reset environment\n",
      "Episode reward: 5359.0586\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.552678   1.5292389  1.5517863 -0.5491535  2.047774   1.5439315]\n",
      "Reset environment\n",
      "Episode reward: 4565.498\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5592701   1.535677    1.5585074  -0.54173356  2.0536108   1.5505136 ]\n",
      "Reset environment\n",
      "Episode reward: 2047.1464\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5624106   1.5386189   1.5618218  -0.53801316  2.056337    1.5536536 ]\n",
      "Reset environment\n",
      "Episode reward: 4940.0454\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5684658  1.5447091  1.5678233 -0.5312401  2.0616646  1.5597001]\n",
      "Reset environment\n",
      "Episode reward: 2971.0576\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5718251  1.5481665  1.5710735 -0.5273784  2.0645874  1.5630642]\n",
      "Reset environment\n",
      "Episode reward: 995.79315\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5736979  1.5500203  1.5729625 -0.5251189  2.0661767  1.564936 ]\n",
      "Reset environment\n",
      "Episode reward: 1284.4934\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.575997   1.5523204  1.5752563 -0.5224977  2.0681956  1.5672365]\n",
      "Reset environment\n",
      "Episode reward: 1650.9607\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.578782   1.5551414  1.5779994 -0.5193252  2.0706341  1.570023 ]\n",
      "Reset environment\n",
      "Episode reward: 1235.3469\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5810034  1.557324   1.5802486 -0.5167899  2.072588   1.5722452]\n",
      "Reset environment\n",
      "Episode reward: 1004.4734\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5829089  1.559186   1.5821865 -0.5145402  2.0742223  1.5741525]\n",
      "Reset environment\n",
      "Episode reward: 1077.9174\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5849125  1.5611957  1.5841807 -0.5121613  2.075924   1.5761567]\n",
      "Reset environment\n",
      "Episode reward: 4694.2754\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5916412  1.567945   1.5908675 -0.5045934  2.081831   1.5828966]\n",
      "Reset environment\n",
      "Episode reward: 3704.833\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5960783   1.572442    1.5952215  -0.49965423  2.0857413   1.5873312 ]\n",
      "Reset environment\n",
      "Episode reward: 1656.4453\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5987056   1.5748848   1.5980123  -0.49640417  2.087953    1.5899578 ]\n",
      "Reset environment\n",
      "Episode reward: 2932.3442\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6021147   1.5783234   1.6013838  -0.49253643  2.0909374   1.5933679 ]\n",
      "Reset environment\n",
      "Episode reward: -377.96667\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.5984564  1.5747993  1.5975825 -0.5066873  2.088635   1.5897074]\n",
      "Reset environment\n",
      "Episode reward: 1482.2747\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6009954  1.5773574  1.6000947 -0.5037689  2.0908277  1.5922465]\n",
      "Reset environment\n",
      "Episode reward: 4549.5903\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.606509    1.5828032   1.6056594  -0.49755207  2.0956843   1.5977596 ]\n",
      "Reset environment\n",
      "Episode reward: -570.1735\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6060051  1.5821187  1.6053268 -0.4979845  2.095252   1.5972553]\n",
      "Reset environment\n",
      "Episode reward: 1532.4899\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6052951   1.58172     1.6042788  -0.50022155  2.0937505   1.5965523 ]\n",
      "Reset environment\n",
      "Episode reward: 2110.9126\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6048592  1.5811586  1.604036  -0.5094953  2.0937665  1.5961226]\n",
      "Reset environment\n",
      "Episode reward: -95.760956\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6050647  1.5815128  1.60409   -0.5091337  2.093941   1.5963267]\n",
      "Reset environment\n",
      "Episode reward: 1741.7047\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6043957  1.5807158  1.6036397 -0.5179231  2.0938013  1.5956875]\n",
      "Reset environment\n",
      "Episode reward: 2540.2283\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6071104   1.5834924   1.6062859  -0.51482075  2.0961735   1.5984054 ]\n",
      "Reset environment\n",
      "Episode reward: 1328.839\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6091181  1.5853763  1.6083997 -0.512327   2.0979166  1.600418 ]\n",
      "Reset environment\n",
      "Episode reward: 3038.9824\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.609635   1.5859058  1.6089478 -0.5114636  2.0982242  1.6008989]\n",
      "Reset environment\n",
      "Episode reward: 1584.6858\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6113633  1.5876396  1.610671  -0.509418   2.0997086  1.6026299]\n",
      "Reset environment\n",
      "Episode reward: 1986.3586\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6140039  1.5903172  1.6132396 -0.5062444  2.1020296  1.6052743]\n",
      "Reset environment\n",
      "Episode reward: -522.20105\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6134751  1.589864   1.6126368 -0.5068264  2.1016119  1.6047434]\n",
      "Reset environment\n",
      "Episode reward: 3588.6572\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6176431   1.5941112   1.616727   -0.50200003  2.105222    1.608915  ]\n",
      "Reset environment\n",
      "Episode reward: 5780.008\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.62465     1.6010596   1.6237726  -0.49414882  2.1113987   1.6159168 ]\n",
      "Reset environment\n",
      "Episode reward: 4309.546\n",
      "Total Steps: 306\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6304727  1.6071554  1.6293226 -0.4872467  2.1165018  1.6217408]\n",
      "Reset environment\n",
      "Episode reward: 4036.9502\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6352482   1.6119853   1.6340257  -0.48190898  2.1207285   1.626512  ]\n",
      "Reset environment\n",
      "Episode reward: 4480.0337\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6407123   1.617416    1.6395229  -0.47578523  2.1255748   1.6319767 ]\n",
      "Reset environment\n",
      "Episode reward: -1189.5953\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6357449  1.6124073  1.6346945 -0.4897591  2.12221    1.6270894]\n",
      "Reset environment\n",
      "Episode reward: 3164.5352\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6401753  1.6170378  1.6389104 -0.4846389  2.126075   1.6315354]\n",
      "Reset environment\n",
      "Episode reward: 1502.7812\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6425085  1.6195357  1.6410819 -0.481925   2.128163   1.6338773]\n",
      "Reset environment\n",
      "Episode reward: 2362.5579\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6460297  1.6232544  1.6443979 -0.4777608  2.1312137  1.6374046]\n",
      "Reset environment\n",
      "Episode reward: 5222.2593\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.652517    1.6298182   1.6508026  -0.47051162  2.1369631   1.6439029 ]\n",
      "Reset environment\n",
      "Episode reward: 1567.5555\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6516103  1.628813   1.6500208 -0.4795325  2.136328   1.6430101]\n",
      "Reset environment\n",
      "Episode reward: 1342.6897\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.65387    1.6310357  1.6523196 -0.4768314  2.1382577  1.6452746]\n",
      "Reset environment\n",
      "Episode reward: 2559.2585\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6576968   1.6347243   1.656268   -0.47243094  2.1416373   1.6491035 ]\n",
      "Reset environment\n",
      "Episode reward: 2691.4395\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6616691   1.6385173   1.6603994  -0.46781096  2.1451144   1.6530724 ]\n",
      "Reset environment\n",
      "Episode reward: 1158.9541\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6637344  1.6406171  1.6624279 -0.4654287  2.1469016  1.6551344]\n",
      "Reset environment\n",
      "Episode reward: 2243.8682\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6669244   1.6440006   1.6654133  -0.46160004  2.149658    1.6583245 ]\n",
      "Reset environment\n",
      "Episode reward: 1974.5211\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6698755   1.6467352   1.668571   -0.45805866  2.1522062   1.6612779 ]\n",
      "Reset environment\n",
      "Episode reward: -533.32666\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6695374  1.6464864  1.668146  -0.4583438  2.151903   1.6609403]\n",
      "Reset environment\n",
      "Episode reward: 3644.374\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6737615   1.6507466   1.6723299  -0.45356628  2.1556087   1.6651628 ]\n",
      "Reset environment\n",
      "Episode reward: 290.28043\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6742644  1.6510057  1.6730608 -0.4528765  2.1561556  1.6656661]\n",
      "Reset environment\n",
      "Episode reward: 1174.4807\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6763327  1.6530154  1.6751806 -0.450499   2.1579661  1.6677358]\n",
      "Reset environment\n",
      "Episode reward: 4214.021\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6813142   1.6578944   1.6802435  -0.44484976  2.1623642   1.6727127 ]\n",
      "Reset environment\n",
      "Episode reward: 2864.6377\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6846808  1.6612895  1.6835682 -0.4410631  2.1653397  1.6760751]\n",
      "Reset environment\n",
      "Episode reward: 2668.604\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6876397   1.6642711   1.6865046  -0.43768573  2.1679313   1.6790384 ]\n",
      "Reset environment\n",
      "Episode reward: 2711.4426\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6911625   1.6678319   1.6899571  -0.43362263  2.1710963   1.6825657 ]\n",
      "Reset environment\n",
      "Episode reward: 1779.3798\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6940075   1.6706893   1.692781   -0.43033132  2.1735547   1.6854097 ]\n",
      "Reset environment\n",
      "Episode reward: 884.3388\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6956805   1.672375    1.6944366  -0.42825365  2.1749167   1.6870824 ]\n",
      "Reset environment\n",
      "Episode reward: 4821.806\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7015914   1.6783886   1.7002352  -0.42166638  2.180145    1.692995  ]\n",
      "Reset environment\n",
      "Episode reward: 263.16772\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.6987318   1.6757194   1.6971973  -0.43471307  2.178538    1.6901317 ]\n",
      "Reset environment\n",
      "Episode reward: 2801.3906\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7018626  1.6788673  1.7003102 -0.4311445  2.1812904  1.693263 ]\n",
      "Reset environment\n",
      "Episode reward: 4589.1626\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7072583   1.6843195   1.7056363  -0.42510438  2.1860695   1.6986635 ]\n",
      "Reset environment\n",
      "Episode reward: 1156.351\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7093008   1.6863405   1.7076952  -0.42270124  2.1878257   1.7007056 ]\n",
      "Reset environment\n",
      "Episode reward: 2073.6008\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7125067   1.6895396   1.7108943  -0.41906732  2.1906424   1.7039105 ]\n",
      "Reset environment\n",
      "Episode reward: 1465.4685\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7147642  1.6920112  1.7129295 -0.4163203  2.1925855  1.7061694]\n",
      "Reset environment\n",
      "Episode reward: 1211.3014\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7168847   1.6941147   1.7150644  -0.41388035  2.1944382   1.7082909 ]\n",
      "Reset environment\n",
      "Episode reward: 1170.7368\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7189411   1.6961384   1.7171465  -0.41148362  2.1962228   1.7103475 ]\n",
      "Reset environment\n",
      "Episode reward: 5643.876\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7256725   1.7027569   1.7239804  -0.40397286  2.2022016   1.7170718 ]\n",
      "Reset environment\n",
      "Episode reward: 995.2051\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7274798  1.7045238  1.7258284 -0.4018383  2.2037532  1.71888  ]\n",
      "Reset environment\n",
      "Episode reward: 1246.0859\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7296357   1.7066854   1.7279788  -0.39934525  2.2056289   1.7210338 ]\n",
      "Reset environment\n",
      "Episode reward: 1197.0753\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7317296   1.7088138   1.7300397  -0.39692953  2.2074504   1.7231283 ]\n",
      "Reset environment\n",
      "Episode reward: 1143.8973\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.733753    1.7108258   1.7320733  -0.39457154  2.2091994   1.725148  ]\n",
      "Reset environment\n",
      "Episode reward: 598.806\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7315423   1.7090714   1.7294463  -0.39906162  2.2064908   1.7229506 ]\n",
      "Reset environment\n",
      "Episode reward: 1234.8151\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7336689  1.7111824  1.7315834 -0.3966095  2.2083447  1.7250755]\n",
      "Reset environment\n",
      "Episode reward: 3403.8442\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7384771   1.716158    1.7362041  -0.39113653  2.2125752   1.7298868 ]\n",
      "Reset environment\n",
      "Episode reward: -337.34973\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7383591   1.7159069   1.736211   -0.39114323  2.2124581   1.7297677 ]\n",
      "Reset environment\n",
      "Episode reward: 2942.601\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7424788  1.7201926  1.7401451 -0.386357   2.215999   1.7338891]\n",
      "Reset environment\n",
      "Episode reward: 1700.4729\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7450418   1.7225952   1.7428579  -0.38329613  2.2182128   1.7364528 ]\n",
      "Reset environment\n",
      "Episode reward: 1638.4861\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7476771  1.7252003  1.7455119 -0.3802638  2.2205079  1.7390845]\n",
      "Reset environment\n",
      "Episode reward: 1155.7228\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7497003  1.7272398  1.7475145 -0.3779174  2.2222548  1.7411045]\n",
      "Reset environment\n",
      "Episode reward: 1413.2543\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7518488   1.7291859   1.7498456  -0.37524608  2.2240837   1.7432524 ]\n",
      "Reset environment\n",
      "Episode reward: 2921.031\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7552457   1.7326065   1.7532048  -0.37141037  2.2270641   1.7466452 ]\n",
      "Reset environment\n",
      "Episode reward: 1203.7941\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7573435   1.7347403   1.7552645  -0.36899257  2.2288866   1.7487427 ]\n",
      "Reset environment\n",
      "Episode reward: 2896.684\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7615254   1.7387519   1.759601   -0.36417627  2.2325659   1.7529178 ]\n",
      "Reset environment\n",
      "Episode reward: 1841.4247\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7635417   1.7407798   1.7615991  -0.36185673  2.2343225   1.75493   ]\n",
      "Reset environment\n",
      "Episode reward: 6737.068\n",
      "Total Steps: 248\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7715784  1.7486956  1.769735  -0.3528686  2.2414317  1.7629608]\n",
      "Reset environment\n",
      "Episode reward: -430.57715\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7714173   1.748459    1.7696434  -0.35304937  2.241335    1.7627972 ]\n",
      "Reset environment\n",
      "Episode reward: 1317.1243\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7736568  1.7507253  1.7718551 -0.3505214  2.2433069  1.7650378]\n",
      "Reset environment\n",
      "Episode reward: 5397.553\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7800239   1.756993    1.7783163  -0.34336975  2.2489321   1.7714065 ]\n",
      "Reset environment\n",
      "Episode reward: 3781.2358\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.785251    1.7620633   1.7836747  -0.33743346  2.2535317   1.7766248 ]\n",
      "Reset environment\n",
      "Episode reward: -433.43854\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7849787  1.7616422  1.7835476 -0.3375757  2.253281   1.776352 ]\n",
      "Reset environment\n",
      "Episode reward: 1090.8427\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7869078   1.763529    1.7855161  -0.33531746  2.254955    1.7782803 ]\n",
      "Reset environment\n",
      "Episode reward: 1435.0421\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7890817   1.7658716   1.7875117  -0.33272874  2.2568545   1.7804514 ]\n",
      "Reset environment\n",
      "Episode reward: 1825.398\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7919444  1.7687789  1.7903242 -0.3294414  2.259341   1.7833105]\n",
      "Reset environment\n",
      "Episode reward: -737.0581\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.791356    1.7682528   1.7896736  -0.33005074  2.258806    1.7827199 ]\n",
      "Reset environment\n",
      "Episode reward: 4454.6074\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7966758  1.7736384  1.7949269 -0.3240821  2.2635016  1.7880471]\n",
      "Reset environment\n",
      "Episode reward: 1698.1345\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.7993623   1.7763615   1.7975742  -0.32096562  2.2658231   1.7907323 ]\n",
      "Reset environment\n",
      "Episode reward: 2262.7532\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8027741  1.779797   1.8009607 -0.3170877  2.268813   1.7941414]\n",
      "Reset environment\n",
      "Episode reward: 794.05676\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8039985   1.780846    1.8023548  -0.31555513  2.269896    1.7953637 ]\n",
      "Reset environment\n",
      "Episode reward: 3095.8445\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8074514  1.7843506  1.8057483 -0.3116782  2.2729523  1.7988183]\n",
      "Reset environment\n",
      "Episode reward: 3801.4011\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8117954  1.7886286  1.8101442 -0.3068226  2.2768133  1.8031623]\n",
      "Reset environment\n",
      "Episode reward: 356.21008\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8126493   1.7892512   1.81122    -0.30549496  2.277444    1.8040221 ]\n",
      "Reset environment\n",
      "Episode reward: 1252.2844\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.814806    1.7914138   1.813363   -0.30301142  2.2793188   1.8061765 ]\n",
      "Reset environment\n",
      "Episode reward: 1783.8872\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8167603   1.79335     1.8153274  -0.30079213  2.2810447   1.8081282 ]\n",
      "Reset environment\n",
      "Episode reward: 1240.5544\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8188905   1.7954805   1.8174556  -0.29833442  2.2829006   1.8102595 ]\n",
      "Reset environment\n",
      "Episode reward: 3352.1616\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8226874   1.7993273   1.8211942  -0.29409763  2.286254    1.8140553 ]\n",
      "Reset environment\n",
      "Episode reward: 3792.7524\n",
      "Total Steps: 215\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8267106   1.8030701   1.8254722  -0.28925934  2.2896948   1.8180836 ]\n",
      "Reset environment\n",
      "Episode reward: 2768.1948\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8306906   1.8069025   1.8295722  -0.28470308  2.2932348   1.8220581 ]\n",
      "Reset environment\n",
      "Episode reward: 1077.6293\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8325862   1.8087599   1.8314968  -0.28248286  2.2948682   1.8239511 ]\n",
      "Reset environment\n",
      "Episode reward: 3186.127\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8361415   1.812366    1.8349981  -0.27849644  2.2980103   1.8275048 ]\n",
      "Reset environment\n",
      "Episode reward: 1367.2744\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8380619   1.8141062   1.8370829  -0.27624062  2.299786    1.8294246 ]\n",
      "Reset environment\n",
      "Episode reward: 2236.105\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8413126  1.8175279  1.8401473 -0.2723959  2.3025923  1.8326726]\n",
      "Reset environment\n",
      "Episode reward: 449.3717\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8377501   1.813915    1.8367581  -0.28255424  2.3005257   1.8291552 ]\n",
      "Reset environment\n",
      "Episode reward: 1854.9613\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8404951  1.816461   1.8396881 -0.2792864  2.302907   1.831901 ]\n",
      "Reset environment\n",
      "Episode reward: 2893.9993\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8445997   1.8204257   1.8439149  -0.27458295  2.3065193   1.8360033 ]\n",
      "Reset environment\n",
      "Episode reward: 4967.145\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8503578  1.8261188  1.8497243 -0.2681855  2.3116302  1.8417614]\n",
      "Reset environment\n",
      "Episode reward: 2202.5532\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8497189   1.8253909   1.849227   -0.27738607  2.3115368   1.8411248 ]\n",
      "Reset environment\n",
      "Episode reward: 3366.1565\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8534949   1.8291938   1.852962   -0.27312934  2.3148525   1.8448956 ]\n",
      "Reset environment\n",
      "Episode reward: 4475.5415\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8587162   1.8343151   1.8582729  -0.26720083  2.3194528   1.8501141 ]\n",
      "Reset environment\n",
      "Episode reward: 2162.1797\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.861692   1.8374761  1.8610427 -0.2636078  2.3220036  1.8530911]\n",
      "Reset environment\n",
      "Episode reward: 2816.186\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8614159   1.8370312   1.8610046  -0.27114445  2.3223135   1.8528676 ]\n",
      "Reset environment\n",
      "Episode reward: 3653.1895\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8665191  1.8420068  1.8662225 -0.265387   2.3268313  1.8579623]\n",
      "Reset environment\n",
      "Episode reward: 1085.5354\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8684176   1.8438798   1.8681347  -0.26316127  2.328468    1.8598572 ]\n",
      "Reset environment\n",
      "Episode reward: 1109.0548\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.870345   1.8457594  1.870105  -0.260923   2.3301487  1.8617862]\n",
      "Reset environment\n",
      "Episode reward: 1364.7574\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8717263   1.8471402   1.8714793  -0.25926438  2.3313177   1.8631669 ]\n",
      "Reset environment\n",
      "Episode reward: 1518.2305\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8739561   1.849556    1.873517   -0.25656423  2.3332405   1.8653983 ]\n",
      "Reset environment\n",
      "Episode reward: 2353.0994\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8772702  1.8530638  1.8766205 -0.2526612  2.3361306  1.8687153]\n",
      "Reset environment\n",
      "Episode reward: 1294.4794\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8794322   1.8551906   1.8788081  -0.25018176  2.338026    1.8708774 ]\n",
      "Reset environment\n",
      "Episode reward: 3826.6233\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8838966   1.8596562   1.8832537  -0.24521098  2.3419907   1.8753422 ]\n",
      "Reset environment\n",
      "Episode reward: 5664.657\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8905437   1.8663728   1.8898263  -0.23783945  2.3479064   1.881993  ]\n",
      "Reset environment\n",
      "Episode reward: 4343.8647\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8954995   1.8713951   1.8947103  -0.23232627  2.3523052   1.8869492 ]\n",
      "Reset environment\n",
      "Episode reward: 2379.1035\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.8987576   1.8748227   1.8977821  -0.22843921  2.3551178   1.8902093 ]\n",
      "Reset environment\n",
      "Episode reward: 2738.867\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.901763    1.8778697   1.9007232  -0.22504887  2.357769    1.893218  ]\n",
      "Reset environment\n",
      "Episode reward: 1290.7949\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9039283   1.8800509   1.9028664  -0.22257973  2.3596616   1.895382  ]\n",
      "Reset environment\n",
      "Episode reward: 2116.543\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9071032   1.8832197   1.906046   -0.21899606  2.3624573   1.8985574 ]\n",
      "Reset environment\n",
      "Episode reward: 1296.1748\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9092692   1.8854053   1.9081879  -0.21653908  2.3643591   1.9007243 ]\n",
      "Reset environment\n",
      "Episode reward: -557.9812\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9088725   1.8850908   1.9077079  -0.21685801  2.3639731   1.9003271 ]\n",
      "Reset environment\n",
      "Episode reward: 1331.9585\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9108673   1.8868968   1.9098811  -0.21441512  2.3656857   1.9023194 ]\n",
      "Reset environment\n",
      "Episode reward: 2601.793\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9146197   1.890501    1.9137591  -0.21010998  2.368994    1.9060689 ]\n",
      "Reset environment\n",
      "Episode reward: 1173.71\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9166253  1.8924719  1.9157917 -0.2078078  2.3707461  1.9080749]\n",
      "Reset environment\n",
      "Episode reward: 3146.4265\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9200647   1.8958684   1.9192585  -0.20391944  2.3737817   1.911512  ]\n",
      "Reset environment\n",
      "Episode reward: 3382.0972\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9238855   1.8997768   1.9229691  -0.19960076  2.3771489   1.9153308 ]\n",
      "Reset environment\n",
      "Episode reward: 2942.6133\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9213053   1.8967152   1.9209218  -0.20504896  2.3756776   1.912724  ]\n",
      "Reset environment\n",
      "Episode reward: 3586.6504\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9261861   1.9014342   1.9259515  -0.19947761  2.3799634   1.917604  ]\n",
      "Reset environment\n",
      "Episode reward: 5756.4717\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.932767    1.9080487   1.9324778  -0.19216256  2.385788    1.9241785 ]\n",
      "Reset environment\n",
      "Episode reward: 258.3693\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9335655   1.9089313   1.9331951  -0.19102395  2.386387    1.9249752 ]\n",
      "Reset environment\n",
      "Episode reward: 3657.739\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9377867   1.9131967   1.9373578  -0.18623018  2.3900774   1.9291927 ]\n",
      "Reset environment\n",
      "Episode reward: 1220.324\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9398335   1.9152048   1.9394361  -0.18389407  2.3918781   1.9312401 ]\n",
      "Reset environment\n",
      "Episode reward: 1288.5233\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9418042   1.9172957   1.9412864  -0.18157111  2.3936381   1.9332113 ]\n",
      "Reset environment\n",
      "Episode reward: -528.6897\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9413866   1.9169717   1.9407816  -0.18193102  2.3932629   1.932798  ]\n",
      "Reset environment\n",
      "Episode reward: 1074.7444\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9428363   1.9182578   1.9423944  -0.18018399  2.394591    1.9342514 ]\n",
      "Reset environment\n",
      "Episode reward: 4377.0625\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9479988   1.9234941   1.9474635  -0.17444035  2.399156    1.9394169 ]\n",
      "Reset environment\n",
      "Episode reward: 1344.8954\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9502205   1.925905    1.9494759  -0.17171958  2.4009902   1.9416369 ]\n",
      "Reset environment\n",
      "Episode reward: 4025.0435\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9548327   1.9304541   1.9541553  -0.16655222  2.405079    1.9462516 ]\n",
      "Reset environment\n",
      "Episode reward: 1166.7837\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9568005   1.9323996   1.9561387  -0.16426262  2.4067843   1.9482177 ]\n",
      "Reset environment\n",
      "Episode reward: 4114.8096\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9615828  1.937246   1.9608413 -0.1589367  2.4110174  1.953002 ]\n",
      "Reset environment\n",
      "Episode reward: 4038.1548\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9661181   1.9418346   1.9653206  -0.15380591  2.4150057   1.9575324 ]\n",
      "Reset environment\n",
      "Episode reward: 1889.648\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9688349   1.9447457   1.9678315  -0.15054554  2.4173412   1.9602494 ]\n",
      "Reset environment\n",
      "Episode reward: 880.8268\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9700718   1.9457793   1.9692628  -0.14897862  2.4184158   1.9614869 ]\n",
      "Reset environment\n",
      "Episode reward: 1318.1526\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9722521   1.9479715   1.9714309  -0.14650938  2.420332    1.9636656 ]\n",
      "Reset environment\n",
      "Episode reward: 4616.855\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.977618    1.9533933   1.9767447  -0.14051466  2.4250731   1.969036  ]\n",
      "Reset environment\n",
      "Episode reward: 374.81393\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9782834   1.9538752   1.9775916  -0.13964853  2.4257212   1.9697032 ]\n",
      "Reset environment\n",
      "Episode reward: 2446.993\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9817053   1.9571286   1.9811654  -0.13567977  2.4287279   1.9731244 ]\n",
      "Reset environment\n",
      "Episode reward: -625.7991\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9813054   1.9566572   1.9808306  -0.13591242  2.4283504   1.9727231 ]\n",
      "Reset environment\n",
      "Episode reward: 4432.73\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9863232   1.961675    1.985851   -0.13028632  2.4327724   1.9777402 ]\n",
      "Reset environment\n",
      "Episode reward: 2751.616\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9894047   1.964817    1.9888589  -0.12681702  2.4354725   1.9808216 ]\n",
      "Reset environment\n",
      "Episode reward: 2173.6526\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9924965   1.9680753   1.9917715  -0.12319459  2.438163    1.983912  ]\n",
      "Reset environment\n",
      "Episode reward: -973.157\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9914176   1.9671528   1.9905397  -0.12422597  2.4371867   1.9828306 ]\n",
      "Reset environment\n",
      "Episode reward: 1228.1145\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9934602  1.9691741  1.9925978 -0.1218759  2.4389677  1.9848695]\n",
      "Reset environment\n",
      "Episode reward: 1405.7323\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 1.9957106   1.9714444   1.9948243  -0.11925937  2.4409125   1.9871194 ]\n",
      "Reset environment\n",
      "Episode reward: 4686.156\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0019953   1.9778097   2.001032   -0.11223789  2.4464693   1.9934101 ]\n",
      "Reset environment\n",
      "Episode reward: 2235.0286\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0049663  1.980944   2.003815  -0.1086582  2.449003   1.9963776]\n",
      "Reset environment\n",
      "Episode reward: -1088.4957\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0002956   1.9763846   1.9991173  -0.12293496  2.4449105   1.9917372 ]\n",
      "Reset environment\n",
      "Episode reward: 2537.953\n",
      "Total Steps: 216\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0035837   1.9795465   2.002489   -0.11904781  2.447865    1.9950268 ]\n",
      "Reset environment\n",
      "Episode reward: 2507.1226\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0061803  1.9822072  2.00502   -0.1160705  2.4501424  1.997625 ]\n",
      "Reset environment\n",
      "Episode reward: 3622.0083\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0101914   1.9862667   2.0089808  -0.11150975  2.4536572   2.0016346 ]\n",
      "Reset environment\n",
      "Episode reward: 1260.8104\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.012058    1.98832     2.0106525  -0.10916894  2.4552672   2.0035038 ]\n",
      "Reset environment\n",
      "Episode reward: 2411.2024\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0146923  1.9909818  2.0132523 -0.1061701  2.4575827  2.0061347]\n",
      "Reset environment\n",
      "Episode reward: 1356.6985\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0169022   1.9931827   2.0154665  -0.10366794  2.4595294   2.0083458 ]\n",
      "Reset environment\n",
      "Episode reward: 3936.51\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0221686   1.998305    2.0208693  -0.09768705  2.46417     2.013609  ]\n",
      "Reset environment\n",
      "Episode reward: -655.0216\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0217543   1.9980514   2.0202966  -0.09798472  2.463854    2.0131955 ]\n",
      "Reset environment\n",
      "Episode reward: 2109.7432\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.023996    2.0003242   2.0224972  -0.09543881  2.4658113   2.0154364 ]\n",
      "Reset environment\n",
      "Episode reward: 4019.0552\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.028442    2.004745    2.0269687  -0.09041998  2.4697294   2.0198827 ]\n",
      "Reset environment\n",
      "Episode reward: 2251.0083\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0314813   2.0079622   2.0298147  -0.08679477  2.4723506   2.0229216 ]\n",
      "Reset environment\n",
      "Episode reward: 1248.284\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0335352   2.0099785   2.0319028  -0.08444871  2.4741569   2.024974  ]\n",
      "Reset environment\n",
      "Episode reward: 1956.3342\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0274012  2.0041454  2.0256584 -0.0915703  2.4694796  2.0189443]\n",
      "Reset environment\n",
      "Episode reward: 6595.7603\n",
      "Total Steps: 235\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0349267   2.011602    2.0332482  -0.08322249  2.4761739   2.026468  ]\n",
      "Reset environment\n",
      "Episode reward: 6317.7617\n",
      "Total Steps: 227\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0421362   2.0187733   2.0404918  -0.07517594  2.482561    2.0336711 ]\n",
      "Reset environment\n",
      "Episode reward: 1106.6155\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0440054   2.0206664   2.0423403  -0.07297972  2.4841588   2.035537  ]\n",
      "Reset environment\n",
      "Episode reward: 1167.1765\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0459547  2.0225914  2.0443096 -0.0707     2.4858406  2.037484 ]\n",
      "Reset environment\n",
      "Episode reward: 1324.136\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0481093   2.0247383   2.046466   -0.06824663  2.4877315   2.039635  ]\n",
      "Reset environment\n",
      "Episode reward: 3161.5576\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.051518    2.028182    2.0498393  -0.06439889  2.490738    2.0430467 ]\n",
      "Reset environment\n",
      "Episode reward: 2697.1968\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0544548   2.031185    2.0526948  -0.06107514  2.4933295   2.0459812 ]\n",
      "Reset environment\n",
      "Episode reward: 1330.895\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0566251   2.0333586   2.0548563  -0.05861363  2.4952345   2.0481493 ]\n",
      "Reset environment\n",
      "Episode reward: 5939.4556\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.063405    2.0401838   2.0615761  -0.05106058  2.501219    2.054927  ]\n",
      "Reset environment\n",
      "Episode reward: 4007.121\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0678442   2.0445855   2.066042   -0.04613092  2.505173    2.0593631 ]\n",
      "Reset environment\n",
      "Episode reward: 3279.7585\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.071391    2.0481493   2.0695686  -0.04214362  2.5082889   2.0629077 ]\n",
      "Reset environment\n",
      "Episode reward: 2612.0454\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0695062   2.045832    2.0681067  -0.04731512  2.5069594   2.061063  ]\n",
      "Reset environment\n",
      "Episode reward: 1241.995\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0715058   2.047861    2.0700743  -0.04494829  2.5086596   2.0630608 ]\n",
      "Reset environment\n",
      "Episode reward: 1850.2267\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0742447   2.050572    2.0728376  -0.04178235  2.5110366   2.0657985 ]\n",
      "Reset environment\n",
      "Episode reward: 1173.0983\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0761833   2.0524955   2.0747895  -0.03953012  2.5127172   2.0677366 ]\n",
      "Reset environment\n",
      "Episode reward: 2253.9563\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0792418   2.0557313   2.0776603  -0.03589433  2.5153637   2.0707963 ]\n",
      "Reset environment\n",
      "Episode reward: 938.0177\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0806131   2.057273    2.078857   -0.03415104  2.5165393   2.072167  ]\n",
      "Reset environment\n",
      "Episode reward: 1408.1287\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0828884   2.0593824   2.0812762  -0.03136414  2.5184498   2.0744445 ]\n",
      "Reset environment\n",
      "Episode reward: 1744.1191\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0852745   2.061605    2.0838165  -0.02856554  2.5205579   2.0768251 ]\n",
      "Reset environment\n",
      "Episode reward: 3457.5266\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.089159    2.065524    2.0876627  -0.02422616  2.5239923   2.0807102 ]\n",
      "Reset environment\n",
      "Episode reward: 1216.3076\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0911512   2.0675528   2.0896244  -0.02192364  2.5257301   2.0827045 ]\n",
      "Reset environment\n",
      "Episode reward: 1102.8093\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0929992   2.069372    2.091497   -0.01976756  2.5273263   2.0845497 ]\n",
      "Reset environment\n",
      "Episode reward: 5302.7114\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0990846   2.0754879   2.0975482  -0.01292581  2.532674    2.0906389 ]\n",
      "Reset environment\n",
      "Episode reward: 3866.7808\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.103313    2.0797365   2.1017432  -0.00816828  2.5363913   2.0948668 ]\n",
      "Reset environment\n",
      "Episode reward: 1548.9164\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.10052     2.076743    2.0992522  -0.01480719  2.5341122   2.0920928 ]\n",
      "Reset environment\n",
      "Episode reward: 24.656128\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.1008549   2.0769215   2.099729   -0.01398643  2.5342574   2.092427  ]\n",
      "Reset environment\n",
      "Episode reward: 429.60803\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.0973604   2.07338     2.0963652  -0.02551582  2.531899    2.088977  ]\n",
      "Reset environment\n",
      "Episode reward: 5326.458\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.1032112   2.079177    2.102262   -0.01891813  2.537043    2.0948277 ]\n",
      "Reset environment\n",
      "Episode reward: 4676.025\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.1092608   2.085104    2.1084318  -0.01211164  2.5424168   2.1008797 ]\n",
      "Reset environment\n",
      "Episode reward: 1146.8926\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.1111643  2.087023   2.110317  -0.0098766  2.5440447  2.102784 ]\n",
      "Reset environment\n",
      "Episode reward: 5489.192\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [ 2.1173487   2.0932677   2.1164484  -0.00302165  2.5495365   2.1089675 ]\n",
      "Reset environment\n",
      "Episode reward: 2121.684\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1202056e+00 2.0959675e+00 2.1194508e+00 3.8274817e-04 2.5520329e+00\n",
      " 2.1118262e+00]\n",
      "Reset environment\n",
      "Episode reward: 1813.3478\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1229162  2.0986931  2.1221488  0.00341931 2.5544288  2.1145356 ]\n",
      "Reset environment\n",
      "Episode reward: 2510.7417\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1263025  2.1022658  2.125345   0.00737776 2.5573902  2.1179242 ]\n",
      "Reset environment\n",
      "Episode reward: 3505.8237\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.130032   2.1059546  2.1291184  0.01158926 2.5606866  2.1216557 ]\n",
      "Reset environment\n",
      "Episode reward: 3771.989\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1341424  2.1101148  2.1331785  0.01621625 2.5643275  2.1257691 ]\n",
      "Reset environment\n",
      "Episode reward: 3558.6267\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1379616  2.1139605  2.1369739  0.02053993 2.5676746  2.1295877 ]\n",
      "Reset environment\n",
      "Episode reward: 815.0678\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1391249  2.1148531  2.1384008  0.02212051 2.5686204  2.1307526 ]\n",
      "Reset environment\n",
      "Episode reward: 2555.262\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1417496  2.1175253  2.140967   0.02509037 2.5709283  2.133375  ]\n",
      "Reset environment\n",
      "Episode reward: 1838.9541\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1442556  2.120196   2.143299   0.02818052 2.5730813  2.1358838 ]\n",
      "Reset environment\n",
      "Episode reward: 1342.3293\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1464045  2.1223521  2.1454418  0.03060784 2.5749772  2.1380334 ]\n",
      "Reset environment\n",
      "Episode reward: 1804.7397\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.14824    2.1241925  2.1472692  0.03276053 2.5765603  2.1398666 ]\n",
      "Reset environment\n",
      "Episode reward: 1900.6621\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1510382  2.127027   2.150036   0.03595221 2.5789974  2.1426663 ]\n",
      "Reset environment\n",
      "Episode reward: 4775.476\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1563282  2.1323555  2.155275   0.04189227 2.583656   2.1479545 ]\n",
      "Reset environment\n",
      "Episode reward: 5431.979\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1623473  2.1384096  2.161246   0.04863197 2.5889482  2.1539679 ]\n",
      "Reset environment\n",
      "Episode reward: 1093.3108\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1641803  2.1402047  2.163108   0.05076069 2.5905352  2.1557984 ]\n",
      "Reset environment\n",
      "Episode reward: 3492.444\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1679888  2.1439018  2.167015   0.05512696 2.5938976  2.1596026 ]\n",
      "Reset environment\n",
      "Episode reward: 1722.2042\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1705618  2.1464953  2.169568   0.05809143 2.5961237  2.1621737 ]\n",
      "Reset environment\n",
      "Episode reward: 5416.646\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1766849  2.152674   2.175631   0.06490063 2.6015408  2.1682944 ]\n",
      "Reset environment\n",
      "Episode reward: 4904.8765\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1820896  2.1580763  2.1810226  0.07096442 2.6063106  2.1736917 ]\n",
      "Reset environment\n",
      "Episode reward: 4099.5522\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.18654    2.162499   2.1854892  0.07597739 2.6102355  2.1781385 ]\n",
      "Reset environment\n",
      "Episode reward: 3092.9016\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1906211  2.1664655  2.1896734  0.08059379 2.6138587  2.182212  ]\n",
      "Reset environment\n",
      "Episode reward: 1481.9355\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1926634  2.1683152  2.191898   0.08312006 2.6155913  2.1842577 ]\n",
      "Reset environment\n",
      "Episode reward: 1358.3838\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1948211  2.170451   2.194077   0.08556776 2.6174898  2.1864152 ]\n",
      "Reset environment\n",
      "Episode reward: 3076.5068\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.1980176 2.1735137 2.1973932 0.0892752 2.6203077 2.1896114]\n",
      "Reset environment\n",
      "Episode reward: 4049.244\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2025273  2.1780584  2.2018719  0.09433671 2.6242862  2.194125  ]\n",
      "Reset environment\n",
      "Episode reward: 1643.3588\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2049947 2.1805394 2.2043245 0.0971463 2.626445  2.1965914]\n",
      "Reset environment\n",
      "Episode reward: 5133.241\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2106223  2.1860306  2.210073   0.10351866 2.6314082  2.2022192 ]\n",
      "Reset environment\n",
      "Episode reward: 986.2677\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.211905   2.1871438  2.2115142  0.10526962 2.632451   2.203507  ]\n",
      "Reset environment\n",
      "Episode reward: -476.4961\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2115743  2.1867251  2.2112658  0.10486408 2.6322107  2.2031758 ]\n",
      "Reset environment\n",
      "Episode reward: 4079.515\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2168386  2.1918633  2.2166467  0.11079423 2.6368678  2.2084327 ]\n",
      "Reset environment\n",
      "Episode reward: 1399.7028\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.21819    2.1932218  2.2179887  0.11239285 2.6380255  2.2097812 ]\n",
      "Reset environment\n",
      "Episode reward: 1219.1671\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.219835  2.1946552 2.219839  0.1144971 2.639405  2.2114284]\n",
      "Reset environment\n",
      "Episode reward: 1095.0146\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2214527  2.1961653  2.2215588  0.11634614 2.6408448  2.213042  ]\n",
      "Reset environment\n",
      "Episode reward: 1035.2339\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2231812  2.1979167  2.2232606  0.11842337 2.6422944  2.214769  ]\n",
      "Reset environment\n",
      "Episode reward: 4212.5215\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2277806  2.2025514  2.2278113  0.12357029 2.6463585  2.2193632 ]\n",
      "Reset environment\n",
      "Episode reward: 2652.3044\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2305012 2.2052505 2.2305474 0.1266883 2.6487403 2.2220802]\n",
      "Reset environment\n",
      "Episode reward: 996.07837\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2319798 2.2068186 2.2319365 0.1283597 2.6501136 2.223557 ]\n",
      "Reset environment\n",
      "Episode reward: 3689.238\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2368195  2.2115211  2.2368987  0.13381512 2.6544042  2.2283895 ]\n",
      "Reset environment\n",
      "Episode reward: 1624.0493\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2390206  2.2138736  2.2389514  0.13639964 2.6563435  2.2305946 ]\n",
      "Reset environment\n",
      "Episode reward: 3479.6748\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2427518  2.217493   2.242776   0.14066029 2.659671   2.2343276 ]\n",
      "Reset environment\n",
      "Episode reward: 3687.7498\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2468169 2.2215958 2.246802  0.1451775 2.6632774 2.2383947]\n",
      "Reset environment\n",
      "Episode reward: 3644.0618\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2507079  2.2254608  2.2507086  0.14948566 2.6667378  2.2422814 ]\n",
      "Reset environment\n",
      "Episode reward: 1255.9303\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2527142  2.2274458  2.2527301  0.15177935 2.668492   2.244285  ]\n",
      "Reset environment\n",
      "Episode reward: 1131.0\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2545638  2.229264   2.2546093  0.15392216 2.6701014  2.246134  ]\n",
      "Reset environment\n",
      "Episode reward: 4522.6504\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2595222  2.2341678  2.2596262  0.15949667 2.674493   2.2510881 ]\n",
      "Reset environment\n",
      "Episode reward: 1944.1683\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2615197  2.2361748  2.261609   0.16176595 2.6762476  2.2530806 ]\n",
      "Reset environment\n",
      "Episode reward: 1369.1155\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2633848  2.2381854  2.2633207  0.16395807 2.677908   2.2549448 ]\n",
      "Reset environment\n",
      "Episode reward: 1228.8835\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2653513  2.2401626  2.2652724  0.16622812 2.679613   2.256909  ]\n",
      "Reset environment\n",
      "Episode reward: 3863.0764\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2694607 2.2442575 2.2693925 0.1708787 2.6832097 2.2610168]\n",
      "Reset environment\n",
      "Episode reward: 2633.5928\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2729719  2.2476192  2.2730334  0.17491683 2.6863225  2.2645285 ]\n",
      "Reset environment\n",
      "Episode reward: 537.46454\n",
      "Total Steps: 24\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2733076 2.2479537 2.2733684 0.1753954 2.6865814 2.2648642]\n",
      "Reset environment\n",
      "Episode reward: 1344.8772\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.274605   2.2492461  2.2746677  0.17690161 2.6877093  2.2661607 ]\n",
      "Reset environment\n",
      "Episode reward: 2692.6914\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.277433   2.2520247  2.277536   0.18011916 2.6902027  2.2689867 ]\n",
      "Reset environment\n",
      "Episode reward: 1667.0455\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.279706   2.254467   2.2796333  0.18283571 2.6921637  2.2712607 ]\n",
      "Reset environment\n",
      "Episode reward: 2866.4045\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2828116  2.257623   2.2826936  0.18633777 2.6949005  2.274371  ]\n",
      "Reset environment\n",
      "Episode reward: 1028.3121\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2837396  2.2585578  2.2836108  0.18742473 2.6957028  2.2752979 ]\n",
      "Reset environment\n",
      "Episode reward: 884.7539\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2800412  2.2547896  2.2800126  0.17611465 2.6928234  2.271628  ]\n",
      "Reset environment\n",
      "Episode reward: 3880.2644\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2842746  2.258987   2.2842722  0.18083693 2.696593   2.2758536 ]\n",
      "Reset environment\n",
      "Episode reward: 1271.2314\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2860417 2.2609081 2.2858777 0.1829824 2.6981146 2.2776208]\n",
      "Reset environment\n",
      "Episode reward: 2587.2017\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2894192  2.2641702  2.2893553  0.18692358 2.7011096  2.280999  ]\n",
      "Reset environment\n",
      "Episode reward: 3699.7415\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2935019 2.2681408 2.293536  0.1915221 2.70475   2.2850761]\n",
      "Reset environment\n",
      "Episode reward: 3473.0645\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.297254   2.2718241  2.2973568  0.19574519 2.7080822  2.2888298 ]\n",
      "Reset environment\n",
      "Episode reward: 1419.0713\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.2994525  2.2739873  2.299585   0.19821742 2.7100332  2.2910247 ]\n",
      "Reset environment\n",
      "Episode reward: 3366.3215\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3031218  2.2776864  2.303218   0.20231988 2.7132707  2.294691  ]\n",
      "Reset environment\n",
      "Episode reward: 3511.1858\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.30691   2.2813876 2.3070838 0.2065758 2.7166421 2.298477 ]\n",
      "Reset environment\n",
      "Episode reward: 1211.1555\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3088498  2.2833147  2.3090372  0.20880978 2.7183383  2.3004186 ]\n",
      "Reset environment\n",
      "Episode reward: 2612.2327\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3122659  2.2868922  2.3122704  0.21275194 2.7213316  2.303831  ]\n",
      "Reset environment\n",
      "Episode reward: 2365.8955\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3154073  2.2898784  2.31556    0.21638928 2.7240968  2.3069735 ]\n",
      "Reset environment\n",
      "Episode reward: 4486.8223\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3203788  2.2948916  2.3204985  0.22188182 2.7285295  2.3119502 ]\n",
      "Reset environment\n",
      "Episode reward: 1471.811\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.321818   2.2963197  2.321945   0.22357379 2.7297747  2.3133898 ]\n",
      "Reset environment\n",
      "Episode reward: 4337.8516\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3273487  2.3017502  2.327577   0.22979258 2.7346826  2.318924  ]\n",
      "Reset environment\n",
      "Episode reward: 1379.0569\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3293579 2.3039713 2.3293633 0.2323195 2.736318  2.3209279]\n",
      "Reset environment\n",
      "Episode reward: 2410.9468\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3319004  2.3065517  2.3318655  0.23521058 2.7385433  2.323472  ]\n",
      "Reset environment\n",
      "Episode reward: 2678.9128\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.334741   2.3094046  2.3346903  0.23839957 2.7410557  2.3263125 ]\n",
      "Reset environment\n",
      "Episode reward: 3520.3276\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3385696  2.3132772  2.3384774  0.24268363 2.7444322  2.3301468 ]\n",
      "Reset environment\n",
      "Episode reward: 5523.031\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.344557   2.3191793  2.344529   0.24939802 2.7496893  2.3361278 ]\n",
      "Reset environment\n",
      "Episode reward: 4737.922\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.349694  2.3242898 2.3496714 0.2551335 2.754215  2.341261 ]\n",
      "Reset environment\n",
      "Episode reward: -802.32227\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3488228  2.3231218  2.349093   0.25453874 2.7533734  2.3403904 ]\n",
      "Reset environment\n",
      "Episode reward: 2401.207\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3521903 2.3265085 2.3524287 0.258309  2.7563434 2.343755 ]\n",
      "Reset environment\n",
      "Episode reward: 1129.677\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3540058 2.328293  2.35427   0.2604257 2.7579126 2.345569 ]\n",
      "Reset environment\n",
      "Episode reward: 3439.2974\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3577142  2.3319695  2.3580117  0.26462474 2.7611675  2.3492765 ]\n",
      "Reset environment\n",
      "Episode reward: 1691.7788\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.355324  2.3293018 2.3558514 0.2596404 2.758657  2.346902 ]\n",
      "Reset environment\n",
      "Episode reward: 3825.8452\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.359488   2.3334584  2.3600285  0.26430425 2.7623363  2.351065  ]\n",
      "Reset environment\n",
      "Episode reward: 2201.1694\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3617556  2.3357487  2.3622649  0.26688606 2.764327   2.3533297 ]\n",
      "Reset environment\n",
      "Episode reward: 1637.7614\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3639061 2.337713  2.3645978 0.2695441 2.766148  2.3554876]\n",
      "Reset environment\n",
      "Episode reward: 4169.784\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.368438   2.3421438  2.3692193  0.27465415 2.7701714  2.3600178 ]\n",
      "Reset environment\n",
      "Episode reward: 2712.5366\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.371977   2.3458533  2.372581   0.27875176 2.7732608  2.3635569 ]\n",
      "Reset environment\n",
      "Episode reward: -897.51855\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3710887  2.3450313  2.3716288  0.27778822 2.772507   2.3626668 ]\n",
      "Reset environment\n",
      "Episode reward: 3641.4421\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3756628  2.349557   2.3762298  0.28296503 2.7765744  2.3672392 ]\n",
      "Reset environment\n",
      "Episode reward: 3321.3958\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.379029  2.353021  2.3794854 0.2867981 2.7795286 2.370605 ]\n",
      "Reset environment\n",
      "Episode reward: 3356.9124\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3826556 2.3566883 2.3830736 0.2908732 2.7827334 2.374234 ]\n",
      "Reset environment\n",
      "Episode reward: 2988.0193\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3857217  2.3597887  2.3861012  0.29431036 2.7854483  2.3772974 ]\n",
      "Reset environment\n",
      "Episode reward: 4823.459\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.390935   2.36498    2.391337   0.30008394 2.7900932  2.3825107 ]\n",
      "Reset environment\n",
      "Episode reward: 3784.3784\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.3949397  2.3690195  2.3953047  0.30455866 2.7936354  2.3865151 ]\n",
      "Reset environment\n",
      "Episode reward: 5948.86\n",
      "Total Steps: 220\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4014442  2.3755062  2.4018238  0.31182793 2.7993693  2.3930156 ]\n",
      "Reset environment\n",
      "Episode reward: 3136.714\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4047947 2.3789082 2.4051101 0.3156131 2.8023202 2.396368 ]\n",
      "Reset environment\n",
      "Episode reward: 3292.3628\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4083526  2.3825269  2.408609   0.31959018 2.8054595  2.3999274 ]\n",
      "Reset environment\n",
      "Episode reward: 4347.201\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.413103   2.3872428  2.4134047  0.32484055 2.809707   2.4046776 ]\n",
      "Reset environment\n",
      "Episode reward: 342.57443\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.413557   2.3879187  2.413632   0.32565597 2.8100643  2.405129  ]\n",
      "Reset environment\n",
      "Episode reward: 3873.4712\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4184752 2.3927026 2.4186766 0.3312122 2.8144162 2.4100442]\n",
      "Reset environment\n",
      "Episode reward: 1301.0175\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4149027  2.3890588  2.4152532  0.32056805 2.8116806  2.4064863 ]\n",
      "Reset environment\n",
      "Episode reward: 1999.3088\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4177017  2.3918822  2.4180336  0.32374784 2.81413    2.4092875 ]\n",
      "Reset environment\n",
      "Episode reward: 5418.493\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.423452  2.3975716 2.4238398 0.3302353 2.8191845 2.4150383]\n",
      "Reset environment\n",
      "Episode reward: 287.18143\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4238062 2.398196  2.423929  0.3309517 2.819415  2.415396 ]\n",
      "Reset environment\n",
      "Episode reward: 1097.1544\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4255605  2.3999028  2.4257205  0.33301917 2.8209198  2.4171486 ]\n",
      "Reset environment\n",
      "Episode reward: 275.55823\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4213398  2.3956668  2.421559   0.31871352 2.8173835  2.4129305 ]\n",
      "Reset environment\n",
      "Episode reward: 6095.228\n",
      "Total Steps: 219\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.427921   2.4022632  2.4281256  0.32606015 2.8232224  2.4195135 ]\n",
      "Reset environment\n",
      "Episode reward: 4275.9004\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4324243  2.4067602  2.4326286  0.33103913 2.8272371  2.424011  ]\n",
      "Reset environment\n",
      "Episode reward: 1187.2898\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.433921   2.4080637  2.4343085  0.33302063 2.8284874  2.4255083 ]\n",
      "Reset environment\n",
      "Episode reward: 3077.5884\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4371266 2.4113533 2.4374292 0.3366902 2.8312995 2.42872  ]\n",
      "Reset environment\n",
      "Episode reward: 4086.3635\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4415526 2.4158108 2.4418252 0.3416313 2.8352091 2.4331446]\n",
      "Reset environment\n",
      "Episode reward: 3459.8176\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4452467  2.4194736  2.4455433  0.34572417 2.8385139  2.4368324 ]\n",
      "Reset environment\n",
      "Episode reward: 2609.742\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4478438  2.4220312  2.4481733  0.34864733 2.8408115  2.4394248 ]\n",
      "Reset environment\n",
      "Episode reward: 5871.613\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.454307   2.4284692  2.4546669  0.35577613 2.8465931  2.4458928 ]\n",
      "Reset environment\n",
      "Episode reward: 2458.3606\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.457291   2.4316056  2.4574735  0.35925844 2.8491948  2.4488702 ]\n",
      "Reset environment\n",
      "Episode reward: 4395.823\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4620516  2.4362783  2.4623141  0.36463517 2.8534153  2.453631  ]\n",
      "Reset environment\n",
      "Episode reward: 4755.9985\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4632254  2.4373753  2.4636128  0.35807866 2.8547785  2.4548178 ]\n",
      "Reset environment\n",
      "Episode reward: 2908.5479\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4662328 2.440355  2.4666486 0.3615098 2.857417  2.4578285]\n",
      "Reset environment\n",
      "Episode reward: 4087.2214\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4705133  2.444648   2.4709086  0.36631656 2.861174   2.462107  ]\n",
      "Reset environment\n",
      "Episode reward: 444.46295\n",
      "Total Steps: 20\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4707432  2.4448895  2.471126   0.36664945 2.8613536  2.4623358 ]\n",
      "Reset environment\n",
      "Episode reward: 2821.7773\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4735584  2.447699   2.4739413  0.36982253 2.8638358  2.4651515 ]\n",
      "Reset environment\n",
      "Episode reward: 373.25113\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4742498  2.4482458  2.474769   0.37061742 2.8645918  2.4658432 ]\n",
      "Reset environment\n",
      "Episode reward: 2129.8198\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4771984  2.4512224  2.4776897  0.37395155 2.8671849  2.468791  ]\n",
      "Reset environment\n",
      "Episode reward: 1115.4877\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4789672  2.4530191  2.47943    0.37603346 2.8686917  2.4705591 ]\n",
      "Reset environment\n",
      "Episode reward: 4134.091\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4832547  2.4573338  2.4836788  0.38087103 2.8724582  2.4748428 ]\n",
      "Reset environment\n",
      "Episode reward: 4625.084\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.489008   2.463039   2.4894753  0.38724175 2.877586   2.480595  ]\n",
      "Reset environment\n",
      "Episode reward: 2825.1782\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.491918   2.4660082  2.4923158  0.39054567 2.8801348  2.4835052 ]\n",
      "Reset environment\n",
      "Episode reward: 3617.6394\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4957516 2.469893  2.4960978 0.3949085 2.8834825 2.487341 ]\n",
      "Reset environment\n",
      "Episode reward: 3706.91\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.4995503 2.4736428 2.4999375 0.3992146 2.8868158 2.491142 ]\n",
      "Reset environment\n",
      "Episode reward: 1830.7859\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5019317  2.4762006  2.5021372  0.40207312 2.8888507  2.4935238 ]\n",
      "Reset environment\n",
      "Episode reward: 1201.3214\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.503798  2.478095  2.5039802 0.4042272 2.890468  2.4953923]\n",
      "Reset environment\n",
      "Episode reward: 472.13266\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5044925  2.4786243  2.5048335  0.40512916 2.8911254  2.4960856 ]\n",
      "Reset environment\n",
      "Episode reward: 2089.0925\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5073783 2.481547  2.5076933 0.4083993 2.8936553 2.4989765]\n",
      "Reset environment\n",
      "Episode reward: 474.0142\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.508065   2.4821208  2.5084946  0.40925336 2.894287   2.49966   ]\n",
      "Reset environment\n",
      "Episode reward: 2075.517\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5109322 2.4849956 2.5113587 0.4124908 2.8968124 2.5025287]\n",
      "Reset environment\n",
      "Episode reward: 3155.5796\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5141075 2.4881403 2.5145662 0.4161012 2.8996084 2.505704 ]\n",
      "Reset environment\n",
      "Episode reward: 1950.443\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5077298 2.481614  2.508407  0.4095796 2.8934665 2.499355 ]\n",
      "Reset environment\n",
      "Episode reward: 3898.262\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5118632  2.4857976  2.5124903  0.41417924 2.8971298  2.5034893 ]\n",
      "Reset environment\n",
      "Episode reward: 2321.8376\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.514833   2.48861    2.5156047  0.41770917 2.8996935  2.5064616 ]\n",
      "Reset environment\n",
      "Episode reward: 372.0642\n",
      "Total Steps: 16\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5149739  2.4887493  2.5157442  0.41794097 2.89979    2.5066009 ]\n",
      "Reset environment\n",
      "Episode reward: 6368.051\n",
      "Total Steps: 225\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.521901  2.4957001 2.5226486 0.4255924 2.905963  2.513536 ]\n",
      "Reset environment\n",
      "Episode reward: 5667.7607\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5280566 2.5018916 2.528773  0.4324277 2.9114318 2.5196974]\n",
      "Reset environment\n",
      "Episode reward: 5860.6035\n",
      "Total Steps: 215\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5343354 2.508233  2.5349803 0.4395002 2.916944  2.5259755]\n",
      "Reset environment\n",
      "Episode reward: 6135.101\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5408375  2.5147595  2.5414362  0.44672033 2.9227185  2.532477  ]\n",
      "Reset environment\n",
      "Episode reward: 726.47144\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5417745  2.5158732  2.5421941  0.44808844 2.9234805  2.5334172 ]\n",
      "Reset environment\n",
      "Episode reward: 3799.8962\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.545584   2.5197673  2.545904   0.45243633 2.9268389  2.5372257 ]\n",
      "Reset environment\n",
      "Episode reward: 1860.3058\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.547396   2.521589   2.5477078  0.45450342 2.9284227  2.5390406 ]\n",
      "Reset environment\n",
      "Episode reward: 1239.1594\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5493011  2.5234995  2.5496109  0.45669472 2.9300826  2.540948  ]\n",
      "Reset environment\n",
      "Episode reward: 3340.3477\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5526876  2.5269291  2.5529435  0.46051714 2.9330602  2.5443275 ]\n",
      "Reset environment\n",
      "Episode reward: 5165.6763\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5581167 2.5323262 2.5584037 0.4665883 2.9378514 2.5497546]\n",
      "Reset environment\n",
      "Episode reward: 1186.4259\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5550208  2.529419   2.5551538  0.45434988 2.9353955  2.5466735 ]\n",
      "Reset environment\n",
      "Episode reward: 3526.9287\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5587473 2.5331812 2.5588481 0.4584851 2.9387035 2.5504022]\n",
      "Reset environment\n",
      "Episode reward: 1127.4569\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5601046 2.5343337 2.5603955 0.4603213 2.9397993 2.5517616]\n",
      "Reset environment\n",
      "Episode reward: 3030.4448\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5631323  2.537398   2.563377   0.46375564 2.9424539  2.554788  ]\n",
      "Reset environment\n",
      "Episode reward: 4100.08\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5674353  2.5416613  2.5677204  0.46857315 2.9462686  2.5590916 ]\n",
      "Reset environment\n",
      "Episode reward: 3780.683\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5714142 2.5456655 2.5716662 0.4730501 2.949765  2.5630708]\n",
      "Reset environment\n",
      "Episode reward: 2397.0469\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5744257  2.5484896  2.5748527  0.47654435 2.952418   2.5660803 ]\n",
      "Reset environment\n",
      "Episode reward: 5933.2886\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5808058  2.554871   2.5812438  0.48356053 2.9581158  2.5724638 ]\n",
      "Reset environment\n",
      "Episode reward: 3397.535\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5842364  2.5583415  2.584627   0.48741624 2.9611313  2.5758889 ]\n",
      "Reset environment\n",
      "Episode reward: 3485.7\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.587871  2.5620332 2.5882099 0.4914885 2.96434   2.5795279]\n",
      "Reset environment\n",
      "Episode reward: 4636.685\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5927832  2.566973   2.5930982  0.49696198 2.9686916  2.5844412 ]\n",
      "Reset environment\n",
      "Episode reward: 4570.8003\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5977018  2.57192    2.5979748  0.50236845 2.9730763  2.5893545 ]\n",
      "Reset environment\n",
      "Episode reward: 1240.981\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.5995927 2.5738127 2.599858  0.5045367 2.9747188 2.5912418]\n",
      "Reset environment\n",
      "Episode reward: 3347.4875\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6029665 2.5770607 2.603342  0.5084044 2.9777095 2.594617 ]\n",
      "Reset environment\n",
      "Episode reward: 6808.7505\n",
      "Total Steps: 252\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6101632 2.5841856 2.6105826 0.516464  2.9840739 2.6018078]\n",
      "Reset environment\n",
      "Episode reward: 3501.3813\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.613717   2.5877767  2.6140897  0.52045256 2.987219   2.605357  ]\n",
      "Reset environment\n",
      "Episode reward: 5082.328\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6198788 2.5939088 2.6202855 0.5273098 2.9926918 2.6115222]\n",
      "Reset environment\n",
      "Episode reward: 1332.3859\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6216345 2.5954957 2.6222043 0.5294215 2.9942293 2.613275 ]\n",
      "Reset environment\n",
      "Episode reward: 102.0253\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6218657  2.5955946  2.6225684  0.52973616 2.9945014  2.6135056 ]\n",
      "Reset environment\n",
      "Episode reward: 4214.697\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6270585 2.600729  2.6278212 0.5355482 2.9991057 2.6186974]\n",
      "Reset environment\n",
      "Episode reward: 4766.726\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6321075 2.6057873 2.6328762 0.5411638 3.0035834 2.6237483]\n",
      "Reset environment\n",
      "Episode reward: 1744.2454\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6345649 2.6082695 2.635312  0.5439604 3.0057366 2.6262045]\n",
      "Reset environment\n",
      "Episode reward: 2472.901\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6376262 2.6114876 2.638207  0.5475758 3.0083888 2.6292677]\n",
      "Reset environment\n",
      "Episode reward: 3452.7217\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6411903 2.6150694 2.6417718 0.5515665 3.011549  2.6328397]\n",
      "Reset environment\n",
      "Episode reward: 1655.3529\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6433194 2.617022  2.6440744 0.5541415 3.0133963 2.6349683]\n",
      "Reset environment\n",
      "Episode reward: 3538.0298\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6468449 2.6205697 2.6475792 0.5581071 3.0165026 2.6384947]\n",
      "Reset environment\n",
      "Episode reward: 1769.1252\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.649308   2.623029   2.650052   0.56093305 3.018651   2.640958  ]\n",
      "Reset environment\n",
      "Episode reward: 3775.537\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6531973  2.6268425  2.6540098  0.56532395 3.0220904  2.644845  ]\n",
      "Reset environment\n",
      "Episode reward: 1896.1123\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6555219  2.6290197  2.6564682  0.56812865 3.024103   2.6471682 ]\n",
      "Reset environment\n",
      "Episode reward: 3598.7085\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6596835  2.6331453  2.660646   0.57292694 3.027812   2.6513348 ]\n",
      "Reset environment\n",
      "Episode reward: -686.65533\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.659043  2.6324966 2.660016  0.5725326 3.0271804 2.6506922]\n",
      "Reset environment\n",
      "Episode reward: 3758.022\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6628332 2.6362648 2.6638286 0.5767976 3.030528  2.654487 ]\n",
      "Reset environment\n",
      "Episode reward: 4178.816\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6671274  2.640621   2.6680648  0.58162785 3.0343263  2.6587858 ]\n",
      "Reset environment\n",
      "Episode reward: 1214.1531\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.668219  2.6416905 2.6691709 0.582889  3.0352762 2.6598752]\n",
      "Reset environment\n",
      "Episode reward: 3231.2449\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.671542   2.6450512  2.6724405  0.58659226 3.038223   2.6631982 ]\n",
      "Reset environment\n",
      "Episode reward: 2322.0957\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.673811  2.647359  2.6746697 0.589266  3.0401556 2.6654713]\n",
      "Reset environment\n",
      "Episode reward: 1131.7463\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.67555    2.6490877  2.6764123  0.59133506 3.04163    2.6672094 ]\n",
      "Reset environment\n",
      "Episode reward: 2239.9683\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6783361 2.6520324 2.6790223 0.5945888 3.0440657 2.669989 ]\n",
      "Reset environment\n",
      "Episode reward: 1886.6355\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6809452  2.654676   2.681596   0.59755784 3.0463445  2.6725962 ]\n",
      "Reset environment\n",
      "Episode reward: 4963.538\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6861942 2.6599844 2.686803  0.6034017 3.0510094 2.6778538]\n",
      "Reset environment\n",
      "Episode reward: 2925.7659\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6898246 2.6637588 2.6902711 0.6076418 3.0541382 2.681481 ]\n",
      "Reset environment\n",
      "Episode reward: 2533.7236\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6930134 2.66678   2.6936145 0.6113292 3.0569522 2.684668 ]\n",
      "Reset environment\n",
      "Episode reward: 2124.9458\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.6958704  2.6696558  2.6964562  0.61456907 3.0594542  2.6875274 ]\n",
      "Reset environment\n",
      "Episode reward: 3512.5352\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.699515  2.6732693 2.7001338 0.6186604 3.062683  2.6911736]\n",
      "Reset environment\n",
      "Episode reward: 1072.5815\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7011683 2.6749241 2.7017834 0.6206462 3.0640728 2.6928263]\n",
      "Reset environment\n",
      "Episode reward: 2659.833\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7044096 2.6780486 2.7051353 0.6244375 3.0669281 2.696074 ]\n",
      "Reset environment\n",
      "Episode reward: 705.9634\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7056627  2.6792145  2.7064638  0.62606364 3.0680888  2.6973295 ]\n",
      "Reset environment\n",
      "Episode reward: 1937.4578\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7080572 2.6817524 2.7087166 0.6288294 3.0702183 2.6997283]\n",
      "Reset environment\n",
      "Episode reward: 2202.543\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.711023   2.6847506  2.7116525  0.63215417 3.0728319  2.7026956 ]\n",
      "Reset environment\n",
      "Episode reward: 1755.432\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7132463  2.6871185  2.7137275  0.63474685 3.0748017  2.7049203 ]\n",
      "Reset environment\n",
      "Episode reward: 505.40378\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.713993  2.687697  2.714635  0.6357108 3.0755012 2.705666 ]\n",
      "Reset environment\n",
      "Episode reward: 3402.1633\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.717366   2.6910434  2.7180276  0.63954145 3.0784695  2.709038  ]\n",
      "Reset environment\n",
      "Episode reward: 3059.264\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7205138 2.6942155 2.7211502 0.6430583 3.0812547 2.7121868]\n",
      "Reset environment\n",
      "Episode reward: 3528.118\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7240496  2.6977658  2.7246735  0.64700603 3.0843797  2.7157211 ]\n",
      "Reset environment\n",
      "Episode reward: 4915.5503\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.729083  2.7028263 2.7296777 0.6526657 3.0888252 2.7207532]\n",
      "Reset environment\n",
      "Episode reward: 776.6386\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7300544 2.7039998 2.7304332 0.654021  3.089627  2.7217174]\n",
      "Reset environment\n",
      "Episode reward: 4733.422\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7358067  2.709691   2.736251   0.66042894 3.0947592  2.727468  ]\n",
      "Reset environment\n",
      "Episode reward: 154.77576\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7363868  2.710085   2.737016   0.66143876 3.0951083  2.728051  ]\n",
      "Reset environment\n",
      "Episode reward: -242.04407\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7362251 2.7100236 2.7367592 0.6613379 3.094939  2.7278903]\n",
      "Reset environment\n",
      "Episode reward: 1962.4084\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7387695  2.7124667  2.739409   0.66433656 3.0971556  2.730437  ]\n",
      "Reset environment\n",
      "Episode reward: 4261.95\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.743208   2.7169387  2.7438195  0.66929966 3.1010566  2.734875  ]\n",
      "Reset environment\n",
      "Episode reward: 1661.3457\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7452786 2.7191494 2.74574   0.6717081 3.1028922 2.7369452]\n",
      "Reset environment\n",
      "Episode reward: 3943.4138\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7493813  2.72329    2.749803   0.67626333 3.106534   2.7410471 ]\n",
      "Reset environment\n",
      "Episode reward: 1904.3673\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7463021 2.7203088 2.7466602 0.6654827 3.1036727 2.7380037]\n",
      "Reset environment\n",
      "Episode reward: 3284.3584\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.749635  2.7235858 2.7500446 0.6692046 3.1066446 2.741333 ]\n",
      "Reset environment\n",
      "Episode reward: 1138.8413\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7510586 2.7248344 2.7516415 0.670975  3.1078749 2.7427576]\n",
      "Reset environment\n",
      "Episode reward: 4885.3193\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7569325  2.7307322  2.7575076  0.67752534 3.1130865  2.748642  ]\n",
      "Reset environment\n",
      "Episode reward: 1275.0498\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.758836   2.7326128  2.7594268  0.67969805 3.1147552  2.750541  ]\n",
      "Reset environment\n",
      "Episode reward: 3330.532\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7622404 2.7359858 2.7628715 0.6834961 3.117793  2.7539456]\n",
      "Reset environment\n",
      "Episode reward: 3298.6096\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7654786 2.7392528 2.7660787 0.6871681 3.1206286 2.757183 ]\n",
      "Reset environment\n",
      "Episode reward: 1068.3143\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7671173 2.7408597 2.7677503 0.6890861 3.1220388 2.7588203]\n",
      "Reset environment\n",
      "Episode reward: 2126.1497\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7699533 2.7437084 2.7705772 0.6922982 3.1245258 2.7616606]\n",
      "Reset environment\n",
      "Episode reward: 6750.0566\n",
      "Total Steps: 241\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.777066   2.7508209  2.7777128  0.70020705 3.130849   2.7687888 ]\n",
      "Reset environment\n",
      "Episode reward: 2339.1602\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.780003   2.753812   2.7805974  0.70345986 3.133504   2.7717257 ]\n",
      "Reset environment\n",
      "Episode reward: 4074.4458\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7849777 2.7588155 2.7855518 0.7090678 3.137886  2.7767053]\n",
      "Reset environment\n",
      "Episode reward: 1838.5831\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.786736  2.76055   2.7873313 0.7110937 3.1394243 2.7784615]\n",
      "Reset environment\n",
      "Episode reward: 846.8961\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7877502 2.7617948 2.788112  0.7125144 3.1402605 2.7794793]\n",
      "Reset environment\n",
      "Episode reward: 3077.1023\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.790806  2.7649257 2.7910826 0.7160057 3.1429403 2.7825367]\n",
      "Reset environment\n",
      "Episode reward: 3780.3096\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7945533  2.7686322  2.7948585  0.72021586 3.1462533  2.786284  ]\n",
      "Reset environment\n",
      "Episode reward: 3836.4438\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7984638  2.772452   2.7988493  0.72458315 3.1497424  2.7901893 ]\n",
      "Reset environment\n",
      "Episode reward: -227.6561\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.7982163  2.7719872  2.798827   0.72453904 3.149524   2.789949  ]\n",
      "Reset environment\n",
      "Episode reward: 1368.5366\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8002217  2.773995   2.800823   0.72679144 3.1512926  2.7919507 ]\n",
      "Reset environment\n",
      "Episode reward: 2440.604\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8032138  2.777082   2.803716   0.73022264 3.1539445  2.7949433 ]\n",
      "Reset environment\n",
      "Episode reward: 1268.4949\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.805092  2.7789314 2.8056195 0.7323783 3.1555831 2.7968183]\n",
      "Reset environment\n",
      "Episode reward: 1929.3667\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8075285  2.7814665  2.80795    0.73520523 3.1577382  2.7992563 ]\n",
      "Reset environment\n",
      "Episode reward: 1234.2578\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.809366   2.7833192  2.809771   0.73732525 3.159327   2.8010921 ]\n",
      "Reset environment\n",
      "Episode reward: 1347.0858\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.811343  2.7853012 2.811742  0.7395468 3.161073  2.8030682]\n",
      "Reset environment\n",
      "Episode reward: 895.8281\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8124564  2.7862523  2.8130193  0.74090934 3.1620903  2.804183  ]\n",
      "Reset environment\n",
      "Episode reward: 3720.6753\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.816952  2.790627  2.8176382 0.7459905 3.1660647 2.8086746]\n",
      "Reset environment\n",
      "Episode reward: 3250.5933\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8202586  2.7939017  2.8209782  0.74968064 3.1690123  2.8119798 ]\n",
      "Reset environment\n",
      "Episode reward: 5976.241\n",
      "Total Steps: 210\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8264534  2.8000655  2.8272085  0.75654787 3.1745152  2.8181736 ]\n",
      "Reset environment\n",
      "Episode reward: 2100.3625\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8292315  2.802863   2.8299706  0.75969166 3.1769445  2.8209517 ]\n",
      "Reset environment\n",
      "Episode reward: 4416.5635\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8336885 2.8073409 2.8344083 0.7647156 3.1808484 2.8254104]\n",
      "Reset environment\n",
      "Episode reward: 1241.96\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8355353 2.8091903 2.8362498 0.7668312 3.1824543 2.827255 ]\n",
      "Reset environment\n",
      "Episode reward: 2282.4553\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8377228 2.8114262 2.8383768 0.7693384 3.1843722 2.8294418]\n",
      "Reset environment\n",
      "Episode reward: 3906.7957\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.841763   2.8154488  2.8424315  0.77379954 3.1879873  2.833478  ]\n",
      "Reset environment\n",
      "Episode reward: 1303.8271\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8436844 2.8173456 2.8443694 0.7759766 3.1896753 2.8353963]\n",
      "Reset environment\n",
      "Episode reward: 1194.4188\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8454635 2.819126  2.8461437 0.7780341 3.1912098 2.8371756]\n",
      "Reset environment\n",
      "Episode reward: 501.4829\n",
      "Total Steps: 21\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8457277 2.8193908 2.8464038 0.7784122 3.1914108 2.8374379]\n",
      "Reset environment\n",
      "Episode reward: 3563.4246\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8500082 2.8235152 2.8508298 0.7832884 3.195193  2.84172  ]\n",
      "Reset environment\n",
      "Episode reward: 2519.8525\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.853036   2.8266983  2.853689   0.78685623 3.1978307  2.8447492 ]\n",
      "Reset environment\n",
      "Episode reward: 1240.4165\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.854873   2.82855    2.8555098  0.78896487 3.1994267  2.846585  ]\n",
      "Reset environment\n",
      "Episode reward: 1618.4774\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8569367  2.8307254  2.8574646  0.79133904 3.2012773  2.8486512 ]\n",
      "Reset environment\n",
      "Episode reward: 4702.4253\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8617167  2.8354926  2.8622522  0.79668146 3.2054944  2.8534303 ]\n",
      "Reset environment\n",
      "Episode reward: 4752.696\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.867345  2.8410666 2.8679574 0.8029975 3.2104938 2.859068 ]\n",
      "Reset environment\n",
      "Episode reward: 2391.1973\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8704364 2.8441617 2.8710554 0.8064727 3.2132258 2.8621628]\n",
      "Reset environment\n",
      "Episode reward: 4741.2295\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8752556 2.8489902 2.875872  0.8118384 3.2174807 2.866985 ]\n",
      "Reset environment\n",
      "Episode reward: 5595.5396\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.880976  2.854691  2.8816173 0.818271  3.2225256 2.8727036]\n",
      "Reset environment\n",
      "Episode reward: 2576.0864\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8835187 2.857271  2.8841195 0.8211392 3.2247806 2.8752446]\n",
      "Reset environment\n",
      "Episode reward: 6892.238\n",
      "Total Steps: 744\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8889523  2.8625886  2.8896656  0.82598907 3.2296462  2.880678  ]\n",
      "Reset environment\n",
      "Episode reward: 4259.7017\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8940094  2.867623   2.894757   0.83170944 3.2341053  2.8857417 ]\n",
      "Reset environment\n",
      "Episode reward: 1680.9126\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8963053  2.8699265  2.8970413  0.83432597 3.2361066  2.8880382 ]\n",
      "Reset environment\n",
      "Episode reward: 1387.0378\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8980722 2.871557  2.8989305 0.8365298 3.2376084 2.889807 ]\n",
      "Reset environment\n",
      "Episode reward: 1897.6948\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.8998525 2.8733609 2.900688  0.8385885 3.2391613 2.8915877]\n",
      "Reset environment\n",
      "Episode reward: 3237.659\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9029968 2.8765407 2.9037945 0.8421301 3.2419336 2.8947337]\n",
      "Reset environment\n",
      "Episode reward: 4808.211\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9078345 2.881341  2.90867   0.8475891 3.246181  2.899577 ]\n",
      "Reset environment\n",
      "Episode reward: 1165.1284\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.909569  2.8830507 2.9104292 0.8496022 3.2476838 2.9013124]\n",
      "Reset environment\n",
      "Episode reward: 2147.702\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9121304  2.8855178  2.9130638  0.85265774 3.2498932  2.903876  ]\n",
      "Reset environment\n",
      "Episode reward: 4255.567\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9172447 2.8906534 2.9181583 0.8583768 3.2544117 2.908993 ]\n",
      "Reset environment\n",
      "Episode reward: 2454.3213\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9196472  2.893086   2.9205248  0.86110306 3.2565188  2.9113927 ]\n",
      "Reset environment\n",
      "Episode reward: -666.8447\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9190562 2.8925455 2.9198859 0.8603638 3.2560017 2.9108014]\n",
      "Reset environment\n",
      "Episode reward: 618.57776\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9197454  2.8930118  2.9207833  0.86149716 3.256485   2.9114919 ]\n",
      "Reset environment\n",
      "Episode reward: 1229.7328\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9212513 2.894367  2.922439  0.8633039 3.2578208 2.9129963]\n",
      "Reset environment\n",
      "Episode reward: 2878.5803\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.924121   2.8972776  2.9252603  0.86650604 3.2603667  2.9158602 ]\n",
      "Reset environment\n",
      "Episode reward: 5577.9087\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9297266 2.902823  2.930921  0.8727981 3.265306  2.9214637]\n",
      "Reset environment\n",
      "Episode reward: 1752.4529\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.932106  2.9052196 2.933289  0.8755086 3.2673898 2.9238493]\n",
      "Reset environment\n",
      "Episode reward: 5124.08\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.937277   2.9103873  2.9384582  0.88131344 3.2719257  2.929023  ]\n",
      "Reset environment\n",
      "Episode reward: 5287.7\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9426074 2.9157097 2.9437926 0.8872775 3.276612  2.934358 ]\n",
      "Reset environment\n",
      "Episode reward: 3597.3186\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9462166  2.9192507  2.94746    0.89130485 3.279827   2.9379623 ]\n",
      "Reset environment\n",
      "Episode reward: 1284.8048\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.948097  2.9211123 2.949355  0.893457  3.2814705 2.9398391]\n",
      "Reset environment\n",
      "Episode reward: 3543.8281\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.951679  2.9247277 2.9529092 0.8974713 3.2846253 2.9434235]\n",
      "Reset environment\n",
      "Episode reward: 4858.489\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9574428 2.9305427 2.958639  0.9038155 3.2897847 2.9491904]\n",
      "Reset environment\n",
      "Episode reward: 5170.6025\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9628549  2.9359713  2.9640331  0.90977734 3.2946074  2.954608  ]\n",
      "Reset environment\n",
      "Episode reward: 2010.2073\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.965471   2.9385839  2.966651   0.91277665 3.296877   2.9572248 ]\n",
      "Reset environment\n",
      "Episode reward: 3291.3416\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9687786 2.9418721 2.9699793 0.9164693 3.2998266 2.9605324]\n",
      "Reset environment\n",
      "Episode reward: 4518.1294\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9733722  2.9464285  2.9746118  0.92159384 3.3038898  2.9651277 ]\n",
      "Reset environment\n",
      "Episode reward: 3293.2642\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9765217 2.9495525 2.9777844 0.9251716 3.3066401 2.9682777]\n",
      "Reset environment\n",
      "Episode reward: 1305.2332\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.978414   2.951432   2.9796903  0.92731357 3.3083088  2.9701698 ]\n",
      "Reset environment\n",
      "Episode reward: 3219.8567\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9815228 2.9545736 2.9827588 0.9307988 3.3110595 2.973277 ]\n",
      "Reset environment\n",
      "Episode reward: 1714.3036\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.983122   2.9561796  2.9843488  0.93261343 3.3124614  2.9748766 ]\n",
      "Reset environment\n",
      "Episode reward: 3207.7395\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.986312  2.959411  2.987483  0.9361962 3.3152757 2.9780602]\n",
      "Reset environment\n",
      "Episode reward: 2457.3074\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9892128 2.962268  2.990415  0.9395615 3.317863  2.9809628]\n",
      "Reset environment\n",
      "Episode reward: 1918.6915\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9914536 2.964355  2.992802  0.9421867 3.3198884 2.9832082]\n",
      "Reset environment\n",
      "Episode reward: 977.4635\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9926636  2.9656835  2.9938915  0.94359756 3.3210058  2.9844208 ]\n",
      "Reset environment\n",
      "Episode reward: 2729.7114\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9959843 2.968849  2.99735   0.9473994 3.3239424 2.987741 ]\n",
      "Reset environment\n",
      "Episode reward: 2475.1956\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [2.9990036 2.972008  3.0002203 0.9508928 3.3265846 2.9907603]\n",
      "Reset environment\n",
      "Episode reward: 2250.4395\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0019314  2.974935   3.0031517  0.95419747 3.3291545  2.9936886 ]\n",
      "Reset environment\n",
      "Episode reward: 4485.435\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0063982 2.979449  3.007564  0.9591724 3.3331203 2.9981556]\n",
      "Reset environment\n",
      "Episode reward: 1021.0705\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0076125 2.9805028 3.008941  0.9606796 3.3341951 2.9993734]\n",
      "Reset environment\n",
      "Episode reward: 1292.2194\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.009492   2.982365   3.0108318  0.96281767 3.3358443  3.001253  ]\n",
      "Reset environment\n",
      "Episode reward: -223.71048\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0093186  2.9823632  3.0105026  0.96279633 3.3356814  3.0010812 ]\n",
      "Reset environment\n",
      "Episode reward: 2321.5054\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0114028 2.984455  3.012575  0.9652138 3.3374724 3.0031624]\n",
      "Reset environment\n",
      "Episode reward: 2047.4146\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.013364  2.9863937 3.0145552 0.9674182 3.339203  3.0051198]\n",
      "Reset environment\n",
      "Episode reward: 5943.3193\n",
      "Total Steps: 215\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.019332   2.9923887  3.0204952  0.97406906 3.3444836  3.0110912 ]\n",
      "Reset environment\n",
      "Episode reward: 4919.522\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0242505  2.9972973  3.0254164  0.97957975 3.348807   3.0160038 ]\n",
      "Reset environment\n",
      "Episode reward: 1725.7928\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0204914 2.993597  3.021609  0.9766441 3.344445  3.012285 ]\n",
      "Reset environment\n",
      "Episode reward: 725.38055\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0213437 2.994689  3.022228  0.9778604 3.3451498 3.0131435]\n",
      "Reset environment\n",
      "Episode reward: 3382.072\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0246525 2.9980335 3.0254958 0.9815402 3.3480973 3.01645  ]\n",
      "Reset environment\n",
      "Episode reward: 4051.1443\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0285726  3.0019329  3.029438   0.98597664 3.351523   3.0203705 ]\n",
      "Reset environment\n",
      "Episode reward: 5434.4897\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.034001  3.00728   3.0349493 0.992055  3.3563185 3.025796 ]\n",
      "Reset environment\n",
      "Episode reward: 1420.3596\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0360248  3.009303   3.0369644  0.99432135 3.3581011  3.0278168 ]\n",
      "Reset environment\n",
      "Episode reward: 229.20389\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0362997 3.0097647 3.0370538 0.9949953 3.3582563 3.0280945]\n",
      "Reset environment\n",
      "Episode reward: 1249.5242\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0381136  3.011578   3.0388646  0.99706894 3.3598335  3.0299058 ]\n",
      "Reset environment\n",
      "Episode reward: 1251.569\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0399382 3.0134048 3.0406892 0.9991555 3.3614237 3.0317297]\n",
      "Reset environment\n",
      "Episode reward: 1308.588\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0418277 3.015276  3.0425973 1.001305  3.3630855 3.033619 ]\n",
      "Reset environment\n",
      "Episode reward: 870.71765\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0424886 3.0159395 3.0432537 1.0021149 3.3636467 3.0342793]\n",
      "Reset environment\n",
      "Episode reward: 860.22644\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0434902 3.0167847 3.0444107 1.0034815 3.3644435 3.0352821]\n",
      "Reset environment\n",
      "Episode reward: -68.91406\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0434012 3.0164795 3.0445328 1.0036961 3.364247  3.0351973]\n",
      "Reset environment\n",
      "Episode reward: 3090.305\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0464075 3.0193992 3.0476134 1.007097  3.3669088 3.038201 ]\n",
      "Reset environment\n",
      "Episode reward: 3658.7217\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0499732 3.0229797 3.0511622 1.0110571 3.3700619 3.041766 ]\n",
      "Reset environment\n",
      "Episode reward: 431.71494\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0505683 3.0234976 3.051836  1.0117162 3.3706167 3.0423632]\n",
      "Reset environment\n",
      "Episode reward: 2373.8005\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.05338   3.026189  3.0547612 1.0150445 3.373098  3.0451775]\n",
      "Reset environment\n",
      "Episode reward: 3016.9744\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0563033 3.0291817 3.0576074 1.0183427 3.37569   3.0481029]\n",
      "Reset environment\n",
      "Episode reward: 1329.094\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.05819   3.0310798 3.0594835 1.0204875 3.3773422 3.0499895]\n",
      "Reset environment\n",
      "Episode reward: 5872.165\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0641053 3.0369663 3.0654192 1.0270218 3.3826053 3.055905 ]\n",
      "Reset environment\n",
      "Episode reward: 7229.822\n",
      "Total Steps: 269\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0713644 3.0441697 3.0727215 1.0351313 3.3890357 3.063161 ]\n",
      "Reset environment\n",
      "Episode reward: 1769.0277\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.072976  3.0457935 3.0743163 1.0369886 3.3904388 3.0647712]\n",
      "Reset environment\n",
      "Episode reward: 2111.859\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0749142 3.047758  3.076223  1.0391928 3.3921428 3.0667086]\n",
      "Reset environment\n",
      "Episode reward: 2386.4097\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0771055 3.0499153 3.0784419 1.0416512 3.3940778 3.0688999]\n",
      "Reset environment\n",
      "Episode reward: 3244.425\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0803337 3.053181  3.0816252 1.0452455 3.396934  3.072129 ]\n",
      "Reset environment\n",
      "Episode reward: 1923.7198\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0828543 3.055721  3.0841215 1.0481108 3.399133  3.0746498]\n",
      "Reset environment\n",
      "Episode reward: 3780.2532\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0863814 3.059105  3.0877817 1.0521597 3.4022288 3.0781803]\n",
      "Reset environment\n",
      "Episode reward: 205.2865\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0865781 3.0591125 3.088156  1.0527956 3.4022515 3.078378 ]\n",
      "Reset environment\n",
      "Episode reward: 2895.2056\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0892901 3.0618598 3.090833  1.0558338 3.4046474 3.0810893]\n",
      "Reset environment\n",
      "Episode reward: -410.99307\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0889795 3.061346  3.090716  1.0555687 3.404353  3.0807803]\n",
      "Reset environment\n",
      "Episode reward: 1141.2966\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0906494 3.0630426 3.09236   1.057514  3.4057941 3.0824513]\n",
      "Reset environment\n",
      "Episode reward: 616.69653\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.091206  3.0634646 3.0930464 1.0583913 3.406253  3.0830114]\n",
      "Reset environment\n",
      "Episode reward: 5142.2056\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.0964952 3.068739  3.0983546 1.0641992 3.4109726 3.088309 ]\n",
      "Reset environment\n",
      "Episode reward: 3698.701\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1001654 3.0724425 3.1019897 1.0683191 3.414207  3.0919838]\n",
      "Reset environment\n",
      "Episode reward: 1273.7465\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1019893 3.0742652 3.103809  1.0703965 3.4158032 3.0938084]\n",
      "Reset environment\n",
      "Episode reward: 4885.5576\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1069603 3.0792508 3.108762  1.0758823 3.4202218 3.0987804]\n",
      "Reset environment\n",
      "Episode reward: 1337.8596\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.108866  3.0811627 3.1106622 1.0780284 3.4219034 3.100685 ]\n",
      "Reset environment\n",
      "Episode reward: 1343.9858\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1105683 3.082761  3.1124632 1.0799994 3.4233997 3.1023867]\n",
      "Reset environment\n",
      "Episode reward: 1124.3053\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1122193 3.0843904 3.1141367 1.0819215 3.4248276 3.1040385]\n",
      "Reset environment\n",
      "Episode reward: 4459.206\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1165404 3.0886116 3.1185417 1.0867958 3.4286535 3.1083572]\n",
      "Reset environment\n",
      "Episode reward: 3614.7712\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.120033  3.091986  3.122141  1.0907797 3.4317572 3.1118488]\n",
      "Reset environment\n",
      "Episode reward: 3307.284\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1231687 3.0950997 3.125301  1.0942967 3.4345288 3.1149848]\n",
      "Reset environment\n",
      "Episode reward: 3118.8728\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.126213  3.0981605 3.1283395 1.0977039 3.4372191 3.1180315]\n",
      "Reset environment\n",
      "Episode reward: 4180.934\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.130394  3.102377  3.1324954 1.1023422 3.4409351 3.1222177]\n",
      "Reset environment\n",
      "Episode reward: 2169.988\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1329918 3.1048498 3.1352007 1.1054163 3.4432032 3.1248157]\n",
      "Reset environment\n",
      "Episode reward: 856.985\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1341121 3.1058564 3.1364317 1.1066532 3.4442573 3.1259365]\n",
      "Reset environment\n",
      "Episode reward: 2886.1567\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1373448 3.109075  3.139661  1.1103468 3.4471939 3.1291714]\n",
      "Reset environment\n",
      "Episode reward: 2770.8682\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1398022 3.1116447 3.1420002 1.1132103 3.4493215 3.1316276]\n",
      "Reset environment\n",
      "Episode reward: 604.2386\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1405149 3.1125765 3.1424935 1.1143284 3.449878  3.1323428]\n",
      "Reset environment\n",
      "Episode reward: 4654.159\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.145888  3.117898  3.14792   1.1203351 3.4546373 3.1377158]\n",
      "Reset environment\n",
      "Episode reward: 1287.74\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1477246 3.1197302 3.149758  1.1224222 3.4562478 3.1395524]\n",
      "Reset environment\n",
      "Episode reward: 3885.5215\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1515644 3.1236064 3.1535678 1.1267363 3.459623  3.1433945]\n",
      "Reset environment\n",
      "Episode reward: 3027.437\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.154488  3.1264796 3.1565382 1.1300213 3.462214  3.1463156]\n",
      "Reset environment\n",
      "Episode reward: 4364.0747\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1586876 3.1306417 3.160778  1.1347392 3.4659066 3.150514 ]\n",
      "Reset environment\n",
      "Episode reward: 2343.419\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1607873 3.1326604 3.16295   1.1371921 3.4677258 3.152611 ]\n",
      "Reset environment\n",
      "Episode reward: -53.70575\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1546474 3.1266696 3.1567025 1.1216555 3.4625084 3.1464918]\n",
      "Reset environment\n",
      "Episode reward: 2138.3022\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.150374  3.1225655 3.1522489 1.113967  3.4587379 3.1422293]\n",
      "Reset environment\n",
      "Episode reward: 2797.3093\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1528647 3.1251483 3.1546352 1.116868  3.4608948 3.1447175]\n",
      "Reset environment\n",
      "Episode reward: 3245.3987\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.156026  3.1282947 3.1578128 1.1204005 3.4636805 3.14788  ]\n",
      "Reset environment\n",
      "Episode reward: 4698.6353\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1607134 3.1329472 3.1625354 1.1256406 3.4678223 3.152572 ]\n",
      "Reset environment\n",
      "Episode reward: 1028.5454\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.155084  3.1271255 3.157136  1.1121333 3.4625986 3.1469846]\n",
      "Reset environment\n",
      "Episode reward: 239.33316\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.155115  3.127347  3.156987  1.1123564 3.4626863 3.1470163]\n",
      "Reset environment\n",
      "Episode reward: 1344.0024\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1570046 3.1292286 3.1588812 1.1145002 3.464345  3.1489062]\n",
      "Reset environment\n",
      "Episode reward: 6164.7866\n",
      "Total Steps: 223\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1630802 3.1352632 3.1649857 1.1213399 3.4696686 3.1549757]\n",
      "Reset environment\n",
      "Episode reward: 1873.3671\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1654806 3.1376474 3.1674035 1.1241192 3.4717324 3.157375 ]\n",
      "Reset environment\n",
      "Episode reward: 1186.3131\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.167182  3.1393378 3.1691103 1.1260993 3.4732022 3.1590729]\n",
      "Reset environment\n",
      "Episode reward: 2202.7305\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.169226  3.1413913 3.171139  1.1284195 3.4749858 3.161114 ]\n",
      "Reset environment\n",
      "Episode reward: 1350.6691\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1711283 3.143301  3.1730304 1.1305616 3.4766595 3.1630127]\n",
      "Reset environment\n",
      "Episode reward: 626.59094\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1658263 3.1379142 3.1678784 1.1209376 3.471366  3.1577249]\n",
      "Reset environment\n",
      "Episode reward: 167.86813\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1660821 3.1382637 3.1680481 1.1212134 3.4716144 3.157981 ]\n",
      "Reset environment\n",
      "Episode reward: 1186.555\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1677675 3.139968  3.1697125 1.12317   3.4730675 3.159664 ]\n",
      "Reset environment\n",
      "Episode reward: 883.63184\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1684072 3.1406026 3.1703565 1.1239802 3.4735906 3.1603034]\n",
      "Reset environment\n",
      "Episode reward: 3626.37\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1718733 3.1439743 3.1739058 1.1279043 3.4766622 3.163769 ]\n",
      "Reset environment\n",
      "Episode reward: 3893.8608\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1756237 3.1476119 3.1777565 1.1321524 3.4799862 3.167518 ]\n",
      "Reset environment\n",
      "Episode reward: 4842.124\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1804104 3.1524405 3.1825204 1.1374875 3.484229  3.172311 ]\n",
      "Reset environment\n",
      "Episode reward: 2889.304\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1830835 3.1552167 3.1850822 1.1405494 3.4865773 3.1749833]\n",
      "Reset environment\n",
      "Episode reward: 1512.2666\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1851304 3.15726   3.187127  1.1428658 3.488368  3.1770265]\n",
      "Reset environment\n",
      "Episode reward: 3170.7812\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.188097  3.160121  3.190184  1.1462559 3.4910047 3.179991 ]\n",
      "Reset environment\n",
      "Episode reward: 197.1193\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1883883 3.1605186 3.1903787 1.1466674 3.4912689 3.1802838]\n",
      "Reset environment\n",
      "Episode reward: -465.17697\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1879747 3.1600018 3.1900697 1.1462475 3.4909189 3.17987  ]\n",
      "Reset environment\n",
      "Episode reward: 855.79065\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1889586 3.1608286 3.1912088 1.1476372 3.4917183 3.180857 ]\n",
      "Reset environment\n",
      "Episode reward: 743.08887\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1898327 3.16154   3.1922526 1.1488945 3.4924362 3.1817367]\n",
      "Reset environment\n",
      "Episode reward: 4524.5044\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1943004 3.1659691 3.1967528 1.1538936 3.4963875 3.1862028]\n",
      "Reset environment\n",
      "Episode reward: 3256.365\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.1981091 3.1696439 3.2006829 1.1581932 3.499784  3.190007 ]\n",
      "Reset environment\n",
      "Episode reward: 3081.8464\n",
      "Total Steps: 232\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2012951 3.172702  3.2039876 1.1619519 3.502609  3.193198 ]\n",
      "Reset environment\n",
      "Episode reward: 3117.883\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2042885 3.175732  3.206945  1.1653041 3.5052514 3.1961942]\n",
      "Reset environment\n",
      "Episode reward: 3506.3044\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2077026 3.179179  3.2103205 1.1691155 3.508269  3.1996074]\n",
      "Reset environment\n",
      "Episode reward: 1381.054\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2093554 3.180732  3.2120767 1.171041  3.5097504 3.2012625]\n",
      "Reset environment\n",
      "Episode reward: 5083.853\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2142706 3.1856153 3.2170231 1.1765188 3.5140984 3.2061744]\n",
      "Reset environment\n",
      "Episode reward: 1843.3004\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2163415 3.1878376 3.2189345 1.1789727 3.5159187 3.2082477]\n",
      "Reset environment\n",
      "Episode reward: 4435.2593\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.220632  3.192172  3.223183  1.1837386 3.5197382 3.2125366]\n",
      "Reset environment\n",
      "Episode reward: 931.2449\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2153475 3.1870642 3.2177503 1.1711628 3.5151298 3.207295 ]\n",
      "Reset environment\n",
      "Episode reward: 4112.655\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2192485 3.1909955 3.2216227 1.1755428 3.5185652 3.2111964]\n",
      "Reset environment\n",
      "Episode reward: 5409.1787\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2244976 3.1962726 3.226842  1.1814148 3.5231771 3.2164443]\n",
      "Reset environment\n",
      "Episode reward: 4074.54\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2283387 3.200031  3.2307618 1.185734  3.5265856 3.220286 ]\n",
      "Reset environment\n",
      "Episode reward: 1135.0009\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2296634 3.2012286 3.2322178 1.187258  3.527815  3.221614 ]\n",
      "Reset environment\n",
      "Episode reward: 3284.5254\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2332478 3.2047076 3.2358863 1.1913644 3.5310438 3.2251947]\n",
      "Reset environment\n",
      "Episode reward: 913.0081\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2341437 3.205419  3.2369676 1.1926348 3.5317683 3.2260938]\n",
      "Reset environment\n",
      "Episode reward: 421.31168\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2347808 3.2059174 3.2377315 1.193562  3.5322704 3.226731 ]\n",
      "Reset environment\n",
      "Episode reward: 3322.4658\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2379172 3.2089832 3.2409282 1.1970819 3.5350626 3.2298641]\n",
      "Reset environment\n",
      "Episode reward: 3713.3352\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2413583 3.2124548 3.2443347 1.201007  3.5380692 3.2333045]\n",
      "Reset environment\n",
      "Episode reward: 3118.636\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2442117 3.215327  3.2471564 1.2042342 3.540564  3.2361503]\n",
      "Reset environment\n",
      "Episode reward: 3907.3345\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.247985  3.219003  3.2510166 1.2084632 3.5439367 3.2399244]\n",
      "Reset environment\n",
      "Episode reward: 122.41989\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2480583 3.219226  3.2509468 1.2086322 3.5440595 3.240002 ]\n",
      "Reset environment\n",
      "Episode reward: 2531.089\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2501297 3.2213767 3.2529225 1.2110554 3.5458164 3.2420695]\n",
      "Reset environment\n",
      "Episode reward: 4779.7944\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.255571  3.2268448 3.2583368 1.2170864 3.5506494 3.247513 ]\n",
      "Reset environment\n",
      "Episode reward: 3143.703\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2585864 3.2298274 3.2613766 1.2204486 3.5533223 3.2505236]\n",
      "Reset environment\n",
      "Episode reward: 2742.8901\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2615018 3.2326174 3.2644048 1.2238314 3.5559034 3.2534404]\n",
      "Reset environment\n",
      "Episode reward: 5217.518\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2665524 3.2376778 3.2694411 1.2294438 3.5603526 3.258489 ]\n",
      "Reset environment\n",
      "Episode reward: 3543.2444\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2699132 3.2409885 3.272858  1.2332335 3.5633223 3.261853 ]\n",
      "Reset environment\n",
      "Episode reward: 2144.135\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.265578  3.2367206 3.268574  1.2252324 3.5591455 3.2575588]\n",
      "Reset environment\n",
      "Episode reward: 2811.212\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.268112  3.239246  3.2711117 1.2281104 3.5613563 3.2600923]\n",
      "Reset environment\n",
      "Episode reward: 3163.6353\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2709913 3.2420373 3.2740624 1.2314094 3.5639102 3.2629726]\n",
      "Reset environment\n",
      "Episode reward: 1259.6707\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2727482 3.243776  3.2758398 1.2334166 3.5654523 3.2647285]\n",
      "Reset environment\n",
      "Episode reward: 938.2445\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2735755 3.2444906 3.2767668 1.2345017 3.566251  3.2655602]\n",
      "Reset environment\n",
      "Episode reward: 2243.3901\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2754927 3.2465034 3.2785811 1.2367506 3.5679133 3.2674763]\n",
      "Reset environment\n",
      "Episode reward: 762.2263\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2763808 3.2475789 3.2792795 1.2379961 3.5686655 3.2683694]\n",
      "Reset environment\n",
      "Episode reward: 1967.198\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2788682 3.250081  3.2817528 1.2407917 3.5708525 3.2708585]\n",
      "Reset environment\n",
      "Episode reward: 2583.1177\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2812614 3.2524452 3.284173  1.2434967 3.572966  3.2732537]\n",
      "Reset environment\n",
      "Episode reward: 699.5815\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2816963 3.2528815 3.284605  1.2440827 3.5733051 3.2736886]\n",
      "Reset environment\n",
      "Episode reward: 4301.0894\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2859006 3.2571247 3.2887728 1.2487643 3.5770419 3.2778978]\n",
      "Reset environment\n",
      "Episode reward: 4888.507\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2914135 3.2626667 3.2942667 1.2548598 3.5819564 3.2834148]\n",
      "Reset environment\n",
      "Episode reward: 1341.7914\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2932627 3.2645223 3.2961104 1.256957  3.5835748 3.2852647]\n",
      "Reset environment\n",
      "Episode reward: 5195.2666\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.2982755 3.2695332 3.3011222 1.2625351 3.5880055 3.2902784]\n",
      "Reset environment\n",
      "Episode reward: 5232.2603\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3033133 3.2745593 3.30617   1.2681202 3.5924666 3.2953184]\n",
      "Reset environment\n",
      "Episode reward: 2075.87\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3058944 3.2771451 3.3087478 1.2710357 3.5947309 3.2978976]\n",
      "Reset environment\n",
      "Episode reward: 877.32935\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3068635 3.2782786 3.3095596 1.272234  3.5956733 3.29887  ]\n",
      "Reset environment\n",
      "Episode reward: 3184.0303\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3098457 3.2811942 3.312602  1.2755768 3.5983312 3.3018534]\n",
      "Reset environment\n",
      "Episode reward: 4586.1963\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3143244 3.2856157 3.317138  1.2805953 3.602296  3.3063357]\n",
      "Reset environment\n",
      "Episode reward: 2999.7063\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.317113  3.2883515 3.31997   1.2837436 3.6047642 3.3091242]\n",
      "Reset environment\n",
      "Episode reward: 2338.5535\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.319139  3.290371  3.3219981 1.2860419 3.606544  3.3111515]\n",
      "Reset environment\n",
      "Episode reward: 3555.9302\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3171432 3.2885864 3.319805  1.2794939 3.6044312 3.3091562]\n",
      "Reset environment\n",
      "Episode reward: 1356.6941\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.318709  3.290348  3.3211825 1.2814518 3.6057909 3.3107266]\n",
      "Reset environment\n",
      "Episode reward: 1317.5709\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.320157  3.2919364 3.3225033 1.2831458 3.607113  3.3121822]\n",
      "Reset environment\n",
      "Episode reward: 1165.0287\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3214688 3.2931316 3.3239362 1.2846704 3.6083076 3.3134966]\n",
      "Reset environment\n",
      "Episode reward: 4404.163\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3255694 3.2971578 3.3281078 1.2893137 3.6119084 3.3176003]\n",
      "Reset environment\n",
      "Episode reward: 1935.4863\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3280003 3.2996018 3.3305302 1.2920597 3.6140487 3.3200336]\n",
      "Reset environment\n",
      "Episode reward: 2754.32\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.330468  3.3019881 3.333071  1.2948861 3.6162348 3.3225045]\n",
      "Reset environment\n",
      "Episode reward: 1135.8232\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.332056  3.30359   3.3346431 1.2967507 3.617591  3.3240907]\n",
      "Reset environment\n",
      "Episode reward: 6762.884\n",
      "Total Steps: 235\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3386183 3.3101578 3.341203  1.3040469 3.6234102 3.3306603]\n",
      "Reset environment\n",
      "Episode reward: 4683.981\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3431344 3.3147063 3.345694  1.3090469 3.6274197 3.3351758]\n",
      "Reset environment\n",
      "Episode reward: 2694.6436\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3455296 3.3171203 3.348071  1.311771  3.6295133 3.3375683]\n",
      "Reset environment\n",
      "Episode reward: 3250.8796\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3485093 3.32013   3.3510149 1.3151076 3.6321518 3.3405485]\n",
      "Reset environment\n",
      "Episode reward: 1304.7222\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3503    3.3219235 3.352802  1.3171611 3.6337154 3.342338 ]\n",
      "Reset environment\n",
      "Episode reward: 1300.202\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3520772 3.323705  3.3545778 1.3192146 3.6352656 3.3441148]\n",
      "Reset environment\n",
      "Episode reward: 4174.6216\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3560977 3.3277617 3.3585773 1.3236763 3.638848  3.3481395]\n",
      "Reset environment\n",
      "Episode reward: 4173.6055\n",
      "Total Steps: 235\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.360544  3.3322568 3.362996  1.3286383 3.6428566 3.3526022]\n",
      "Reset environment\n",
      "Episode reward: 2815.942\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3631458 3.3347824 3.365666  1.3315798 3.645171  3.3552036]\n",
      "Reset environment\n",
      "Episode reward: 2039.464\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.365672  3.3373206 3.368185  1.3344394 3.6473851 3.3577323]\n",
      "Reset environment\n",
      "Episode reward: 2158.6323\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3675747 3.3392448 3.370062  1.3365716 3.649068  3.3596325]\n",
      "Reset environment\n",
      "Episode reward: 1799.748\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3691568 3.340849  3.3716242 1.3383573 3.6504729 3.361214 ]\n",
      "Reset environment\n",
      "Episode reward: 4467.709\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3733606 3.3450708 3.3758016 1.3430011 3.6542077 3.3654199]\n",
      "Reset environment\n",
      "Episode reward: 723.9673\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.37399   3.3458633 3.3762674 1.3439138 3.65477   3.3660512]\n",
      "Reset environment\n",
      "Episode reward: 1995.7349\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3764706 3.3483484 3.3787417 1.346728  3.6569352 3.3685308]\n",
      "Reset environment\n",
      "Episode reward: 2642.487\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3788989 3.3508136 3.3811214 1.3494638 3.6590776 3.3709545]\n",
      "Reset environment\n",
      "Episode reward: 2033.8668\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.381419  3.3533323 3.3836443 1.3523071 3.6612961 3.3734777]\n",
      "Reset environment\n",
      "Episode reward: 4422.1416\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3863344 3.3581924 3.3886147 1.3577836 3.6656692 3.3783915]\n",
      "Reset environment\n",
      "Episode reward: 1405.7056\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3878627 3.3596067 3.3902595 1.359694  3.6669936 3.3799224]\n",
      "Reset environment\n",
      "Episode reward: 5624.693\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.387789  3.359721  3.3900325 1.3535293 3.666678  3.3798401]\n",
      "Reset environment\n",
      "Episode reward: 2473.2207\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3900042 3.361868  3.39231   1.3560351 3.668641  3.3820534]\n",
      "Reset environment\n",
      "Episode reward: 1729.7434\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3914683 3.3633301 3.3937685 1.3577893 3.6698692 3.3835163]\n",
      "Reset environment\n",
      "Episode reward: 3645.9697\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3948581 3.3666384 3.3972309 1.3615965 3.6728868 3.3869033]\n",
      "Reset environment\n",
      "Episode reward: 2753.9773\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3978763 3.369798  3.400092  1.3650447 3.6755497 3.3899157]\n",
      "Reset environment\n",
      "Episode reward: 2057.7412\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.3996997 3.3716445 3.4018934 1.3671246 3.6771555 3.3917391]\n",
      "Reset environment\n",
      "Episode reward: 773.09973\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.400483  3.3725607 3.4025464 1.3680139 3.6779928 3.3925192]\n",
      "Reset environment\n",
      "Episode reward: 1177.8759\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4021182 3.3741908 3.404184  1.3699211 3.6793966 3.394156 ]\n",
      "Reset environment\n",
      "Episode reward: 998.80225\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4032545 3.3751874 3.4054565 1.3712921 3.6804054 3.3952913]\n",
      "Reset environment\n",
      "Episode reward: 238.55258\n",
      "Total Steps: 8\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4032621 3.3751929 3.405466  1.3713334 3.680401  3.395299 ]\n",
      "Reset environment\n",
      "Episode reward: 1619.3848\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4046414 3.3765903 3.4068232 1.3729178 3.6816127 3.3966753]\n",
      "Reset environment\n",
      "Episode reward: 4241.752\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.40859   3.3805249 3.410781  1.3773116 3.685104  3.4006238]\n",
      "Reset environment\n",
      "Episode reward: 4075.654\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.412382  3.384349  3.414542  1.3815471 3.6884618 3.4044156]\n",
      "Reset environment\n",
      "Episode reward: 1405.7922\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4142606 3.3862119 3.416436  1.3836746 3.6901119 3.4062953]\n",
      "Reset environment\n",
      "Episode reward: 680.9286\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4146838 3.3866456 3.416847  1.3842195 3.6904607 3.4067192]\n",
      "Reset environment\n",
      "Episode reward: 3241.234\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4177022 3.3896956 3.419835  1.3876312 3.693104  3.409734 ]\n",
      "Reset environment\n",
      "Episode reward: -588.0785\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4171565 3.389233  3.4192157 1.3870736 3.692614  3.4091895]\n",
      "Reset environment\n",
      "Episode reward: 6115.684\n",
      "Total Steps: 214\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4230468 3.3951516 3.42508   1.3936063 3.6978421 3.41508  ]\n",
      "Reset environment\n",
      "Episode reward: 5392.9424\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4281397 3.400263  3.4301457 1.3992407 3.7023654 3.42017  ]\n",
      "Reset environment\n",
      "Episode reward: 4703.9\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.432665  3.404825  3.4346418 1.4042687 3.7063806 3.424698 ]\n",
      "Reset environment\n",
      "Episode reward: 1198.1373\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4340246 3.4060662 3.4361212 1.4058619 3.7076285 3.4260614]\n",
      "Reset environment\n",
      "Episode reward: 346.42218\n",
      "Total Steps: 14\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4341252 3.4061675 3.4362233 1.4060389 3.7076957 3.4261622]\n",
      "Reset environment\n",
      "Episode reward: 2077.6274\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4366794 3.4087465 3.438753  1.4089236 3.7099376 3.428716 ]\n",
      "Reset environment\n",
      "Episode reward: 2838.2861\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4391885 3.4112308 3.4412763 1.4117415 3.7121503 3.4312236]\n",
      "Reset environment\n",
      "Episode reward: 5316.9136\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4441934 3.4162517 3.4462464 1.4172803 3.716601  3.4362197]\n",
      "Reset environment\n",
      "Episode reward: 1817.5619\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.446016  3.417949  3.4481883 1.4195124 3.7182088 3.438049 ]\n",
      "Reset environment\n",
      "Episode reward: 2605.8535\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4482698 3.4201713 3.4504743 1.4220879 3.7201822 3.4403026]\n",
      "Reset environment\n",
      "Episode reward: 4039.251\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.452035  3.4238777 3.4542913 1.4263214 3.7235034 3.4440677]\n",
      "Reset environment\n",
      "Episode reward: 1286.0464\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4537888 3.4256213 3.456053  1.4283353 3.72503   3.4458215]\n",
      "Reset environment\n",
      "Episode reward: 2430.3345\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4559505 3.4278357 3.458159  1.4307909 3.7269332 3.4479842]\n",
      "Reset environment\n",
      "Episode reward: 5107.5317\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.461508  3.4333425 3.4637642 1.4370292 3.7318656 3.453542 ]\n",
      "Reset environment\n",
      "Episode reward: 6015.262\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.467371  3.4392312 3.469606  1.4434681 3.7371092 3.4594061]\n",
      "Reset environment\n",
      "Episode reward: 913.25934\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4680216 3.4399006 3.4702353 1.4442525 3.7376597 3.4600558]\n",
      "Reset environment\n",
      "Episode reward: 1041.2693\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.469363  3.4414232 3.4714038 1.4459733 3.738827  3.4613996]\n",
      "Reset environment\n",
      "Episode reward: 2152.925\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4713132 3.4435265 3.4731908 1.448277  3.740522  3.4633512]\n",
      "Reset environment\n",
      "Episode reward: 3940.7612\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4749873 3.4471307 3.4769268 1.452381  3.7437944 3.4670281]\n",
      "Reset environment\n",
      "Episode reward: 4076.9614\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.478882  3.4510093 3.4808378 1.4566914 3.7472498 3.4709253]\n",
      "Reset environment\n",
      "Episode reward: 1254.1104\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4805903 3.4527159 3.482548  1.4586456 3.7487407 3.4726331]\n",
      "Reset environment\n",
      "Episode reward: 5278.4814\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4855847 3.4576557 3.4875805 1.4642591 3.7531793 3.4776256]\n",
      "Reset environment\n",
      "Episode reward: 3474.628\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4894688 3.4616497 3.4913461 1.4686457 3.7566023 3.4815052]\n",
      "Reset environment\n",
      "Episode reward: 623.9965\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4897912 3.46197   3.491668  1.469136  3.7568216 3.4818275]\n",
      "Reset environment\n",
      "Episode reward: 5028.2866\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.49458   3.4667168 3.4964955 1.4744608 3.7610774 3.4866157]\n",
      "Reset environment\n",
      "Episode reward: 4253.8984\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.4984994 3.470664  3.5003796 1.4788787 3.7645166 3.4905324]\n",
      "Reset environment\n",
      "Episode reward: 2638.5784\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5007646 3.472874  3.502699  1.4814423 3.7665117 3.4927988]\n",
      "Reset environment\n",
      "Episode reward: 1278.8928\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5025    3.4746075 3.5044334 1.4834285 3.7680213 3.4945319]\n",
      "Reset environment\n",
      "Episode reward: 2645.505\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5049148 3.4769866 3.5068803 1.4861405 3.7701519 3.4969418]\n",
      "Reset environment\n",
      "Episode reward: 926.83545\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5059805 3.4781632 3.507838  1.4873773 3.7711334 3.4980063]\n",
      "Reset environment\n",
      "Episode reward: 5429.8696\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5111008 3.48327   3.5129623 1.4930328 3.7756653 3.5031202]\n",
      "Reset environment\n",
      "Episode reward: 3120.915\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5139563 3.4861526 3.5157888 1.496224  3.7781842 3.5059764]\n",
      "Reset environment\n",
      "Episode reward: 3117.8965\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5168467 3.4889963 3.5187242 1.4994514 3.780757  3.5088654]\n",
      "Reset environment\n",
      "Episode reward: 1583.7146\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5188737 3.4910061 3.5207632 1.5017728 3.7825198 3.51089  ]\n",
      "Reset environment\n",
      "Episode reward: 3156.5205\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.521747  3.4939713 3.523531  1.5050594 3.78502   3.5137587]\n",
      "Reset environment\n",
      "Episode reward: 1963.7\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5234697 3.4956932 3.5252483 1.5070233 3.7865188 3.5154798]\n",
      "Reset environment\n",
      "Episode reward: 1979.2911\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5252054 3.497448  3.526964  1.508973  3.7880607 3.5172138]\n",
      "Reset environment\n",
      "Episode reward: 4151.9067\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5290673 3.5012352 3.5308938 1.5133004 3.7915146 3.5210757]\n",
      "Reset environment\n",
      "Episode reward: 4035.2375\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.532732  3.5048716 3.5345783 1.5174085 3.7947364 3.524739 ]\n",
      "Reset environment\n",
      "Episode reward: 3284.9048\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5357795 3.507891  3.5376492 1.5208181 3.7974265 3.5277836]\n",
      "Reset environment\n",
      "Episode reward: 5150.785\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5406234 3.5127182 3.5424995 1.5261881 3.8017128 3.5326293]\n",
      "Reset environment\n",
      "Episode reward: 1107.108\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.541474  3.5135684 3.5433497 1.5271883 3.8024426 3.5334783]\n",
      "Reset environment\n",
      "Episode reward: 2851.3508\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5440915 3.5162122 3.5459318 1.5301663 3.804727  3.5360932]\n",
      "Reset environment\n",
      "Episode reward: 1165.8789\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5456858 3.517799  3.547528  1.5320141 3.8061001 3.5376856]\n",
      "Reset environment\n",
      "Episode reward: 4072.465\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5494223 3.5215285 3.5512643 1.5361538 3.8094122 3.5414252]\n",
      "Reset environment\n",
      "Episode reward: 4357.905\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.547462  3.5195327 3.5494256 1.5264108 3.8078995 3.5394914]\n",
      "Reset environment\n",
      "Episode reward: 2673.0503\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5498645 3.5219634 3.5517967 1.5291272 3.8100069 3.5418952]\n",
      "Reset environment\n",
      "Episode reward: 3139.8723\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5526018 3.5247962 3.554427  1.5322851 3.8123643 3.5446353]\n",
      "Reset environment\n",
      "Episode reward: 4601.357\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5568025 3.5289783 3.558647  1.5370414 3.8160377 3.5488434]\n",
      "Reset environment\n",
      "Episode reward: 3472.6301\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5598915 3.5320358 3.5617616 1.5404996 3.8187616 3.5519326]\n",
      "Reset environment\n",
      "Episode reward: 2194.8933\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5618076 3.533907  3.563721  1.5426911 3.820447  3.5538466]\n",
      "Reset environment\n",
      "Episode reward: 1182.1045\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5634072 3.535531  3.565298  1.5445634 3.8218243 3.5554466]\n",
      "Reset environment\n",
      "Episode reward: 1953.022\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5657828 3.5379105 3.5676715 1.5472723 3.8238947 3.5578187]\n",
      "Reset environment\n",
      "Episode reward: -431.29486\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5654187 3.5374687 3.5673826 1.5470706 3.8235447 3.557455 ]\n",
      "Reset environment\n",
      "Episode reward: 2828.2615\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.567912  3.5398867 3.5699472 1.5499475 3.8257256 3.5599473]\n",
      "Reset environment\n",
      "Episode reward: 2121.0896\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5704665 3.542455  3.572479  1.5528586 3.827942  3.562498 ]\n",
      "Reset environment\n",
      "Episode reward: 4546.408\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5745971 3.546584  3.5765994 1.557502  3.8315918 3.5666254]\n",
      "Reset environment\n",
      "Episode reward: 2906.0967\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5772543 3.5492733 3.5792274 1.5604647 3.8339548 3.5692797]\n",
      "Reset environment\n",
      "Episode reward: 5451.5605\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5823152 3.5543664 3.584247  1.5661207 3.838414  3.5743365]\n",
      "Reset environment\n",
      "Episode reward: 1017.8157\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5831387 3.5553582 3.5849104 1.5672194 3.8391595 3.575165 ]\n",
      "Reset environment\n",
      "Episode reward: 1382.916\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.58457   3.5569725 3.5861592 1.5689995 3.8404212 3.576602 ]\n",
      "Reset environment\n",
      "Episode reward: 3226.3184\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.587425  3.5598536 3.588988  1.5721998 3.8429434 3.5794547]\n",
      "Reset environment\n",
      "Episode reward: 2506.2217\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5896459 3.562061  3.591226  1.5747142 3.8448946 3.5816767]\n",
      "Reset environment\n",
      "Episode reward: 1080.2573\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.590725  3.5629978 3.5924492 1.576033  3.845886  3.5827618]\n",
      "Reset environment\n",
      "Episode reward: 3122.449\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5934906 3.5657554 3.59522   1.5791012 3.8483324 3.585526 ]\n",
      "Reset environment\n",
      "Episode reward: 3343.8862\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.596471  3.5687573 3.598179  1.5824416 3.8509498 3.5885072]\n",
      "Reset environment\n",
      "Episode reward: 2813.5808\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.5989742 3.571339  3.6006    1.5852901 3.853143  3.5910141]\n",
      "Reset environment\n",
      "Episode reward: 1307.5507\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.600002  3.5723672 3.6016293 1.5865147 3.8540187 3.5920439]\n",
      "Reset environment\n",
      "Episode reward: 1239.575\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6014378 3.5736604 3.6031973 1.5883453 3.855224  3.5934834]\n",
      "Reset environment\n",
      "Episode reward: 2623.3325\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6037145 3.5760205 3.6053758 1.5909729 3.8571782 3.5957582]\n",
      "Reset environment\n",
      "Episode reward: 3467.3276\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6069038 3.5792048 3.6085687 1.5945508 3.8599901 3.5989456]\n",
      "Reset environment\n",
      "Episode reward: 2618.9746\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.609134  3.5813406 3.6108778 1.597119  3.8619545 3.601178 ]\n",
      "Reset environment\n",
      "Episode reward: 3494.2607\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6123528 3.5845752 3.614077  1.6007442 3.8647838 3.6043973]\n",
      "Reset environment\n",
      "Episode reward: 1923.381\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6140132 3.5862513 3.615724  1.6026232 3.8662474 3.6060605]\n",
      "Reset environment\n",
      "Episode reward: 1919.6045\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6156728 3.5879369 3.6173575 1.6045084 3.8677213 3.607723 ]\n",
      "Reset environment\n",
      "Episode reward: 2197.587\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6180182 3.5901558 3.6198184 1.6073518 3.8697462 3.610075 ]\n",
      "Reset environment\n",
      "Episode reward: 3848.6748\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6214778 3.593666  3.6232204 1.6112392 3.872795  3.6135364]\n",
      "Reset environment\n",
      "Episode reward: 2689.8347\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.623753  3.5959933 3.6254416 1.6138227 3.874807  3.6158116]\n",
      "Reset environment\n",
      "Episode reward: 1985.1107\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6261413 3.5983865 3.6278217 1.6165487 3.8768823 3.6181977]\n",
      "Reset environment\n",
      "Episode reward: 2907.663\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.628759  3.6009617 3.6304774 1.6194783 3.8792121 3.620819 ]\n",
      "Reset environment\n",
      "Episode reward: 2823.1401\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6311586 3.6034663 3.632767  1.6222702 3.8812952 3.6232238]\n",
      "Reset environment\n",
      "Episode reward: 2701.8687\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6335669 3.6059    3.6351452 1.6249856 3.8834078 3.6256313]\n",
      "Reset environment\n",
      "Episode reward: 5506.3115\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6388187 3.611165  3.640386  1.6307567 3.8881018 3.6308818]\n",
      "Reset environment\n",
      "Episode reward: 5863.1235\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6441998 3.616589  3.645726  1.6368203 3.892844  3.6362684]\n",
      "Reset environment\n",
      "Episode reward: 4911.073\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6487951 3.6211576 3.6503537 1.641977  3.896885  3.6408677]\n",
      "Reset environment\n",
      "Episode reward: 2942.0437\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.65146   3.6238036 3.6530373 1.6449676 3.8992379 3.6435332]\n",
      "Reset environment\n",
      "Episode reward: 4843.149\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6559112 3.6282392 3.6574998 1.6499003 3.903167  3.6479838]\n",
      "Reset environment\n",
      "Episode reward: 281.37686\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.656305  3.628566  3.6579673 1.6503445 3.903515  3.6483808]\n",
      "Reset environment\n",
      "Episode reward: 2957.6484\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6589713 3.631163  3.6606913 1.6533316 3.905877  3.6510425]\n",
      "Reset environment\n",
      "Episode reward: 2319.1792\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6616971 3.6339018 3.6634035 1.6564299 3.9082687 3.6537669]\n",
      "Reset environment\n",
      "Episode reward: 3086.2983\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6644988 3.636728  3.6661768 1.6595589 3.9107313 3.6565652]\n",
      "Reset environment\n",
      "Episode reward: 4705.1323\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6688933 3.641156  3.670546  1.6644284 3.9146245 3.660958 ]\n",
      "Reset environment\n",
      "Episode reward: 1062.612\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6703358 3.642604  3.6719778 1.6661524 3.9158359 3.6623971]\n",
      "Reset environment\n",
      "Episode reward: 3455.5073\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6740384 3.646316  3.6756754 1.6703485 3.9191396 3.6661024]\n",
      "Reset environment\n",
      "Episode reward: 4131.028\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.677769  3.6499496 3.6795015 1.6745554 3.922455  3.6698363]\n",
      "Reset environment\n",
      "Episode reward: 4512.642\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6818805 3.6540444 3.6836224 1.6791252 3.9260902 3.6739442]\n",
      "Reset environment\n",
      "Episode reward: 1323.203\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6836286 3.6557903 3.6853697 1.6811049 3.9276187 3.6756904]\n",
      "Reset environment\n",
      "Episode reward: 6591.8003\n",
      "Total Steps: 230\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6898968 3.6620264 3.6916811 1.6880239 3.9332178 3.6819649]\n",
      "Reset environment\n",
      "Episode reward: 2676.1672\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.692258  3.6643324 3.6940875 1.6906837 3.9353032 3.6843219]\n",
      "Reset environment\n",
      "Episode reward: 3151.8396\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6949723 3.6671414 3.6966867 1.6938251 3.9376273 3.6870306]\n",
      "Reset environment\n",
      "Episode reward: 3082.8044\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6976519 3.6698275 3.6993504 1.6968496 3.9399753 3.689707 ]\n",
      "Reset environment\n",
      "Episode reward: 1707.7546\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.699088  3.6712394 3.7008123 1.6984786 3.9412408 3.691142 ]\n",
      "Reset environment\n",
      "Episode reward: 1438.7291\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.694192  3.6664443 3.6958253 1.684943  3.9368627 3.6862438]\n",
      "Reset environment\n",
      "Episode reward: 1325.0739\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.695932  3.6681912 3.6975532 1.6869359 3.9383814 3.6879826]\n",
      "Reset environment\n",
      "Episode reward: 2829.8857\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.6984468 3.6707456 3.7000265 1.6897928 3.9405887 3.6905003]\n",
      "Reset environment\n",
      "Episode reward: 3392.2954\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.70151   3.6737638 3.7031322 1.6932359 3.9432864 3.6935623]\n",
      "Reset environment\n",
      "Episode reward: 1980.3167\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7032032 3.6754177 3.704863  1.6951557 3.9447782 3.6952543]\n",
      "Reset environment\n",
      "Episode reward: 2144.7805\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7050686 3.6773005 3.7067108 1.6972603 3.9464219 3.6971176]\n",
      "Reset environment\n",
      "Episode reward: 4622.1167\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7092142 3.6813607 3.71093   1.7019314 3.9500787 3.7012603]\n",
      "Reset environment\n",
      "Episode reward: 2876.2424\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7117677 3.6839786 3.7134092 1.7047976 3.9523468 3.7038114]\n",
      "Reset environment\n",
      "Episode reward: 1946.951\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.713587  3.6859615 3.7150607 1.7069908 3.9539223 3.7056334]\n",
      "Reset environment\n",
      "Episode reward: 6485.848\n",
      "Total Steps: 237\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.719553  3.6919446 3.7209978 1.7136267 3.9592226 3.711596 ]\n",
      "Reset environment\n",
      "Episode reward: 5579.904\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7246783 3.6970584 3.7261271 1.7192947 3.9637601 3.7167234]\n",
      "Reset environment\n",
      "Episode reward: 2750.4656\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7270432 3.699412  3.7284982 1.721938  3.9658558 3.7190876]\n",
      "Reset environment\n",
      "Episode reward: 1038.0319\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7278008 3.700169  3.7292535 1.7228504 3.966498  3.7198448]\n",
      "Reset environment\n",
      "Episode reward: 947.2932\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7284584 3.7008288 3.729909  1.7236664 3.9670498 3.7205017]\n",
      "Reset environment\n",
      "Episode reward: 2424.4268\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.731279  3.703644  3.7327309 1.7268142 3.969537  3.7233202]\n",
      "Reset environment\n",
      "Episode reward: 1666.4175\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.732914  3.7050955 3.7345386 1.728898  3.97092   3.7249632]\n",
      "Reset environment\n",
      "Episode reward: 2637.8086\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7358236 3.708016  3.7374372 1.7321275 3.9735441 3.7278726]\n",
      "Reset environment\n",
      "Episode reward: 3059.5117\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7384331 3.7106645 3.7400131 1.7350713 3.9758472 3.7304854]\n",
      "Reset environment\n",
      "Episode reward: 3043.2083\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7411165 3.7134383 3.7425969 1.7381115 3.978174  3.7331674]\n",
      "Reset environment\n",
      "Episode reward: 4526.03\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7459455 3.7182498 3.7474387 1.7435281 3.9824553 3.7379925]\n",
      "Reset environment\n",
      "Episode reward: 3428.751\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7490027 3.72138   3.7504141 1.7469869 3.9851599 3.741049 ]\n",
      "Reset environment\n",
      "Episode reward: 1446.6749\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7504168 3.722633  3.7519767 1.7488297 3.9863472 3.742467 ]\n",
      "Reset environment\n",
      "Episode reward: 3815.5703\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7538004 3.7260203 3.7553492 1.7526203 3.989328  3.7458458]\n",
      "Reset environment\n",
      "Episode reward: 2367.9922\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7565649 3.728778  3.7581148 1.7556947 3.9917824 3.748608 ]\n",
      "Reset environment\n",
      "Episode reward: 2697.2046\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7588413 3.7310457 3.760408  1.7582912 3.9937828 3.7508914]\n",
      "Reset environment\n",
      "Episode reward: 1918.914\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7608867 3.7329822 3.7625613 1.7606622 3.9956074 3.752941 ]\n",
      "Reset environment\n",
      "Episode reward: 2877.3743\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7633748 3.7353885 3.7651265 1.7635001 3.9978147 3.7554286]\n",
      "Reset environment\n",
      "Episode reward: 1869.1628\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.765627  3.7376378 3.7673793 1.7660418 3.9997878 3.7576797]\n",
      "Reset environment\n",
      "Episode reward: 4132.193\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7693677 3.7412975 3.771195  1.7702208 4.0031166 3.761421 ]\n",
      "Reset environment\n",
      "Episode reward: 5215.933\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7742443 3.7462003 3.7760565 1.7756307 4.007462  3.766307 ]\n",
      "Reset environment\n",
      "Episode reward: 3042.187\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.776803  3.7486563 3.7787123 1.7786056 4.009729  3.7688704]\n",
      "Reset environment\n",
      "Episode reward: 1224.6715\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7784195 3.7502656 3.7803304 1.7804694 4.011125  3.7704868]\n",
      "Reset environment\n",
      "Episode reward: 3861.975\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7819233 3.7537284 3.783874  1.7844092 4.0142045 3.7739906]\n",
      "Reset environment\n",
      "Episode reward: 2114.044\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7844372 3.756226  3.7864013 1.7872115 4.016422  3.7765033]\n",
      "Reset environment\n",
      "Episode reward: 4183.397\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7881782 3.7599635 3.7901402 1.7913753 4.019713  3.7802446]\n",
      "Reset environment\n",
      "Episode reward: 1333.248\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7899191 3.761703  3.7918797 1.7933422 4.0212417 3.781986 ]\n",
      "Reset environment\n",
      "Episode reward: 3382.7773\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.792981  3.7647202 3.794977  1.7967558 4.023952  3.785045 ]\n",
      "Reset environment\n",
      "Episode reward: 1144.8065\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.794502  3.7662418 3.7964962 1.7985284 4.025259  3.7865694]\n",
      "Reset environment\n",
      "Episode reward: 2661.6445\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7972982 3.7691839 3.7991395 1.8017656 4.0276957 3.7893703]\n",
      "Reset environment\n",
      "Episode reward: 2778.0088\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.7996652 3.771554  3.8015044 1.8044227 4.029772  3.7917395]\n",
      "Reset environment\n",
      "Episode reward: 1284.4943\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8013422 3.7732174 3.8031924 1.8063378 4.031236  3.7934167]\n",
      "Reset environment\n",
      "Episode reward: 2878.9402\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8038497 3.775665  3.8057528 1.8091466 4.0334797 3.7959256]\n",
      "Reset environment\n",
      "Episode reward: 1347.5446\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.804905  3.7767208 3.8068054 1.8103765 4.03439   3.796982 ]\n",
      "Reset environment\n",
      "Episode reward: 2373.79\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8068476 3.7787497 3.8086534 1.8126398 4.036067  3.798925 ]\n",
      "Reset environment\n",
      "Episode reward: 4450.166\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8116302 3.783482  3.8134835 1.8179376 4.040325  3.8037076]\n",
      "Reset environment\n",
      "Episode reward: 4824.74\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8159666 3.787808  3.8178375 1.8227388 4.044163  3.8080504]\n",
      "Reset environment\n",
      "Episode reward: 3129.544\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.818591  3.7903244 3.8205438 1.825736  4.046463  3.810673 ]\n",
      "Reset environment\n",
      "Episode reward: 348.93326\n",
      "Total Steps: 14\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8186805 3.7904146 3.8206317 1.8258924 4.0465207 3.8107615]\n",
      "Reset environment\n",
      "Episode reward: 2562.4722\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.82091   3.792701  3.8228028 1.8284097 4.0484867 3.8129947]\n",
      "Reset environment\n",
      "Episode reward: 1189.8618\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8224754 3.7942677 3.8243706 1.8302258 4.04984   3.8145628]\n",
      "Reset environment\n",
      "Episode reward: 4898.211\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8269958 3.798753  3.8289263 1.8352395 4.0538588 3.8190854]\n",
      "Reset environment\n",
      "Episode reward: 3512.579\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8300643 3.8018458 3.83197   1.8386798 4.056573  3.8221543]\n",
      "Reset environment\n",
      "Episode reward: 2503.7703\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8321893 3.8040059 3.8340497 1.841096  4.0584345 3.824276 ]\n",
      "Reset environment\n",
      "Episode reward: 4397.6934\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8369222 3.808682  3.838831  1.8463403 4.0626645 3.8290086]\n",
      "Reset environment\n",
      "Episode reward: 5397.8022\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8356328 3.8073478 3.8376262 1.8382589 4.061825  3.8277152]\n",
      "Reset environment\n",
      "Episode reward: 3414.27\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8387227 3.8105078 3.8406258 1.8417534 4.0644803 3.8308065]\n",
      "Reset environment\n",
      "Episode reward: 5900.2554\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8442266 3.8160195 3.8461287 1.8478525 4.0693784 3.836309 ]\n",
      "Reset environment\n",
      "Episode reward: 1197.1792\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.845804  3.8175864 3.8477106 1.8496854 4.070738  3.837886 ]\n",
      "Reset environment\n",
      "Episode reward: 4158.866\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8494673 3.8212304 3.8513923 1.8537757 4.073984  3.8415475]\n",
      "Reset environment\n",
      "Episode reward: 1748.0227\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.850893  3.822626  3.8528452 1.8554277 4.0752215 3.842972 ]\n",
      "Reset environment\n",
      "Episode reward: 1647.0234\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8522234 3.823955  3.854177  1.8569758 4.0763702 3.8443034]\n",
      "Reset environment\n",
      "Episode reward: 3112.871\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8549674 3.8267555 3.8568556 1.8600606 4.0788026 3.8470442]\n",
      "Reset environment\n",
      "Episode reward: 2523.437\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8575838 3.8292186 3.859601  1.8631012 4.081077  3.8496609]\n",
      "Reset environment\n",
      "Episode reward: 2679.3303\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8599482 3.8315966 3.8619478 1.8657615 4.083153  3.8520222]\n",
      "Reset environment\n",
      "Episode reward: 1283.4492\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8612082 3.8327303 3.8633308 1.8673964 4.084222  3.8532906]\n",
      "Reset environment\n",
      "Episode reward: 3452.9644\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8642812 3.8358464 3.8663623 1.8708379 4.086925  3.8563614]\n",
      "Reset environment\n",
      "Episode reward: 2208.5662\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.866173  3.8377557 3.868235  1.87299   4.0885844 3.858251 ]\n",
      "Reset environment\n",
      "Episode reward: 3720.0808\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8694222 3.841001  3.8714793 1.8766371 4.091431  3.861498 ]\n",
      "Reset environment\n",
      "Episode reward: 1851.2089\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.871633  3.8432152 3.8736873 1.8791293 4.0933685 3.8637075]\n",
      "Reset environment\n",
      "Episode reward: 3379.9097\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8745537 3.8461242 3.876613  1.8823974 4.0959315 3.8666255]\n",
      "Reset environment\n",
      "Episode reward: 3233.5784\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8778646 3.849438  3.879924  1.886147  4.0988626 3.8699336]\n",
      "Reset environment\n",
      "Episode reward: 2581.1052\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8799925 3.8516335 3.8819604 1.8886002 4.1006618 3.8720603]\n",
      "Reset environment\n",
      "Episode reward: 2695.7236\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8823054 3.8539758 3.8842337 1.8912269 4.102691  3.8743706]\n",
      "Reset environment\n",
      "Episode reward: 1716.816\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8840442 3.855612  3.8860536 1.8932971 4.1042504 3.8761127]\n",
      "Reset environment\n",
      "Episode reward: 2783.771\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8863018 3.857962  3.8882065 1.8959441 4.106197  3.878368 ]\n",
      "Reset environment\n",
      "Episode reward: 5285.0444\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8910365 3.862682  3.8929605 1.9011875 4.110391  3.8831036]\n",
      "Reset environment\n",
      "Episode reward: 3368.9705\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8939497 3.8657064 3.8957553 1.9045051 4.112958  3.8860164]\n",
      "Reset environment\n",
      "Episode reward: 4791.946\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.8982077 3.8699777 3.8999956 1.9092286 4.1167274 3.8902752]\n",
      "Reset environment\n",
      "Episode reward: 5002.0405\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.903471  3.875217  3.9052918 1.9150319 4.1214294 3.895544 ]\n",
      "Reset environment\n",
      "Episode reward: 2844.701\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9059348 3.877655  3.9077864 1.917844  4.123583  3.898008 ]\n",
      "Reset environment\n",
      "Episode reward: 2150.0369\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9084501 3.8801677 3.9103074 1.9206539 4.1258087 3.9005268]\n",
      "Reset environment\n",
      "Episode reward: 3215.6912\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9118803 3.883682  3.9136355 1.9245149 4.1288548 3.903954 ]\n",
      "Reset environment\n",
      "Episode reward: 3717.026\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9152036 3.886966  3.9169903 1.9282376 4.1317782 3.9072738]\n",
      "Reset environment\n",
      "Episode reward: 42.853607\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9151893 3.8868067 3.9171221 1.9283168 4.1317744 3.9072604]\n",
      "Reset environment\n",
      "Episode reward: 2215.7412\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9169922 3.8886774 3.9188402 1.9304116 4.133302  3.9090588]\n",
      "Reset environment\n",
      "Episode reward: 4397.79\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9208374 3.8925018 3.9227087 1.9347566 4.136678  3.9129047]\n",
      "Reset environment\n",
      "Episode reward: 609.6454\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9215355 3.8932972 3.923314  1.9355867 4.1373067 3.913603 ]\n",
      "Reset environment\n",
      "Episode reward: 3853.086\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.924944  3.8966515 3.9267697 1.9394076 4.140317  3.9170105]\n",
      "Reset environment\n",
      "Episode reward: 3828.44\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9283147 3.8999536 3.9302018 1.9431784 4.1432986 3.9203777]\n",
      "Reset environment\n",
      "Episode reward: 1170.613\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9297845 3.9013212 3.9317644 1.9450012 4.1445346 3.9218478]\n",
      "Reset environment\n",
      "Episode reward: 1988.2308\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.923946  3.8955708 3.925959  1.9350752 4.139275  3.916045 ]\n",
      "Reset environment\n",
      "Episode reward: 1353.223\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.925661  3.8972683 3.9276865 1.9370204 4.1407776 3.9177573]\n",
      "Reset environment\n",
      "Episode reward: 1885.0038\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.927863  3.899464  3.9298897 1.9395345 4.1426954 3.9199572]\n",
      "Reset environment\n",
      "Episode reward: 6012.511\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9332743 3.904859  3.9353244 1.9455178 4.1474957 3.9253693]\n",
      "Reset environment\n",
      "Episode reward: 4436.8623\n",
      "Total Steps: 221\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9377408 3.9093368 3.9397774 1.9504919 4.1514945 3.9298382]\n",
      "Reset environment\n",
      "Episode reward: 2280.3843\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9396386 3.9111989 3.9417014 1.9526662 4.153149  3.9317334]\n",
      "Reset environment\n",
      "Episode reward: 5560.419\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9446957 3.9162068 3.9468043 1.9582994 4.157637  3.9367933]\n",
      "Reset environment\n",
      "Episode reward: 4667.2334\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.948783  3.9201884 3.9509866 1.9628886 4.1612644 3.9408832]\n",
      "Reset environment\n",
      "Episode reward: 4119.715\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9524803 3.9239175 3.9546509 1.9670061 4.1645346 3.9445798]\n",
      "Reset environment\n",
      "Episode reward: -704.06476\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9517298 3.9231808 3.953894  1.9664162 4.1638174 3.9438293]\n",
      "Reset environment\n",
      "Episode reward: 1663.9873\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9537277 3.925158  3.95591   1.9687115 4.165561  3.9458263]\n",
      "Reset environment\n",
      "Episode reward: 2913.6963\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9562523 3.9277005 3.958406  1.9715447 4.167783  3.9483485]\n",
      "Reset environment\n",
      "Episode reward: 3968.0027\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9597056 3.9311442 3.9618592 1.9753649 4.170842  3.9518003]\n",
      "Reset environment\n",
      "Episode reward: 3383.2952\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9631646 3.934608  3.9653072 1.9792292 4.1739354 3.955255 ]\n",
      "Reset environment\n",
      "Episode reward: 3182.2185\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9659739 3.9374375 3.968092  1.9823596 4.176415  3.958061 ]\n",
      "Reset environment\n",
      "Episode reward: 4658.134\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9708529 3.9422991 3.9729896 1.9877642 4.1807594 3.9629412]\n",
      "Reset environment\n",
      "Episode reward: 3192.4702\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9736247 3.944999  3.9758265 1.9908668 4.183237  3.9657118]\n",
      "Reset environment\n",
      "Episode reward: 2136.0103\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9760878 3.9474788 3.9782743 1.9936339 4.185407  3.9681752]\n",
      "Reset environment\n",
      "Episode reward: 1302.152\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9777503 3.9491427 3.9799452 1.9955233 4.1868634 3.9698412]\n",
      "Reset environment\n",
      "Episode reward: 4999.235\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9829347 3.9543033 3.9851577 2.0012722 4.191474  3.9750273]\n",
      "Reset environment\n",
      "Episode reward: 2572.8528\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.98517   3.9565568 3.9873743 2.0037763 4.193448  3.977263 ]\n",
      "Reset environment\n",
      "Episode reward: 3475.6265\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9881737 3.9595091 3.9904284 2.0071447 4.1961203 3.980268 ]\n",
      "Reset environment\n",
      "Episode reward: 3375.5042\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.99103   3.962362  3.9932854 2.0103917 4.198611  3.9831254]\n",
      "Reset environment\n",
      "Episode reward: 2748.9746\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9934013 3.9647572 3.9956386 2.013065  4.200708  3.9854999]\n",
      "Reset environment\n",
      "Episode reward: 2574.8413\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.995512  3.9668784 3.997738  2.0154424 4.2025614 3.9876122]\n",
      "Reset environment\n",
      "Episode reward: 2439.5752\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [3.9975026 3.9689355 3.999653  2.0177305 4.2042584 3.9896076]\n",
      "Reset environment\n",
      "Episode reward: 2185.7678\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.000006  3.9714546 4.0021496 2.0205207 4.206484  3.9921157]\n",
      "Reset environment\n",
      "Episode reward: 2863.3008\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0024114 3.9738708 4.00454   2.0232205 4.2086015 3.9945195]\n",
      "Reset environment\n",
      "Episode reward: 3427.83\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0060425 3.9775946 4.008071  2.0272782 4.2118297 3.9981482]\n",
      "Reset environment\n",
      "Episode reward: 3222.1572\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0088964 3.9804747 4.0109    2.030441  4.214366  4.001002 ]\n",
      "Reset environment\n",
      "Episode reward: 556.2125\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.009528  3.9809678 4.0116644 2.0313816 4.21487   4.001635 ]\n",
      "Reset environment\n",
      "Episode reward: 2050.9146\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0111895 3.9826996 4.0132556 2.0332637 4.2163515 4.0032964]\n",
      "Reset environment\n",
      "Episode reward: 2660.627\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0133457 3.984832  4.01543   2.0357082 4.218238  4.00545  ]\n",
      "Reset environment\n",
      "Episode reward: 5741.403\n",
      "Total Steps: 215\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0184207 3.989882  4.0205274 2.0413783 4.2227325 4.010524 ]\n",
      "Reset environment\n",
      "Episode reward: 3453.2568\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0214596 3.9928668 4.0236163 2.0447552 4.2254443 4.0135627]\n",
      "Reset environment\n",
      "Episode reward: 1573.3837\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0231643 3.9945033 4.025391  2.0466611 4.2269874 4.015267 ]\n",
      "Reset environment\n",
      "Episode reward: 4713.095\n",
      "Total Steps: 239\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0276837 3.9990458 4.029888  2.0517406 4.231017  4.019782 ]\n",
      "Reset environment\n",
      "Episode reward: 2276.8901\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0296035 4.0009527 4.0318165 2.0539043 4.2327037 4.0217004]\n",
      "Reset environment\n",
      "Episode reward: 4564.108\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0335116 4.004816  4.035773  2.0583034 4.236144  4.0256095]\n",
      "Reset environment\n",
      "Episode reward: 3542.281\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0366073 4.007938  4.0388455 2.0617423 4.2388783 4.028711 ]\n",
      "Reset environment\n",
      "Episode reward: -713.69464\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0359225 4.0072474 4.0381675 2.061282  4.238174  4.0280256]\n",
      "Reset environment\n",
      "Episode reward: 2988.661\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0384226 4.0096726 4.040734  2.0641174 4.2404013 4.0305276]\n",
      "Reset environment\n",
      "Episode reward: 1822.6333\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.039907  4.0111837 4.0421977 2.0658143 4.241713  4.032015 ]\n",
      "Reset environment\n",
      "Episode reward: 2842.1865\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0423484 4.013669  4.044597  2.0685592 4.243871  4.0344577]\n",
      "Reset environment\n",
      "Episode reward: 2093.565\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0447316 4.0160666 4.0469675 2.0712693 4.2459435 4.036839 ]\n",
      "Reset environment\n",
      "Episode reward: 1502.138\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0459056 4.0172606 4.0481215 2.0726275 4.246968  4.0380125]\n",
      "Reset environment\n",
      "Episode reward: 2793.0142\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0483174 4.019689  4.0505147 2.0753307 4.249091  4.040425 ]\n",
      "Reset environment\n",
      "Episode reward: 812.3059\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0490975 4.020365  4.051401  2.0763996 4.2497797 4.041206 ]\n",
      "Reset environment\n",
      "Episode reward: 5947.8296\n",
      "Total Steps: 211\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.054517  4.025809  4.0568066 2.0823958 4.2546005 4.046625 ]\n",
      "Reset environment\n",
      "Episode reward: 4180.9336\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0588098 4.0300803 4.0611176 2.0872755 4.2583675 4.050917 ]\n",
      "Reset environment\n",
      "Episode reward: 3431.67\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.061747  4.0331287 4.063936  2.090601  4.2609587 4.0538535]\n",
      "Reset environment\n",
      "Episode reward: 2956.43\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.064302  4.0356994 4.066469  2.0934453 4.263228  4.0564075]\n",
      "Reset environment\n",
      "Episode reward: 3197.708\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.067071  4.038443  4.069262  2.0965633 4.2656603 4.0591745]\n",
      "Reset environment\n",
      "Episode reward: 2308.184\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0689907 4.0404024 4.071129  2.0987272 4.2673492 4.0610895]\n",
      "Reset environment\n",
      "Episode reward: 4070.4111\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.072489  4.043883  4.074643  2.1026459 4.270425  4.064587 ]\n",
      "Reset environment\n",
      "Episode reward: 3566.8743\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0756226 4.0470376 4.0777545 2.1060965 4.2732134 4.0677238]\n",
      "Reset environment\n",
      "Episode reward: 1281.1709\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0772367 4.0486593 4.079358  2.107925  4.274629  4.069339 ]\n",
      "Reset environment\n",
      "Episode reward: 4997.1436\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0817385 4.0532055 4.08382   2.1129131 4.278644  4.0738416]\n",
      "Reset environment\n",
      "Episode reward: 2098.173\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.08414   4.055623  4.086207  2.1156058 4.28076   4.076242 ]\n",
      "Reset environment\n",
      "Episode reward: 3139.4255\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0868692 4.05833   4.088957  2.1186557 4.2831655 4.0789695]\n",
      "Reset environment\n",
      "Episode reward: 503.8791\n",
      "Total Steps: 19\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.087097  4.058559  4.089183  2.1189759 4.2833433 4.079199 ]\n",
      "Reset environment\n",
      "Episode reward: 3253.1807\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.089899  4.0613317 4.0920143 2.1221294 4.285803  4.081999 ]\n",
      "Reset environment\n",
      "Episode reward: 1599.5862\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.091573  4.0628724 4.093809  2.1241796 4.287219  4.083674 ]\n",
      "Reset environment\n",
      "Episode reward: 6753.853\n",
      "Total Steps: 231\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.0977793 4.0690985 4.1000056 2.1309974 4.292783  4.089887 ]\n",
      "Reset environment\n",
      "Episode reward: 3643.0127\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1008563 4.0721107 4.1031446 2.1344357 4.2955236 4.0929623]\n",
      "Reset environment\n",
      "Episode reward: 2885.0066\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1033306 4.074544  4.1056523 2.1372066 4.2977095 4.0954337]\n",
      "Reset environment\n",
      "Episode reward: 1753.603\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.104723  4.0759554 4.1070247 2.1388173 4.298926  4.096825 ]\n",
      "Reset environment\n",
      "Episode reward: 5837.749\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1100087 4.0812445 4.11231   2.1446695 4.3036313 4.102111 ]\n",
      "Reset environment\n",
      "Episode reward: 2700.9915\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.112087  4.083414  4.1142993 2.1471353 4.3054047 4.104193 ]\n",
      "Reset environment\n",
      "Episode reward: 1142.6135\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1135507 4.0848837 4.1157556 2.1488733 4.306648  4.1056557]\n",
      "Reset environment\n",
      "Episode reward: 3316.727\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1164656 4.0878243 4.1186433 2.1521153 4.309235  4.10857  ]\n",
      "Reset environment\n",
      "Episode reward: 2613.5857\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1186533 4.0899706 4.120872  2.1545706 4.311183  4.110758 ]\n",
      "Reset environment\n",
      "Episode reward: 485.81586\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.118926  4.090026  4.121361  2.1552043 4.311338  4.111035 ]\n",
      "Reset environment\n",
      "Episode reward: 2098.1792\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1205606 4.091663  4.1229887 2.1570687 4.3127623 4.1126685]\n",
      "Reset environment\n",
      "Episode reward: 2380.7585\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1225133 4.0936856 4.124866  2.1592886 4.314486  4.114622 ]\n",
      "Reset environment\n",
      "Episode reward: 5085.522\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.127001  4.0981593 4.1293607 2.164251  4.318455  4.1191087]\n",
      "Reset environment\n",
      "Episode reward: 3674.1975\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.130717  4.101896  4.1330557 2.1684084 4.3217697 4.122822 ]\n",
      "Reset environment\n",
      "Episode reward: 5604.442\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.135771  4.106915  4.138136  2.1739776 4.3262787 4.127874 ]\n",
      "Reset environment\n",
      "Episode reward: 86.28635\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.135822  4.1067863 4.1383595 2.1741428 4.32635   4.1279287]\n",
      "Reset environment\n",
      "Episode reward: 1100.0336\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.136701  4.10779   4.1391125 2.17524   4.327191  4.1288047]\n",
      "Reset environment\n",
      "Episode reward: 3264.2214\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1395264 4.110641  4.1419067 2.1783822 4.3296914 4.1316276]\n",
      "Reset environment\n",
      "Episode reward: 2263.085\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.141321  4.112524  4.143613  2.180493  4.331224  4.1334243]\n",
      "Reset environment\n",
      "Episode reward: 3779.5059\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.145066  4.1162767 4.147344  2.184692  4.334556  4.1371675]\n",
      "Reset environment\n",
      "Episode reward: 2722.6863\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1473737 4.1185603 4.1496787 2.1872935 4.3365874 4.139476 ]\n",
      "Reset environment\n",
      "Episode reward: 1457.789\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1485085 4.1196895 4.15082   2.1885927 4.3375807 4.14061  ]\n",
      "Reset environment\n",
      "Episode reward: 2604.9695\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1507072 4.121851  4.153054  2.1910596 4.3395305 4.1428084]\n",
      "Reset environment\n",
      "Episode reward: 2497.4346\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.152738  4.123915  4.1550517 2.1933284 4.341338  4.144841 ]\n",
      "Reset environment\n",
      "Episode reward: 2784.8474\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1551156 4.126311  4.157414  2.1959925 4.3434367 4.147224 ]\n",
      "Reset environment\n",
      "Episode reward: 2517.0066\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.15717   4.128308  4.1595206 2.1983552 4.345248  4.14928  ]\n",
      "Reset environment\n",
      "Episode reward: 3483.4683\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.160169  4.1313286 4.1624994 2.2017257 4.347888  4.15228  ]\n",
      "Reset environment\n",
      "Episode reward: 3025.268\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.16272   4.1338224 4.1651073 2.204602  4.3501487 4.1548324]\n",
      "Reset environment\n",
      "Episode reward: 5266.6167\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.167458  4.13858   4.1698256 2.2097852 4.354386  4.159572 ]\n",
      "Reset environment\n",
      "Episode reward: 2251.664\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1692886 4.1404405 4.171619  2.2118359 4.356003  4.1614027]\n",
      "Reset environment\n",
      "Episode reward: 1770.5437\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.171103  4.1421313 4.173555  2.2140293 4.357574  4.163222 ]\n",
      "Reset environment\n",
      "Episode reward: 3662.7065\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1742635 4.1452475 4.176756  2.2175825 4.360351  4.1663804]\n",
      "Reset environment\n",
      "Episode reward: 2340.507\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1759534 4.1470513 4.1783285 2.2196772 4.361772  4.1680717]\n",
      "Reset environment\n",
      "Episode reward: 3056.4353\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.178571  4.14962   4.1809883 2.222593  4.364095  4.170688 ]\n",
      "Reset environment\n",
      "Episode reward: -247.19037\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.178307  4.149294  4.1807942 2.2223368 4.3638816 4.170427 ]\n",
      "Reset environment\n",
      "Episode reward: 2641.53\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1804414 4.15144   4.182908  2.2247617 4.3657465 4.1725593]\n",
      "Reset environment\n",
      "Episode reward: 2886.2295\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.182902  4.1538725 4.185392  2.2275136 4.3679137 4.175016 ]\n",
      "Reset environment\n",
      "Episode reward: 3043.925\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.185407  4.156389  4.187882  2.2303555 4.3701067 4.1775217]\n",
      "Reset environment\n",
      "Episode reward: 4565.446\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1893363 4.1603365 4.191788  2.23472   4.3735943 4.1814504]\n",
      "Reset environment\n",
      "Episode reward: 2545.5396\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1919155 4.1630583 4.1942296 2.2377357 4.3758397 4.1840334]\n",
      "Reset environment\n",
      "Episode reward: 3702.3513\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.1950116 4.1661234 4.1973586 2.241207  4.378565  4.1871295]\n",
      "Reset environment\n",
      "Episode reward: 5814.5654\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2002563 4.1713676 4.2026014 2.2469616 4.383225  4.192376 ]\n",
      "Reset environment\n",
      "Episode reward: 3339.8328\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2031345 4.174298  4.205422  2.2501607 4.385791  4.1952567]\n",
      "Reset environment\n",
      "Episode reward: 2855.6382\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2055635 4.176704  4.2078676 2.252876  4.3879347 4.197685 ]\n",
      "Reset environment\n",
      "Episode reward: -691.546\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.20482   4.175936  4.207151  2.2521753 4.387063  4.1969457]\n",
      "Reset environment\n",
      "Episode reward: 291.5776\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2049904 4.175945  4.207482  2.2526    4.3872185 4.197117 ]\n",
      "Reset environment\n",
      "Episode reward: 5548.4033\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.209935  4.1809196 4.212402  2.2580996 4.3916163 4.202063 ]\n",
      "Reset environment\n",
      "Episode reward: -574.1459\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2093835 4.1803355 4.2118826 2.2577806 4.3910284 4.201511 ]\n",
      "Reset environment\n",
      "Episode reward: 3389.5283\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2123237 4.183296  4.214796  2.2610314 4.3936367 4.2044516]\n",
      "Reset environment\n",
      "Episode reward: 3275.315\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2150393 4.186037  4.2174807 2.2640777 4.396029  4.2071643]\n",
      "Reset environment\n",
      "Episode reward: 174.77808\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2078433 4.1787753 4.2104244 2.248542  4.389697  4.199999 ]\n",
      "Reset environment\n",
      "Episode reward: 1309.9913\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.209484  4.1804075 4.2120686 2.2503881 4.391139  4.201638 ]\n",
      "Reset environment\n",
      "Episode reward: 4817.203\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.214362  4.1852584 4.2169857 2.2558148 4.395475  4.2065206]\n",
      "Reset environment\n",
      "Episode reward: 1977.4023\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2166233 4.18752   4.2192497 2.2583473 4.39747   4.2087827]\n",
      "Reset environment\n",
      "Episode reward: 2857.3071\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.218905  4.1897197 4.221605  2.2609754 4.39949   4.2110653]\n",
      "Reset environment\n",
      "Episode reward: 4636.897\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2235966 4.194368  4.226338  2.26622   4.4036417 4.215754 ]\n",
      "Reset environment\n",
      "Episode reward: 2439.715\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2255864 4.196422  4.228259  2.2684765 4.405352  4.217742 ]\n",
      "Reset environment\n",
      "Episode reward: 2728.8381\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.227879  4.1987553 4.230514  2.2710328 4.407378  4.220037 ]\n",
      "Reset environment\n",
      "Episode reward: 3097.1472\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2305155 4.201417  4.233121  2.273978  4.409717  4.2226725]\n",
      "Reset environment\n",
      "Episode reward: 2627.9714\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.232702  4.2035713 4.2353373 2.2764423 4.4116483 4.224858 ]\n",
      "Reset environment\n",
      "Episode reward: 335.1251\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2327623 4.2034445 4.2355785 2.2767136 4.4117136 4.224922 ]\n",
      "Reset environment\n",
      "Episode reward: 956.81946\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2334023 4.204081  4.2362204 2.2774978 4.412252  4.2255626]\n",
      "Reset environment\n",
      "Episode reward: 2985.3125\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2358603 4.206479  4.2387376 2.2802918 4.4144278 4.2280226]\n",
      "Reset environment\n",
      "Episode reward: 1829.133\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.237666  4.20813   4.24069   2.2825034 4.415981  4.229829 ]\n",
      "Reset environment\n",
      "Episode reward: 5380.909\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.243102  4.2135906 4.246112  2.28849   4.420848  4.2352724]\n",
      "Reset environment\n",
      "Episode reward: 3360.9812\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2458763 4.216385  4.248866  2.2915926 4.423302  4.238047 ]\n",
      "Reset environment\n",
      "Episode reward: 204.0043\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.246059  4.2167034 4.248917  2.2918878 4.4235024 4.23823  ]\n",
      "Reset environment\n",
      "Episode reward: 5947.856\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2513723 4.2219987 4.2542515 2.2977679 4.4282293 4.243545 ]\n",
      "Reset environment\n",
      "Episode reward: 2006.5471\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.253637  4.224266  4.2565103 2.3003259 4.430219  4.2458096]\n",
      "Reset environment\n",
      "Episode reward: 1980.0433\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2558584 4.2265    4.2587233 2.302839  4.432164  4.2480326]\n",
      "Reset environment\n",
      "Episode reward: 2602.9624\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.257993  4.228654  4.2608314 2.3052537 4.4340363 4.250163 ]\n",
      "Reset environment\n",
      "Episode reward: 4543.315\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.261999  4.2326946 4.2648067 2.3097084 4.437602  4.2541723]\n",
      "Reset environment\n",
      "Episode reward: 2333.7434\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.263848  4.2345376 4.2666583 2.311783  4.4392347 4.2560215]\n",
      "Reset environment\n",
      "Episode reward: 4359.7764\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.267665  4.2383804 4.2704477 2.3159919 4.4426355 4.2598352]\n",
      "Reset environment\n",
      "Episode reward: 135.43814\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.267822  4.238627  4.2705283 2.3161416 4.4428053 4.2599955]\n",
      "Reset environment\n",
      "Episode reward: 2605.3823\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2699695 4.2408037 4.2726355 2.318564  4.444695  4.2621384]\n",
      "Reset environment\n",
      "Episode reward: 2093.317\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2723193 4.2431545 4.2749877 2.3211827 4.44678   4.264489 ]\n",
      "Reset environment\n",
      "Episode reward: 1969.0148\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2738247 4.244725  4.27642   2.3229332 4.4480596 4.265994 ]\n",
      "Reset environment\n",
      "Episode reward: 3924.4385\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.277069  4.247939  4.2796965 2.3265758 4.4509034 4.2692375]\n",
      "Reset environment\n",
      "Episode reward: 3909.3901\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2804265 4.25127   4.2830815 2.3303342 4.453859  4.272595 ]\n",
      "Reset environment\n",
      "Episode reward: 1037.4758\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2817326 4.2525744 4.2843823 2.3319182 4.4549465 4.273899 ]\n",
      "Reset environment\n",
      "Episode reward: 4253.787\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2854385 4.2563033 4.28807   2.336033  4.458236  4.277604 ]\n",
      "Reset environment\n",
      "Episode reward: 3147.1345\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2881136 4.259013  4.2907095 2.3390012 4.46062   4.280279 ]\n",
      "Reset environment\n",
      "Episode reward: 2803.9048\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2903748 4.2613115 4.2929296 2.341551  4.4626164 4.2825413]\n",
      "Reset environment\n",
      "Episode reward: 3801.5374\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.293491  4.264359  4.296114  2.3450751 4.465372  4.285662 ]\n",
      "Reset environment\n",
      "Episode reward: 2358.5413\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.295431  4.266322  4.298029  2.3472679 4.467085  4.287601 ]\n",
      "Reset environment\n",
      "Episode reward: -296.20203\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.295079  4.2660832 4.2975717 2.3470578 4.4666924 4.2872505]\n",
      "Reset environment\n",
      "Episode reward: 3699.9927\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2982874 4.2692804 4.300793  2.35061   4.469544  4.2904596]\n",
      "Reset environment\n",
      "Episode reward: 1725.3104\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.300272  4.2712717 4.302773  2.3528554 4.4712787 4.2924447]\n",
      "Reset environment\n",
      "Episode reward: 922.4738\n",
      "Total Steps: 30\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.300888  4.271889  4.303387  2.3535829 4.47181   4.2930603]\n",
      "Reset environment\n",
      "Episode reward: -214.99359\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3005805 4.2717505 4.302924  2.3533516 4.471543  4.292754 ]\n",
      "Reset environment\n",
      "Episode reward: 1300.7291\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3021855 4.273353  4.304531  2.3551803 4.4729395 4.2943587]\n",
      "Reset environment\n",
      "Episode reward: -725.3509\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3013945 4.2724867 4.3038135 2.3543575 4.472244  4.2935696]\n",
      "Reset environment\n",
      "Episode reward: -1036.4609\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.2998614 4.2706637 4.302575  2.3530095 4.470732  4.292037 ]\n",
      "Reset environment\n",
      "Episode reward: 2727.2927\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.302124  4.2729406 4.3048177 2.3555522 4.4727254 4.2943   ]\n",
      "Reset environment\n",
      "Episode reward: 1850.1062\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.304218  4.275047  4.3068967 2.3579466 4.4745398 4.2963934]\n",
      "Reset environment\n",
      "Episode reward: 2611.2363\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3062887 4.2771616 4.3089123 2.3603094 4.476353  4.298463 ]\n",
      "Reset environment\n",
      "Episode reward: -1263.2296\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.304776  4.275924  4.307145  2.358989  4.4749117 4.2969546]\n",
      "Reset environment\n",
      "Episode reward: 1366.2166\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.30581   4.2769656 4.308166  2.360193  4.475809  4.2979856]\n",
      "Reset environment\n",
      "Episode reward: 4854.2324\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.309986  4.2811437 4.3123326 2.3648086 4.4795065 4.3021626]\n",
      "Reset environment\n",
      "Episode reward: -733.052\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.309054  4.280053  4.311558  2.3639886 4.4785633 4.3012323]\n",
      "Reset environment\n",
      "Episode reward: 4863.8247\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.313289  4.2842894 4.315798  2.368726  4.482314  4.3054667]\n",
      "Reset environment\n",
      "Episode reward: -26.078308\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3128443 4.283598  4.3155956 2.3685317 4.4818206 4.305025 ]\n",
      "Reset environment\n",
      "Episode reward: 1700.3799\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3148174 4.285573  4.317568  2.3707647 4.4835515 4.3069973]\n",
      "Reset environment\n",
      "Episode reward: 1296.4429\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.316422  4.2871747 4.319171  2.3725708 4.4849586 4.3085995]\n",
      "Reset environment\n",
      "Episode reward: -462.03568\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.315942 4.286852 4.318544 2.372108 4.48454  4.308122]\n",
      "Reset environment\n",
      "Episode reward: 3384.9167\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3188233 4.28976   4.321394  2.375283  4.487099  4.3110023]\n",
      "Reset environment\n",
      "Episode reward: 6622.6816\n",
      "Total Steps: 229\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3246055 4.2955127 4.3271956 2.3816988 4.492217  4.316789 ]\n",
      "Reset environment\n",
      "Episode reward: -107.80414\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.324409  4.2955    4.3268247 2.3816144 4.492045  4.3165956]\n",
      "Reset environment\n",
      "Episode reward: 2046.2477\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3260207 4.2971272 4.3284173 2.3834863 4.4934435 4.318206 ]\n",
      "Reset environment\n",
      "Episode reward: 2290.0537\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3276553 4.2988424 4.329967  2.3854325 4.4948354 4.319839 ]\n",
      "Reset environment\n",
      "Episode reward: 1906.4137\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3291645 4.3003726 4.331457  2.3871257 4.4961786 4.3213487]\n",
      "Reset environment\n",
      "Episode reward: 4211.843\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.332811  4.304044  4.3350835 2.39116   4.4994144 4.3249993]\n",
      "Reset environment\n",
      "Episode reward: 1385.415\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.334504  4.3057303 4.3367796 2.3930478 4.500911  4.326693 ]\n",
      "Reset environment\n",
      "Episode reward: 2558.8367\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3365927 4.307838  4.3388524 2.3954382 4.5027223 4.3287807]\n",
      "Reset environment\n",
      "Episode reward: 1275.0887\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.337837  4.3090067 4.3401766 2.3968427 4.5038924 4.330027 ]\n",
      "Reset environment\n",
      "Episode reward: 2746.2283\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.339614  4.310679  4.3420587 2.3990552 4.505401  4.3318086]\n",
      "Reset environment\n",
      "Episode reward: 4827.362\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.343712  4.3147683 4.346171  2.4035788 4.5090294 4.3359075]\n",
      "Reset environment\n",
      "Episode reward: 1975.0538\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3459177 4.3169794 4.3483696 2.406076  4.5109596 4.3381114]\n",
      "Reset environment\n",
      "Episode reward: 2320.1956\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3476415 4.318808  4.349986  2.4081006 4.5124917 4.3398337]\n",
      "Reset environment\n",
      "Episode reward: 1195.0013\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.34885   4.3199587 4.3512583 2.4095166 4.513565  4.3410416]\n",
      "Reset environment\n",
      "Episode reward: 4575.399\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.352609  4.3236794 4.35506   2.413761  4.516873  4.3448057]\n",
      "Reset environment\n",
      "Episode reward: 1967.2802\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.354168  4.325265  4.3565903 2.4155226 4.5182476 4.3463645]\n",
      "Reset environment\n",
      "Episode reward: 1947.555\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.355525  4.3267    4.3578672 2.4171412 4.5194297 4.347722 ]\n",
      "Reset environment\n",
      "Episode reward: 1387.083\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.357209  4.3283806 4.359553  2.4190392 4.5209093 4.3494053]\n",
      "Reset environment\n",
      "Episode reward: 942.9596\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3580627 4.3294106 4.36024   2.4202836 4.5215974 4.350261 ]\n",
      "Reset environment\n",
      "Episode reward: 5742.3403\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.36312   4.334492  4.365285  2.4258668 4.526119  4.3553257]\n",
      "Reset environment\n",
      "Episode reward: 3378.542\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3659496 4.3372693 4.3681545 2.4290514 4.5286155 4.3581495]\n",
      "Reset environment\n",
      "Episode reward: 4157.93\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.369417  4.3407583 4.371597  2.4329164 4.5316873 4.3616166]\n",
      "Reset environment\n",
      "Episode reward: 1372.4548\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3710923 4.3424363 4.373268  2.434793  4.533165  4.3632913]\n",
      "Reset environment\n",
      "Episode reward: 2545.453\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.373034  4.3444476 4.375129  2.4370427 4.5348134 4.3652315]\n",
      "Reset environment\n",
      "Episode reward: 6111.605\n",
      "Total Steps: 233\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.379099  4.3505354 4.3811855 2.4437184 4.5402308 4.3713045]\n",
      "Reset environment\n",
      "Episode reward: 2084.0789\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.380777  4.3522325 4.382846  2.4456182 4.541712  4.3729835]\n",
      "Reset environment\n",
      "Episode reward: 2511.9487\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.382752  4.3542085 4.3848166 2.447816  4.543453  4.3749585]\n",
      "Reset environment\n",
      "Episode reward: 2989.2588\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.385254  4.35674   4.3872924 2.450614  4.5456605 4.3774605]\n",
      "Reset environment\n",
      "Episode reward: -125.55151\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3849916 4.3565917 4.3869214 2.4505713 4.545381  4.3772   ]\n",
      "Reset environment\n",
      "Episode reward: 2669.3892\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3876047 4.359068  4.3896637 2.453658  4.5476627 4.379815 ]\n",
      "Reset environment\n",
      "Episode reward: 2969.497\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.38998   4.3614163 4.3920603 2.4563236 4.5497594 4.382188 ]\n",
      "Reset environment\n",
      "Episode reward: 2448.891\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.391951  4.363416  4.3939962 2.4585419 4.551503  4.384158 ]\n",
      "Reset environment\n",
      "Episode reward: 1755.457\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.393271  4.3647027 4.395347  2.460063  4.5526643 4.385476 ]\n",
      "Reset environment\n",
      "Episode reward: 2573.2144\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.395277  4.3666353 4.397417  2.462378  4.5544343 4.38748  ]\n",
      "Reset environment\n",
      "Episode reward: 2844.8896\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.3976355 4.3690114 4.399757  2.464995  4.5565214 4.3898377]\n",
      "Reset environment\n",
      "Episode reward: 5388.296\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4022517 4.373606  4.4043922 2.4701095 4.5606146 4.394451 ]\n",
      "Reset environment\n",
      "Episode reward: 2394.938\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4041595 4.375458  4.40635   2.4722524 4.5623116 4.396358 ]\n",
      "Reset environment\n",
      "Episode reward: 3312.426\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.406905  4.378154  4.4091406 2.4753287 4.5647717 4.399103 ]\n",
      "Reset environment\n",
      "Episode reward: 5579.374\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4116926 4.382895  4.4139776 2.4806342 4.5690293 4.4038906]\n",
      "Reset environment\n",
      "Episode reward: 2931.6265\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4141316 4.385383  4.4163656 2.4833553 4.5712    4.4063315]\n",
      "Reset environment\n",
      "Episode reward: 4616.9424\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4180036 4.3892727 4.4202104 2.4876478 4.5746355 4.4102035]\n",
      "Reset environment\n",
      "Episode reward: 4054.7883\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.421469  4.392749  4.423664  2.4914854 4.577706  4.413671 ]\n",
      "Reset environment\n",
      "Episode reward: 2288.2388\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4233117 4.394596  4.4254985 2.4935703 4.5793233 4.415513 ]\n",
      "Reset environment\n",
      "Episode reward: 1344.3496\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.424933  4.3962097 4.4271226 2.4954    4.580742  4.417131 ]\n",
      "Reset environment\n",
      "Episode reward: 3831.9583\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4281693 4.3995275 4.430274  2.4989934 4.5836153 4.42037  ]\n",
      "Reset environment\n",
      "Episode reward: 2969.3438\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4306054 4.4019117 4.4327607 2.5017312 4.5857773 4.422805 ]\n",
      "Reset environment\n",
      "Episode reward: 3700.6194\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.43372   4.4049697 4.4359226 2.5051937 4.5885425 4.4259167]\n",
      "Reset environment\n",
      "Episode reward: 894.08044\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4342623 4.4055166 4.4364595 2.5058973 4.5889773 4.4264584]\n",
      "Reset environment\n",
      "Episode reward: 3851.093\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4375196 4.408727  4.439755  2.5095148 4.591858  4.4297113]\n",
      "Reset environment\n",
      "Episode reward: 2389.4614\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4306307 4.401683  4.4330773 2.4984376 4.5860977 4.42283  ]\n",
      "Reset environment\n",
      "Episode reward: 2878.8276\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4327703 4.40393   4.435105  2.5009632 4.5879345 4.4249716]\n",
      "Reset environment\n",
      "Episode reward: -292.27765\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.432455  4.4035378 4.434868  2.5006244 4.587674  4.424659 ]\n",
      "Reset environment\n",
      "Episode reward: 3009.588\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.434954  4.4060135 4.437391  2.503448  4.589879  4.427159 ]\n",
      "Reset environment\n",
      "Episode reward: 3792.9185\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4380326 4.4090185 4.4405427 2.5069325 4.5926085 4.430236 ]\n",
      "Reset environment\n",
      "Episode reward: 1315.9153\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4396267 4.410614  4.4421315 2.5087583 4.593994  4.431829 ]\n",
      "Reset environment\n",
      "Episode reward: 3848.3367\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4427757 4.413751  4.4452896 2.5122838 4.59676   4.4349794]\n",
      "Reset environment\n",
      "Episode reward: 2374.5552\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.444614  4.41561   4.4471083 2.5143487 4.598388  4.4368186]\n",
      "Reset environment\n",
      "Episode reward: 4319.461\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.448304  4.4193115 4.4507957 2.518458  4.601664  4.440514 ]\n",
      "Reset environment\n",
      "Episode reward: 2036.5194\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4499235 4.4209476 4.4524016 2.5203013 4.6030984 4.442135 ]\n",
      "Reset environment\n",
      "Episode reward: 2271.9165\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4517303 4.422788  4.4541693 2.522338  4.604688  4.4439406]\n",
      "Reset environment\n",
      "Episode reward: 1233.8502\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4532313 4.424295  4.4556623 2.524051  4.605992  4.4454417]\n",
      "Reset environment\n",
      "Episode reward: 2170.6013\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4548235 4.4259677 4.4571724 2.52591   4.607385  4.447034 ]\n",
      "Reset environment\n",
      "Episode reward: 2343.3967\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4573636 4.428522  4.459696  2.5287557 4.609629  4.4495745]\n",
      "Reset environment\n",
      "Episode reward: 3466.3694\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.460693  4.4318056 4.4630575 2.532468  4.61263   4.4529033]\n",
      "Reset environment\n",
      "Episode reward: 2093.658\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4623885 4.433515  4.4647417 2.5343728 4.614131  4.4546013]\n",
      "Reset environment\n",
      "Episode reward: 2625.353\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.46438   4.4355874 4.4666452 2.5366912 4.6158366 4.456592 ]\n",
      "Reset environment\n",
      "Episode reward: 1495.3904\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4654975 4.436719  4.467749  2.5379815 4.616816  4.4577117]\n",
      "Reset environment\n",
      "Episode reward: 1981.0748\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.467058  4.4382806 4.469307  2.5397415 4.6181836 4.4592724]\n",
      "Reset environment\n",
      "Episode reward: 3984.925\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4703608 4.4415894 4.472605  2.543395  4.6211214 4.462578 ]\n",
      "Reset environment\n",
      "Episode reward: 5608.121\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4752746 4.446525  4.4775014 2.5487666 4.6255307 4.4674897]\n",
      "Reset environment\n",
      "Episode reward: 3170.3105\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4779005 4.4491787 4.4800973 2.5517251 4.6278358 4.4701166]\n",
      "Reset environment\n",
      "Episode reward: 2334.996\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4797926 4.451034  4.4820175 2.5538464 4.6295047 4.4720025]\n",
      "Reset environment\n",
      "Episode reward: 3403.983\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4825115 4.453734  4.4847536 2.5569065 4.6318946 4.4747233]\n",
      "Reset environment\n",
      "Episode reward: 5520.6616\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.487952  4.4591794 4.4901905 2.562909  4.636741  4.480164 ]\n",
      "Reset environment\n",
      "Episode reward: 1500.1964\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4890323 4.460219  4.4913087 2.564168  4.637683  4.481241 ]\n",
      "Reset environment\n",
      "Episode reward: 231.8956\n",
      "Total Steps: 5\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4890356 4.460223  4.4913116 2.5641952 4.637679  4.4812446]\n",
      "Reset environment\n",
      "Episode reward: 991.12616\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4902606 4.461461  4.4925222 2.5656664 4.6387053 4.482468 ]\n",
      "Reset environment\n",
      "Episode reward: 1295.0045\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4918303 4.463028  4.4940915 2.567444  4.6400757 4.484037 ]\n",
      "Reset environment\n",
      "Episode reward: 4686.2983\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.488557  4.4596977 4.4909034 2.5570488 4.6371436 4.4807534]\n",
      "Reset environment\n",
      "Episode reward: 5185.6587\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4929323 4.4640775 4.4952755 2.5618756 4.6410084 4.485132 ]\n",
      "Reset environment\n",
      "Episode reward: 2439.2986\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.494886  4.4660907 4.4971595 2.5640795 4.6426954 4.4870863]\n",
      "Reset environment\n",
      "Episode reward: 2692.818\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.497089  4.468313  4.499345  2.5665343 4.6446424 4.489289 ]\n",
      "Reset environment\n",
      "Episode reward: 1317.511\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.4986777 4.4698987 4.5009375 2.56835   4.646035  4.490877 ]\n",
      "Reset environment\n",
      "Episode reward: 4969.89\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5029445 4.4741654 4.505211  2.5730658 4.649823  4.4951434]\n",
      "Reset environment\n",
      "Episode reward: 4414.061\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5066614 4.4779396 4.5088654 2.577194  4.653136  4.4988623]\n",
      "Reset environment\n",
      "Episode reward: 4725.831\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5105762 4.481838  4.512797  2.5815375 4.6565957 4.50278  ]\n",
      "Reset environment\n",
      "Episode reward: 5628.9194\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5153165 4.4865737 4.5175476 2.586774  4.660805  4.5075274]\n",
      "Reset environment\n",
      "Episode reward: 177.92477\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.515446  4.4866242 4.5177636 2.5869172 4.6609597 4.5076604]\n",
      "Reset environment\n",
      "Episode reward: 2219.3599\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5169616 4.488242  4.519176  2.5887597 4.6622744 4.5091767]\n",
      "Reset environment\n",
      "Episode reward: 4035.7534\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.520346  4.491645  4.5225363 2.5925317 4.6652613 4.512559 ]\n",
      "Reset environment\n",
      "Episode reward: 5103.9565\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.524709  4.496043  4.526873  2.5973532 4.6691365 4.51692  ]\n",
      "Reset environment\n",
      "Episode reward: 3774.062\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.52786   4.499221  4.5299873 2.6008573 4.6719084 4.520072 ]\n",
      "Reset environment\n",
      "Episode reward: 5468.5166\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5325565 4.503884  4.534717  2.6060631 4.676084  4.524763 ]\n",
      "Reset environment\n",
      "Episode reward: 127.80307\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5325985 4.5040264 4.5346675 2.6061392 4.6761284 4.524814 ]\n",
      "Reset environment\n",
      "Episode reward: 3625.7852\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.535626  4.507057  4.537678  2.6094708 4.6788135 4.5278387]\n",
      "Reset environment\n",
      "Episode reward: 4835.954\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.539751  4.5111623 4.5418305 2.61403   4.6824765 4.5319633]\n",
      "Reset environment\n",
      "Episode reward: 1294.1671\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.541306  4.5127096 4.5433865 2.6157985 4.6838307 4.5335145]\n",
      "Reset environment\n",
      "Episode reward: 3142.855\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5438895 4.515257  4.545998  2.6186867 4.686108  4.5360985]\n",
      "Reset environment\n",
      "Episode reward: 2137.1155\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.54556   4.516889  4.5477076 2.6205802 4.6875763 4.5377674]\n",
      "Reset environment\n",
      "Episode reward: 2555.965\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5476084 4.5189004 4.549799  2.6228783 4.6893973 4.539816 ]\n",
      "Reset environment\n",
      "Episode reward: 1000.2333\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.548506  4.519908  4.5505924 2.6238847 4.690311  4.540719 ]\n",
      "Reset environment\n",
      "Episode reward: 2427.8022\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.550465  4.521876  4.5525446 2.6260667 4.692044  4.542681 ]\n",
      "Reset environment\n",
      "Episode reward: 4096.3486\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.55391   4.5253444 4.5559645 2.6298943 4.6950994 4.5461273]\n",
      "Reset environment\n",
      "Episode reward: 2050.1987\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.556126  4.5275517 4.5581875 2.6323776 4.6970406 4.548345 ]\n",
      "Reset environment\n",
      "Episode reward: 4474.6978\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.559783 4.531221 4.56182  2.636454 4.70028  4.551997]\n",
      "Reset environment\n",
      "Episode reward: 2851.272\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5620704 4.533554  4.5640626 2.639039  4.7022934 4.5542865]\n",
      "Reset environment\n",
      "Episode reward: 1349.5068\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5636797 4.5351653 4.5656652 2.640846  4.7037106 4.5558963]\n",
      "Reset environment\n",
      "Episode reward: 1899.0754\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5651393 4.5366106 4.567141  2.642523  4.70498   4.5573554]\n",
      "Reset environment\n",
      "Episode reward: 3884.3945\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5684323 4.53991   4.5704336 2.6461651 4.707904  4.5606475]\n",
      "Reset environment\n",
      "Episode reward: 2579.0469\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.570462  4.5419827 4.5724144 2.6484585 4.7096796 4.5626755]\n",
      "Reset environment\n",
      "Episode reward: 2113.6633\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5721064 4.5436516 4.574028  2.6502979 4.7111306 4.5643187]\n",
      "Reset environment\n",
      "Episode reward: 2984.8208\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.574506  4.5459948 4.576477  2.6529799 4.713262  4.566715 ]\n",
      "Reset environment\n",
      "Episode reward: 4084.6208\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5779386 4.549372  4.5799413 2.6567845 4.7163057 4.5701394]\n",
      "Reset environment\n",
      "Episode reward: 3525.288\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.580788  4.5522203 4.582786  2.659932  4.718825  4.5729823]\n",
      "Reset environment\n",
      "Episode reward: 3411.735\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.583515  4.554901  4.5855393 2.663013  4.7212033 4.575701 ]\n",
      "Reset environment\n",
      "Episode reward: 4642.487\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5874505 4.5588446 4.5894656 2.667375  4.724672  4.5796328]\n",
      "Reset environment\n",
      "Episode reward: 5771.0737\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5923934 4.5638123 4.5943937 2.672835  4.7290897 4.5845814]\n",
      "Reset environment\n",
      "Episode reward: 3429.074\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5952315 4.5666842 4.5972095 2.6760013 4.731598  4.5874214]\n",
      "Reset environment\n",
      "Episode reward: 3543.5972\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5981865 4.569651  4.6001334 2.6792653 4.7342114 4.590371 ]\n",
      "Reset environment\n",
      "Episode reward: 108.05481\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.5983744 4.569727  4.600425  2.679716  4.7343116 4.5905595]\n",
      "Reset environment\n",
      "Episode reward: 591.90564\n",
      "Total Steps: 23\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.598654  4.570007  4.600702  2.6800985 4.734535  4.5908384]\n",
      "Reset environment\n",
      "Episode reward: 3541.021\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.601465  4.5727973 4.603538  2.6832716 4.7370067 4.593652 ]\n",
      "Reset environment\n",
      "Episode reward: 2142.7163\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6030746 4.574347  4.6052003 2.685131  4.738426  4.595261 ]\n",
      "Reset environment\n",
      "Episode reward: 5390.9106\n",
      "Total Steps: 217\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.608247  4.5795193 4.610373  2.690816  4.7430124 4.6004314]\n",
      "Reset environment\n",
      "Episode reward: 4218.8164\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.611798  4.583047  4.6139464 2.6947424 4.7461576 4.6039815]\n",
      "Reset environment\n",
      "Episode reward: 1769.038\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.613231  4.5846133 4.6152573 2.696477  4.747433  4.605419 ]\n",
      "Reset environment\n",
      "Episode reward: 2330.6685\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6150894 4.5864835 4.6170945 2.6985512 4.7490654 4.607276 ]\n",
      "Reset environment\n",
      "Episode reward: 1040.0537\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.61578  4.587177 4.617783 2.699386 4.749648 4.607966]\n",
      "Reset environment\n",
      "Episode reward: 1793.5802\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.617153  4.5885477 4.619157  2.700928  4.7508516 4.609338 ]\n",
      "Reset environment\n",
      "Episode reward: 2429.571\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.619033  4.590449  4.62101   2.7030854 4.752484  4.6112146]\n",
      "Reset environment\n",
      "Episode reward: 6280.8706\n",
      "Total Steps: 221\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.624327  4.5957475 4.6263185 2.7089264 4.757191  4.616515 ]\n",
      "Reset environment\n",
      "Episode reward: 4042.981\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6277175 4.5991244 4.6297245 2.7126763 4.7601967 4.6199055]\n",
      "Reset environment\n",
      "Episode reward: 1476.8918\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6288166 4.600226  4.63082   2.7139316 4.761162  4.6210036]\n",
      "Reset environment\n",
      "Episode reward: 4901.546\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6328516 4.604257  4.6348577 2.718434  4.7647157 4.6250434]\n",
      "Reset environment\n",
      "Episode reward: 4166.8804\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6362333 4.607631  4.6382422 2.72217   4.7677093 4.628426 ]\n",
      "Reset environment\n",
      "Episode reward: 5058.674\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.640574  4.611941  4.6426044 2.726949  4.771582  4.6327634]\n",
      "Reset environment\n",
      "Episode reward: 2934.5454\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.642852  4.614225  4.6448703 2.7295046 4.7735868 4.635041 ]\n",
      "Reset environment\n",
      "Episode reward: 4441.599\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.646571  4.6179023 4.648627  2.7336562 4.776863  4.638758 ]\n",
      "Reset environment\n",
      "Episode reward: 5758.2983\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.651458  4.6227803 4.653531  2.7390618 4.7811947 4.643649 ]\n",
      "Reset environment\n",
      "Episode reward: 1246.0896\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6529427 4.624265  4.6550174 2.7407637 4.7824802 4.645134 ]\n",
      "Reset environment\n",
      "Episode reward: 1884.4979\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.654371  4.6257186 4.656424  2.742423  4.783733  4.646566 ]\n",
      "Reset environment\n",
      "Episode reward: 334.11328\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.654354  4.62549   4.6566143 2.7427387 4.7836394 4.64655  ]\n",
      "Reset environment\n",
      "Episode reward: 2195.3684\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6560225 4.6271977 4.658242  2.7446465 4.7851005 4.6482186]\n",
      "Reset environment\n",
      "Episode reward: 1403.7816\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.657299  4.628641  4.659353  2.7463248 4.7861915 4.6494985]\n",
      "Reset environment\n",
      "Episode reward: 984.13416\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.658028  4.6295166 4.6599426 2.7472875 4.786882  4.6502314]\n",
      "Reset environment\n",
      "Episode reward: 2948.174\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6604347 4.631939  4.6623363 2.7499585 4.7890277 4.6526413]\n",
      "Reset environment\n",
      "Episode reward: 3918.3628\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.663696  4.635227  4.66557   2.7535374 4.7919292 4.655903 ]\n",
      "Reset environment\n",
      "Episode reward: 524.0268\n",
      "Total Steps: 18\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.663925  4.6354585 4.665796  2.7538483 4.792113  4.6561317]\n",
      "Reset environment\n",
      "Episode reward: 2611.8843\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6659875 4.6374984 4.667881  2.7561946 4.7939134 4.6581945]\n",
      "Reset environment\n",
      "Episode reward: 3367.2446\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.668745  4.640237  4.6706514 2.759277  4.7963405 4.660946 ]\n",
      "Reset environment\n",
      "Episode reward: 3449.387\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6715665 4.6430135 4.673509  2.7624202 4.798836  4.6637635]\n",
      "Reset environment\n",
      "Episode reward: 3997.7117\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6748004 4.6462364 4.676746  2.7659993 4.8017015 4.6670012]\n",
      "Reset environment\n",
      "Episode reward: 1180.1797\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6762004 4.6476383 4.6781445 2.7676122 4.802905  4.6684003]\n",
      "Reset environment\n",
      "Episode reward: 3614.0522\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6791563 4.650626  4.68107   2.7709165 4.805508  4.671354 ]\n",
      "Reset environment\n",
      "Episode reward: 1128.0774\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.680498  4.651964  4.682414  2.7724915 4.8066406 4.672695 ]\n",
      "Reset environment\n",
      "Episode reward: 2698.5244\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.682635  4.6540756 4.684574  2.7749321 4.808508  4.6748323]\n",
      "Reset environment\n",
      "Episode reward: 1427.816\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6836767 4.655103  4.685631  2.7761235 4.809422  4.675873 ]\n",
      "Reset environment\n",
      "Episode reward: 6320.743\n",
      "Total Steps: 221\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.688948  4.66035   4.690925  2.782006  4.8140903 4.6811514]\n",
      "Reset environment\n",
      "Episode reward: 3545.4138\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.691842  4.663258  4.693795  2.785214  4.8166423 4.6840434]\n",
      "Reset environment\n",
      "Episode reward: 1922.7904\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6933312 4.6647606 4.6952643 2.7869084 4.817953  4.685529 ]\n",
      "Reset environment\n",
      "Episode reward: 2211.2847\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.695068  4.6665087 4.6969852 2.788879  4.8194904 4.687264 ]\n",
      "Reset environment\n",
      "Episode reward: 1449.8042\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.6961303 4.667582  4.6980324 2.7900803 4.820434  4.688327 ]\n",
      "Reset environment\n",
      "Episode reward: 2145.1235\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.697789  4.6692476 4.699687  2.791969  4.8218923 4.689988 ]\n",
      "Reset environment\n",
      "Episode reward: 2902.3914\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7000594 4.671474  4.701999  2.794562  4.8238745 4.6922574]\n",
      "Reset environment\n",
      "Episode reward: 3704.45\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7030163 4.674426  4.7049537 2.7978773 4.826477  4.6952147]\n",
      "Reset environment\n",
      "Episode reward: 2292.0679\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7047887 4.676233  4.7066913 2.7998855 4.8280387 4.696988 ]\n",
      "Reset environment\n",
      "Episode reward: 2628.989\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.706849  4.678247  4.7088003 2.802218  4.829864  4.69905  ]\n",
      "Reset environment\n",
      "Episode reward: 3242.0664\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7093344 4.680714  4.7113056 2.8050504 4.832035  4.701534 ]\n",
      "Reset environment\n",
      "Episode reward: 1259.2324\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.710823  4.682203  4.7127934 2.8067384 4.8333287 4.7030225]\n",
      "Reset environment\n",
      "Episode reward: 4839.806\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.714876  4.6862445 4.7168665 2.8112376 4.8369093 4.707078 ]\n",
      "Reset environment\n",
      "Episode reward: 2973.4932\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7171884 4.688481  4.7192426 2.8138509 4.8389726 4.7093863]\n",
      "Reset environment\n",
      "Episode reward: -56.025513\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7169704 4.6884236 4.718872  2.8137207 4.838761  4.709172 ]\n",
      "Reset environment\n",
      "Episode reward: 3489.4285\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.719787 4.691268 4.721656 2.816869 4.841229 4.711988]\n",
      "Reset environment\n",
      "Episode reward: 5232.674\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7241063 4.6955757 4.725976  2.8216538 4.8450365 4.716309 ]\n",
      "Reset environment\n",
      "Episode reward: 1772.1908\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7254314 4.696915  4.727282  2.8231626 4.8462043 4.7176323]\n",
      "Reset environment\n",
      "Episode reward: 2142.9297\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7266874 4.698073  4.728626  2.8247902 4.847274  4.718889 ]\n",
      "Reset environment\n",
      "Episode reward: 2761.0781\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.728842  4.700192  4.7308106 2.8272574 4.8491488 4.721045 ]\n",
      "Reset environment\n",
      "Episode reward: 3788.3748\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.731963  4.7033377 4.7339005 2.8307152 4.851906  4.7241626]\n",
      "Reset environment\n",
      "Episode reward: 2517.8123\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.73385   4.7051625 4.7358384 2.832879  4.8535686 4.726049 ]\n",
      "Reset environment\n",
      "Episode reward: 1203.5042\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7346745 4.7059855 4.7366633 2.833844  4.8542757 4.7268734]\n",
      "Reset environment\n",
      "Episode reward: 2358.2861\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.737149  4.7084627 4.7391315 2.836603  4.8564615 4.7293463]\n",
      "Reset environment\n",
      "Episode reward: 2670.4424\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.739258  4.7105646 4.741254  2.8389575 4.8583302 4.7314568]\n",
      "Reset environment\n",
      "Episode reward: 376.074\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7393937 4.710596  4.7414885 2.839236  4.858494  4.731595 ]\n",
      "Reset environment\n",
      "Episode reward: 2287.063\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7410755 4.712225  4.743224  2.8411887 4.8599677 4.7332764]\n",
      "Reset environment\n",
      "Episode reward: 4007.8872\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7442575 4.715382  4.7464266 2.8447587 4.8627644 4.73646  ]\n",
      "Reset environment\n",
      "Episode reward: 2481.8406\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7462063 4.71732   4.7483726 2.846947  4.864466  4.7384033]\n",
      "Reset environment\n",
      "Episode reward: 2174.4873\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.748512  4.7196207 4.7506747 2.849523  4.8664985 4.7407055]\n",
      "Reset environment\n",
      "Episode reward: 3554.7148\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.751394  4.722458  4.7536006 2.8527255 4.8690553 4.7435856]\n",
      "Reset environment\n",
      "Episode reward: 3833.8228\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7545495 4.725579  4.756787  2.8562217 4.871853  4.74674  ]\n",
      "Reset environment\n",
      "Episode reward: 2060.918\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7567787 4.727831  4.758993  2.8587248 4.8738127 4.7489686]\n",
      "Reset environment\n",
      "Episode reward: 502.78668\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.757359  4.728608  4.7593856 2.8595984 4.874292  4.7495565]\n",
      "Reset environment\n",
      "Episode reward: 2377.6787\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7591367 4.7304    4.7611475 2.861591  4.875863  4.751334 ]\n",
      "Reset environment\n",
      "Episode reward: 2689.1794\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.761187  4.7325344 4.763106  2.8639417 4.877639  4.753388 ]\n",
      "Reset environment\n",
      "Episode reward: 4180.3193\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7645674 4.7359066 4.76648   2.8676915 4.8806148 4.756764 ]\n",
      "Reset environment\n",
      "Episode reward: -105.28\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.764099  4.7355857 4.765877  2.8673835 4.8801966 4.7563   ]\n",
      "Reset environment\n",
      "Episode reward: 2011.0437\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.765615  4.737103  4.7673965 2.8691194 4.8815107 4.7578173]\n",
      "Reset environment\n",
      "Episode reward: 2455.3877\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.76796   4.739509  4.769677  2.8716974 4.8836403 4.760163 ]\n",
      "Reset environment\n",
      "Episode reward: 4439.6562\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7716403 4.743171  4.773363  2.8757744 4.886895  4.763841 ]\n",
      "Reset environment\n",
      "Episode reward: 2573.7263\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.773678  4.745251  4.7753534 2.8780549 4.888704  4.765881 ]\n",
      "Reset environment\n",
      "Episode reward: 2976.7046\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7759337 4.747433  4.7776723 2.8806403 4.8907    4.768136 ]\n",
      "Reset environment\n",
      "Episode reward: 3026.9897\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.778362  4.7498784 4.780075  2.883328  4.892851  4.7705636]\n",
      "Reset environment\n",
      "Episode reward: 2454.449\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.780172  4.751771  4.7818007 2.8854406 4.8944097 4.772371 ]\n",
      "Reset environment\n",
      "Episode reward: 1778.4115\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7814302 4.7529883 4.783103  2.8869138 4.8955116 4.77363  ]\n",
      "Reset environment\n",
      "Episode reward: 2109.163\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7830753 4.7546268 4.7847524 2.8887494 4.896962  4.775273 ]\n",
      "Reset environment\n",
      "Episode reward: 2446.571\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.784919  4.7564583 4.786602  2.8908148 4.898587  4.777113 ]\n",
      "Reset environment\n",
      "Episode reward: 5427.1475\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.789448  4.7609744 4.791151  2.8957837 4.902617  4.7816434]\n",
      "Reset environment\n",
      "Episode reward: 4046.076\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.7926393 4.764047  4.7944493 2.8993876 4.905454  4.7848353]\n",
      "Reset environment\n",
      "Episode reward: 3295.7312\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.795162  4.766585  4.796954  2.9022248 4.9076843 4.787359 ]\n",
      "Reset environment\n",
      "Episode reward: 5808.7207\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8000393 4.771442  4.801857  2.9075868 4.912043  4.792235 ]\n",
      "Reset environment\n",
      "Episode reward: 701.14136\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8005066 4.7717605 4.802469  2.9083362 4.9124284 4.792707 ]\n",
      "Reset environment\n",
      "Episode reward: 2594.9521\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8024464 4.7736864 4.804421  2.910521  4.914134  4.7946444]\n",
      "Reset environment\n",
      "Episode reward: 244.12213\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.802491  4.77392   4.8042927 2.9108582 4.914123  4.794695 ]\n",
      "Reset environment\n",
      "Episode reward: 6692.0522\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.800328  4.7719264 4.80199   2.9066966 4.9118977 4.792533 ]\n",
      "Reset environment\n",
      "Episode reward: 3311.8708\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8028526 4.774347  4.8046093 2.909588  4.914135  4.7950525]\n",
      "Reset environment\n",
      "Episode reward: 3259.0151\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8053446 4.776805  4.8071337 2.9123855 4.9163213 4.797542 ]\n",
      "Reset environment\n",
      "Episode reward: 2243.751\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8069577 4.7783947 4.808771  2.91422   4.917734  4.799154 ]\n",
      "Reset environment\n",
      "Episode reward: 1993.2076\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8090577 4.7804837 4.810882  2.9165983 4.9195676 4.801252 ]\n",
      "Reset environment\n",
      "Episode reward: 3169.9185\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.811575  4.782953  4.8134437 2.9194148 4.9217935 4.803767 ]\n",
      "Reset environment\n",
      "Episode reward: 3291.0645\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8142343 4.78558   4.816132  2.922359  4.9241657 4.8064265]\n",
      "Reset environment\n",
      "Episode reward: 1521.7485\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8153353 4.7867002 4.817215  2.92361   4.925143  4.807529 ]\n",
      "Reset environment\n",
      "Episode reward: 1291.3481\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8168344 4.7882056 4.8187127 2.9253027 4.926458  4.809028 ]\n",
      "Reset environment\n",
      "Episode reward: 3895.0776\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.820024  4.7914224 4.8218746 2.9288566 4.929281  4.812218 ]\n",
      "Reset environment\n",
      "Episode reward: 4189.847\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.823383  4.794774  4.8252378 2.9325883 4.932246  4.815574 ]\n",
      "Reset environment\n",
      "Episode reward: 3097.4575\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.825757  4.7971654 4.827584  2.9352627 4.934339  4.8179445]\n",
      "Reset environment\n",
      "Episode reward: 2315.5305\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.827538  4.798921  4.829383  2.9372864 4.9359007 4.819722 ]\n",
      "Reset environment\n",
      "Episode reward: 1803.3048\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8288636 4.800274  4.83068   2.9387965 4.9370685 4.821049 ]\n",
      "Reset environment\n",
      "Episode reward: 2672.8738\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.830823  4.8022695 4.8326015 2.941046  4.93878   4.823011 ]\n",
      "Reset environment\n",
      "Episode reward: 2549.7598\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8327656 4.8042836 4.834465  2.9432456 4.9404664 4.824953 ]\n",
      "Reset environment\n",
      "Episode reward: 2770.9304\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8348126 4.806317  4.8365245 2.945586  4.9422336 4.827    ]\n",
      "Reset environment\n",
      "Episode reward: 2733.13\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8369937 4.808512  4.8386827 2.9480102 4.9441695 4.8291802]\n",
      "Reset environment\n",
      "Episode reward: 3725.8088\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8400393 4.8115706 4.8417068 2.951355  4.94687   4.8322253]\n",
      "Reset environment\n",
      "Episode reward: 5548.4976\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.844677  4.8162317 4.8463264 2.9564703 4.9510074 4.8368673]\n",
      "Reset environment\n",
      "Episode reward: 4326.186\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8482375 4.8197784 4.8498974 2.960387  4.954164  4.8404245]\n",
      "Reset environment\n",
      "Episode reward: 2021.9077\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8500834 4.821567  4.851798  2.96247   4.9558563 4.842268 ]\n",
      "Reset environment\n",
      "Episode reward: 2505.4084\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.85203   4.823501  4.853755  2.9646544 4.957571  4.844212 ]\n",
      "Reset environment\n",
      "Episode reward: 3438.1597\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.854804  4.8262973 4.856507  2.9677303 4.9600263 4.8469887]\n",
      "Reset environment\n",
      "Episode reward: 1314.2124\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8563194 4.8278227 4.8580184 2.9694514 4.9613514 4.8485065]\n",
      "Reset environment\n",
      "Episode reward: 3295.2498\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.858954  4.8304205 4.8606877 2.9723835 4.9636874 4.851136 ]\n",
      "Reset environment\n",
      "Episode reward: 2757.4778\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8611274 4.8325534 4.862894  2.974801  4.965613  4.853309 ]\n",
      "Reset environment\n",
      "Episode reward: 1280.7771\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8626094 4.8340235 4.8643827 2.9764905 4.966901  4.8547926]\n",
      "Reset environment\n",
      "Episode reward: 4174.922\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.866019  4.837456  4.8677726 2.9802723 4.9699206 4.8582034]\n",
      "Reset environment\n",
      "Episode reward: 2498.0757\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.867854  4.839284  4.8696117 2.982342  4.9715266 4.8600416]\n",
      "Reset environment\n",
      "Episode reward: 5755.5415\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.872538 4.843992 4.874265 2.987537 4.975668 4.864727]\n",
      "Reset environment\n",
      "Episode reward: 2937.661\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8748603 4.846333  4.876561  2.9901078 4.9777317 4.867046 ]\n",
      "Reset environment\n",
      "Episode reward: 2234.2407\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8765826 4.848069  4.878267  2.9920495 4.9792423 4.868768 ]\n",
      "Reset environment\n",
      "Episode reward: 3134.707\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8790965 4.8506002 4.8807693 2.9948416 4.981471  4.8712845]\n",
      "Reset environment\n",
      "Episode reward: 1595.2301\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8808365 4.8523254 4.8825145 2.9968243 4.9829845 4.873019 ]\n",
      "Reset environment\n",
      "Episode reward: 125.12381\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.880839  4.8522253 4.882614  2.996903  4.983058  4.8730197]\n",
      "Reset environment\n",
      "Episode reward: 3986.729\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.88401   4.855398  4.885782  3.000403  4.985868  4.8761935]\n",
      "Reset environment\n",
      "Episode reward: 2322.8386\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8864155 4.857806  4.8881793 3.003085  4.988     4.878596 ]\n",
      "Reset environment\n",
      "Episode reward: 3485.9902\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.889047  4.8603854 4.8908634 3.0060754 4.990306  4.881228 ]\n",
      "Reset environment\n",
      "Episode reward: 3695.3845\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.891833  4.8631315 4.8936844 3.0092654 4.9927335 4.8840146]\n",
      "Reset environment\n",
      "Episode reward: 2342.03\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.89362   4.8649397 4.8954506 3.0112932 4.9943037 4.885803 ]\n",
      "Reset environment\n",
      "Episode reward: 3095.053\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.896058 4.867344 4.897918 3.014027 4.996457 4.888241]\n",
      "Reset environment\n",
      "Episode reward: 3743.4497\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.8994627 4.8707457 4.9013276 3.0177877 4.999485  4.8916473]\n",
      "Reset environment\n",
      "Episode reward: 953.9662\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9002576 4.8714175 4.902244  3.0187626 5.000191  4.892443 ]\n",
      "Reset environment\n",
      "Episode reward: 3858.16\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.90327   4.874458  4.905224  3.022103  5.0028596 4.895455 ]\n",
      "Reset environment\n",
      "Episode reward: 1379.1279\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.904856  4.876041  4.9068065 3.0238721 5.0042562 4.897039 ]\n",
      "Reset environment\n",
      "Episode reward: 1467.2458\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9059033 4.877092  4.9078503 3.0250766 5.005169  4.898085 ]\n",
      "Reset environment\n",
      "Episode reward: 284.5931\n",
      "Total Steps: 9\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9059334 4.8771214 4.907879  3.025148  5.005181  4.898115 ]\n",
      "Reset environment\n",
      "Episode reward: 2003.5378\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9074206 4.8785896 4.9093776 3.0268614 5.0064664 4.8996015]\n",
      "Reset environment\n",
      "Episode reward: 2445.2153\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.909304  4.880512  4.911226  3.0289607 5.0081425 4.9014874]\n",
      "Reset environment\n",
      "Episode reward: -241.73767\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9088216 4.880208  4.910569  3.0285485 5.0077076 4.9010086]\n",
      "Reset environment\n",
      "Episode reward: 2259.7246\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9105124 4.881924  4.9122353 3.0304956 5.0091867 4.902699 ]\n",
      "Reset environment\n",
      "Episode reward: 4799.092\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9143443 4.8857565 4.91606   3.034762  5.0125585 4.906531 ]\n",
      "Reset environment\n",
      "Episode reward: 550.10474\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9147763 4.886102  4.916581  3.0353284 5.01298   4.9069667]\n",
      "Reset environment\n",
      "Episode reward: 2375.9888\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.916534  4.887885  4.918319  3.0372944 5.0145454 4.9087234]\n",
      "Reset environment\n",
      "Episode reward: 3282.7517\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.919141  4.8905134 4.920902  3.0401812 5.016856  4.9113293]\n",
      "Reset environment\n",
      "Episode reward: 1622.2587\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9203043 4.891702  4.922038  3.0415363 5.0178795 4.9124928]\n",
      "Reset environment\n",
      "Episode reward: 2194.2358\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9219694 4.8933764 4.9236917 3.04342   5.0193405 4.914159 ]\n",
      "Reset environment\n",
      "Episode reward: 3153.3765\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9244995 4.8959174 4.926211  3.0462317 5.021589  4.9166913]\n",
      "Reset environment\n",
      "Episode reward: 2462.3845\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.926127  4.8976417 4.92774   3.048155  5.0230107 4.918318 ]\n",
      "Reset environment\n",
      "Episode reward: 1293.4966\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.92762   4.899137  4.9292245 3.0498488 5.0243106 4.9198084]\n",
      "Reset environment\n",
      "Episode reward: 1270.2104\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.929086  4.900601  4.930688  3.051514  5.0255876 4.921273 ]\n",
      "Reset environment\n",
      "Episode reward: -155.58972\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9287286 4.900098  4.930481  3.0512514 5.0252686 4.9209204]\n",
      "Reset environment\n",
      "Episode reward: 2442.3438\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9306126 4.9020023 4.932336  3.0533874 5.0269303 4.922804 ]\n",
      "Reset environment\n",
      "Episode reward: 3572.0215\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.933486  4.9049015 4.935174  3.0565784 5.0294766 4.925679 ]\n",
      "Reset environment\n",
      "Episode reward: 4001.4602\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.936705  4.90809   4.938418  3.0601556 5.032319  4.9288964]\n",
      "Reset environment\n",
      "Episode reward: 1808.4988\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.938057  4.9094405 4.9397655 3.0616755 5.033503  4.9302444]\n",
      "Reset environment\n",
      "Episode reward: 2411.6792\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.940521  4.911908  4.942226  3.064413  5.0356913 4.9327083]\n",
      "Reset environment\n",
      "Episode reward: 1290.4092\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.94201   4.913392  4.943718  3.0661128 5.0369906 4.9341955]\n",
      "Reset environment\n",
      "Episode reward: 5629.014\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9466457 4.918009  4.948374  3.0711963 5.041115  4.9388328]\n",
      "Reset environment\n",
      "Episode reward: 4165.3916\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.950039  4.9213758 4.9518    3.0749521 5.0441246 4.942229 ]\n",
      "Reset environment\n",
      "Episode reward: 2457.8945\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.951874  4.9231515 4.953687  3.0770354 5.045754  4.944062 ]\n",
      "Reset environment\n",
      "Episode reward: 3426.8438\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.954633  4.9259133 4.956436  3.0800858 5.0482087 4.9468217]\n",
      "Reset environment\n",
      "Episode reward: 2453.3403\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.956268  4.927656  4.95796   3.0820527 5.049637  4.948456 ]\n",
      "Reset environment\n",
      "Episode reward: 2118.9062\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9576554 4.9291153 4.959272  3.0837188 5.0508037 4.9498415]\n",
      "Reset environment\n",
      "Episode reward: 1627.7115\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9588532 4.930332  4.960449  3.0850694 5.05187   4.9510407]\n",
      "Reset environment\n",
      "Episode reward: 2043.0066\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9609704 4.9324503 4.9625654 3.0874624 5.0537257 4.9531584]\n",
      "Reset environment\n",
      "Episode reward: 2367.0571\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9627686 4.93422   4.964394  3.0894773 5.055321  4.954954 ]\n",
      "Reset environment\n",
      "Episode reward: 2079.8928\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.964274  4.935787  4.965826  3.0912347 5.056595  4.956459 ]\n",
      "Reset environment\n",
      "Episode reward: -454.37952\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.963535  4.9348574 4.965299  3.0906534 5.055894  4.9557304]\n",
      "Reset environment\n",
      "Episode reward: -921.0123\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.962386  4.933585  4.964288  3.089502  5.0548863 4.9545856]\n",
      "Reset environment\n",
      "Episode reward: 5305.1426\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.96663   4.937847  4.968509  3.0941563 5.0586715 4.958828 ]\n",
      "Reset environment\n",
      "Episode reward: 2046.0248\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.968433  4.939749  4.9702077 3.0962167 5.0602636 4.9606338]\n",
      "Reset environment\n",
      "Episode reward: 3140.063\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9709115 4.94221   4.9727025 3.0989869 5.0624495 4.963112 ]\n",
      "Reset environment\n",
      "Episode reward: 826.82043\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.971696  4.943042  4.9734426 3.0998592 5.063197  4.9639006]\n",
      "Reset environment\n",
      "Episode reward: 3108.122\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9740515 4.945304  4.9758797 3.10254   5.065286  4.966254 ]\n",
      "Reset environment\n",
      "Episode reward: 1542.5311\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9754925 4.9467926 4.9772654 3.1041436 5.066609  4.967698 ]\n",
      "Reset environment\n",
      "Episode reward: 4418.722\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9789915 4.950282  4.9807577 3.1080048 5.0696945 4.9711947]\n",
      "Reset environment\n",
      "Episode reward: 3865.8276\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.982072  4.9533525 4.9838524 3.1114347 5.072405  4.9742737]\n",
      "Reset environment\n",
      "Episode reward: 1205.2307\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.983454  4.9547358 4.9852347 3.1130261 5.0735984 4.9756575]\n",
      "Reset environment\n",
      "Episode reward: 2585.3835\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9854407 4.956727  4.9872184 3.1152675 5.0753484 4.977643 ]\n",
      "Reset environment\n",
      "Episode reward: 3956.5269\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.988588  4.9598565 4.990383  3.1188037 5.078104  4.980784 ]\n",
      "Reset environment\n",
      "Episode reward: 3423.5125\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9913    4.9625864 4.9930773 3.1218028 5.0805    4.9834943]\n",
      "Reset environment\n",
      "Episode reward: 5031.098\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.995306  4.9665775 4.997093  3.1262307 5.0840473 4.987503 ]\n",
      "Reset environment\n",
      "Episode reward: 3025.9656\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [4.9977036 4.968994  4.9994764 3.128891  5.08618   4.9899025]\n",
      "Reset environment\n",
      "Episode reward: 3692.6052\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.000647  4.971957  5.0023994 3.1321864 5.088766  4.9928493]\n",
      "Reset environment\n",
      "Episode reward: 2595.0518\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0026116 4.9739876 5.004293  3.1344025 5.0904856 4.9948163]\n",
      "Reset environment\n",
      "Episode reward: 1318.9266\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0041194 4.9754987 5.0058026 3.136108  5.0918045 4.9963255]\n",
      "Reset environment\n",
      "Episode reward: 4017.5217\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0072823 4.9786587 5.00896   3.139593  5.09461   4.999483 ]\n",
      "Reset environment\n",
      "Episode reward: 2558.0693\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.009278  4.980665  5.0109434 3.1418197 5.0963745 5.00148  ]\n",
      "Reset environment\n",
      "Episode reward: 3294.2102\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0118933 4.9833    5.0135403 3.1447325 5.098682  5.004095 ]\n",
      "Reset environment\n",
      "Episode reward: 5365.867\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0162883 4.987682  5.0179496 3.1495488 5.1026025 5.008487 ]\n",
      "Reset environment\n",
      "Episode reward: 1627.7072\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.017482  4.9888744 5.0191445 3.150888  5.1036544 5.0096807]\n",
      "Reset environment\n",
      "Episode reward: 4369.3535\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.020899  4.9922757 5.0225782 3.1546738 5.106672  5.0130982]\n",
      "Reset environment\n",
      "Episode reward: 4669.382\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.024597  4.995967  5.0262723 3.158763  5.1099334 5.0167947]\n",
      "Reset environment\n",
      "Episode reward: 5449.8486\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0290523 5.0004177 5.030728  3.163685  5.1138797 5.021247 ]\n",
      "Reset environment\n",
      "Episode reward: 2761.1033\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.031104  5.002467  5.0327764 3.1659937 5.115679  5.0232987]\n",
      "Reset environment\n",
      "Episode reward: 1311.8815\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0326    5.00396   5.034267  3.1676795 5.1169868 5.0247927]\n",
      "Reset environment\n",
      "Episode reward: 1315.0345\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0336866 5.004918  5.035481  3.1689107 5.1179824 5.025881 ]\n",
      "Reset environment\n",
      "Episode reward: 3339.3538\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0362864 5.0075645 5.038023  3.171814  5.1202874 5.028482 ]\n",
      "Reset environment\n",
      "Episode reward: 2664.2314\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0383415 5.0095816 5.0401073 3.1741042 5.1221185 5.030534 ]\n",
      "Reset environment\n",
      "Episode reward: 3252.5132\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.040799  5.0119777 5.0426183 3.1768851 5.1242995 5.0329924]\n",
      "Reset environment\n",
      "Episode reward: 316.12753\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0408344 5.0122066 5.042478  3.1770895 5.1243763 5.0330358]\n",
      "Reset environment\n",
      "Episode reward: 2036.0173\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.042937  5.014301  5.0445886 3.1794589 5.1262145 5.035137 ]\n",
      "Reset environment\n",
      "Episode reward: 1428.0125\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0440793 5.015353  5.045826  3.1808596 5.127212  5.036286 ]\n",
      "Reset environment\n",
      "Episode reward: 2559.453\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0458107 5.0171747 5.047458  3.1828847 5.1287155 5.038018 ]\n",
      "Reset environment\n",
      "Episode reward: 2194.8582\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.047454  5.0187955 5.0491266 3.1847456 5.1301575 5.0396605]\n",
      "Reset environment\n",
      "Episode reward: -603.0621\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.046759  5.0181875 5.04835   3.1840308 5.1295547 5.038968 ]\n",
      "Reset environment\n",
      "Episode reward: 3097.8486\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0491576 5.0206113 5.0507293 3.1867337 5.1316586 5.0413666]\n",
      "Reset environment\n",
      "Episode reward: 5198.569\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0539536 5.025381  5.055541  3.192054  5.135921  5.0461593]\n",
      "Reset environment\n",
      "Episode reward: 2056.3398\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0560694 5.0275064 5.057646  3.1944523 5.137774  5.0482745]\n",
      "Reset environment\n",
      "Episode reward: 2388.83\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.057785  5.0292954 5.059289  3.1964378 5.1392484 5.049991 ]\n",
      "Reset environment\n",
      "Episode reward: 990.3015\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0585527 5.0299225 5.0601816 3.197476  5.139906  5.0507607]\n",
      "Reset environment\n",
      "Episode reward: 2378.001\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0609455 5.032333  5.0625515 3.200167  5.1420045 5.053153 ]\n",
      "Reset environment\n",
      "Episode reward: 4074.0542\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0641127 5.0355086 5.065714  3.2037263 5.144785  5.056325 ]\n",
      "Reset environment\n",
      "Episode reward: 1067.803\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0649157 5.0361776 5.066652  3.204745  5.1455064 5.0571313]\n",
      "Reset environment\n",
      "Episode reward: 2085.0718\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.067046  5.0383224 5.068765  3.2071643 5.14737   5.0592594]\n",
      "Reset environment\n",
      "Episode reward: 2816.5051\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.069226  5.0405264 5.0709133 3.2096138 5.149284  5.061434 ]\n",
      "Reset environment\n",
      "Episode reward: 3454.1797\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.071889  5.0432396 5.073512  3.2126002 5.151623  5.0640965]\n",
      "Reset environment\n",
      "Episode reward: 3035.85\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0742207 5.045584  5.075832  3.2152376 5.1536684 5.066429 ]\n",
      "Reset environment\n",
      "Episode reward: 5137.7295\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0782485 5.049615  5.079837  3.2196991 5.1572256 5.070451 ]\n",
      "Reset environment\n",
      "Episode reward: 2163.1548\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.079825  5.051173  5.0814238 3.2215054 5.1585927 5.0720215]\n",
      "Reset environment\n",
      "Episode reward: 3486.0015\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0825715 5.0539455 5.0841513 3.224558  5.161026  5.074768 ]\n",
      "Reset environment\n",
      "Episode reward: 4857.024\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0863123 5.057606  5.087972  3.2287576 5.164343  5.0785108]\n",
      "Reset environment\n",
      "Episode reward: 4434.259\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.089858  5.0611334 5.091524  3.2327015 5.1674643 5.082056 ]\n",
      "Reset environment\n",
      "Episode reward: 2271.0884\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0915775 5.062841  5.093255  3.23463   5.1689787 5.0837784]\n",
      "Reset environment\n",
      "Episode reward: 5176.9077\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.0957828 5.067078  5.09743   3.2392921 5.1727176 5.0879817]\n",
      "Reset environment\n",
      "Episode reward: 2045.5171\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.097298  5.0685897 5.0989537 3.2410078 5.174051  5.0894966]\n",
      "Reset environment\n",
      "Episode reward: 1319.949\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.098789  5.0700746 5.1004453 3.2426934 5.1753597 5.0909877]\n",
      "Reset environment\n",
      "Episode reward: 5455.627\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1032333 5.074511  5.1048913 3.2475522 5.179309  5.095433 ]\n",
      "Reset environment\n",
      "Episode reward: -513.24414\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.102657  5.074001  5.104263  3.2468796 5.178798  5.094863 ]\n",
      "Reset environment\n",
      "Episode reward: 2200.3801\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.104242  5.07553   5.105891  3.2486837 5.180198  5.096446 ]\n",
      "Reset environment\n",
      "Episode reward: 4618.8267\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.107789  5.0790524 5.1094575 3.2526426 5.183327  5.099992 ]\n",
      "Reset environment\n",
      "Episode reward: 2978.4705\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1100764 5.0813093 5.1117744 3.255217  5.185335  5.102275 ]\n",
      "Reset environment\n",
      "Episode reward: 2946.17\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.112298  5.0834723 5.114043  3.2577157 5.187316  5.1044965]\n",
      "Reset environment\n",
      "Episode reward: 1417.1085\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.113271  5.0844436 5.115017  3.258855  5.188154  5.1054697]\n",
      "Reset environment\n",
      "Episode reward: 5233.454\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1181035 5.0893083 5.1198306 3.2641842 5.192474  5.110306 ]\n",
      "Reset environment\n",
      "Episode reward: 3251.953\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.120654  5.091877  5.122362  3.2670248 5.194732  5.112857 ]\n",
      "Reset environment\n",
      "Episode reward: 3295.9802\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1232066 5.094442  5.124892  3.2698512 5.196982  5.115409 ]\n",
      "Reset environment\n",
      "Episode reward: 2787.7498\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1253467 5.096617  5.126988  3.2722363 5.198884  5.117551 ]\n",
      "Reset environment\n",
      "Episode reward: 4849.951\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1291203 5.100378  5.1307683 3.2763944 5.2022405 5.121322 ]\n",
      "Reset environment\n",
      "Episode reward: 2144.5432\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.131305  5.102578  5.132942  3.2788413 5.204173  5.1235094]\n",
      "Reset environment\n",
      "Episode reward: 2247.8604\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1329403 5.10428   5.1345105 3.2806966 5.2056217 5.1251483]\n",
      "Reset environment\n",
      "Episode reward: 2155.6638\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.134358  5.105765  5.1358533 3.2823582 5.206847  5.126568 ]\n",
      "Reset environment\n",
      "Episode reward: 2757.371\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1363773 5.107712  5.137936  3.284656  5.2086425 5.1285863]\n",
      "Reset environment\n",
      "Episode reward: -389.80725\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1356063 5.106713  5.1373987 3.2841167 5.207829  5.1278205]\n",
      "Reset environment\n",
      "Episode reward: 5939.6846\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1403327 5.111414  5.142158  3.289339  5.2120275 5.1325536]\n",
      "Reset environment\n",
      "Episode reward: 2077.9368\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.141859  5.1129413 5.143679  3.2910764 5.2133546 5.1340804]\n",
      "Reset environment\n",
      "Episode reward: 2759.062\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1439657 5.1150665 5.1457634 3.2934363 5.215202  5.136184 ]\n",
      "Reset environment\n",
      "Episode reward: 1299.6921\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1448646 5.115972  5.146652  3.2944653 5.2159925 5.137082 ]\n",
      "Reset environment\n",
      "Episode reward: 5339.71\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.14917   5.120247  5.1509833 3.2992344 5.219813  5.141387 ]\n",
      "Reset environment\n",
      "Episode reward: 5954.437\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1539073 5.124977  5.155725  3.3044555 5.224019  5.1461325]\n",
      "Reset environment\n",
      "Episode reward: 1355.0103\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1554255 5.1264973 5.1572356 3.306161  5.2253485 5.1476507]\n",
      "Reset environment\n",
      "Episode reward: 4306.6353\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.158853  5.1299376 5.1606464 3.3099346 5.2283983 5.1510816]\n",
      "Reset environment\n",
      "Episode reward: 2420.9768\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.16067   5.1317587 5.1624513 3.3119674 5.230013  5.1529   ]\n",
      "Reset environment\n",
      "Episode reward: 1303.4762\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1615458 5.1326365 5.1633267 3.312991  5.23077   5.1537766]\n",
      "Reset environment\n",
      "Episode reward: 4379.137\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.165035  5.1361465 5.166795  3.3168352 5.2338777 5.15727  ]\n",
      "Reset environment\n",
      "Episode reward: 3567.3547\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.168227  5.1393332 5.1699986 3.3203263 5.2367635 5.160467 ]\n",
      "Reset environment\n",
      "Episode reward: 1983.0652\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1696305 5.140794  5.1713376 3.3219283 5.2379894 5.1618705]\n",
      "Reset environment\n",
      "Episode reward: 2597.4028\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.171578  5.142771  5.1732526 3.324106  5.239711  5.1638193]\n",
      "Reset environment\n",
      "Episode reward: 4482.303\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1751347 5.1462893 5.1768436 3.3280573 5.242861  5.1673756]\n",
      "Reset environment\n",
      "Episode reward: 4460.238\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.178553  5.1497207 5.1802483 3.3318548 5.245884  5.170793 ]\n",
      "Reset environment\n",
      "Episode reward: 2036.4314\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1800046 5.1512294 5.1816416 3.3334973 5.2471786 5.1722484]\n",
      "Reset environment\n",
      "Episode reward: 2437.4104\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1817355 5.152966  5.1833663 3.3354616 5.2486935 5.173977 ]\n",
      "Reset environment\n",
      "Episode reward: 2361.352\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1834497 5.154634  5.1851254 3.3374176 5.2501993 5.1756887]\n",
      "Reset environment\n",
      "Episode reward: 2579.6763\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.185225  5.1564875 5.186825  3.339492  5.251724  5.177471 ]\n",
      "Reset environment\n",
      "Episode reward: 1227.8894\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.186018  5.1572785 5.187619  3.3404362 5.252398  5.178263 ]\n",
      "Reset environment\n",
      "Episode reward: 5033.506\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1900163 5.161273  5.1916256 3.3449032 5.255911  5.1822634]\n",
      "Reset environment\n",
      "Episode reward: 3331.186\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1925874 5.163869  5.194184  3.3477788 5.258186  5.1848373]\n",
      "Reset environment\n",
      "Episode reward: 2096.9736\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1944256 5.1657534 5.1959558 3.349991  5.259795  5.1866746]\n",
      "Reset environment\n",
      "Episode reward: 1267.2903\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.1958466 5.1671743 5.197369  3.3516161 5.261028  5.188094 ]\n",
      "Reset environment\n",
      "Episode reward: 5195.085\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2000203 5.17136   5.2015257 3.3562436 5.264749  5.192268 ]\n",
      "Reset environment\n",
      "Episode reward: 793.4177\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.200382  5.1718407 5.201785  3.3566546 5.2652063 5.192635 ]\n",
      "Reset environment\n",
      "Episode reward: 3706.819\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.203273  5.1747217 5.2046857 3.3598635 5.2677546 5.1955266]\n",
      "Reset environment\n",
      "Episode reward: 2624.7134\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2051697 5.1765456 5.2066483 3.362025  5.2694407 5.1974187]\n",
      "Reset environment\n",
      "Episode reward: 1331.4023\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2066617 5.178034  5.2081413 3.3637033 5.270748  5.198909 ]\n",
      "Reset environment\n",
      "Episode reward: 2660.097\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2086296 5.1800466 5.210062  3.365908  5.2724857 5.200878 ]\n",
      "Reset environment\n",
      "Episode reward: 4226.948\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2119546 5.1834316 5.2133217 3.3695781 5.2754416 5.204204 ]\n",
      "Reset environment\n",
      "Episode reward: 4892.2783\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.215874  5.1873364 5.2172465 3.3739102 5.278899  5.2081175]\n",
      "Reset environment\n",
      "Episode reward: 2834.1582\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2179184 5.189337  5.219339  3.3762486 5.2807064 5.2101626]\n",
      "Reset environment\n",
      "Episode reward: 1632.0068\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.219064  5.190487  5.2204785 3.377551  5.281704  5.211307 ]\n",
      "Reset environment\n",
      "Episode reward: 5339.705\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.223363  5.1947703 5.224781  3.382305  5.285504  5.2156043]\n",
      "Reset environment\n",
      "Episode reward: 2078.971\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2254567 5.196859  5.22687   3.3846571 5.2873464 5.217697 ]\n",
      "Reset environment\n",
      "Episode reward: 3533.914\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.228204  5.199657  5.229555  3.387697  5.289766  5.2204485]\n",
      "Reset environment\n",
      "Episode reward: 2142.9348\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.229695  5.2012157 5.2309694 3.3894224 5.29105   5.2219415]\n",
      "Reset environment\n",
      "Episode reward: 3935.4766\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.232686  5.20429   5.2338743 3.3927839 5.2936845 5.224935 ]\n",
      "Reset environment\n",
      "Episode reward: 5391.3857\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2369957 5.208585  5.238206  3.3975246 5.2975345 5.2292485]\n",
      "Reset environment\n",
      "Episode reward: 4484.122\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2405453 5.212159  5.24173   3.4014668 5.3006854 5.232799 ]\n",
      "Reset environment\n",
      "Episode reward: 3814.8882\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.24342   5.2150297 5.2446046 3.4046762 5.3032017 5.2356772]\n",
      "Reset environment\n",
      "Episode reward: 2101.1165\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.245548  5.2171483 5.2467365 3.4070356 5.3050776 5.2378025]\n",
      "Reset environment\n",
      "Episode reward: 1564.4252\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2468357 5.2183084 5.248154  3.408554  5.306203  5.2390933]\n",
      "Reset environment\n",
      "Episode reward: 5416.0796\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2510843 5.222576  5.2523727 3.413215  5.3099837 5.2433386]\n",
      "Reset environment\n",
      "Episode reward: 2036.6863\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.252561  5.224093  5.253812  3.4148874 5.3112907 5.244816 ]\n",
      "Reset environment\n",
      "Episode reward: 4013.7231\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.255676  5.227181  5.256955  3.4183626 5.314042  5.2479324]\n",
      "Reset environment\n",
      "Episode reward: 3837.422\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.258688  5.230204  5.259948  3.4216762 5.316711  5.2509446]\n",
      "Reset environment\n",
      "Episode reward: 4987.4917\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2624784 5.2339716 5.2637486 3.4259176 5.320025  5.2547336]\n",
      "Reset environment\n",
      "Episode reward: 1303.8654\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.263924  5.235412  5.2651873 3.427549  5.3212857 5.256177 ]\n",
      "Reset environment\n",
      "Episode reward: 1423.4891\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.265057  5.2364497 5.2664175 3.4288924 5.322321  5.2573133]\n",
      "Reset environment\n",
      "Episode reward: 356.15665\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.265296  5.2367635 5.2665763 3.4291942 5.322511  5.2575502]\n",
      "Reset environment\n",
      "Episode reward: 3784.3596\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2682123 5.239703  5.269465  3.4324403 5.32508   5.260468 ]\n",
      "Reset environment\n",
      "Episode reward: 5471.3647\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2725844 5.244101  5.273819  3.4372356 5.328989  5.2648377]\n",
      "Reset environment\n",
      "Episode reward: 3755.304\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2755084 5.247042  5.2767196 3.4404318 5.331599  5.267761 ]\n",
      "Reset environment\n",
      "Episode reward: 2254.994\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.277012  5.248633  5.27813   3.4421816 5.3329287 5.2692647]\n",
      "Reset environment\n",
      "Episode reward: 3287.2192\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.279464  5.251024  5.2806354 3.4449327 5.335103  5.271715 ]\n",
      "Reset environment\n",
      "Episode reward: 4640.8193\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2829747 5.2545195 5.284147  3.4488893 5.338164  5.275224 ]\n",
      "Reset environment\n",
      "Episode reward: 1907.0704\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.28435   5.25589   5.285527  3.4504626 5.3393636 5.2766   ]\n",
      "Reset environment\n",
      "Episode reward: 1496.0161\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.285962  5.257504  5.28714   3.4522836 5.340779  5.278213 ]\n",
      "Reset environment\n",
      "Episode reward: 3623.9973\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2886057 5.260099  5.289823  3.455262  5.343145  5.2808504]\n",
      "Reset environment\n",
      "Episode reward: 1568.3011\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2896934 5.261194  5.290899  3.4565063 5.3440986 5.281937 ]\n",
      "Reset environment\n",
      "Episode reward: 3723.1208\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.292491  5.2640185 5.29367   3.4596214 5.3465652 5.2847342]\n",
      "Reset environment\n",
      "Episode reward: 1225.8967\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.293281  5.2648053 5.29446   3.4605532 5.3472424 5.285524 ]\n",
      "Reset environment\n",
      "Episode reward: 2527.6284\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.295121  5.266701  5.2962427 3.462643  5.3488545 5.2873664]\n",
      "Reset environment\n",
      "Episode reward: 1656.9854\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.2963023 5.267874  5.2974367 3.4639778 5.349896  5.288549 ]\n",
      "Reset environment\n",
      "Episode reward: 4709.9414\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.300022  5.271553  5.3011928 3.46809   5.3532004 5.2922645]\n",
      "Reset environment\n",
      "Episode reward: 2450.6104\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.301853  5.273402  5.3030057 3.4701452 5.354826  5.294097 ]\n",
      "Reset environment\n",
      "Episode reward: 3047.1685\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.304096  5.275642  5.3052473 3.4726355 5.35681   5.2963386]\n",
      "Reset environment\n",
      "Episode reward: 1683.5148\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.305832  5.277372  5.3069797 3.4745982 5.35832   5.2980733]\n",
      "Reset environment\n",
      "Episode reward: 5416.513\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3101263 5.2816744 5.3112683 3.479352  5.362145  5.302371 ]\n",
      "Reset environment\n",
      "Episode reward: 1943.3528\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3115487 5.28309   5.312697  3.480948  5.3633986 5.3037944]\n",
      "Reset environment\n",
      "Episode reward: 1244.8618\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3123555 5.283909  5.313493  3.4818988 5.3641005 5.3046045]\n",
      "Reset environment\n",
      "Episode reward: 2034.6968\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.314414  5.2859726 5.315538  3.484192  5.365918  5.306658 ]\n",
      "Reset environment\n",
      "Episode reward: 2595.3225\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.316339  5.287857  5.317498  3.4863527 5.3676286 5.308584 ]\n",
      "Reset environment\n",
      "Episode reward: 1713.0317\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.317565  5.2890697 5.318734  3.487728  5.368716  5.309809 ]\n",
      "Reset environment\n",
      "Episode reward: 5738.0317\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3221283 5.293618  5.323315  3.4927707 5.372766  5.314376 ]\n",
      "Reset environment\n",
      "Episode reward: 1473.9952\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3231206 5.2946105 5.324307  3.4939187 5.373623  5.3153687]\n",
      "Reset environment\n",
      "Episode reward: 1180.5378\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3239    5.2953844 5.32509   3.4948173 5.374307  5.3161483]\n",
      "Reset environment\n",
      "Episode reward: 3198.4421\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3262367 5.297682  5.3274703 3.4974363 5.3763723 5.3184857]\n",
      "Reset environment\n",
      "Episode reward: 4793.6895\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3299265 5.3013673 5.331155  3.5015144 5.3796244 5.3221745]\n",
      "Reset environment\n",
      "Episode reward: 5149.7534\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.334021  5.305422  5.335274  3.5060272 5.383255  5.3262653]\n",
      "Reset environment\n",
      "Episode reward: 3412.7058\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.336606  5.3080297 5.3378315 3.508902  5.385529  5.328849 ]\n",
      "Reset environment\n",
      "Episode reward: 213.21341\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.336503  5.3081203 5.337545  3.5089602 5.385449  5.328751 ]\n",
      "Reset environment\n",
      "Episode reward: 3180.4836\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3389072 5.310551  5.3399134 3.5116417 5.387562  5.3311524]\n",
      "Reset environment\n",
      "Episode reward: 5078.008\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.342772  5.3144207 5.343761  3.5159504 5.390964  5.3350124]\n",
      "Reset environment\n",
      "Episode reward: 2574.9731\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3445387 5.3161106 5.3456087 3.5179975 5.392516  5.33678  ]\n",
      "Reset environment\n",
      "Episode reward: 2557.6118\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3463016 5.317789  5.3474503 3.520029  5.3940682 5.338546 ]\n",
      "Reset environment\n",
      "Episode reward: 3738.6792\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3491063 5.3205247 5.3503194 3.5231667 5.396581  5.34135  ]\n",
      "Reset environment\n",
      "Episode reward: 4885.5728\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.352959  5.324401  5.354156  3.5274103 5.400026  5.345204 ]\n",
      "Reset environment\n",
      "Episode reward: 3719.7334\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.35583   5.327237  5.3570557 3.5305767 5.402571  5.348071 ]\n",
      "Reset environment\n",
      "Episode reward: 2140.5303\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.357971  5.329371  5.3592033 3.5329468 5.4044676 5.350211 ]\n",
      "Reset environment\n",
      "Episode reward: 3443.355\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3605933 5.33201   5.3617997 3.5358307 5.406799  5.352831 ]\n",
      "Reset environment\n",
      "Episode reward: 2237.512\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.362074  5.333555  5.363203  3.5375674 5.408061  5.354313 ]\n",
      "Reset environment\n",
      "Episode reward: 3177.823\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.364387  5.3357964 5.365579  3.5401988 5.410117  5.3566284]\n",
      "Reset environment\n",
      "Episode reward: 2847.5156\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.366445  5.3378477 5.3676453 3.5424943 5.4119396 5.3586884]\n",
      "Reset environment\n",
      "Episode reward: 2578.7087\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.368336  5.339777  5.369493  3.5446002 5.41361   5.360578 ]\n",
      "Reset environment\n",
      "Episode reward: 2966.8806\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.370464  5.341878  5.3716474 3.546992  5.4155083 5.3627043]\n",
      "Reset environment\n",
      "Episode reward: 2257.228\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3727136 5.344118  5.3739014 3.5494943 5.417489  5.3649526]\n",
      "Reset environment\n",
      "Episode reward: 2129.4736\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.374833  5.3462267 5.3760257 3.5518665 5.419366  5.3670735]\n",
      "Reset environment\n",
      "Episode reward: 2273.5063\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.377079  5.348468  5.37828   3.554369  5.4213514 5.3693185]\n",
      "Reset environment\n",
      "Episode reward: 456.18225\n",
      "Total Steps: 17\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.377226  5.348614  5.3784275 3.5545897 5.421463  5.3694663]\n",
      "Reset environment\n",
      "Episode reward: 4188.0503\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3804817 5.35185   5.3816967 3.5582056 5.424337  5.372717 ]\n",
      "Reset environment\n",
      "Episode reward: 5475.9434\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.384794  5.356153  5.386027  3.5629556 5.428179  5.3770247]\n",
      "Reset environment\n",
      "Episode reward: 2354.314\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.386493  5.3578773 5.38769   3.5648541 5.4296765 5.378722 ]\n",
      "Reset environment\n",
      "Episode reward: 4603.1836\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3901157 5.3615193 5.3912935 3.568846  5.432906  5.382347 ]\n",
      "Reset environment\n",
      "Episode reward: 2694.4678\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.3920903 5.363544  5.393217  3.5710568 5.4346623 5.384325 ]\n",
      "Reset environment\n",
      "Episode reward: 1297.7411\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.393518  5.3649735 5.3946433 3.5726695 5.435914  5.3857527]\n",
      "Reset environment\n",
      "Episode reward: 4361.7603\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.396797  5.368244  5.397929  3.5763464 5.4387994 5.389034 ]\n",
      "Reset environment\n",
      "Episode reward: 3564.2234\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.399497  5.3709674 5.4006076 3.57933   5.4411902 5.3917346]\n",
      "Reset environment\n",
      "Episode reward: 5557.6387\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.403899  5.375349  5.4050217 3.5841722 5.445106  5.396136 ]\n",
      "Reset environment\n",
      "Episode reward: 2718.79\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4059067 5.3773785 5.4070063 3.5864131 5.4468718 5.398144 ]\n",
      "Reset environment\n",
      "Episode reward: 1258.7612\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.407293  5.378763  5.408395  3.5879934 5.4480767 5.399527 ]\n",
      "Reset environment\n",
      "Episode reward: 4944.0547\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.411051  5.382525  5.412145  3.5921493 5.45142   5.4032893]\n",
      "Reset environment\n",
      "Episode reward: 40.98065\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4104834 5.3817177 5.4118237 3.5918584 5.4508157 5.4027295]\n",
      "Reset environment\n",
      "Episode reward: -173.32376\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4099216 5.381336  5.4110885 3.5914812 5.4502773 5.40217  ]\n",
      "Reset environment\n",
      "Episode reward: 1786.9788\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4111047 5.3825803 5.412207  3.5928452 5.451328  5.4033546]\n",
      "Reset environment\n",
      "Episode reward: 1221.8306\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4124384 5.3839126 5.413541  3.5943887 5.4524736 5.4046893]\n",
      "Reset environment\n",
      "Episode reward: 5034.2456\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.41639   5.387875  5.4174724 3.598705  5.455996  5.4086356]\n",
      "Reset environment\n",
      "Episode reward: 3997.0444\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4194427 5.390911  5.4205365 3.6021233 5.4586782 5.411684 ]\n",
      "Reset environment\n",
      "Episode reward: 1914.1533\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4213486 5.39282   5.4224415 3.6042821 5.4603467 5.413592 ]\n",
      "Reset environment\n",
      "Episode reward: 2489.7275\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.423139  5.3946214 5.424225  3.6062808 5.461943  5.4153833]\n",
      "Reset environment\n",
      "Episode reward: 2848.2837\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4252553 5.39677   5.4262977 3.6086257 5.463829  5.417497 ]\n",
      "Reset environment\n",
      "Episode reward: 1340.6143\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4267206 5.3982315 5.4277635 3.6102743 5.465111  5.418961 ]\n",
      "Reset environment\n",
      "Episode reward: 4403.676\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.430044  5.401567  5.4310713 3.6139295 5.4680667 5.422285 ]\n",
      "Reset environment\n",
      "Episode reward: -439.0223\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.429429  5.400869  5.430539  3.6133668 5.4675007 5.421673 ]\n",
      "Reset environment\n",
      "Episode reward: 5562.295\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.434448  5.40591   5.4355392 3.6188703 5.4719925 5.426691 ]\n",
      "Reset environment\n",
      "Episode reward: 2321.322\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4361587 5.407611  5.437253  3.6207917 5.473497  5.4284005]\n",
      "Reset environment\n",
      "Episode reward: 1821.9221\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.437962  5.4094186 5.4390464 3.6228542 5.4750576 5.4302015]\n",
      "Reset environment\n",
      "Episode reward: 2412.181\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.439547  5.411076  5.440552  3.6247163 5.476419  5.4317894]\n",
      "Reset environment\n",
      "Episode reward: 2521.7437\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.441314  5.4127784 5.4423776 3.6267247 5.477985  5.4335546]\n",
      "Reset environment\n",
      "Episode reward: 455.13156\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4414573 5.413035  5.442414  3.626909  5.478219  5.433706 ]\n",
      "Reset environment\n",
      "Episode reward: 2526.37\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.443213  5.4147773 5.4441824 3.6288962 5.479765  5.435462 ]\n",
      "Reset environment\n",
      "Episode reward: 3193.4895\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.445527  5.417077  5.446502  3.6314735 5.4818    5.4377785]\n",
      "Reset environment\n",
      "Episode reward: 2644.4475\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.447449  5.4190316 5.448391  3.6336224 5.483492  5.4397   ]\n",
      "Reset environment\n",
      "Episode reward: 2082.1328\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.449534  5.4211087 5.4504766 3.6359258 5.485337  5.441783 ]\n",
      "Reset environment\n",
      "Episode reward: 4669.962\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4531684 5.4247394 5.4541097 3.6399443 5.488543  5.4454165]\n",
      "Reset environment\n",
      "Episode reward: 2126.963\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4546976 5.4262614 5.455647  3.6416569 5.489893  5.446947 ]\n",
      "Reset environment\n",
      "Episode reward: 3673.2417\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.457539  5.4291205 5.4584694 3.6447828 5.492418  5.44979  ]\n",
      "Reset environment\n",
      "Episode reward: 3424.1707\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.460027  5.431669  5.460887  3.6475937 5.4946127 5.452277 ]\n",
      "Reset environment\n",
      "Episode reward: 4886.204\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.463854  5.435507  5.464709  3.6518106 5.498034  5.4561057]\n",
      "Reset environment\n",
      "Episode reward: 2479.4502\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.46565   5.4373302 5.4664807 3.653847  5.499619  5.4579034]\n",
      "Reset environment\n",
      "Episode reward: 328.27655\n",
      "Total Steps: 11\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4657044 5.437384  5.466535  3.6539495 5.499652  5.4579573]\n",
      "Reset environment\n",
      "Episode reward: 2649.669\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4676023 5.4393473 5.468368  3.6561117 5.5013247 5.459858 ]\n",
      "Reset environment\n",
      "Episode reward: 4499.5117\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.471094 5.442809 5.471885 3.659976 5.504414 5.46335 ]\n",
      "Reset environment\n",
      "Episode reward: 2412.6455\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.472809  5.4445353 5.4735866 3.6619573 5.5058928 5.4650655]\n",
      "Reset environment\n",
      "Episode reward: 2767.5598\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.474814  5.446485  5.475635  3.6642017 5.5076733 5.4670725]\n",
      "Reset environment\n",
      "Episode reward: 3117.2336\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.477165  5.4488525 5.477966  3.6667953 5.509762  5.4694242]\n",
      "Reset environment\n",
      "Episode reward: -975.8138\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4759483 5.447482  5.476907  3.6656284 5.5086303 5.468213 ]\n",
      "Reset environment\n",
      "Episode reward: 2324.5195\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4779725 5.4495893 5.478845  3.6678944 5.5104504 5.470242 ]\n",
      "Reset environment\n",
      "Episode reward: 2446.301\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4796557 5.4512734 5.4805264 3.6698115 5.5119157 5.4719253]\n",
      "Reset environment\n",
      "Episode reward: 2318.2576\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.481341  5.452949  5.482214  3.6717038 5.513395  5.473609 ]\n",
      "Reset environment\n",
      "Episode reward: 4189.9565\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.484563  5.4561224 5.485471  3.675269  5.5162587 5.476825 ]\n",
      "Reset environment\n",
      "Episode reward: 3486.4434\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4871054 5.4586587 5.4880176 3.6780822 5.5185013 5.4793706]\n",
      "Reset environment\n",
      "Episode reward: 2689.3652\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.488978  5.460462  5.4899607 3.680224  5.5201674 5.4812427]\n",
      "Reset environment\n",
      "Episode reward: 2427.5044\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4907517 5.462246  5.491718  3.6822088 5.521723  5.4830146]\n",
      "Reset environment\n",
      "Episode reward: 2818.819\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4927883 5.464327  5.4937096 3.6845105 5.523512  5.4850516]\n",
      "Reset environment\n",
      "Episode reward: 2300.9155\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.494237  5.4658575 5.495073  3.686209  5.524786  5.486503 ]\n",
      "Reset environment\n",
      "Episode reward: 3963.4766\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.4972706 5.4688745 5.49812   3.6896002 5.527444  5.489536 ]\n",
      "Reset environment\n",
      "Episode reward: 5298.994\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.501265  5.472857  5.5021234 3.6939912 5.530984  5.493532 ]\n",
      "Reset environment\n",
      "Episode reward: 2891.035\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5033774 5.474923  5.5042763 3.6963546 5.532857  5.495641 ]\n",
      "Reset environment\n",
      "Episode reward: -424.6875\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.502425  5.473707  5.503586  3.6956382 5.531898  5.4946938]\n",
      "Reset environment\n",
      "Episode reward: 2604.3857\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5043116 5.475579  5.5054812 3.6977637 5.533555  5.4965787]\n",
      "Reset environment\n",
      "Episode reward: 4974.1343\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5080924 5.479329  5.5092864 3.7019439 5.536917  5.5003614]\n",
      "Reset environment\n",
      "Episode reward: 2109.0376\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5101886 5.481416  5.5113797 3.7042928 5.5387597 5.5024548]\n",
      "Reset environment\n",
      "Episode reward: 252.33972\n",
      "Total Steps: 6\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5101943 5.4814224 5.511386  3.704325  5.538756  5.502461 ]\n",
      "Reset environment\n",
      "Episode reward: 1727.9447\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5113564 5.482562  5.5125704 3.7056417 5.5397882 5.5036197]\n",
      "Reset environment\n",
      "Episode reward: 1662.7981\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.513074  5.484278  5.5142884 3.7075653 5.541299  5.505337 ]\n",
      "Reset environment\n",
      "Episode reward: 2888.9216\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5151167 5.4863276 5.516317  3.7098758 5.5430956 5.5073824]\n",
      "Reset environment\n",
      "Episode reward: 2417.5747\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5168796 5.4880967 5.518073  3.7118714 5.544646  5.509143 ]\n",
      "Reset environment\n",
      "Episode reward: 3534.6973\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.519544  5.4907746 5.520723  3.714835  5.547006  5.511808 ]\n",
      "Reset environment\n",
      "Episode reward: 2010.9097\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.52154   5.4927664 5.522719  3.717072  5.548758  5.513799 ]\n",
      "Reset environment\n",
      "Episode reward: 4199.3765\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5246625 5.4959025 5.525824  3.72052   5.551525  5.516921 ]\n",
      "Reset environment\n",
      "Episode reward: 2548.3455\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5265245 5.497766  5.527683  3.7225978 5.5531707 5.518783 ]\n",
      "Reset environment\n",
      "Episode reward: 2166.0757\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5280757 5.499342  5.5292087 3.7243383 5.5545526 5.5203333]\n",
      "Reset environment\n",
      "Episode reward: 1656.1361\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5293126 5.500448  5.530571  3.7258513 5.5556107 5.521571 ]\n",
      "Reset environment\n",
      "Episode reward: 4023.9077\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5323467 5.503443  5.5336356 3.7292502 5.558275  5.524603 ]\n",
      "Reset environment\n",
      "Episode reward: 4610.961\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5357943 5.5069156 5.5370593 3.7330506 5.561347  5.528053 ]\n",
      "Reset environment\n",
      "Episode reward: 3209.0962\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.538082  5.509116  5.539425  3.7356646 5.5633903 5.5303397]\n",
      "Reset environment\n",
      "Episode reward: 3740.848\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.540884  5.5118885 5.5422463 3.738788  5.565853  5.5331364]\n",
      "Reset environment\n",
      "Episode reward: 2934.2178\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.543088  5.51411   5.5444355 3.74123   5.5678163 5.5353427]\n",
      "Reset environment\n",
      "Episode reward: 4713.675\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5466733 5.5176635 5.5480537 3.7452385 5.570982  5.538929 ]\n",
      "Reset environment\n",
      "Episode reward: 4904.664\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.550408  5.521414  5.551772  3.749407  5.5742664 5.542669 ]\n",
      "Reset environment\n",
      "Episode reward: 1938.4205\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5517726 5.522799  5.553114  3.7509449 5.575485  5.544035 ]\n",
      "Reset environment\n",
      "Episode reward: 2128.168\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5532393 5.5242567 5.5545897 3.7526286 5.576755  5.5455   ]\n",
      "Reset environment\n",
      "Episode reward: 163.8057\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.553065  5.524008  5.5544896 3.752432  5.5766606 5.545328 ]\n",
      "Reset environment\n",
      "Episode reward: 2001.7831\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5544796 5.525423  5.5559015 3.75402   5.5779085 5.5467424]\n",
      "Reset environment\n",
      "Episode reward: 5118.9316\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5584173 5.5293384 5.559856  3.7583885 5.581391  5.5506835]\n",
      "Reset environment\n",
      "Episode reward: 2780.5388\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5604424 5.5313754 5.5618715 3.760668  5.5831795 5.5527096]\n",
      "Reset environment\n",
      "Episode reward: 5394.1484\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5646358 5.5355906 5.566036  3.7652974 5.586911  5.5569005]\n",
      "Reset environment\n",
      "Episode reward: 1988.7092\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5665846 5.5375347 5.567988  3.7674985 5.588616  5.558849 ]\n",
      "Reset environment\n",
      "Episode reward: -693.24304\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.565771  5.5367446 5.5671687 3.7667482 5.5878353 5.558037 ]\n",
      "Reset environment\n",
      "Episode reward: 2858.0007\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5678577 5.5388603 5.569224  3.7690687 5.5896735 5.560121 ]\n",
      "Reset environment\n",
      "Episode reward: 4020.0103\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.560722  5.5322356 5.5616555 3.7608578 5.583754  5.5530095]\n",
      "Reset environment\n",
      "Episode reward: 1949.3851\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.562113  5.533615  5.5630565 3.762417  5.5849767 5.554398 ]\n",
      "Reset environment\n",
      "Episode reward: 4753.1724\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.565748  5.5372314 5.5667033 3.766461  5.588183  5.5580306]\n",
      "Reset environment\n",
      "Episode reward: 4840.617\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.569347  5.540824  5.5703025 3.770436  5.591361  5.5616293]\n",
      "Reset environment\n",
      "Episode reward: 1334.6625\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.570778  5.5422535 5.5717306 3.77205   5.5926113 5.5630603]\n",
      "Reset environment\n",
      "Episode reward: 2940.4172\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5727286 5.5441093 5.5737705 3.7743196 5.5943446 5.5650144]\n",
      "Reset environment\n",
      "Episode reward: 4375.382\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5760436 5.5474334 5.577067  3.7779572 5.597293  5.5683265]\n",
      "Reset environment\n",
      "Episode reward: 3450.6667\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.578638  5.550016  5.5796704 3.7808213 5.599595  5.570921 ]\n",
      "Reset environment\n",
      "Episode reward: 4085.9526\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5817523 5.553116  5.5827913 3.7842596 5.602352  5.574033 ]\n",
      "Reset environment\n",
      "Episode reward: 1370.9569\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5832224 5.5545855 5.5842586 3.7859023 5.6036444 5.575502 ]\n",
      "Reset environment\n",
      "Episode reward: 2827.0256\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.585215  5.55659   5.586234  3.7881396 5.6054063 5.5774965]\n",
      "Reset environment\n",
      "Episode reward: 2815.1812\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5872335 5.5585675 5.5882883 3.7904062 5.607187  5.579513 ]\n",
      "Reset environment\n",
      "Episode reward: 697.4177\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.587607  5.559068  5.5885406 3.7909124 5.6076107 5.5798917]\n",
      "Reset environment\n",
      "Episode reward: 4223.189\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5908375 5.56228   5.5917807 3.7944534 5.610477  5.58312  ]\n",
      "Reset environment\n",
      "Episode reward: 5624.372\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.595077  5.5665407 5.5959888 3.799117  5.6142592 5.5873585]\n",
      "Reset environment\n",
      "Episode reward: 1535.2537\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.5966673 5.568134  5.5975723 3.8009036 5.6156535 5.588946 ]\n",
      "Reset environment\n",
      "Episode reward: 2678.0593\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.598572  5.569993  5.599517  3.8030632 5.617333  5.59085  ]\n",
      "Reset environment\n",
      "Episode reward: 3023.4006\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6006856 5.5721045 5.601628  3.8054469 5.6191754 5.592961 ]\n",
      "Reset environment\n",
      "Episode reward: 3563.9695\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.603281  5.5747    5.604217  3.8083117 5.6214623 5.5955553]\n",
      "Reset environment\n",
      "Episode reward: 5573.21\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6075764 5.578986  5.608527  3.813027  5.6252933 5.5998507]\n",
      "Reset environment\n",
      "Episode reward: 2223.2236\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.609063  5.5805426 5.6099396 3.8147643 5.6265626 5.6013384]\n",
      "Reset environment\n",
      "Episode reward: 1478.291\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.610274  5.581747  5.6111584 3.8161201 5.6276584 5.6025505]\n",
      "Reset environment\n",
      "Episode reward: 3858.2678\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.613188  5.5846267 5.614101  3.8193274 5.6302567 5.6054597]\n",
      "Reset environment\n",
      "Episode reward: 1065.9437\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6138196 5.585406  5.6145935 3.8201125 5.6308885 5.606099 ]\n",
      "Reset environment\n",
      "Episode reward: 4122.221\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6169176 5.588473  5.61772   3.8235419 5.6336246 5.6091957]\n",
      "Reset environment\n",
      "Episode reward: 1086.5695\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6176662 5.5893235 5.618371  3.8243725 5.6344037 5.609948 ]\n",
      "Reset environment\n",
      "Episode reward: 3010.738\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6196423 5.5913715 5.6202726 3.8266792 5.636112  5.6119285]\n",
      "Reset environment\n",
      "Episode reward: 3791.266\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.622405  5.594134  5.6230283 3.8297362 5.6385517 5.61469  ]\n",
      "Reset environment\n",
      "Episode reward: 3623.4817\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.625051  5.596732  5.625723  3.8326855 5.64092   5.6173353]\n",
      "Reset environment\n",
      "Episode reward: 3151.666\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.627343  5.5989823 5.628046  3.8352525 5.6429353 5.6196218]\n",
      "Reset environment\n",
      "Episode reward: 1562.882\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6284046 5.600038  5.629111  3.8364627 5.6438723 5.6206856]\n",
      "Reset environment\n",
      "Episode reward: 1438.6643\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6294327 5.601195  5.6300125 3.837829  5.644761  5.621719 ]\n",
      "Reset environment\n",
      "Episode reward: 3020.234\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.631662  5.6034455 5.632222  3.8403037 5.646736  5.623953 ]\n",
      "Reset environment\n",
      "Episode reward: 1926.1986\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.633007  5.604791  5.633565  3.8418114 5.6479163 5.6253   ]\n",
      "Reset environment\n",
      "Episode reward: 6301.4653\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.637876  5.6096644 5.638439  3.8471904 5.6522512 5.6301723]\n",
      "Reset environment\n",
      "Episode reward: 1288.7354\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6392503 5.61104   5.63981   3.8487403 5.6534476 5.631546 ]\n",
      "Reset environment\n",
      "Episode reward: 1758.9238\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6404586 5.6122613 5.6410055 3.8501203 5.654517  5.632754 ]\n",
      "Reset environment\n",
      "Episode reward: 5121.15\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6449523 5.6167693 5.6454854 3.85507   5.658524  5.6372504]\n",
      "Reset environment\n",
      "Episode reward: 3680.9949\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.647661  5.619454  5.648219  3.8580892 5.6609097 5.6399603]\n",
      "Reset environment\n",
      "Episode reward: 318.8\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6475554 5.6191754 5.6482806 3.8582835 5.660723  5.639859 ]\n",
      "Reset environment\n",
      "Episode reward: 4784.1704\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6511493 5.622766  5.651881  3.8623168 5.6638675 5.6434546]\n",
      "Reset environment\n",
      "Episode reward: 4191.75\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6542015 5.625824  5.654933  3.865736  5.666554  5.64651  ]\n",
      "Reset environment\n",
      "Episode reward: 3464.7278\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6567783 5.628416  5.6574874 3.8685815 5.668835  5.649088 ]\n",
      "Reset environment\n",
      "Episode reward: 2327.3853\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.658391  5.6300583 5.6590643 3.8703954 5.670255  5.6507015]\n",
      "Reset environment\n",
      "Episode reward: 3196.2622\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.660735  5.632423  5.6613917 3.8729944 5.6723237 5.653049 ]\n",
      "Reset environment\n",
      "Episode reward: 4597.9614\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6640887 5.635775  5.664745  3.8767428 5.675268  5.6564083]\n",
      "Reset environment\n",
      "Episode reward: 803.22656\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.664484  5.636043  5.665275  3.8773441 5.675592  5.6568084]\n",
      "Reset environment\n",
      "Episode reward: 1942.1421\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6658225 5.637364  5.6666284 3.8788846 5.676754  5.6581483]\n",
      "Reset environment\n",
      "Episode reward: 4280.3354\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.66901   5.6406226 5.6697364 3.882428  5.6795893 5.6613374]\n",
      "Reset environment\n",
      "Episode reward: 75.10574\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6687136 5.640488  5.669291  3.8822064 5.679306  5.6610446]\n",
      "Reset environment\n",
      "Episode reward: 851.39935\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6691732 5.640954  5.669745  3.8827732 5.679698  5.661504 ]\n",
      "Reset environment\n",
      "Episode reward: 5441.524\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6733375 5.645121  5.6739016 3.8873463 5.6833954 5.6656666]\n",
      "Reset environment\n",
      "Episode reward: 1586.5413\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6743565 5.6461234 5.6749396 3.8884933 5.6843047 5.6666856]\n",
      "Reset environment\n",
      "Episode reward: 1380.3286\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6758227 5.647588  5.6764064 3.89013   5.6855946 5.668151 ]\n",
      "Reset environment\n",
      "Episode reward: 3683.7546\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6785707 5.6503286 5.6791677 3.893184  5.68802   5.670901 ]\n",
      "Reset environment\n",
      "Episode reward: 1562.5233\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.679623  5.651382  5.6802154 3.8943903 5.688934  5.671953 ]\n",
      "Reset environment\n",
      "Episode reward: 5006.5083\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6833453 5.6550975 5.6839385 3.8985207 5.6922445 5.675678 ]\n",
      "Reset environment\n",
      "Episode reward: 2139.5793\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6847963 5.656551  5.6853833 3.9001276 5.6935334 5.677127 ]\n",
      "Reset environment\n",
      "Episode reward: 1757.546\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6859827 5.6577287 5.6865754 3.9014962 5.6945605 5.6783113]\n",
      "Reset environment\n",
      "Episode reward: -470.12466\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6852612 5.6568823 5.685978  3.900807  5.6938615 5.677593 ]\n",
      "Reset environment\n",
      "Episode reward: 2316.512\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.686736  5.6583    5.687504  3.9025493 5.6951337 5.6790657]\n",
      "Reset environment\n",
      "Episode reward: 4354.767\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.689913  5.6614637 5.6906915 3.9060698 5.6979485 5.6822486]\n",
      "Reset environment\n",
      "Episode reward: 4209.0117\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.693093  5.664638  5.693867  3.909575  5.700756  5.6854258]\n",
      "Reset environment\n",
      "Episode reward: 2616.4172\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.694966  5.666495  5.695751  3.9116724 5.702403  5.6872964]\n",
      "Reset environment\n",
      "Episode reward: 5662.3853\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6993027 5.6708336 5.700091  3.9164574 5.7062445 5.6916385]\n",
      "Reset environment\n",
      "Episode reward: 511.4461\n",
      "Total Steps: 21\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.6994753 5.671007  5.700261  3.9167147 5.706373  5.69181  ]\n",
      "Reset environment\n",
      "Episode reward: 2812.9863\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7014236 5.672959  5.7021947 3.9189045 5.70808   5.6937585]\n",
      "Reset environment\n",
      "Episode reward: 4634.7407\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.704934  5.6764855 5.7056847 3.922772  5.711214  5.6972694]\n",
      "Reset environment\n",
      "Episode reward: 4300.6104\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7081666 5.679741  5.7088885 3.9263399 5.7140737 5.700502 ]\n",
      "Reset environment\n",
      "Episode reward: 1991.1984\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7101026 5.681669  5.710826  3.9285    5.715776  5.7024384]\n",
      "Reset environment\n",
      "Episode reward: 2185.215\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7122054 5.6837726 5.712928  3.9308383 5.717641  5.7045426]\n",
      "Reset environment\n",
      "Episode reward: 809.7405\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.712773  5.6844187 5.713421  3.9314873 5.718201  5.7051153]\n",
      "Reset environment\n",
      "Episode reward: 1375.0538\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7136693 5.6853185 5.7143083 3.9325156 5.718982  5.706012 ]\n",
      "Reset environment\n",
      "Episode reward: 2089.675\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.71566   5.6872954 5.7163053 3.9347606 5.7207203 5.7079988]\n",
      "Reset environment\n",
      "Episode reward: 3851.1328\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7184505 5.6900797 5.719098  3.9378319 5.7231865 5.7107906]\n",
      "Reset environment\n",
      "Episode reward: 1968.5737\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7203536 5.691983  5.720996  3.9399762 5.72486   5.712693 ]\n",
      "Reset environment\n",
      "Episode reward: 1841.6564\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7124553 5.6841354 5.7130613 3.9239783 5.7176967 5.7048   ]\n",
      "Reset environment\n",
      "Episode reward: -446.15067\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.711777  5.683337  5.7125015 3.9232366 5.7171154 5.704123 ]\n",
      "Reset environment\n",
      "Episode reward: 1682.8286\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7128897 5.6844544 5.7136064 3.924522  5.718083  5.7052364]\n",
      "Reset environment\n",
      "Episode reward: 2199.7861\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7143393 5.685892  5.7150702 3.9261565 5.719356  5.706687 ]\n",
      "Reset environment\n",
      "Episode reward: 4552.533\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7183313 5.6898484 5.71909   3.9305546 5.7229075 5.710675 ]\n",
      "Reset environment\n",
      "Episode reward: 1918.8557\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.720183  5.6916966 5.7209425 3.9326396 5.7245345 5.7125273]\n",
      "Reset environment\n",
      "Episode reward: 2150.7358\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7216344 5.693196  5.722338  3.9343216 5.725806  5.713978 ]\n",
      "Reset environment\n",
      "Episode reward: 2146.4543\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.723686  5.695254  5.7243786 3.9366171 5.7276196 5.7160263]\n",
      "Reset environment\n",
      "Episode reward: 1492.4161\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7252445 5.6968026 5.7259517 3.9383748 5.729001  5.717585 ]\n",
      "Reset environment\n",
      "Episode reward: 903.63684\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7257447 5.697197  5.7265525 3.9390213 5.729459  5.718086 ]\n",
      "Reset environment\n",
      "Episode reward: 2367.11\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.727438  5.6989    5.7282386 3.9409122 5.7309775 5.7197785]\n",
      "Reset environment\n",
      "Episode reward: 1670.5569\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.728619  5.6999464 5.729554  3.9423795 5.7319922 5.720963 ]\n",
      "Reset environment\n",
      "Episode reward: -782.6904\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7271466 5.698203  5.728353  3.9411123 5.730555  5.7194967]\n",
      "Reset environment\n",
      "Episode reward: -414.19144\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7263927 5.697262  5.7277846 3.9404898 5.729811  5.718745 ]\n",
      "Reset environment\n",
      "Episode reward: 1953.2836\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7277446 5.6986365 5.7291155 3.9420094 5.731023  5.7201004]\n",
      "Reset environment\n",
      "Episode reward: 4860.147\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7314124 5.7022996 5.7327776 3.9460742 5.734266  5.7237687]\n",
      "Reset environment\n",
      "Episode reward: 2525.3682\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7331624 5.7040396 5.73454   3.9480782 5.735789  5.7255187]\n",
      "Reset environment\n",
      "Episode reward: 5416.955\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7372394 5.7081285 5.7386026 3.952562  5.7394176 5.7295966]\n",
      "Reset environment\n",
      "Episode reward: 5193.682\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.741093  5.711972  5.742461  3.9567628 5.742853  5.733454 ]\n",
      "Reset environment\n",
      "Episode reward: 6200.942\n",
      "Total Steps: 217\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.745704  5.716569  5.7470794 3.9618974 5.7469215 5.7380643]\n",
      "Reset environment\n",
      "Episode reward: 1524.1001\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.746693 5.717552 5.748075 3.963038 5.74778  5.739055]\n",
      "Reset environment\n",
      "Episode reward: 3406.5198\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.749199  5.7200637 5.750563  3.9658372 5.749983  5.741559 ]\n",
      "Reset environment\n",
      "Episode reward: 5101.552\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.753069  5.7239494 5.75441   3.9700787 5.7534437 5.745433 ]\n",
      "Reset environment\n",
      "Episode reward: 2794.6116\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7551103 5.726006  5.7564344 3.972318  5.7552657 5.747475 ]\n",
      "Reset environment\n",
      "Episode reward: 2979.3784\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7572618 5.7281857 5.758553  3.9746997 5.7571797 5.749625 ]\n",
      "Reset environment\n",
      "Episode reward: 4329.7485\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7604995 5.731438  5.7617702 3.9782672 5.76005   5.7528605]\n",
      "Reset environment\n",
      "Episode reward: 1877.4525\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.762316  5.73325   5.7635865 3.9803154 5.761637  5.7546773]\n",
      "Reset environment\n",
      "Episode reward: 5020.807\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.766015  5.7369266 5.7673006 3.9843974 5.76491   5.7583795]\n",
      "Reset environment\n",
      "Episode reward: 3245.1736\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7683096 5.739218  5.7695932 3.9869552 5.766925  5.7606726]\n",
      "Reset environment\n",
      "Episode reward: -513.1709\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.76755   5.738336  5.7689567 3.9862247 5.7661977 5.7599154]\n",
      "Reset environment\n",
      "Episode reward: 1805.3209\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.768851  5.739554  5.770342  3.9878633 5.7673297 5.7612157]\n",
      "Reset environment\n",
      "Episode reward: 3559.1504\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7714133 5.74207   5.772949  3.9907048 5.769606  5.7637763]\n",
      "Reset environment\n",
      "Episode reward: 1890.2415\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.772605  5.7433286 5.774071  3.9920764 5.770669  5.764968 ]\n",
      "Reset environment\n",
      "Episode reward: 1112.7394\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7737694 5.744493  5.7752347 3.9934428 5.771659  5.766134 ]\n",
      "Reset environment\n",
      "Episode reward: 3371.2996\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.776226  5.746969  5.7776637 3.9961596 5.7738333 5.768589 ]\n",
      "Reset environment\n",
      "Episode reward: 2541.4546\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7779913 5.7487555 5.7793913 3.9981377 5.77539   5.770352 ]\n",
      "Reset environment\n",
      "Episode reward: 3942.6895\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7808394 5.7515583 5.7822804 4.0013084 5.77796   5.7731953]\n",
      "Reset environment\n",
      "Episode reward: 4980.414\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7851577 5.755883  5.78658   4.0060387 5.7818155 5.7775083]\n",
      "Reset environment\n",
      "Episode reward: 5107.2085\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7890215 5.759735  5.7904496 4.010266  5.785247  5.781375 ]\n",
      "Reset environment\n",
      "Episode reward: 1528.3033\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.790572 5.761286 5.791998 4.012014 5.786608 5.782924]\n",
      "Reset environment\n",
      "Episode reward: 1581.0118\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7915874 5.762264  5.793047  4.013163  5.7875094 5.7839375]\n",
      "Reset environment\n",
      "Episode reward: 3245.7336\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7939377 5.7646303 5.795374  4.0157623 5.78959   5.786287 ]\n",
      "Reset environment\n",
      "Episode reward: 2135.2449\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7953506 5.7660923 5.796724  4.017392  5.7908    5.787702 ]\n",
      "Reset environment\n",
      "Episode reward: 3245.5344\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.7976074 5.7683434 5.798982  4.0199084 5.792782  5.7899613]\n",
      "Reset environment\n",
      "Episode reward: 1957.5605\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.798935  5.7696805 5.800302  4.0214295 5.793947  5.7912917]\n",
      "Reset environment\n",
      "Episode reward: 4546.352\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8021684 5.772884  5.80357   4.0250587 5.796787  5.7945294]\n",
      "Reset environment\n",
      "Episode reward: 4483.6143\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8055215 5.776257  5.8068933 4.0287485 5.7997713 5.7978773]\n",
      "Reset environment\n",
      "Episode reward: 3018.8313\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.807702  5.7784314 5.8090825 4.031173  5.801692  5.8000607]\n",
      "Reset environment\n",
      "Episode reward: 3559.1262\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8103004 5.7810025 5.811711  4.0340624 5.8039937 5.802662 ]\n",
      "Reset environment\n",
      "Episode reward: 5604.491\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.81444   5.7851343 5.815863  4.0386014 5.807676  5.806808 ]\n",
      "Reset environment\n",
      "Episode reward: 4637.105\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.817923  5.788633  5.819339  4.0424438 5.810761  5.8102922]\n",
      "Reset environment\n",
      "Episode reward: 1903.4772\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8192134 5.7899227 5.8206244 4.043904  5.8118896 5.811581 ]\n",
      "Reset environment\n",
      "Episode reward: 3495.2546\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.821782  5.7924585 5.8232174 4.046742  5.814171  5.8141456]\n",
      "Reset environment\n",
      "Episode reward: 3165.6484\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8239756 5.7946396 5.825416  4.0492015 5.816097  5.8163385]\n",
      "Reset environment\n",
      "Episode reward: 3189.421\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8262587 5.796877  5.827736  4.051757  5.818114  5.8186193]\n",
      "Reset environment\n",
      "Episode reward: 4697.5664\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8297577 5.8003793 5.8312354 4.0556326 5.821237  5.822122 ]\n",
      "Reset environment\n",
      "Episode reward: 281.74255\n",
      "Total Steps: 9\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8297777 5.8004007 5.831253  4.0556893 5.8212423 5.8221426]\n",
      "Reset environment\n",
      "Episode reward: 5488.7144\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8339314 5.804574  5.8353868 4.060254  5.824958  5.826298 ]\n",
      "Reset environment\n",
      "Episode reward: 3850.2222\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8367257 5.807401  5.8381453 4.063368  5.8274164 5.829093 ]\n",
      "Reset environment\n",
      "Episode reward: 2703.8982\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8386836 5.8093495 5.8401074 4.065541  5.829139  5.8310504]\n",
      "Reset environment\n",
      "Episode reward: 1910.7284\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.839971  5.8106527 5.8413806 4.0669875 5.8302794 5.8323393]\n",
      "Reset environment\n",
      "Episode reward: -105.03482\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8396645 5.8102474 5.8411684 4.066662  5.8300066 5.832032 ]\n",
      "Reset environment\n",
      "Episode reward: 4753.7925\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.843066  5.813635  5.8445816 4.070422  5.8330116 5.835434 ]\n",
      "Reset environment\n",
      "Episode reward: 2560.5146\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8448615 5.8154526 5.846356  4.0724087 5.834602  5.8372283]\n",
      "Reset environment\n",
      "Episode reward: 2096.2783\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8463206 5.81692   5.8478    4.0740485 5.8359017 5.8386827]\n",
      "Reset environment\n",
      "Episode reward: 1063.801\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8469534 5.81755   5.848434  4.0747933 5.8364544 5.839317 ]\n",
      "Reset environment\n",
      "Episode reward: 2917.5303\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.848974  5.819525  5.850495  4.0770617 5.838248  5.8413334]\n",
      "Reset environment\n",
      "Episode reward: 2163.8738\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8510075 5.821552  5.85253   4.079341  5.84003   5.8433642]\n",
      "Reset environment\n",
      "Episode reward: 1275.2317\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8523316 5.822871  5.8538475 4.080846  5.841176  5.844685 ]\n",
      "Reset environment\n",
      "Episode reward: 3715.6348\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.855052  5.8256035 5.8565593 4.0838575 5.8436036 5.847405 ]\n",
      "Reset environment\n",
      "Episode reward: 2615.0881\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8568063 5.8273697 5.8583045 4.085839  5.845145  5.8491597]\n",
      "Reset environment\n",
      "Episode reward: 1430.6523\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.857704  5.828151  5.8593154 4.086943  5.845942  5.8500624]\n",
      "Reset environment\n",
      "Episode reward: 1822.0583\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8587418 5.8292613 5.860282  4.088205  5.8468175 5.851103 ]\n",
      "Reset environment\n",
      "Episode reward: 2784.9922\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.860616  5.8311877 5.8620915 4.0903444 5.8484535 5.852977 ]\n",
      "Reset environment\n",
      "Episode reward: -561.49805\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.859913  5.8304224 5.8614516 4.0895147 5.8478413 5.8522778]\n",
      "Reset environment\n",
      "Episode reward: 2153.6208\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.861405  5.8318877 5.8629622 4.091182  5.849159  5.853768 ]\n",
      "Reset environment\n",
      "Episode reward: 5228.399\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8653207 5.8358097 5.866873  4.0955153 5.852611  5.857682 ]\n",
      "Reset environment\n",
      "Episode reward: -95.26001\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.865072  5.8356166 5.8665814 4.095241  5.8523874 5.8574386]\n",
      "Reset environment\n",
      "Episode reward: 3299.4846\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8673553 5.8378997 5.8688602 4.0977955 5.8543863 5.8597226]\n",
      "Reset environment\n",
      "Episode reward: 794.3506\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8676453 5.838316  5.869033  4.0984025 5.854595  5.860021 ]\n",
      "Reset environment\n",
      "Episode reward: 5564.797\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.87173   5.8424134 5.8731036 4.1029315 5.85821   5.86411  ]\n",
      "Reset environment\n",
      "Episode reward: 1812.2965\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8729444 5.843638  5.874304  4.1043215 5.8592806 5.865325 ]\n",
      "Reset environment\n",
      "Episode reward: 2493.4495\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8746767 5.8453903 5.8760166 4.1062446 5.860816  5.8670616]\n",
      "Reset environment\n",
      "Episode reward: 2415.5986\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8762407 5.846882  5.8776484 4.1080384 5.862201  5.8686256]\n",
      "Reset environment\n",
      "Episode reward: 3269.5156\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.878494  5.8491144 5.8799176 4.110563  5.8641863 5.8708816]\n",
      "Reset environment\n",
      "Episode reward: 3421.015\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8807583 5.8513165 5.8822465 4.1131573 5.866181  5.8731484]\n",
      "Reset environment\n",
      "Episode reward: 5639.531\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.884942  5.8554907 5.88643   4.1177692 5.8698893 5.877332 ]\n",
      "Reset environment\n",
      "Episode reward: 3215.6357\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8872366 5.8577495 5.888761  4.120317  5.871939  5.8796263]\n",
      "Reset environment\n",
      "Episode reward: 1433.2936\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8881593 5.858671  5.8896856 4.1213713 5.8727446 5.880549 ]\n",
      "Reset environment\n",
      "Episode reward: 3379.8162\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8905745 5.8610506 5.8921227 4.1240993 5.8748674 5.882962 ]\n",
      "Reset environment\n",
      "Episode reward: 1298.8926\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8919177 5.86239   5.8934636 4.1256113 5.8760405 5.8843045]\n",
      "Reset environment\n",
      "Episode reward: 4194.407\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8950152 5.8654647 5.896573  4.1290255 5.8787827 5.8874006]\n",
      "Reset environment\n",
      "Episode reward: 2411.906\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8968334 5.867287  5.8983784 4.131136  5.8804383 5.8892264]\n",
      "Reset environment\n",
      "Episode reward: 1236.4939\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.8981156 5.868567  5.899655  4.1326094 5.8815413 5.8905067]\n",
      "Reset environment\n",
      "Episode reward: -723.3646\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.897239  5.867792  5.8986917 4.131687  5.8807397 5.8896356]\n",
      "Reset environment\n",
      "Episode reward: 1558.1064\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.898235  5.868819  5.8996553 4.132816  5.881622  5.8906326]\n",
      "Reset environment\n",
      "Episode reward: 3169.9531\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.900437  5.8710117 5.9018598 4.135249  5.8835807 5.892839 ]\n",
      "Reset environment\n",
      "Episode reward: 4617.304\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9038715 5.87443   5.9052973 4.139005  5.886627  5.8962693]\n",
      "Reset environment\n",
      "Episode reward: 586.0276\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9040904 5.87455   5.9056106 4.139338  5.8868365 5.8964844]\n",
      "Reset environment\n",
      "Episode reward: 2093.8225\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9060674 5.8765273 5.9075866 4.1415462 5.888579  5.8984604]\n",
      "Reset environment\n",
      "Episode reward: 3326.3384\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9084682 5.878946  5.9099655 4.1441817 5.890716  5.9008594]\n",
      "Reset environment\n",
      "Episode reward: 1378.3176\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9093504 5.8798203 5.910854  4.1451883 5.89149   5.90174  ]\n",
      "Reset environment\n",
      "Episode reward: 2294.8967\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.910887  5.881292  5.9124465 4.146939  5.8928504 5.9032745]\n",
      "Reset environment\n",
      "Episode reward: 4769.095\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9144177 5.884835  5.915959  4.150833  5.895993  5.906801 ]\n",
      "Reset environment\n",
      "Episode reward: 3683.3801\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.917083  5.8875136 5.918609  4.1537633 5.898358  5.9094653]\n",
      "Reset environment\n",
      "Episode reward: 320.88858\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9170175 5.887303  5.918687  4.1538453 5.8982835 5.9094033]\n",
      "Reset environment\n",
      "Episode reward: 2079.306\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9183807 5.888628  5.920082  4.155377  5.8994927 5.9107676]\n",
      "Reset environment\n",
      "Episode reward: 3976.075\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9212766 5.891527  5.9229655 4.1585813 5.902062  5.913662 ]\n",
      "Reset environment\n",
      "Episode reward: 3085.7637\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9234457 5.893729  5.9250903 4.1609874 5.903989  5.915831 ]\n",
      "Reset environment\n",
      "Episode reward: 4211.62\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.926465  5.8967576 5.928103  4.164331  5.9066806 5.918856 ]\n",
      "Reset environment\n",
      "Episode reward: -885.2452\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.925092  5.895129  5.926987  4.1631374 5.9053197 5.9174857]\n",
      "Reset environment\n",
      "Episode reward: 3325.6323\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9274764 5.897482  5.929394  4.1657734 5.907436  5.919869 ]\n",
      "Reset environment\n",
      "Episode reward: 2532.9084\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9292407 5.899234  5.9311647 4.1677513 5.9089804 5.921632 ]\n",
      "Reset environment\n",
      "Episode reward: 1935.7697\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.931069  5.901063  5.9329896 4.1698074 5.910589  5.9234586]\n",
      "Reset environment\n",
      "Episode reward: 1800.4403\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.932453  5.9023824 5.9344373 4.17136   5.91187   5.924839 ]\n",
      "Reset environment\n",
      "Episode reward: 1824.1412\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9342127 5.9041405 5.936196  4.173315  5.9134264 5.9265995]\n",
      "Reset environment\n",
      "Episode reward: 3328.8223\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9365797 5.9064713 5.9385962 4.1759515 5.915525  5.9289656]\n",
      "Reset environment\n",
      "Episode reward: 4017.4006\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.939527  5.9093904 5.941567  4.1791787 5.918154  5.9319115]\n",
      "Reset environment\n",
      "Episode reward: 1865.9694\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.940783  5.910648  5.9428215 4.1805825 5.919262  5.9331675]\n",
      "Reset environment\n",
      "Episode reward: 5064.81\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.94441   5.9142895 5.946431  4.184598  5.922479  5.936791 ]\n",
      "Reset environment\n",
      "Episode reward: 4855.994\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.947933  5.917829  5.9499416 4.188539  5.9255815 5.9403133]\n",
      "Reset environment\n",
      "Episode reward: 2133.7485\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.949354  5.9192777 5.951334  4.190124  5.92684   5.941735 ]\n",
      "Reset environment\n",
      "Episode reward: 3599.4944\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.951863  5.9217925 5.9538302 4.192932  5.9290495 5.9442444]\n",
      "Reset environment\n",
      "Episode reward: 4910.869\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9554973 5.925433  5.9574556 4.1969385 5.9322824 5.94788  ]\n",
      "Reset environment\n",
      "Episode reward: 2206.9673\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.956931  5.9268055 5.958946  4.198568  5.9335546 5.9493165]\n",
      "Reset environment\n",
      "Episode reward: 5728.638\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9611855 5.9310565 5.963201  4.203268  5.937329  5.9535675]\n",
      "Reset environment\n",
      "Episode reward: 1747.8302\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9623504 5.9322453 5.9643416 4.20458   5.938364  5.954734 ]\n",
      "Reset environment\n",
      "Episode reward: 3006.281\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.964478  5.9343557 5.966491  4.206956  5.94025   5.956857 ]\n",
      "Reset environment\n",
      "Episode reward: 5394.522\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9683676 5.9382544 5.970357  4.211233  5.943706  5.9607434]\n",
      "Reset environment\n",
      "Episode reward: 5218.543\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9722376 5.942112  5.9742355 4.215483  5.9471493 5.9646144]\n",
      "Reset environment\n",
      "Episode reward: 214.73007\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9720454 5.9417496 5.974208  4.215586  5.94691   5.9644256]\n",
      "Reset environment\n",
      "Episode reward: 3989.0815\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9748654 5.9445634 5.9770293 4.218698  5.949398  5.967246 ]\n",
      "Reset environment\n",
      "Episode reward: 2267.733\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.976379  5.946094  5.9785233 4.2203836 5.9507318 5.968761 ]\n",
      "Reset environment\n",
      "Episode reward: 2266.621\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9776855 5.9474955 5.979735  4.221943  5.95188   5.9700694]\n",
      "Reset environment\n",
      "Episode reward: 1363.6805\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.97908   5.9488873 5.9811273 4.2235107 5.9531016 5.9714646]\n",
      "Reset environment\n",
      "Episode reward: 2058.3674\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.981014  5.9508276 5.9830513 4.2256618 5.954807  5.9733977]\n",
      "Reset environment\n",
      "Episode reward: 1532.9641\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.982028  5.9517245 5.984177  4.226859  5.9557123 5.974413 ]\n",
      "Reset environment\n",
      "Episode reward: 2243.494\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.983378  5.953135  5.9854608 4.2284536 5.956864  5.975764 ]\n",
      "Reset environment\n",
      "Episode reward: 2213.0159\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.985425  5.9551735 5.9875126 4.2307334 5.9586697 5.977811 ]\n",
      "Reset environment\n",
      "Episode reward: 1958.1179\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.986759  5.9565225 5.98883   4.232228  5.9598637 5.979146 ]\n",
      "Reset environment\n",
      "Episode reward: 1535.2677\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.98772   5.957462  5.9898124 4.2333107 5.960722  5.9801083]\n",
      "Reset environment\n",
      "Episode reward: 2596.1077\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9894314 5.959098  5.991586  4.23525   5.962237  5.981819 ]\n",
      "Reset environment\n",
      "Episode reward: 1573.4836\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9904513 5.9601192 5.992601  4.2364225 5.963121  5.982839 ]\n",
      "Reset environment\n",
      "Episode reward: 2051.2437\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.991807  5.9614797 5.9939485 4.237989  5.96429   5.984196 ]\n",
      "Reset environment\n",
      "Episode reward: 5173.93\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9956203 5.965291  5.9977612 4.242224  5.9676557 5.9880075]\n",
      "Reset environment\n",
      "Episode reward: 2231.591\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9971414 5.966796  5.9993005 4.243942  5.968995  5.9895315]\n",
      "Reset environment\n",
      "Episode reward: 3806.9004\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [5.9998913 5.9695325 6.00206   4.246991  5.9714236 5.9922814]\n",
      "Reset environment\n",
      "Episode reward: 3077.5618\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.002044  5.9716644 6.0042257 4.2494025 5.9733143 5.9944344]\n",
      "Reset environment\n",
      "Episode reward: 3647.3154\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.004664  5.9742994 6.006824  4.2522902 5.9756346 5.997056 ]\n",
      "Reset environment\n",
      "Episode reward: 184.16312\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.004673  5.974394  6.0067554 4.2523537 5.9756613 5.99707  ]\n",
      "Reset environment\n",
      "Episode reward: -694.93634\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0038333 5.9735694 6.0059114 4.2515507 5.9748526 5.9962325]\n",
      "Reset environment\n",
      "Episode reward: 1672.7212\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0049324 5.974687  6.00699   4.2527914 5.975832  5.9973297]\n",
      "Reset environment\n",
      "Episode reward: 1738.498\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0060716 5.9758425 6.0081096 4.254074  5.9768434 5.9984694]\n",
      "Reset environment\n",
      "Episode reward: 5182.551\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.009893  5.9796653 6.011912  4.2582936 5.980243  6.0022855]\n",
      "Reset environment\n",
      "Episode reward: 4578.119\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0132184 5.983016  6.0152116 4.261964  5.9831924 6.0056133]\n",
      "Reset environment\n",
      "Episode reward: 3669.4094\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0158057 5.9855843 6.017811  4.2648754 5.985469  6.008199 ]\n",
      "Reset environment\n",
      "Episode reward: 1447.2549\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.016734  5.9865093 6.018743  4.265935  5.9862866 6.0091286]\n",
      "Reset environment\n",
      "Episode reward: 1607.0044\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.017785  5.9875827 6.019771  4.267124  5.9872212 6.010179 ]\n",
      "Reset environment\n",
      "Episode reward: 4330.908\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0208755 5.990677  6.0228553 4.270506  5.9899726 6.013269 ]\n",
      "Reset environment\n",
      "Episode reward: 1722.3445\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.02202   5.991833  6.0239873 4.2717996 5.990985  6.0144157]\n",
      "Reset environment\n",
      "Episode reward: 2472.7205\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0236297 5.993384  6.0256495 4.27364   5.9924088 6.0160246]\n",
      "Reset environment\n",
      "Episode reward: 3142.5286\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.025787  5.9954886 6.0278544 4.276052  5.994339  6.01818  ]\n",
      "Reset environment\n",
      "Episode reward: 5853.474\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0300155 5.9997272 6.032068  4.280703  5.9981117 6.02241  ]\n",
      "Reset environment\n",
      "Episode reward: 1568.1361\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0314083 6.0011206 6.0334563 4.282261  5.9993334 6.0238023]\n",
      "Reset environment\n",
      "Episode reward: 2628.168\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0332313 6.002953  6.0352693 4.2842927 6.000944  6.0256267]\n",
      "Reset environment\n",
      "Episode reward: 1986.1755\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0344176 6.0041995 6.036384  4.285675  6.0019703 6.026814 ]\n",
      "Reset environment\n",
      "Episode reward: 2439.8342\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0362763 6.0059657 6.0383363 4.2878175 6.00364   6.028673 ]\n",
      "Reset environment\n",
      "Episode reward: 2042.6105\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0381536 6.007851  6.0402107 4.289941  6.005283  6.030551 ]\n",
      "Reset environment\n",
      "Episode reward: 791.7406\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.038452  6.008267  6.040398  4.2904325 6.0055842 6.030855 ]\n",
      "Reset environment\n",
      "Episode reward: 3336.5103\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.040826  6.0106106 6.0428014 4.293051  6.0077014 6.0332284]\n",
      "Reset environment\n",
      "Episode reward: 4934.178\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.044447  6.0142446 6.0463953 4.297033  6.010934  6.0368466]\n",
      "Reset environment\n",
      "Episode reward: 4916.086\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.048044  6.0178185 6.0500083 4.301015  6.014125  6.0404425]\n",
      "Reset environment\n",
      "Episode reward: 996.9501\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.048724  6.018506  6.0506816 4.301793  6.014746  6.041125 ]\n",
      "Reset environment\n",
      "Episode reward: 1936.0935\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0500154 6.0198174 6.051951  4.3032527 6.015892  6.0424147]\n",
      "Reset environment\n",
      "Episode reward: 2193.4355\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.052032  6.0218244 6.053972  4.305506  6.0176597 6.04443  ]\n",
      "Reset environment\n",
      "Episode reward: 3499.6187\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.05454   6.024343  6.0564604 4.3082423 6.0198956 6.0469346]\n",
      "Reset environment\n",
      "Episode reward: 2945.3223\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.056594  6.0263715 6.058539  4.3105416 6.0217133 6.048989 ]\n",
      "Reset environment\n",
      "Episode reward: 1604.727\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.057609  6.0273776 6.0595646 4.311711  6.022594  6.050004 ]\n",
      "Reset environment\n",
      "Episode reward: 1868.8125\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.058871  6.0286307 6.060833  4.313113  6.023709  6.051266 ]\n",
      "Reset environment\n",
      "Episode reward: 3500.3667\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.061283  6.0310335 6.063255  4.315782  6.0258465 6.0536795]\n",
      "Reset environment\n",
      "Episode reward: 1652.5447\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.062621  6.032359  6.064606  4.3173037 6.027052  6.0550194]\n",
      "Reset environment\n",
      "Episode reward: 3855.8423\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0653477 6.0351033 6.067312  4.3203387 6.029453  6.05775  ]\n",
      "Reset environment\n",
      "Episode reward: -698.06793\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0645123 6.03428   6.0664663 4.3195076 6.028661  6.056912 ]\n",
      "Reset environment\n",
      "Episode reward: 3296.7378\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.066866  6.036646  6.068798  4.322075  6.030759  6.0592637]\n",
      "Reset environment\n",
      "Episode reward: 2280.0974\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.068959  6.0387373 6.0708885 4.3244042 6.032615  6.0613565]\n",
      "Reset environment\n",
      "Episode reward: 2641.8933\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0707297 6.0404553 6.072706  4.326389  6.0341964 6.0631266]\n",
      "Reset environment\n",
      "Episode reward: 3670.8108\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0733185 6.043076  6.0752635 4.3292503 6.036492  6.0657163]\n",
      "Reset environment\n",
      "Episode reward: 2143.2024\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0747    6.0444546 6.076648  4.330799  6.037706  6.067098 ]\n",
      "Reset environment\n",
      "Episode reward: 1299.009\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0760174 6.0457687 6.0779643 4.3322906 6.0388517 6.0684156]\n",
      "Reset environment\n",
      "Episode reward: 4786.651\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.079526  6.0492783 6.081467  4.336136  6.0419908 6.071925 ]\n",
      "Reset environment\n",
      "Episode reward: 4491.321\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0826945 6.052463  6.084616  4.339633  6.044795  6.0750957]\n",
      "Reset environment\n",
      "Episode reward: 2002.5874\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0845723 6.054342  6.086483  4.341722  6.046453  6.076969 ]\n",
      "Reset environment\n",
      "Episode reward: 4722.523\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.087908  6.0576825 6.089819  4.345399  6.0493984 6.0803103]\n",
      "Reset environment\n",
      "Episode reward: 1204.4534\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.088629  6.0584116 6.0905304 4.346234  6.050033  6.0810337]\n",
      "Reset environment\n",
      "Episode reward: 4580.417\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0919003 6.0617003 6.0937896 4.349866  6.0529323 6.0843062]\n",
      "Reset environment\n",
      "Episode reward: -692.45135\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0910535 6.0608697 6.0929403 4.348995  6.052137  6.083461 ]\n",
      "Reset environment\n",
      "Episode reward: 2806.5076\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0928497 6.0625854 6.0948057 4.3510647 6.0537353 6.085256 ]\n",
      "Reset environment\n",
      "Episode reward: 2666.0254\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0945935 6.0642624 6.096616  4.353043  6.0552945 6.0869994]\n",
      "Reset environment\n",
      "Episode reward: 2107.1487\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0959897 6.0656843 6.097988  4.3546076 6.0565343 6.0883975]\n",
      "Reset environment\n",
      "Episode reward: 2814.7744\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.0979376 6.0676036 6.099961  4.3567743 6.058259  6.0903435]\n",
      "Reset environment\n",
      "Episode reward: 4448.6343\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1011515 6.0708375 6.1031585 4.360325  6.0611167 6.093559 ]\n",
      "Reset environment\n",
      "Episode reward: 2046.9479\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.102531  6.072229  6.1045256 4.361858  6.0623393 6.094937 ]\n",
      "Reset environment\n",
      "Episode reward: 1357.4165\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1039023 6.0736027 6.105896  4.363401  6.0635448 6.0963097]\n",
      "Reset environment\n",
      "Episode reward: 2013.2466\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.105249  6.0749564 6.107235  4.364919  6.064737  6.0976596]\n",
      "Reset environment\n",
      "Episode reward: 2397.3665\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.10687   6.076597  6.108831  4.3667336 6.0661736 6.09928  ]\n",
      "Reset environment\n",
      "Episode reward: 2260.0195\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1083956 6.0781145 6.110366  4.368462  6.067508  6.1008077]\n",
      "Reset environment\n",
      "Episode reward: 2599.1853\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1101847 6.079882  6.112166  4.3704567 6.0690823 6.102596 ]\n",
      "Reset environment\n",
      "Episode reward: 2385.0261\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1123443 6.082035  6.114328  4.372855  6.070984  6.104751 ]\n",
      "Reset environment\n",
      "Episode reward: 3157.25\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.114474  6.0841103 6.116508  4.3752513 6.072881  6.106881 ]\n",
      "Reset environment\n",
      "Episode reward: 4810.893\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.117874  6.087532  6.119874  4.3790073 6.0759    6.1102824]\n",
      "Reset environment\n",
      "Episode reward: -395.39835\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1173615 6.086974  6.119404  4.3783154 6.075413  6.1097717]\n",
      "Reset environment\n",
      "Episode reward: 2957.8716\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.119292  6.088941  6.1212983 4.3804917 6.0771403 6.111706 ]\n",
      "Reset environment\n",
      "Episode reward: 4597.21\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1224976 6.092164  6.124477  4.384062  6.0799556 6.114912 ]\n",
      "Reset environment\n",
      "Episode reward: 5462.8037\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.126326  6.095928  6.1283674 4.388356  6.083335  6.1187453]\n",
      "Reset environment\n",
      "Episode reward: 2686.5833\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1281176 6.0977206 6.1301584 4.3903394 6.0849233 6.1205373]\n",
      "Reset environment\n",
      "Episode reward: 1878.0352\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.129876  6.09948   6.1319127 4.392306  6.086472  6.122296 ]\n",
      "Reset environment\n",
      "Episode reward: 4294.5767\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.13296   6.102547  6.1350055 4.3957214 6.0891976 6.1253786]\n",
      "Reset environment\n",
      "Episode reward: 4137.278\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1359363 6.1055326 6.1379724 4.399005  6.0918503 6.128357 ]\n",
      "Reset environment\n",
      "Episode reward: 2119.733\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.137285  6.1069098 6.1392827 4.4005485 6.093022  6.1297045]\n",
      "Reset environment\n",
      "Episode reward: 508.12057\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.137351  6.1071    6.139239  4.4006042 6.093127  6.129775 ]\n",
      "Reset environment\n",
      "Episode reward: 3309.3662\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1396546 6.1094213 6.1415215 4.4031887 6.095151  6.1320786]\n",
      "Reset environment\n",
      "Episode reward: 1621.9133\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1412125 6.110981  6.1430817 4.404945  6.0965166 6.1336384]\n",
      "Reset environment\n",
      "Episode reward: 2880.3306\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.143037  6.1128597 6.1448436 4.4070396 6.0981236 6.1354637]\n",
      "Reset environment\n",
      "Episode reward: 2566.192\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.144668  6.114429  6.146526  4.408902  6.0995665 6.137095 ]\n",
      "Reset environment\n",
      "Episode reward: 2768.2324\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1465664 6.116297  6.148444  4.4110227 6.101239  6.138992 ]\n",
      "Reset environment\n",
      "Episode reward: 4944.968\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1506834 6.1204214 6.152555  4.4155526 6.104918  6.1431065]\n",
      "Reset environment\n",
      "Episode reward: 5329.219\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.154554  6.124309  6.156404  4.419834  6.1083694 6.146974 ]\n",
      "Reset environment\n",
      "Episode reward: 2235.7036\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1559653 6.1257253 6.1578083 4.421442  6.109606  6.1483884]\n",
      "Reset environment\n",
      "Episode reward: 2492.3994\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.157691  6.1274595 6.159516  4.4233456 6.1111445 6.1501126]\n",
      "Reset environment\n",
      "Episode reward: 2270.052\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1591964 6.128984  6.160997  4.425052  6.112463  6.151622 ]\n",
      "Reset environment\n",
      "Episode reward: 5275.488\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.16288   6.1326613 6.1646857 4.4291706 6.115712  6.155308 ]\n",
      "Reset environment\n",
      "Episode reward: 5911.476\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1671076 6.1368833 6.1689134 4.433823  6.119451  6.1595407]\n",
      "Reset environment\n",
      "Episode reward: 1702.316\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1682005 6.1379776 6.1700077 4.435066  6.1204047 6.1606355]\n",
      "Reset environment\n",
      "Episode reward: 1990.5756\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.169477  6.1392703 6.171268  4.436533  6.121523  6.1619115]\n",
      "Reset environment\n",
      "Episode reward: 2737.1208\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.171105  6.140975  6.172823  4.4384427 6.1229377 6.1635385]\n",
      "Reset environment\n",
      "Episode reward: 3015.7183\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1731763 6.1430764 6.174862  4.4407535 6.1247606 6.165609 ]\n",
      "Reset environment\n",
      "Episode reward: 1889.0322\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.174909  6.1448083 6.1765943 4.4427276 6.126271  6.1673417]\n",
      "Reset environment\n",
      "Episode reward: -573.04376\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1739736 6.143733  6.175799  4.4419055 6.1253757 6.166407 ]\n",
      "Reset environment\n",
      "Episode reward: 2145.974\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1754117 6.1451654 6.177238  4.4435277 6.1266356 6.167846 ]\n",
      "Reset environment\n",
      "Episode reward: 1409.8855\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.176823  6.146584  6.1786494 4.4450974 6.1278853 6.1692605]\n",
      "Reset environment\n",
      "Episode reward: 5475.9326\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.180745  6.150505  6.1825633 4.4493785 6.131377  6.1731844]\n",
      "Reset environment\n",
      "Episode reward: 3588.8306\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1832585 6.1530085 6.185078  4.452185  6.133581  6.175695 ]\n",
      "Reset environment\n",
      "Episode reward: 1355.0244\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1846204 6.1543694 6.186438  4.453708  6.134777  6.1770554]\n",
      "Reset environment\n",
      "Episode reward: 2738.1426\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1864142 6.156164  6.1882296 4.45572   6.136355  6.178851 ]\n",
      "Reset environment\n",
      "Episode reward: 2562.0298\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1881285 6.1578445 6.189981  4.4576406 6.137877  6.180563 ]\n",
      "Reset environment\n",
      "Episode reward: 2751.3088\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1899385 6.159651  6.1917887 4.459646  6.139467  6.1823707]\n",
      "Reset environment\n",
      "Episode reward: 4103.4346\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1928782 6.1626143 6.1947083 4.462867  6.1420894 6.185313 ]\n",
      "Reset environment\n",
      "Episode reward: 1724.815\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1939936 6.1637583 6.1958017 4.464128  6.143083  6.18643  ]\n",
      "Reset environment\n",
      "Episode reward: 5111.005\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.1976748 6.1674504 6.1994696 4.468204  6.146334  6.190112 ]\n",
      "Reset environment\n",
      "Episode reward: 6229.7217\n",
      "Total Steps: 215\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.20224   6.1720185 6.2040253 4.4732428 6.1504245 6.1946807]\n",
      "Reset environment\n",
      "Episode reward: 1392.3395\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2030888 6.17289   6.204849  4.4742064 6.15117   6.1955295]\n",
      "Reset environment\n",
      "Episode reward: 2578.9539\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2050543 6.1748157 6.206838  4.4764647 6.152913  6.197492 ]\n",
      "Reset environment\n",
      "Episode reward: 2019.8967\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2069235 6.176683  6.208706  4.4785457 6.1545634 6.19936  ]\n",
      "Reset environment\n",
      "Episode reward: 3702.0852\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2095284 6.1792727 6.2113233 4.4814396 6.1568685 6.201963 ]\n",
      "Reset environment\n",
      "Episode reward: 5831.822\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2136803 6.1833906 6.2154956 4.486015  6.1605663 6.206115 ]\n",
      "Reset environment\n",
      "Episode reward: 434.54257\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.213632 6.183519 6.215288 4.486134 6.160498 6.206077]\n",
      "Reset environment\n",
      "Episode reward: 1723.1447\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2152753 6.1851645 6.2169294 4.4879546 6.1619563 6.207722 ]\n",
      "Reset environment\n",
      "Episode reward: 1996.387\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2170863 6.1869802 6.2187395 4.4900055 6.1635423 6.209535 ]\n",
      "Reset environment\n",
      "Episode reward: 4304.445\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2201715 6.1900735 6.2218137 4.4933934 6.1663017 6.21262  ]\n",
      "Reset environment\n",
      "Episode reward: 1280.9366\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.22094   6.190832  6.222596  4.4942756 6.1669765 6.21339  ]\n",
      "Reset environment\n",
      "Episode reward: 3269.483\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2232046 6.1930637 6.2248883 4.496791  6.1689825 6.2156515]\n",
      "Reset environment\n",
      "Episode reward: 3215.1782\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.225349  6.195226  6.227014  4.4991775 6.170882  6.2177954]\n",
      "Reset environment\n",
      "Episode reward: 3989.7595\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2281523 6.1980414 6.2297997 4.5022798 6.1733613 6.2205963]\n",
      "Reset environment\n",
      "Episode reward: 2152.8252\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2294993 6.1993723 6.2311625 4.503806  6.174542  6.221943 ]\n",
      "Reset environment\n",
      "Episode reward: 2001.8008\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2313123 6.201188  6.2329674 4.505861  6.1761327 6.223757 ]\n",
      "Reset environment\n",
      "Episode reward: 3591.7605\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.233847  6.2037344 6.235482  4.50863   6.178394  6.226292 ]\n",
      "Reset environment\n",
      "Episode reward: 2032.9475\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.23568   6.2055697 6.2373137 4.5106974 6.180007  6.228126 ]\n",
      "Reset environment\n",
      "Episode reward: 3251.5344\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2379723 6.2078595 6.239606  4.5132203 6.1820345 6.2304144]\n",
      "Reset environment\n",
      "Episode reward: 1801.0098\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.239125  6.209031  6.2407417 4.5145407 6.183051  6.2315683]\n",
      "Reset environment\n",
      "Episode reward: 3250.7148\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2412558 6.211088  6.242935  4.516943  6.1849527 6.2336965]\n",
      "Reset environment\n",
      "Episode reward: 5257.823\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2450595 6.2149153 6.2467165 4.5211163 6.1883545 6.2375   ]\n",
      "Reset environment\n",
      "Episode reward: 5508.1094\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.249035  6.218909  6.2506666 4.525485  6.1919003 6.241475 ]\n",
      "Reset environment\n",
      "Episode reward: 3657.044\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2515364 6.2214103 6.253165  4.5282445 6.1941133 6.243977 ]\n",
      "Reset environment\n",
      "Episode reward: 4911.0913\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.255085  6.2249446 6.256729  4.5321336 6.1972666 6.2475257]\n",
      "Reset environment\n",
      "Episode reward: -303.15884\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2545557 6.224336  6.2562795 4.531529  6.196798  6.2470007]\n",
      "Reset environment\n",
      "Episode reward: 2431.908\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2561707 6.225969  6.257879  4.5333614 6.198209  6.248617 ]\n",
      "Reset environment\n",
      "Episode reward: 2709.8994\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2579603 6.2277207 6.2597003 4.535385  6.1997805 6.2504044]\n",
      "Reset environment\n",
      "Episode reward: 1825.263\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2596602 6.2294173 6.2613993 4.53729   6.2012734 6.252102 ]\n",
      "Reset environment\n",
      "Episode reward: 4965.8926\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2632356 6.2329893 6.264975  4.5412307 6.204429  6.2556767]\n",
      "Reset environment\n",
      "Episode reward: 1724.141\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2648473 6.2346034 6.266583  4.543038  6.2058377 6.2572885]\n",
      "Reset environment\n",
      "Episode reward: 1753.0315\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2659855 6.2357345 6.2677255 4.544325  6.206832  6.2584267]\n",
      "Reset environment\n",
      "Episode reward: 1662.8718\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.267041  6.2367935 6.2687793 4.5455174 6.2077622 6.2594843]\n",
      "Reset environment\n",
      "Episode reward: 1999.6617\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.26829   6.2380075 6.2700586 4.5469346 6.208862  6.2607307]\n",
      "Reset environment\n",
      "Episode reward: 1830.7212\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2694483 6.239152  6.2712297 4.5482526 6.20987   6.261889 ]\n",
      "Reset environment\n",
      "Episode reward: 2002.0537\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.270729  6.240423  6.2725205 4.5497074 6.2109876 6.2631683]\n",
      "Reset environment\n",
      "Episode reward: 4334.6206\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.273822  6.2435126 6.2756147 4.5530987 6.213734  6.266265 ]\n",
      "Reset environment\n",
      "Episode reward: 3768.7925\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2764707 6.2461762 6.278245  4.555978  6.216091  6.2689133]\n",
      "Reset environment\n",
      "Episode reward: 2390.0073\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.278013  6.247669  6.279826  4.557715  6.217463  6.2704554]\n",
      "Reset environment\n",
      "Episode reward: 2545.8508\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.279713  6.2493925 6.281495  4.5595937 6.2189736 6.2721553]\n",
      "Reset environment\n",
      "Episode reward: 4894.1616\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2831454 6.2528076 6.284925  4.563357  6.222013  6.275588 ]\n",
      "Reset environment\n",
      "Episode reward: 248.24374\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2829876 6.252494  6.2849264 4.5632763 6.22185   6.27543  ]\n",
      "Reset environment\n",
      "Episode reward: 1982.3083\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2841344 6.2535796 6.2861223 4.56461   6.2228537 6.276573 ]\n",
      "Reset environment\n",
      "Episode reward: -1253.352\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2824955 6.2518053 6.2846313 4.5631223 6.221262  6.274937 ]\n",
      "Reset environment\n",
      "Episode reward: 3680.5952\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.285058  6.2543507 6.287207  4.565982  6.2235174 6.277499 ]\n",
      "Reset environment\n",
      "Episode reward: 3597.2505\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2874794 6.2567644 6.2896338 4.5686707 6.2256627 6.279925 ]\n",
      "Reset environment\n",
      "Episode reward: -57.041046\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2870708 6.2562575 6.289332  4.568314  6.2252865 6.279519 ]\n",
      "Reset environment\n",
      "Episode reward: -894.18994\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2860556 6.2552915 6.2882724 4.5671506 6.224391  6.2785068]\n",
      "Reset environment\n",
      "Episode reward: 2926.5405\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.287941  6.2571087 6.2902193 4.569298  6.2260675 6.2803926]\n",
      "Reset environment\n",
      "Episode reward: 4822.7803\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2913804 6.260547  6.29366   4.573077  6.229106  6.283832 ]\n",
      "Reset environment\n",
      "Episode reward: 2599.3228\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.293111  6.2623053 6.295365  4.5749955 6.230635  6.285562 ]\n",
      "Reset environment\n",
      "Episode reward: 2449.7317\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2946615 6.2638087 6.296956  4.5767617 6.2320065 6.287111 ]\n",
      "Reset environment\n",
      "Episode reward: 3673.999\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.29721   6.2663937 6.29946   4.5795627 6.2342806 6.28966  ]\n",
      "Reset environment\n",
      "Episode reward: 2363.3623\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.2987456 6.267922  6.300998  4.5813065 6.2356253 6.291194 ]\n",
      "Reset environment\n",
      "Episode reward: 3312.6106\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.30105   6.270217  6.303313  4.5838614 6.237662  6.2935004]\n",
      "Reset environment\n",
      "Episode reward: 2203.2957\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3030133 6.272192  6.3052673 4.586066  6.2394004 6.2954683]\n",
      "Reset environment\n",
      "Episode reward: 5922.355\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.30732   6.276515  6.3095517 4.590761  6.2432666 6.2997727]\n",
      "Reset environment\n",
      "Episode reward: 3176.034\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.309491  6.2787175 6.31169   4.593166  6.2451916 6.301946 ]\n",
      "Reset environment\n",
      "Episode reward: 2344.4275\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.311028  6.280279  6.313202  4.5948734 6.2465553 6.303483 ]\n",
      "Reset environment\n",
      "Episode reward: 3831.797\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.313694  6.282922  6.315882  4.597828  6.2489085 6.3061457]\n",
      "Reset environment\n",
      "Episode reward: 3423.7349\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.315989  6.2852306 6.3181605 4.60035   6.2509446 6.308442 ]\n",
      "Reset environment\n",
      "Episode reward: 2151.1384\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3179455 6.2871976 6.3201036 4.6025286 6.252678  6.310399 ]\n",
      "Reset environment\n",
      "Episode reward: 2178.129\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3199105 6.289174  6.3220572 4.6047077 6.254421  6.3123646]\n",
      "Reset environment\n",
      "Episode reward: 2264.9387\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3212876 6.2906017 6.3233767 4.606293  6.255622  6.3137393]\n",
      "Reset environment\n",
      "Episode reward: 3205.6062\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.323434  6.292719  6.325543  4.608712  6.2574987 6.315882 ]\n",
      "Reset environment\n",
      "Episode reward: 1755.0577\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.324666  6.293972  6.326748  4.6100874 6.258614  6.3171115]\n",
      "Reset environment\n",
      "Episode reward: 3461.304\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3270626 6.296344  6.32916   4.6127343 6.260739  6.319504 ]\n",
      "Reset environment\n",
      "Episode reward: 46.529205\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3265605 6.295691  6.3288155 4.612291  6.2602983 6.319005 ]\n",
      "Reset environment\n",
      "Episode reward: 2279.5237\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3280745 6.2972217 6.3303123 4.6139865 6.261645  6.3205194]\n",
      "Reset environment\n",
      "Episode reward: 5939.354\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3322434 6.301417  6.334448  4.61857   6.265347  6.324691 ]\n",
      "Reset environment\n",
      "Episode reward: 5366.746\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3360486 6.305233  6.3382425 4.622804  6.268733  6.3284965]\n",
      "Reset environment\n",
      "Episode reward: 4938.0283\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.339558  6.30876   6.3417296 4.626659  6.271863  6.332009 ]\n",
      "Reset environment\n",
      "Episode reward: 148.06955\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3392315 6.3082314 6.3415923 4.6265297 6.271507  6.3316784]\n",
      "Reset environment\n",
      "Episode reward: 3627.075\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3417583 6.31076   6.3441052 4.6293025 6.27376   6.334205 ]\n",
      "Reset environment\n",
      "Episode reward: 2436.6394\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.343347  6.312374  6.34566   4.6310663 6.275162  6.3357906]\n",
      "Reset environment\n",
      "Episode reward: 742.843\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.343595  6.3124986 6.346036  4.6314526 6.275357  6.336039 ]\n",
      "Reset environment\n",
      "Episode reward: 2574.8037\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3452764 6.314167  6.347728  4.6333222 6.2768693 6.337723 ]\n",
      "Reset environment\n",
      "Episode reward: 2160.7354\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3471966 6.3160925 6.3496413 4.635499  6.2785587 6.3396416]\n",
      "Reset environment\n",
      "Episode reward: 1785.6759\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3485065 6.317408  6.3509364 4.6369495 6.2797484 6.340952 ]\n",
      "Reset environment\n",
      "Episode reward: 1341.9159\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.34983  6.318733 6.352257 4.638446 6.280906 6.342274]\n",
      "Reset environment\n",
      "Episode reward: 3124.3\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.351984  6.3208838 6.3544154 4.6408267 6.282816  6.344429 ]\n",
      "Reset environment\n",
      "Episode reward: 2261.082\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3533597 6.322204  6.3558364 4.642393  6.2840376 6.345802 ]\n",
      "Reset environment\n",
      "Episode reward: 2221.875\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3548465 6.323705  6.3573055 4.6440463 6.285367  6.3472853]\n",
      "Reset environment\n",
      "Episode reward: 2070.008\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.356699  6.32555   6.3591595 4.646125  6.286984  6.3491354]\n",
      "Reset environment\n",
      "Episode reward: 2215.1853\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3581057 6.3269534 6.360567  4.6477375 6.2881947 6.3505435]\n",
      "Reset environment\n",
      "Episode reward: 6087.2974\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.362375  6.3312097 6.3648415 4.652459  6.291997  6.3548155]\n",
      "Reset environment\n",
      "Episode reward: 1444.0914\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.363216  6.3320575 6.3656783 4.6534586 6.2927127 6.3556566]\n",
      "Reset environment\n",
      "Episode reward: 4996.017\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3666778 6.33553   6.369116  4.6572385 6.2957973 6.3591185]\n",
      "Reset environment\n",
      "Episode reward: 1367.0502\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3680177 6.3368673 6.3704557 4.658742  6.29697   6.3604574]\n",
      "Reset environment\n",
      "Episode reward: 2532.7522\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3696375 6.338483  6.3720717 4.6605353 6.298396  6.3620777]\n",
      "Reset environment\n",
      "Episode reward: 4804.521\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3730564 6.341911  6.375474  4.6643224 6.30141   6.365497 ]\n",
      "Reset environment\n",
      "Episode reward: 4057.41\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.375882  6.3447466 6.378292  4.667431  6.3039126 6.368322 ]\n",
      "Reset environment\n",
      "Episode reward: 5162.725\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.379548  6.348407  6.3819804 4.6714535 6.3071737 6.371989 ]\n",
      "Reset environment\n",
      "Episode reward: 5923.996\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3836756 6.352504  6.3861303 4.676016  6.310852  6.376117 ]\n",
      "Reset environment\n",
      "Episode reward: 2827.1594\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3855224 6.354301  6.3880186 4.678094  6.3125014 6.3779635]\n",
      "Reset environment\n",
      "Episode reward: 4228.823\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3885045 6.357296  6.390985  4.6813564 6.3151717 6.380945 ]\n",
      "Reset environment\n",
      "Episode reward: 168.26028\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3882785 6.3569646 6.3908677 4.681188  6.3149843 6.380723 ]\n",
      "Reset environment\n",
      "Episode reward: 2660.9211\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3900466 6.358749  6.392618  4.683169  6.316552  6.3824925]\n",
      "Reset environment\n",
      "Episode reward: 1308.8545\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.391328  6.36003   6.3939004 4.684627  6.317665  6.3837748]\n",
      "Reset environment\n",
      "Episode reward: 2054.7341\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3931684 6.3618655 6.395744  4.686681  6.319282  6.3856173]\n",
      "Reset environment\n",
      "Episode reward: 3869.4119\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.395809  6.3644767 6.3984127 4.689608  6.321613  6.388256 ]\n",
      "Reset environment\n",
      "Episode reward: 5644.2397\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.3998337 6.3684816 6.402448  4.6940193 6.325191  6.392279 ]\n",
      "Reset environment\n",
      "Episode reward: 1744.0693\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.400829  6.3695254 6.4033895 4.695177  6.326056  6.393272 ]\n",
      "Reset environment\n",
      "Episode reward: 3836.3928\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4035006 6.3722095 6.4060435 4.698133  6.3284345 6.395943 ]\n",
      "Reset environment\n",
      "Episode reward: 4713.588\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4067736 6.375488  6.409305  4.701791  6.3313346 6.3992147]\n",
      "Reset environment\n",
      "Episode reward: 1634.5175\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4078    6.376416  6.4104342 4.7030096 6.332252  6.4002447]\n",
      "Reset environment\n",
      "Episode reward: 3007.4575\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4095254 6.3780704 6.412221  4.7050147 6.3337874 6.401972 ]\n",
      "Reset environment\n",
      "Episode reward: 308.0192\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.409404  6.3778467 6.4122133 4.704913  6.3337126 6.4018564]\n",
      "Reset environment\n",
      "Episode reward: 2238.3362\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.411391  6.3798203 6.4142003 4.7071333 6.3354597 6.403842 ]\n",
      "Reset environment\n",
      "Episode reward: 1861.105\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4125576 6.3810034 6.415344  4.708438  6.336492  6.4050093]\n",
      "Reset environment\n",
      "Episode reward: 2210.222\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.413855  6.3822417 6.416694  4.7099295 6.3376346 6.4063053]\n",
      "Reset environment\n",
      "Episode reward: 1767.4263\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.414992  6.3833933 6.417813  4.7112083 6.3386526 6.407442 ]\n",
      "Reset environment\n",
      "Episode reward: 4971.8267\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4185004 6.3869114 6.421307  4.715079  6.341748  6.410949 ]\n",
      "Reset environment\n",
      "Episode reward: 1455.096\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.419911  6.3883243 6.422715  4.7166567 6.3429937 6.4123597]\n",
      "Reset environment\n",
      "Episode reward: 4341.759\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4229593 6.391383  6.425746  4.720002  6.345711  6.415406 ]\n",
      "Reset environment\n",
      "Episode reward: 1999.3351\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4242606 6.39268   6.4270477 4.721462  6.34685   6.416709 ]\n",
      "Reset environment\n",
      "Episode reward: 4998.745\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4277983 6.396232  6.4305797 4.725365  6.349986  6.4202485]\n",
      "Reset environment\n",
      "Episode reward: 2935.5083\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.429719  6.39811   6.432536  4.7275124 6.3516936 6.422169 ]\n",
      "Reset environment\n",
      "Episode reward: 2765.3975\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4315553 6.3999677 6.434359  4.729558  6.3533163 6.424008 ]\n",
      "Reset environment\n",
      "Episode reward: 4019.3198\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4343047 6.4026847 6.4371343 4.7326045 6.3557515 6.4267564]\n",
      "Reset environment\n",
      "Episode reward: 1309.4825\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4350786 6.4034696 6.437895  4.7335033 6.3564305 6.4275293]\n",
      "Reset environment\n",
      "Episode reward: 2224.2644\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.436525  6.4049263 6.439323  4.735148  6.3577003 6.4289756]\n",
      "Reset environment\n",
      "Episode reward: 3366.343\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4387393 6.407141  6.4415298 4.7376075 6.359638  6.43119  ]\n",
      "Reset environment\n",
      "Episode reward: 4558.539\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.441922  6.4102917 6.444739  4.7411075 6.362458  6.4343705]\n",
      "Reset environment\n",
      "Episode reward: 2096.3098\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4432664 6.4116225 6.446099  4.7426267 6.363641  6.4357142]\n",
      "Reset environment\n",
      "Episode reward: 2959.3096\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4452353 6.4136167 6.448035  4.744816  6.365373  6.4376807]\n",
      "Reset environment\n",
      "Episode reward: 2437.259\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4468503 6.4152384 6.4496446 4.7466125 6.3668036 6.4392962]\n",
      "Reset environment\n",
      "Episode reward: 1883.2269\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4485393 6.4169316 6.4513297 4.7485046 6.3682823 6.440983 ]\n",
      "Reset environment\n",
      "Episode reward: 4464.771\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4516497 6.4200597 6.4544253 4.751951  6.3710384 6.444093 ]\n",
      "Reset environment\n",
      "Episode reward: 4336.4185\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4546776 6.4231043 6.4574394 4.7552586 6.3737383 6.447121 ]\n",
      "Reset environment\n",
      "Episode reward: 5702.604\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4586926 6.427115  6.461456  4.7596545 6.37731   6.4511347]\n",
      "Reset environment\n",
      "Episode reward: 3212.9543\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.460793  6.4292126 6.463552  4.761986  6.3791547 6.4532332]\n",
      "Reset environment\n",
      "Episode reward: 5586.5957\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.464657  6.433068  6.4674196 4.7662363 6.3825846 6.457102 ]\n",
      "Reset environment\n",
      "Episode reward: 3126.4922\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.466738  6.4351315 6.4695168 4.76858   6.384438  6.4591827]\n",
      "Reset environment\n",
      "Episode reward: 4001.7302\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.469453  6.4378777 6.4722023 4.771617  6.38682   6.4618964]\n",
      "Reset environment\n",
      "Episode reward: 3598.1936\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4719296 6.4403625 6.4746666 4.7743244 6.3890295 6.464374 ]\n",
      "Reset environment\n",
      "Episode reward: 2837.4402\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4737034 6.4420815 6.4764953 4.7763414 6.3906164 6.466146 ]\n",
      "Reset environment\n",
      "Episode reward: 2007.9175\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.474991  6.4433737 6.4777803 4.777786  6.3917537 6.4674344]\n",
      "Reset environment\n",
      "Episode reward: 3027.4753\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.47694   6.4453773 6.4796658 4.779974  6.3934555 6.4693856]\n",
      "Reset environment\n",
      "Episode reward: 3691.5237\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4793906 6.447822  6.4821157 4.782684  6.3956203 6.4718375]\n",
      "Reset environment\n",
      "Episode reward: 2419.2854\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.480954  6.449419  6.48364   4.7844296 6.396999  6.4734025]\n",
      "Reset environment\n",
      "Episode reward: 2265.2559\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4829507 6.451407  6.485642  4.7866364 6.3987646 6.4753976]\n",
      "Reset environment\n",
      "Episode reward: 5079.8027\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.486525 6.454964 6.489224 4.790572 6.401941 6.478973]\n",
      "Reset environment\n",
      "Episode reward: 1508.2968\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.487445  6.455893  6.4901323 4.7916155 6.4027567 6.479894 ]\n",
      "Reset environment\n",
      "Episode reward: 2792.9055\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.489242  6.457688  6.4919276 4.7936244 6.40436   6.4816933]\n",
      "Reset environment\n",
      "Episode reward: 4812.787\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4926357 6.46106   6.495344  4.7973456 6.407388  6.485087 ]\n",
      "Reset environment\n",
      "Episode reward: 2531.7715\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4942265 6.4626184 6.496964  4.7991533 6.408786  6.486676 ]\n",
      "Reset environment\n",
      "Episode reward: 4455.3857\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.497314  6.4657183 6.500031  4.8025293 6.4115286 6.489764 ]\n",
      "Reset environment\n",
      "Episode reward: 2941.0664\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.4992957 6.467694  6.502019  4.8047347 6.4132805 6.491746 ]\n",
      "Reset environment\n",
      "Episode reward: 4886.346\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.502708  6.4710827 6.505457  4.8085012 6.416315  6.495157 ]\n",
      "Reset environment\n",
      "Episode reward: 3331.2573\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.504929  6.473323  6.5076623 4.8109894 6.4182734 6.497379 ]\n",
      "Reset environment\n",
      "Episode reward: 3384.1526\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5072193 6.47559   6.509983  4.8135257 6.420305  6.4996686]\n",
      "Reset environment\n",
      "Episode reward: 4807.0713\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.510556  6.47895   6.5133023 4.8172145 6.423269  6.503006 ]\n",
      "Reset environment\n",
      "Episode reward: 4850.2573\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.513949  6.482358  6.516678  4.8209047 6.426299  6.5063987]\n",
      "Reset environment\n",
      "Episode reward: -438.0909\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.513422  6.481876  6.5161085 4.820422  6.425833  6.5058746]\n",
      "Reset environment\n",
      "Episode reward: 932.8574\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5138645 6.4824276 6.5164466 4.820932  6.4262815 6.5063205]\n",
      "Reset environment\n",
      "Episode reward: -204.5929\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5133452 6.481788  6.5160427 4.820614  6.4257574 6.505799 ]\n",
      "Reset environment\n",
      "Episode reward: 2238.6455\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.514737  6.4831743 6.5174403 4.82217   6.4269834 6.5071917]\n",
      "Reset environment\n",
      "Episode reward: 793.98145\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5152574 6.483691  6.5179744 4.822687  6.427496  6.5077157]\n",
      "Reset environment\n",
      "Episode reward: 2120.1565\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5165563 6.484928  6.5193257 4.824159  6.428645  6.5090127]\n",
      "Reset environment\n",
      "Episode reward: 3280.581\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.51867   6.486975  6.5214963 4.826535  6.430535  6.511125 ]\n",
      "Reset environment\n",
      "Episode reward: 2402.8003\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5200396 6.488261  6.522942  4.828148  6.431717  6.512492 ]\n",
      "Reset environment\n",
      "Episode reward: 3599.747\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.522435  6.4906945 6.525298  4.830813  6.433838  6.5148864]\n",
      "Reset environment\n",
      "Episode reward: 3580.9766\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5248203 6.493043  6.527718  4.833472  6.435955  6.5172706]\n",
      "Reset environment\n",
      "Episode reward: 2269.553\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.526298  6.494495  6.5292134 4.835127  6.437259  6.518745 ]\n",
      "Reset environment\n",
      "Episode reward: 2191.0088\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5282407 6.496432  6.531158  4.837262  6.4389772 6.5206857]\n",
      "Reset environment\n",
      "Episode reward: 5148.5566\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5318336 6.4999986 6.5347724 4.8412237 6.4421706 6.5242763]\n",
      "Reset environment\n",
      "Episode reward: 1942.2578\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.533084  6.5012465 6.5360236 4.842623  6.443272  6.525527 ]\n",
      "Reset environment\n",
      "Episode reward: 1126.8866\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.533719  6.501881  6.5366635 4.8433557 6.443833  6.526164 ]\n",
      "Reset environment\n",
      "Episode reward: 469.09225\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5339775 6.502143  6.5369287 4.8435946 6.444072  6.526426 ]\n",
      "Reset environment\n",
      "Episode reward: 2555.503\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5354967 6.5035987 6.538504  4.8453546 6.445398  6.527947 ]\n",
      "Reset environment\n",
      "Episode reward: 2865.8665\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5373874 6.5054665 6.5404077 4.847472  6.4470587 6.529836 ]\n",
      "Reset environment\n",
      "Episode reward: 2654.203\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.539082  6.50712   6.54215   4.8493695 6.448579  6.5315332]\n",
      "Reset environment\n",
      "Episode reward: 5340.996\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5427933 6.5108223 6.545868  4.8534636 6.451863  6.5352426]\n",
      "Reset environment\n",
      "Episode reward: 1569.8394\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.543768  6.511815  6.546827  4.8545585 6.4527373 6.5362177]\n",
      "Reset environment\n",
      "Episode reward: 1831.9546\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5449185 6.512987  6.547954  4.8558483 6.453763  6.53737  ]\n",
      "Reset environment\n",
      "Episode reward: 2043.9939\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5467014 6.514755  6.549744  4.8578663 6.4553227 6.5391517]\n",
      "Reset environment\n",
      "Episode reward: 5705.344\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5506997 6.5187545 6.553737  4.8622584 6.4588604 6.5431476]\n",
      "Reset environment\n",
      "Episode reward: -365.4278\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5500517 6.518078  6.553128  4.861665  6.4583025 6.5425   ]\n",
      "Reset environment\n",
      "Episode reward: 5291.2197\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5537558 6.521761  6.556847  4.8657236 6.4616    6.546202 ]\n",
      "Reset environment\n",
      "Episode reward: 3181.0522\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.555875  6.52391   6.558927  4.8680453 6.463491  6.548321 ]\n",
      "Reset environment\n",
      "Episode reward: -46.522156\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5554185 6.523316  6.558607  4.86772   6.463024  6.5478654]\n",
      "Reset environment\n",
      "Episode reward: 1698.2091\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5564365 6.524354  6.5596056 4.8688884 6.463912  6.5488853]\n",
      "Reset environment\n",
      "Episode reward: 1312.4316\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5576963 6.525611  6.560861  4.870325  6.4650073 6.5501413]\n",
      "Reset environment\n",
      "Episode reward: 4346.02\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5606546 6.5285797 6.5638046 4.873598  6.4676204 6.553097 ]\n",
      "Reset environment\n",
      "Episode reward: 4260.1294\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.563584  6.531498  6.5667334 4.876831  6.470203  6.556024 ]\n",
      "Reset environment\n",
      "Episode reward: 3207.3271\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5655684 6.533532  6.5686593 4.8790946 6.4719496 6.558009 ]\n",
      "Reset environment\n",
      "Episode reward: 4636.793\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5687575 6.536707  6.5718603 4.8826146 6.4747643 6.561196 ]\n",
      "Reset environment\n",
      "Episode reward: 4253.8286\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5716925 6.5396423 6.5747905 4.8858414 6.4773903 6.5641313]\n",
      "Reset environment\n",
      "Episode reward: 2730.87\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5734234 6.541389  6.576506  4.887772  6.4789324 6.5658646]\n",
      "Reset environment\n",
      "Episode reward: 3021.3333\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5753345 6.543247  6.5784626 4.8899326 6.480637  6.5677752]\n",
      "Reset environment\n",
      "Episode reward: 2082.3933\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.576663  6.544584  6.579779  4.8914127 6.481809  6.569104 ]\n",
      "Reset environment\n",
      "Episode reward: 2173.3708\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.578055 6.546015 6.581127 4.892977 6.483035 6.570499]\n",
      "Reset environment\n",
      "Episode reward: 3135.3044\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.580168  6.5481086 6.583253  4.895314  6.48491   6.57261  ]\n",
      "Reset environment\n",
      "Episode reward: 3639.407\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.582551  6.550495  6.585626  4.8979588 6.487012  6.5749907]\n",
      "Reset environment\n",
      "Episode reward: 3454.915\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5848713 6.5528364 6.587923  4.9005256 6.4890695 6.5773106]\n",
      "Reset environment\n",
      "Episode reward: 3350.9568\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.587084  6.555048  6.590131  4.9029512 6.4910364 6.5795226]\n",
      "Reset environment\n",
      "Episode reward: 4846.047\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5904474 6.558403  6.5934954 4.906642  6.494     6.5828824]\n",
      "Reset environment\n",
      "Episode reward: -220.2489\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.589931  6.55774   6.593114  4.9062495 6.493548  6.582365 ]\n",
      "Reset environment\n",
      "Episode reward: 4814.2466\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5931835 6.560996  6.596358  4.909806  6.4964256 6.585621 ]\n",
      "Reset environment\n",
      "Episode reward: 4425.165\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5962095 6.564034  6.599371  4.9131255 6.499121  6.5886474]\n",
      "Reset environment\n",
      "Episode reward: 4705.5444\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.5994806 6.5673203 6.6026273 4.9166965 6.502054  6.5919204]\n",
      "Reset environment\n",
      "Episode reward: 3635.771\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6019597 6.5698166 6.605092  4.919414  6.504268  6.5944023]\n",
      "Reset environment\n",
      "Episode reward: 1522.0587\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6028533 6.57072   6.605978  4.920463  6.5050397 6.595299 ]\n",
      "Reset environment\n",
      "Episode reward: 1810.3394\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6039324 6.5718374 6.607024  4.921694  6.505992  6.5963807]\n",
      "Reset environment\n",
      "Episode reward: 2052.9612\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6057386 6.57363   6.6088357 4.923707  6.507591  6.598185 ]\n",
      "Reset environment\n",
      "Episode reward: 673.2312\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.605923  6.5737395 6.609095  4.9239683 6.5077972 6.5983706]\n",
      "Reset environment\n",
      "Episode reward: 3046.2178\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6078625 6.5756745 6.6110373 4.926114  6.509507  6.60031  ]\n",
      "Reset environment\n",
      "Episode reward: 6064.219\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.612037  6.5798335 6.615221  4.9306965 6.5132294 6.604485 ]\n",
      "Reset environment\n",
      "Episode reward: 2278.981\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6140175 6.58181   6.6172047 4.932887  6.5149803 6.606465 ]\n",
      "Reset environment\n",
      "Episode reward: 4360.0386\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6170406 6.584842  6.620214  4.9361715 6.517696  6.609488 ]\n",
      "Reset environment\n",
      "Episode reward: 1212.5428\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6177    6.5855136 6.620858  4.936963  6.5182605 6.610146 ]\n",
      "Reset environment\n",
      "Episode reward: 3281.4812\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.619935  6.5877542 6.6230955 4.9394426 6.5202575 6.6123824]\n",
      "Reset environment\n",
      "Episode reward: 4525.686\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6230464 6.590852  6.626212  4.942861  6.523013  6.615491 ]\n",
      "Reset environment\n",
      "Episode reward: 1776.3257\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.624129  6.5919294 6.627301  4.9440956 6.523954  6.616574 ]\n",
      "Reset environment\n",
      "Episode reward: 1909.3541\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.625827  6.593625  6.6290026 4.9459853 6.525454  6.618273 ]\n",
      "Reset environment\n",
      "Episode reward: 1954.6064\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.627047  6.594838  6.6302195 4.9473615 6.5265245 6.6194897]\n",
      "Reset environment\n",
      "Episode reward: -396.3781\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.626259  6.594225  6.629268  4.9467173 6.525723  6.618706 ]\n",
      "Reset environment\n",
      "Episode reward: 2750.6694\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6277623 6.5956535 6.6308403 4.9484944 6.5270395 6.620209 ]\n",
      "Reset environment\n",
      "Episode reward: 2418.4275\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6290812 6.5968823 6.63225   4.950063  6.5282006 6.6215296]\n",
      "Reset environment\n",
      "Episode reward: 2994.513\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6310096 6.598792  6.6341963 4.952239  6.5298924 6.6234565]\n",
      "Reset environment\n",
      "Episode reward: 2511.6296\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6325674 6.600308  6.6357956 4.953997  6.531274  6.6250153]\n",
      "Reset environment\n",
      "Episode reward: 2677.139\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6342845 6.602     6.6375346 4.955928  6.532786  6.62673  ]\n",
      "Reset environment\n",
      "Episode reward: 2034.521\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.636052  6.603763  6.6393113 4.95791   6.5343356 6.628498 ]\n",
      "Reset environment\n",
      "Episode reward: 4173.6636\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6389356 6.6066484 6.642184  4.961093  6.5368953 6.631381 ]\n",
      "Reset environment\n",
      "Episode reward: 5345.3867\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6426425 6.6103635 6.645872  4.965175  6.540207  6.6350875]\n",
      "Reset environment\n",
      "Episode reward: 2463.1367\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6442313 6.611967  6.647446  4.9669585 6.541603  6.6366763]\n",
      "Reset environment\n",
      "Episode reward: 2753.2395\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.645978  6.6136746 6.6492214 4.9689164 6.543148  6.63842  ]\n",
      "Reset environment\n",
      "Episode reward: 2389.0264\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6475077 6.615218  6.650737  4.9706244 6.5444927 6.6399503]\n",
      "Reset environment\n",
      "Episode reward: 4625.8696\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.650657  6.618393  6.653868  4.974121  6.5472884 6.6431046]\n",
      "Reset environment\n",
      "Episode reward: 3288.2598\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.652846  6.620575  6.6560574 4.976548  6.5492153 6.645294 ]\n",
      "Reset environment\n",
      "Episode reward: 6706.598\n",
      "Total Steps: 229\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6575685 6.625284  6.6607857 4.981704  6.553437  6.6500144]\n",
      "Reset environment\n",
      "Episode reward: 5626.06\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6613736 6.6291046 6.6645694 4.985898  6.5568223 6.6538196]\n",
      "Reset environment\n",
      "Episode reward: 5159.2896\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6649313 6.6326656 6.6681204 4.989802  6.559972  6.65738  ]\n",
      "Reset environment\n",
      "Episode reward: 1339.5784\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.666214  6.6339483 6.669402  4.9912415 6.5610957 6.658662 ]\n",
      "Reset environment\n",
      "Episode reward: 4373.346\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6692142 6.6369586 6.672381  4.9945087 6.563778  6.6616607]\n",
      "Reset environment\n",
      "Episode reward: 1390.4816\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6705456 6.6382904 6.673711  4.995979  6.564949  6.6629915]\n",
      "Reset environment\n",
      "Episode reward: -80.778656\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6701317 6.637767  6.6734047 4.9957075 6.564534  6.6625805]\n",
      "Reset environment\n",
      "Episode reward: 2036.3639\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6713943 6.6390214 6.6746745 4.997133  6.565638  6.6638427]\n",
      "Reset environment\n",
      "Episode reward: 2166.7373\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.673278 6.640899 6.676562 4.999231 6.567303 6.665725]\n",
      "Reset environment\n",
      "Episode reward: 1314.72\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6745267 6.64215   6.67781   5.0006413 6.5683985 6.666977 ]\n",
      "Reset environment\n",
      "Episode reward: 253.66394\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.674253  6.6416993 6.6777034 5.000593  6.568066  6.666703 ]\n",
      "Reset environment\n",
      "Episode reward: 4058.0823\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6769795 6.6444063 6.6804447 5.003626  6.5704722 6.669428 ]\n",
      "Reset environment\n",
      "Episode reward: 2186.4248\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6788926 6.646316  6.682363  5.005736  6.5721674 6.671342 ]\n",
      "Reset environment\n",
      "Episode reward: 1884.2764\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6800723 6.6474895 6.683545  5.007051  6.5732055 6.67252  ]\n",
      "Reset environment\n",
      "Episode reward: 3207.1584\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6821337 6.649585  6.685569  5.0093465 6.575029  6.6745825]\n",
      "Reset environment\n",
      "Episode reward: 1790.0913\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.683218  6.6506586 6.6866603 5.0105877 6.5759764 6.675668 ]\n",
      "Reset environment\n",
      "Episode reward: 3333.34\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.685355  6.6527987 6.6887946 5.012948  6.577861  6.6778083]\n",
      "Reset environment\n",
      "Episode reward: 2741.2358\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.687123  6.65458   6.69055   5.014912  6.5794196 6.679576 ]\n",
      "Reset environment\n",
      "Episode reward: 5160.813\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.690731  6.6581836 6.694154  5.018843  6.5826077 6.6831837]\n",
      "Reset environment\n",
      "Episode reward: -456.83908\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6900063 6.657394  6.6934924 5.0180364 6.5819955 6.6824603]\n",
      "Reset environment\n",
      "Episode reward: 1341.4973\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.691286  6.6586742 6.6947684 5.019464  6.5831203 6.68374  ]\n",
      "Reset environment\n",
      "Episode reward: -44.67737\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6908846 6.6583786 6.694271  5.0190005 6.5827885 6.683347 ]\n",
      "Reset environment\n",
      "Episode reward: 432.68716\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.690748  6.658353  6.6940427 5.01877   6.5827346 6.683217 ]\n",
      "Reset environment\n",
      "Episode reward: 2113.7969\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.691906  6.6594563 6.695252  5.020118  6.583754  6.684375 ]\n",
      "Reset environment\n",
      "Episode reward: 2231.387\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6932616 6.660864  6.69655   5.0216546 6.5849543 6.685731 ]\n",
      "Reset environment\n",
      "Episode reward: 1735.6653\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6943245 6.661923  6.697616  5.0228434 6.5858874 6.6867924]\n",
      "Reset environment\n",
      "Episode reward: 1216.7001\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6954794 6.6630764 6.698773  5.024165  6.5868793 6.6879497]\n",
      "Reset environment\n",
      "Episode reward: 3989.5789\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6981053 6.665704  6.701394  5.0270424 6.589203  6.6905746]\n",
      "Reset environment\n",
      "Episode reward: 805.3071\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6984925 6.66614   6.7017374 5.0274944 6.5895677 6.6909704]\n",
      "Reset environment\n",
      "Episode reward: 1695.8762\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.6994915 6.6671124 6.7027593 5.0286307 6.5904503 6.6919684]\n",
      "Reset environment\n",
      "Episode reward: 5149.1055\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7029405 6.6705446 6.7062182 5.0324216 6.5935054 6.6954184]\n",
      "Reset environment\n",
      "Episode reward: 5473.887\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.706721  6.6743174 6.7100086 5.0365343 6.5968738 6.6992006]\n",
      "Reset environment\n",
      "Episode reward: 1865.0948\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7078714 6.6754756 6.7111535 5.0378375 6.5978928 6.700354 ]\n",
      "Reset environment\n",
      "Episode reward: 2042.7284\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.709134  6.676743  6.712407  5.039276  6.598993  6.7016163]\n",
      "Reset environment\n",
      "Episode reward: 1765.9731\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.710158  6.6777234 6.713468  5.040445  6.5998974 6.702638 ]\n",
      "Reset environment\n",
      "Episode reward: 4975.3765\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7135987 6.6811433 6.7169185 5.0442085 6.6029525 6.70608  ]\n",
      "Reset environment\n",
      "Episode reward: 3704.6836\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7161107 6.6836658 6.71941   5.0469737 6.605184  6.708587 ]\n",
      "Reset environment\n",
      "Episode reward: 4038.6287\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.718782  6.6863346 6.722084  5.049971  6.607527  6.7112637]\n",
      "Reset environment\n",
      "Episode reward: 3023.8982\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7207575 6.688298  6.7240686 5.052165  6.6092715 6.71324  ]\n",
      "Reset environment\n",
      "Episode reward: 2256.8418\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.721999  6.689603  6.725248  5.0536222 6.610354  6.714483 ]\n",
      "Reset environment\n",
      "Episode reward: 2760.6094\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7237372 6.691314  6.727011  5.0555954 6.611877  6.7162232]\n",
      "Reset environment\n",
      "Episode reward: 1858.4539\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.724479  6.691983  6.727822  5.0565867 6.6124954 6.7169666]\n",
      "Reset environment\n",
      "Episode reward: 1317.1649\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.725729  6.693233  6.7290716 5.057991  6.6135864 6.718217 ]\n",
      "Reset environment\n",
      "Episode reward: 2389.3867\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7272367 6.694727  6.730596  5.0596943 6.6149173 6.7197223]\n",
      "Reset environment\n",
      "Episode reward: 1109.4828\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.727828  6.6952963 6.731207  5.060388  6.6154294 6.720315 ]\n",
      "Reset environment\n",
      "Episode reward: 4156.405\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7306437 6.6981173 6.734014  5.063509  6.617934  6.7231326]\n",
      "Reset environment\n",
      "Episode reward: 3530.7737\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7330174 6.7004857 6.736387  5.066117  6.620043  6.7255054]\n",
      "Reset environment\n",
      "Episode reward: 2107.2402\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7341743 6.7017093 6.737478  5.0674663 6.6210737 6.7266645]\n",
      "Reset environment\n",
      "Episode reward: 2256.621\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.735566  6.70315   6.738818  5.0690255 6.6223097 6.728059 ]\n",
      "Reset environment\n",
      "Episode reward: 3300.5464\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.737718  6.7052684 6.740998  5.0714135 6.6242123 6.7302117]\n",
      "Reset environment\n",
      "Episode reward: 1380.4077\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7385077 6.7060757 6.741766  5.0723248 6.624903  6.7310014]\n",
      "Reset environment\n",
      "Episode reward: 2926.9722\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.740423  6.707987  6.743678  5.0744476 6.6265955 6.7329135]\n",
      "Reset environment\n",
      "Episode reward: 1843.7134\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7415786 6.709156  6.7448134 5.0757346 6.6276283 6.7340684]\n",
      "Reset environment\n",
      "Episode reward: 4006.6802\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.744161  6.711753  6.7473855 5.0785937 6.629917  6.736651 ]\n",
      "Reset environment\n",
      "Episode reward: 815.8646\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7444    6.7118406 6.747777  5.0790386 6.6300936 6.73689  ]\n",
      "Reset environment\n",
      "Episode reward: 1941.6968\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7455845 6.713013  6.7489705 5.080383  6.6311293 6.7380757]\n",
      "Reset environment\n",
      "Episode reward: 1670.8212\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.746566  6.714019  6.7499294 5.081489  6.631994  6.739057 ]\n",
      "Reset environment\n",
      "Episode reward: 972.9297\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7470665 6.7145333 6.750415  5.082073  6.632432  6.7395577]\n",
      "Reset environment\n",
      "Episode reward: 1535.6819\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.747975  6.7154417 6.751327  5.0831137 6.6332245 6.740468 ]\n",
      "Reset environment\n",
      "Episode reward: 4675.874\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.751172  6.7186327 6.7545276 5.086621  6.6360574 6.743664 ]\n",
      "Reset environment\n",
      "Episode reward: 1610.2777\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.752083  6.719565  6.7554083 5.0876737 6.636847  6.744575 ]\n",
      "Reset environment\n",
      "Episode reward: 2931.8647\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7539353 6.7214475 6.757222  5.0897465 6.638502  6.7464256]\n",
      "Reset environment\n",
      "Episode reward: 4165.08\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7567306 6.7242365 6.760027  5.092848  6.6409726 6.74922  ]\n",
      "Reset environment\n",
      "Episode reward: 2245.3083\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7581344 6.72563   6.761437  5.0944314 6.6422057 6.750623 ]\n",
      "Reset environment\n",
      "Episode reward: 5105.6143\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7616377 6.7291365 6.7649345 5.098276  6.6453156 6.7541294]\n",
      "Reset environment\n",
      "Episode reward: 4353.8276\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7644877 6.731989  6.7677784 5.1014276 6.6478267 6.7569804]\n",
      "Reset environment\n",
      "Episode reward: 5168.5034\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7680106 6.73551   6.7712903 5.1052833 6.6509433 6.7605   ]\n",
      "Reset environment\n",
      "Episode reward: 3477.4927\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7703013 6.7378254 6.7735586 5.107826  6.6529803 6.7627926]\n",
      "Reset environment\n",
      "Episode reward: 5102.5557\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.773662  6.741176  6.776928  5.111534  6.655954  6.7661552]\n",
      "Reset environment\n",
      "Episode reward: 2740.1992\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7754483 6.7429523 6.7787166 5.1135015 6.6575327 6.767939 ]\n",
      "Reset environment\n",
      "Episode reward: 5845.172\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.779448  6.7469687 6.7827077 5.1178885 6.661119  6.7719426]\n",
      "Reset environment\n",
      "Episode reward: 987.581\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.77993   6.747458  6.78318   5.118484  6.6615286 6.7724233]\n",
      "Reset environment\n",
      "Episode reward: 3511.231\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.782191  6.7497683 6.7853904 5.1209817 6.6635423 6.7746844]\n",
      "Reset environment\n",
      "Episode reward: 1680.478\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.783199  6.750777  6.786398  5.1221166 6.664422  6.775693 ]\n",
      "Reset environment\n",
      "Episode reward: 5706.04\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.787114  6.7547045 6.790301  5.126409  6.6679235 6.7796054]\n",
      "Reset environment\n",
      "Episode reward: 5234.758\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.790703  6.758314  6.79387   5.130351  6.6711335 6.783195 ]\n",
      "Reset environment\n",
      "Episode reward: 1403.1127\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7915225 6.759131  6.794692  5.1312995 6.6718464 6.7840157]\n",
      "Reset environment\n",
      "Episode reward: 1548.3346\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.792445  6.760057  6.7956123 5.132344  6.672655  6.7849402]\n",
      "Reset environment\n",
      "Episode reward: 1639.7762\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7934175 6.7610326 6.7965794 5.133449  6.673508  6.785913 ]\n",
      "Reset environment\n",
      "Episode reward: 1309.548\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.7941675 6.761795  6.7973146 5.134303  6.6741734 6.786663 ]\n",
      "Reset environment\n",
      "Episode reward: 2275.7283\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.795525  6.763116  6.798706  5.1358447 6.6753674 6.7880197]\n",
      "Reset environment\n",
      "Episode reward: 4660.667\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.798686  6.766268  6.8018713 5.1393304 6.678165  6.79118  ]\n",
      "Reset environment\n",
      "Episode reward: 1946.9946\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8003726 6.767952  6.80356   5.1412187 6.67965   6.7928653]\n",
      "Reset environment\n",
      "Episode reward: 2680.9182\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.802023  6.7696023 6.8052073 5.14305   6.6811004 6.794516 ]\n",
      "Reset environment\n",
      "Episode reward: 2152.8958\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.80387   6.7714424 6.80706   5.14509   6.68273   6.7963643]\n",
      "Reset environment\n",
      "Episode reward: 2666.2964\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.805543  6.7731395 6.8087115 5.1469574 6.684201  6.798039 ]\n",
      "Reset environment\n",
      "Episode reward: 1961.7006\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.807254  6.774855  6.8104243 5.1488585 6.6857166 6.799752 ]\n",
      "Reset environment\n",
      "Episode reward: 2897.308\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8090353 6.7766376 6.8121996 5.150865  6.687275  6.801533 ]\n",
      "Reset environment\n",
      "Episode reward: 4156.385\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.811792  6.7793655 6.814981  5.153905  6.6897216 6.804291 ]\n",
      "Reset environment\n",
      "Episode reward: 201.77975\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.811759  6.779325  6.8149667 5.153772  6.6897273 6.804261 ]\n",
      "Reset environment\n",
      "Episode reward: 4719.2026\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8149533 6.7825217 6.818147  5.157278  6.692576  6.8074527]\n",
      "Reset environment\n",
      "Episode reward: 4639.3916\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.818048  6.785633  6.82122   5.1607046 6.6953206 6.8105454]\n",
      "Reset environment\n",
      "Episode reward: 4778.9756\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8212757 6.788864  6.8244348 5.164264  6.69817   6.8137755]\n",
      "Reset environment\n",
      "Episode reward: 4349.506\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8242006 6.791802  6.8273406 5.167492  6.700781  6.8167005]\n",
      "Reset environment\n",
      "Episode reward: 1731.5132\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8257475 6.7933464 6.8288856 5.1692085 6.702138  6.8182464]\n",
      "Reset environment\n",
      "Episode reward: 1088.4108\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8262434 6.793943  6.829295  5.169737  6.7026114 6.818751 ]\n",
      "Reset environment\n",
      "Episode reward: 5452.503\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8298783 6.7975802 6.83292   5.173728  6.7058334 6.822388 ]\n",
      "Reset environment\n",
      "Episode reward: 4276.6826\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8327494 6.8004255 6.835796  5.176887  6.7083745 6.825257 ]\n",
      "Reset environment\n",
      "Episode reward: 1349.0902\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8335323 6.801205  6.8365817 5.1777754 6.709064  6.8260393]\n",
      "Reset environment\n",
      "Episode reward: 4796.461\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.836771  6.804444  6.839815  5.1813216 6.7119584 6.829276 ]\n",
      "Reset environment\n",
      "Episode reward: 899.3568\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.837061  6.804855  6.8399987 5.181655  6.712244  6.829574 ]\n",
      "Reset environment\n",
      "Episode reward: 2204.3752\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8383937 6.80615   6.8413687 5.1831546 6.7134314 6.830906 ]\n",
      "Reset environment\n",
      "Episode reward: 1410.322\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.83922   6.8069854 6.842182  5.184097  6.714161  6.8317323]\n",
      "Reset environment\n",
      "Episode reward: 4441.0054\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.842187  6.8099346 6.8451633 5.1873717 6.7167883 6.834699 ]\n",
      "Reset environment\n",
      "Episode reward: 2578.3613\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8438244 6.811592  6.846778  5.1891837 6.718237  6.8363395]\n",
      "Reset environment\n",
      "Episode reward: 4459.967\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.846838  6.8146095 6.8497887 5.192515  6.720914  6.8393555]\n",
      "Reset environment\n",
      "Episode reward: 1933.2346\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8479896 6.81579   6.8509145 5.1938043 6.721926  6.840509 ]\n",
      "Reset environment\n",
      "Episode reward: 2763.617\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8497725 6.8175893 6.85268   5.1957808 6.723506  6.842294 ]\n",
      "Reset environment\n",
      "Episode reward: 1636.6327\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8509617 6.818771  6.85388   5.1970906 6.7246127 6.8434863]\n",
      "Reset environment\n",
      "Episode reward: 4835.3135\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8542376 6.8220396 6.857159  5.200663  6.727519  6.846765 ]\n",
      "Reset environment\n",
      "Episode reward: 3576.8552\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.856541  6.8243756 6.859424  5.2031903 6.729586  6.8490686]\n",
      "Reset environment\n",
      "Episode reward: 2404.4385\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.858027  6.825888  6.8608747 5.2048416 6.730897  6.850555 ]\n",
      "Reset environment\n",
      "Episode reward: 1573.4198\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.858951  6.8268385 6.861774  5.2058806 6.73171   6.8514814]\n",
      "Reset environment\n",
      "Episode reward: 4624.1353\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8620267 6.8299317 6.864826  5.209268  6.734444  6.854553 ]\n",
      "Reset environment\n",
      "Episode reward: 295.49515\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8618603 6.8299003 6.8645296 5.2091627 6.734317  6.8543906]\n",
      "Reset environment\n",
      "Episode reward: 3719.7236\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.864319  6.8323708 6.866969  5.211859  6.736504  6.856846 ]\n",
      "Reset environment\n",
      "Episode reward: 4632.5293\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8674335 6.8355007 6.8700666 5.215281  6.739294  6.859963 ]\n",
      "Reset environment\n",
      "Episode reward: 5101.4053\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8708797 6.83894   6.8735166 5.2190566 6.742357  6.863409 ]\n",
      "Reset environment\n",
      "Episode reward: 2143.615\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8720827 6.8400893 6.874768  5.220439  6.743417  6.86461  ]\n",
      "Reset environment\n",
      "Episode reward: 2420.763\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.874115  6.8421183 6.8768015 5.222688  6.7452264 6.866642 ]\n",
      "Reset environment\n",
      "Episode reward: 3298.617\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8762574 6.844278  6.8789268 5.2250457 6.7471213 6.8687825]\n",
      "Reset environment\n",
      "Episode reward: 4899.428\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.87959   6.8476024 6.882256  5.2286663 6.7500772 6.872117 ]\n",
      "Reset environment\n",
      "Episode reward: -63.92157\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.879059  6.8469105 6.8818784 5.2283077 6.7495427 6.871586 ]\n",
      "Reset environment\n",
      "Episode reward: 5296.299\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8825307 6.8503985 6.8853283 5.2321267 6.752624  6.875053 ]\n",
      "Reset environment\n",
      "Episode reward: 4577.687\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8855696 6.8534303 6.8883657 5.235482  6.7553115 6.878092 ]\n",
      "Reset environment\n",
      "Episode reward: 1320.8785\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.886794  6.854659  6.889586  5.2368674 6.7563777 6.879317 ]\n",
      "Reset environment\n",
      "Episode reward: 2307.7134\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8885617 6.856432  6.891344  5.23882   6.7579694 6.8810844]\n",
      "Reset environment\n",
      "Episode reward: 1923.9342\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8896427 6.857462  6.8924723 5.2400665 6.758921  6.882168 ]\n",
      "Reset environment\n",
      "Episode reward: 441.2868\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8896456 6.857371  6.892575  5.2402725 6.7588553 6.882179 ]\n",
      "Reset environment\n",
      "Episode reward: 5574.372\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.893436  6.861175  6.896351  5.244433  6.7622194 6.8859706]\n",
      "Reset environment\n",
      "Episode reward: 2594.1755\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8950267 6.8627386 6.897964  5.2462273 6.763623  6.887562 ]\n",
      "Reset environment\n",
      "Episode reward: 1882.0388\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.896157  6.863886  6.8990803 5.247516  6.764626  6.8886933]\n",
      "Reset environment\n",
      "Episode reward: 2548.8242\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.8976955 6.865425  6.900612  5.2492313 6.765975  6.890234 ]\n",
      "Reset environment\n",
      "Episode reward: 2595.7007\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.899314  6.867017  6.902257  5.2510386 6.7674103 6.891854 ]\n",
      "Reset environment\n",
      "Episode reward: 2970.3582\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9011703 6.868851  6.9041348 5.2530932 6.769057  6.8937135]\n",
      "Reset environment\n",
      "Episode reward: 3293.0999\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.903282  6.8709793 6.9062233 5.2554274 6.770924  6.895823 ]\n",
      "Reset environment\n",
      "Episode reward: 1779.1234\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.904306  6.871988  6.9072533 5.256607  6.7718077 6.8968463]\n",
      "Reset environment\n",
      "Episode reward: 728.83435\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9047656 6.8724337 6.9077315 5.2570734 6.7722545 6.8973083]\n",
      "Reset environment\n",
      "Episode reward: 984.176\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9051538 6.8727317 6.908206  5.257561  6.772625  6.8976965]\n",
      "Reset environment\n",
      "Episode reward: 3103.21\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9070787 6.8746586 6.9101276 5.259711  6.7743125 6.899625 ]\n",
      "Reset environment\n",
      "Episode reward: 2249.068\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9084845 6.876079  6.911519  5.2612896 6.7755666 6.9010305]\n",
      "Reset environment\n",
      "Episode reward: 5417.219\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9121146 6.879726  6.9151278 5.265291  6.778792  6.9046597]\n",
      "Reset environment\n",
      "Episode reward: 3085.696\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.914102  6.8817296 6.9171023 5.267476  6.7805567 6.9066477]\n",
      "Reset environment\n",
      "Episode reward: 5747.8706\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.917991  6.8856215 6.920987  5.2717443 6.784019  6.9105406]\n",
      "Reset environment\n",
      "Episode reward: 1741.0072\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.919049  6.8866816 6.9220395 5.272928  6.784956  6.9115973]\n",
      "Reset environment\n",
      "Episode reward: 3348.0535\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9211154 6.8887525 6.9240966 5.2752366 6.7867723 6.9136653]\n",
      "Reset environment\n",
      "Episode reward: 2932.648\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9229684 6.8905716 6.92598   5.277293  6.788418  6.915517 ]\n",
      "Reset environment\n",
      "Episode reward: 4256.1333\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.925696  6.8933153 6.928693  5.2802935 6.79083   6.9182453]\n",
      "Reset environment\n",
      "Episode reward: 2416.787\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.927213  6.8948426 6.930193  5.2819767 6.792172  6.919762 ]\n",
      "Reset environment\n",
      "Episode reward: 1887.3903\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9282637 6.895852  6.931282  5.2831917 6.7930956 6.9208145]\n",
      "Reset environment\n",
      "Episode reward: 1944.9832\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9294457 6.8970494 6.932448  5.2845316 6.794148  6.9219966]\n",
      "Reset environment\n",
      "Episode reward: 1655.0745\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.930441  6.8980594 6.933432  5.2856517 6.795036  6.9229927]\n",
      "Reset environment\n",
      "Episode reward: 811.50775\n",
      "Total Steps: 25\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.93083   6.8984456 6.933821  5.28611   6.795373  6.923382 ]\n",
      "Reset environment\n",
      "Episode reward: 2677.4995\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9325356 6.900163  6.9355125 5.2879987 6.796883  6.9250884]\n",
      "Reset environment\n",
      "Episode reward: 3030.1663\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.934469  6.902087  6.9374576 5.2901425 6.798591  6.9270244]\n",
      "Reset environment\n",
      "Episode reward: 1298.9451\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.93567  6.903283 6.938655 5.291512 6.799631 6.928224]\n",
      "Reset environment\n",
      "Episode reward: 1933.0996\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.937336  6.9049535 6.940316  5.293364  6.8011017 6.9298897]\n",
      "Reset environment\n",
      "Episode reward: 4249.071\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.940087  6.9076967 6.943074  5.296371  6.803551  6.9326434]\n",
      "Reset environment\n",
      "Episode reward: -205.83057\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.939555  6.906987  6.9427257 5.295997  6.803002  6.9321165]\n",
      "Reset environment\n",
      "Episode reward: 3743.991\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9420257 6.909473  6.9451847 5.2987103 6.8052077 6.9345884]\n",
      "Reset environment\n",
      "Episode reward: 1279.8811\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.943203  6.9106493 6.9463663 5.300055  6.806224  6.9357657]\n",
      "Reset environment\n",
      "Episode reward: 2024.6553\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.944442  6.9118876 6.9476013 5.3014417 6.8073077 6.937004 ]\n",
      "Reset environment\n",
      "Episode reward: 4667.291\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.947547  6.915008  6.9506884 5.3048463 6.8100715 6.940109 ]\n",
      "Reset environment\n",
      "Episode reward: 13.063629\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9473047 6.9147234 6.9504957 5.304514  6.809881  6.939872 ]\n",
      "Reset environment\n",
      "Episode reward: 5227.451\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.950825  6.91824   6.9540124 5.3083305 6.8130093 6.943391 ]\n",
      "Reset environment\n",
      "Episode reward: 3402.1267\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.952962  6.9203806 6.9561424 5.3107095 6.8149033 6.945527 ]\n",
      "Reset environment\n",
      "Episode reward: 2987.5115\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.954845  6.922279  6.958007  5.3128014 6.8165603 6.9474087]\n",
      "Reset environment\n",
      "Episode reward: 3760.0771\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9573007 6.924744  6.9604526 5.315519  6.818748  6.9498663]\n",
      "Reset environment\n",
      "Episode reward: 1670.4142\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.958236  6.9255915 6.9614787 5.3166265 6.8195977 6.9508076]\n",
      "Reset environment\n",
      "Episode reward: 1987.4651\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9593706 6.9267745 6.9625626 5.317941  6.820603  6.9519463]\n",
      "Reset environment\n",
      "Episode reward: 5280.031\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.962927  6.930323  6.9661236 5.321833  6.823767  6.9555035]\n",
      "Reset environment\n",
      "Episode reward: 3822.2246\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.965424  6.932835  6.968608  5.3245597 6.8259926 6.9580007]\n",
      "Reset environment\n",
      "Episode reward: 2750.6062\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.967021  6.9343715 6.970259  5.326382  6.827416  6.959596 ]\n",
      "Reset environment\n",
      "Episode reward: 3954.8167\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.969612  6.9369774 6.9728346 5.329223  6.8297315 6.962187 ]\n",
      "Reset environment\n",
      "Episode reward: 2447.0288\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9711494 6.9385047 6.9743814 5.330944  6.831086  6.9637246]\n",
      "Reset environment\n",
      "Episode reward: 3724.8992\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9735518 6.94089   6.976807  5.333608  6.8332157 6.966129 ]\n",
      "Reset environment\n",
      "Episode reward: 2864.6194\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9753447 6.942682  6.9786    5.3356104 6.8347926 6.9679213]\n",
      "Reset environment\n",
      "Episode reward: 3693.864\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.977785  6.945141  6.9810143 5.338287  6.836969  6.9703608]\n",
      "Reset environment\n",
      "Episode reward: 966.9761\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9782605 6.9457297 6.981382  5.3388333 6.8374195 6.9708443]\n",
      "Reset environment\n",
      "Episode reward: 1204.8728\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9793625 6.9468346 6.982481  5.340099  6.8383656 6.9719467]\n",
      "Reset environment\n",
      "Episode reward: 1170.3883\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.979994  6.9474573 6.983115  5.3408384 6.8389106 6.9725776]\n",
      "Reset environment\n",
      "Episode reward: 1320.7759\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9812064 6.948671  6.984322  5.3422127 6.8399634 6.9737897]\n",
      "Reset environment\n",
      "Episode reward: 2032.9822\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9829    6.9503694 6.986011  5.3441205 6.8414497 6.975481 ]\n",
      "Reset environment\n",
      "Episode reward: 1960.9736\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.984083  6.9515433 6.9872017 5.345441  6.8424907 6.9766636]\n",
      "Reset environment\n",
      "Episode reward: 3400.3376\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.986196  6.953669  6.9893003 5.3477845 6.844355  6.9787774]\n",
      "Reset environment\n",
      "Episode reward: 5434.239\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.989815  6.9572887 6.992919  5.3517404 6.847572  6.982395 ]\n",
      "Reset environment\n",
      "Episode reward: 4106.3945\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9925203 6.9599843 6.995629  5.3547187 6.849973  6.985099 ]\n",
      "Reset environment\n",
      "Episode reward: 2732.4207\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9942465 6.9617333 6.9973397 5.35664   6.8515105 6.9868264]\n",
      "Reset environment\n",
      "Episode reward: 2430.2036\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9956737 6.9631157 6.9988055 5.358253  6.8527718 6.9882545]\n",
      "Reset environment\n",
      "Episode reward: 1536.7524\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.996562  6.9640117 6.9996867 5.359266  6.8535557 6.989144 ]\n",
      "Reset environment\n",
      "Episode reward: 2382.431\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.9979076 6.965303  7.0010786 5.360825  6.854741  6.9904876]\n",
      "Reset environment\n",
      "Episode reward: 2889.8547\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [6.999634  6.9670315 7.002795  5.3627896 6.8562465 6.992214 ]\n",
      "Reset environment\n",
      "Episode reward: 3160.7888\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0016284 6.9689975 7.0048094 5.365006  6.858002  6.994207 ]\n",
      "Reset environment\n",
      "Episode reward: 1875.2637\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0027637 6.970107  7.005969  5.366258  6.8590217 6.9953403]\n",
      "Reset environment\n",
      "Episode reward: 36.545563\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.002288  6.9694705 7.0056596 5.3659286 6.858553  6.99487  ]\n",
      "Reset environment\n",
      "Episode reward: 5543.5874\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.005996  6.973185  7.0093613 5.3699837 6.861853  6.998581 ]\n",
      "Reset environment\n",
      "Episode reward: 1907.6376\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.007138  6.974321  7.0105057 5.37126   6.8628526 6.999724 ]\n",
      "Reset environment\n",
      "Episode reward: 2465.4014\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0086927 6.9758654 7.0120707 5.372992  6.8642316 7.0012817]\n",
      "Reset environment\n",
      "Episode reward: 2113.1768\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0099754 6.977158  7.0133443 5.3744435 6.86536   7.002565 ]\n",
      "Reset environment\n",
      "Episode reward: 2216.384\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.011289  6.9784493 7.014679  5.3759236 6.866525  7.0038786]\n",
      "Reset environment\n",
      "Episode reward: 3855.6882\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.013788  6.980919  7.017199  5.3786693 6.868742  7.0063767]\n",
      "Reset environment\n",
      "Episode reward: 2127.8767\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.015051  6.9821987 7.0184417 5.3801117 6.8698554 7.007641 ]\n",
      "Reset environment\n",
      "Episode reward: 4660.0312\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.01804   6.9851866 7.0214243 5.3834114 6.872492  7.0106316]\n",
      "Reset environment\n",
      "Episode reward: 1291.8994\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0187445 6.9859138 7.0221047 5.384214  6.873113  7.011337 ]\n",
      "Reset environment\n",
      "Episode reward: 1293.0472\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0199194 6.9870915 7.023273  5.385553  6.87413   7.0125117]\n",
      "Reset environment\n",
      "Episode reward: 5100.905\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.023286  6.9904857 7.0266147 5.3892527 6.8771334 7.015882 ]\n",
      "Reset environment\n",
      "Episode reward: 4838.284\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.026512  6.993704  7.029845  5.3928013 6.879991  7.0191054]\n",
      "Reset environment\n",
      "Episode reward: -316.48993\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.025995  6.993145  7.029372  5.3921285 6.879527  7.0185905]\n",
      "Reset environment\n",
      "Episode reward: 5434.4824\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0296206 6.9967866 7.0329823 5.396099  6.8827677 7.02222  ]\n",
      "Reset environment\n",
      "Episode reward: 1853.525\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0311966 6.998362  7.034558  5.397869  6.8841505 7.023796 ]\n",
      "Reset environment\n",
      "Episode reward: 4175.0635\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.033909  7.001054  7.0372844 5.4008746 6.88655   7.0265083]\n",
      "Reset environment\n",
      "Episode reward: 2575.781\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0353794 7.0024643 7.038812  5.402555  6.8878565 7.027983 ]\n",
      "Reset environment\n",
      "Episode reward: 1293.3595\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.036558  7.0036454 7.039991  5.4038987 6.8888803 7.029165 ]\n",
      "Reset environment\n",
      "Episode reward: 2086.789\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.037817  7.0048733 7.0412807 5.4053082 6.890002  7.030425 ]\n",
      "Reset environment\n",
      "Episode reward: 2246.2861\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.039218  7.0062757 7.042677  5.4068804 6.8912497 7.031826 ]\n",
      "Reset environment\n",
      "Episode reward: 4981.037\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.042521  7.0095606 7.0459948 5.410517  6.89419   7.0351305]\n",
      "Reset environment\n",
      "Episode reward: 275.80777\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0426044 7.0096617 7.046065  5.4105387 6.894251  7.0352144]\n",
      "Reset environment\n",
      "Episode reward: 1654.5198\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0435762 7.0106416 7.0470295 5.411642  6.8951025 7.0361876]\n",
      "Reset environment\n",
      "Episode reward: 2637.6921\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.045077  7.012083  7.048578  5.4133515 6.8964305 7.037689 ]\n",
      "Reset environment\n",
      "Episode reward: 1732.9313\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0460687 7.013072  7.049575  5.414504  6.89729   7.0386825]\n",
      "Reset environment\n",
      "Episode reward: 4994.1035\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0493712 7.016352  7.0528893 5.4181376 6.9002314 7.0419855]\n",
      "Reset environment\n",
      "Episode reward: 3338.2822\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0515127 7.018491  7.05503   5.420503  6.9021277 7.0441284]\n",
      "Reset environment\n",
      "Episode reward: 5293.8193\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0549245 7.021912  7.0584297 5.4242473 6.905167  7.047546 ]\n",
      "Reset environment\n",
      "Episode reward: 2674.959\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0565124 7.0235095 7.060009  5.4260273 6.906562  7.0491343]\n",
      "Reset environment\n",
      "Episode reward: 3022.1277\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.058332  7.0252748 7.0618773 5.4280705 6.9081855 7.0509553]\n",
      "Reset environment\n",
      "Episode reward: 2067.074\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0595503 7.0265136 7.063077  5.4294333 6.9092584 7.0521755]\n",
      "Reset environment\n",
      "Episode reward: -381.91754\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.058694  7.0258007 7.06209   5.4285564 6.90847   7.051324 ]\n",
      "Reset environment\n",
      "Episode reward: 1028.5743\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.059221  7.026337  7.062611  5.4291763 6.908932  7.0518513]\n",
      "Reset environment\n",
      "Episode reward: 4612.6074\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.062187  7.029293  7.0655704 5.432414  6.911562  7.0548124]\n",
      "Reset environment\n",
      "Episode reward: 2005.7544\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.063404  7.030503  7.066791  5.4337773 6.912628  7.05603  ]\n",
      "Reset environment\n",
      "Episode reward: 2458.8164\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.064877  7.0320187 7.0682244 5.435436  6.913928  7.0575085]\n",
      "Reset environment\n",
      "Episode reward: 3686.6475\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0672345 7.0343447 7.070618  5.4380465 6.916019  7.0598664]\n",
      "Reset environment\n",
      "Episode reward: 1835.5941\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0681787 7.035346  7.0715046 5.4391556 6.916844  7.060811 ]\n",
      "Reset environment\n",
      "Episode reward: 3045.3767\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.070044  7.0372396 7.073332  5.441225  6.918494  7.0626745]\n",
      "Reset environment\n",
      "Episode reward: 2444.1528\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0714874 7.038679  7.074779  5.442833  6.9197674 7.064121 ]\n",
      "Reset environment\n",
      "Episode reward: 2222.856\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0728426 7.040044  7.076124  5.444348  6.920965  7.065477 ]\n",
      "Reset environment\n",
      "Episode reward: 1425.7738\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0736346 7.040863  7.0768886 5.4452477 6.921665  7.066269 ]\n",
      "Reset environment\n",
      "Episode reward: 2085.1958\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.074882  7.0420976 7.078146  5.4466577 6.9227557 7.0675178]\n",
      "Reset environment\n",
      "Episode reward: 2228.6658\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.076261  7.043473  7.0795264 5.448188  6.923974  7.0688977]\n",
      "Reset environment\n",
      "Episode reward: 1155.1504\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0768847 7.044104  7.0801396 5.4489064 6.924522  7.0695214]\n",
      "Reset environment\n",
      "Episode reward: 1747.0837\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.078357  7.0455775 7.0816092 5.450565  6.9258018 7.0709968]\n",
      "Reset environment\n",
      "Episode reward: 1890.1509\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.079491  7.0467114 7.0827403 5.451834  6.9268017 7.0721297]\n",
      "Reset environment\n",
      "Episode reward: 1599.7347\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.080893  7.0481095 7.084141  5.4533987 6.928033  7.073531 ]\n",
      "Reset environment\n",
      "Episode reward: 2499.6277\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0824447 7.0496683 7.0856757 5.455129  6.929402  7.0750804]\n",
      "Reset environment\n",
      "Episode reward: 1479.9249\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.083467  7.050738  7.0866547 5.456269  6.9303336 7.076108 ]\n",
      "Reset environment\n",
      "Episode reward: 2422.2488\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0848546 7.0520697 7.088098  5.457857  6.9315634 7.077499 ]\n",
      "Reset environment\n",
      "Episode reward: 3629.446\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.087039  7.0542216 7.0903144 5.4603105 6.9334784 7.079684 ]\n",
      "Reset environment\n",
      "Episode reward: 2166.3135\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.088328  7.0555015 7.0916095 5.461771  6.9346113 7.0809712]\n",
      "Reset environment\n",
      "Episode reward: 3017.6292\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.090233  7.057383  7.0935326 5.463891  6.9362965 7.0828733]\n",
      "Reset environment\n",
      "Episode reward: 4831.016\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.093413  7.060578  7.096696  5.4673853 6.9391465 7.086056 ]\n",
      "Reset environment\n",
      "Episode reward: 2276.9038\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0948176 7.0619926 7.098086  5.468946  6.940399  7.087461 ]\n",
      "Reset environment\n",
      "Episode reward: 3713.1604\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.0971723 7.0643783 7.1004043 5.47152   6.9425025 7.089814 ]\n",
      "Reset environment\n",
      "Episode reward: 5704.814\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.100862  7.0680733 7.1040797 5.475558  6.945787  7.0935063]\n",
      "Reset environment\n",
      "Episode reward: 3646.758\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.103253  7.0704536 7.1064787 5.4781775 6.9479284 7.0958967]\n",
      "Reset environment\n",
      "Episode reward: 1848.7075\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.104343  7.071555  7.1075635 5.4793863 6.948906  7.0969887]\n",
      "Reset environment\n",
      "Episode reward: 2869.3442\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1061807 7.0733914 7.1094027 5.4814124 6.9505415 7.0988255]\n",
      "Reset environment\n",
      "Episode reward: 2062.2356\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.107426  7.074636  7.1106434 5.4827976 6.9516335 7.1000705]\n",
      "Reset environment\n",
      "Episode reward: 4279.893\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.110208  7.0774174 7.1134276 5.4858856 6.9540954 7.1028557]\n",
      "Reset environment\n",
      "Episode reward: 1715.3777\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.110998  7.078266  7.1141562 5.4868565 6.9547806 7.1036434]\n",
      "Reset environment\n",
      "Episode reward: 2407.8289\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1128287 7.080095  7.115991  5.4888854 6.9564    7.105475 ]\n",
      "Reset environment\n",
      "Episode reward: 1967.7037\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1139216 7.0811367 7.1171284 5.490147  6.9573684 7.106569 ]\n",
      "Reset environment\n",
      "Episode reward: 3365.9539\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1160626 7.083295  7.1192503 5.4925065 6.9592633 7.1087117]\n",
      "Reset environment\n",
      "Episode reward: 1706.0526\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.117017  7.0842113 7.1202354 5.4935875 6.9601097 7.1096663]\n",
      "Reset environment\n",
      "Episode reward: 2993.0781\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1188626 7.0860896 7.12204   5.495635  6.9617333 7.111511 ]\n",
      "Reset environment\n",
      "Episode reward: 2944.867\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1206937 7.087893  7.1238933 5.497666  6.9633555 7.1133404]\n",
      "Reset environment\n",
      "Episode reward: 2128.791\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1219797 7.08916   7.125198  5.4991083 6.964489  7.114629 ]\n",
      "Reset environment\n",
      "Episode reward: 4667.326\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.125025  7.0922165 7.1282277 5.502456  6.9671946 7.117672 ]\n",
      "Reset environment\n",
      "Episode reward: 2087.467\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.126773  7.0939665 7.1299725 5.5043936 6.9687467 7.119421 ]\n",
      "Reset environment\n",
      "Episode reward: 3290.517\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.128868  7.0960574 7.132069  5.5066895 6.970601  7.121517 ]\n",
      "Reset environment\n",
      "Episode reward: 4268.0815\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1316423 7.0988235 7.134852  5.50974   6.973069  7.1242924]\n",
      "Reset environment\n",
      "Episode reward: 2375.2305\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.132959  7.100175  7.136123  5.5112524 6.9742327 7.1256084]\n",
      "Reset environment\n",
      "Episode reward: 652.7357\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1330667 7.1004186 7.136108  5.511504  6.974346  7.125719 ]\n",
      "Reset environment\n",
      "Episode reward: 5722.359\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.13685   7.1042156 7.1398754 5.5156293 6.9777026 7.1294994]\n",
      "Reset environment\n",
      "Episode reward: 2603.903\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1384673 7.105842  7.14148   5.5174284 6.979135  7.1311183]\n",
      "Reset environment\n",
      "Episode reward: 2046.8201\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.140173  7.1075478 7.1431837 5.51933   6.980642  7.132822 ]\n",
      "Reset environment\n",
      "Episode reward: 1789.2251\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1416926 7.109067  7.1447062 5.5210238 6.9819827 7.1343393]\n",
      "Reset environment\n",
      "Episode reward: 4932.9233\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1449146 7.1122975 7.147917  5.524567  6.984855  7.137563 ]\n",
      "Reset environment\n",
      "Episode reward: 1562.3629\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1458244 7.113218  7.1488085 5.525584  6.985669  7.1384735]\n",
      "Reset environment\n",
      "Episode reward: 2155.094\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1476107 7.115005  7.1505876 5.5275617 6.987246  7.1402593]\n",
      "Reset environment\n",
      "Episode reward: 2325.7236\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1489735 7.11632   7.151993  5.5290947 6.9884577 7.141621 ]\n",
      "Reset environment\n",
      "Episode reward: 4665.617\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.152022  7.119369  7.1550417 5.5324583 6.9911637 7.144671 ]\n",
      "Reset environment\n",
      "Episode reward: 2779.134\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1535296 7.1207848 7.156636  5.5342135 6.9924903 7.146182 ]\n",
      "Reset environment\n",
      "Episode reward: 2123.1147\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1552944 7.122549  7.1583986 5.536157  6.994047  7.1479464]\n",
      "Reset environment\n",
      "Episode reward: 4779.509\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1584177 7.125686  7.161501  5.5395837 6.996835  7.151071 ]\n",
      "Reset environment\n",
      "Episode reward: 2857.107\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.160132  7.1274004 7.1632123 5.541507  6.9983377 7.1527843]\n",
      "Reset environment\n",
      "Episode reward: 3754.5425\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1625237 7.1298323 7.1655626 5.544124  7.000479  7.1551733]\n",
      "Reset environment\n",
      "Episode reward: 5048.0737\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1657567 7.133059  7.1688004 5.5476565 7.0033517 7.1584125]\n",
      "Reset environment\n",
      "Episode reward: 3734.1714\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.168173  7.1354885 7.1712017 5.550284  7.005511  7.1608286]\n",
      "Reset environment\n",
      "Episode reward: 1530.1012\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.169058  7.136393  7.17207   5.551281  7.0063014 7.1617146]\n",
      "Reset environment\n",
      "Episode reward: 1962.3909\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.17068   7.13801   7.173695  5.5530953 7.007731  7.1633387]\n",
      "Reset environment\n",
      "Episode reward: 2130.292\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.171976  7.139321  7.1749773 5.554545  7.008895  7.1646357]\n",
      "Reset environment\n",
      "Episode reward: 3139.4578\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1738534 7.1412344 7.176814  5.556637  7.0105724 7.16651  ]\n",
      "Reset environment\n",
      "Episode reward: 2118.0015\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.175116  7.142476  7.178099  5.558054  7.011692  7.1677766]\n",
      "Reset environment\n",
      "Episode reward: 2716.8528\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1768    7.1441526 7.1797824 5.5599303 7.0131736 7.1694593]\n",
      "Reset environment\n",
      "Episode reward: 2289.762\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1780963 7.1454425 7.181087  5.5613976 7.014307  7.170757 ]\n",
      "Reset environment\n",
      "Episode reward: 2299.6487\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1794744 7.146818  7.182463  5.562952  7.015507  7.1721334]\n",
      "Reset environment\n",
      "Episode reward: 1447.432\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1802926 7.147628  7.18329   5.5638704 7.0162344 7.172951 ]\n",
      "Reset environment\n",
      "Episode reward: 5067.4917\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1836286 7.1509657 7.186625  5.5675006 7.0192227 7.176286 ]\n",
      "Reset environment\n",
      "Episode reward: 3873.68\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.186086  7.1534367 7.189064  5.5702157 7.021401  7.1787453]\n",
      "Reset environment\n",
      "Episode reward: 2999.3872\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1878657 7.1551623 7.190893  5.5722146 7.0229936 7.1805263]\n",
      "Reset environment\n",
      "Episode reward: -368.3402\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1872554 7.1545076 7.190333  5.571414  7.0224595 7.179919 ]\n",
      "Reset environment\n",
      "Episode reward: 2638.2644\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1889005 7.1561303 7.191998  5.573228  7.0239267 7.181563 ]\n",
      "Reset environment\n",
      "Episode reward: 2245.3936\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.190266  7.1575103 7.193355  5.574757  7.025151  7.182934 ]\n",
      "Reset environment\n",
      "Episode reward: 2237.3137\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1914196 7.1587343 7.1944404 5.576115  7.0261526 7.1840844]\n",
      "Reset environment\n",
      "Episode reward: 1684.7808\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.192875  7.160193  7.195894  5.577742  7.027427  7.1855364]\n",
      "Reset environment\n",
      "Episode reward: 2295.7507\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1942477 7.161583  7.197246  5.579264  7.028637  7.1869082]\n",
      "Reset environment\n",
      "Episode reward: 3140.2112\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.1961293 7.1635027 7.1990843 5.581358  7.0303097 7.188789 ]\n",
      "Reset environment\n",
      "Episode reward: 2602.9934\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.197632  7.165011  7.2005816 5.583053  7.031624  7.1902943]\n",
      "Reset environment\n",
      "Episode reward: 4936.122\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.200692 7.168049 7.203654 5.586473 7.034318 7.193355]\n",
      "Reset environment\n",
      "Episode reward: 2259.0723\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.202088  7.169439  7.2050576 5.588031  7.0355697 7.194753 ]\n",
      "Reset environment\n",
      "Episode reward: 3550.8667\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.204346  7.171707  7.2073035 5.5905247 7.037578  7.197014 ]\n",
      "Reset environment\n",
      "Episode reward: 845.254\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.204558  7.1718125 7.2076254 5.5908775 7.03778   7.1972294]\n",
      "Reset environment\n",
      "Episode reward: 3026.7644\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2064013 7.1736174 7.2094984 5.5929155 7.039425  7.1990747]\n",
      "Reset environment\n",
      "Episode reward: 3828.3782\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2088437 7.176075  7.211927  5.595623  7.041599  7.2015176]\n",
      "Reset environment\n",
      "Episode reward: 2528.333\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.210402  7.1776505 7.213468  5.597346  7.0429854 7.2030764]\n",
      "Reset environment\n",
      "Episode reward: 2156.6462\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2121754 7.1794114 7.215249  5.5993166 7.0445576 7.2048492]\n",
      "Reset environment\n",
      "Episode reward: 1957.6697\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2133274 7.1805525 7.2164116 5.6006074 7.0455766 7.206001 ]\n",
      "Reset environment\n",
      "Episode reward: 2704.3086\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2150187 7.182243  7.218102  5.602483  7.047077  7.2076917]\n",
      "Reset environment\n",
      "Episode reward: 2404.6226\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2164783 7.1837144 7.21955   5.6041036 7.048379  7.209154 ]\n",
      "Reset environment\n",
      "Episode reward: 3064.9688\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2182956 7.185484  7.221415  5.6061397 7.049998  7.2109723]\n",
      "Reset environment\n",
      "Episode reward: 3184.0332\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.220309  7.1874905 7.223427  5.6083612 7.05178   7.212985 ]\n",
      "Reset environment\n",
      "Episode reward: 1852.5609\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2213717 7.188555  7.2244854 5.6095686 7.0527067 7.214047 ]\n",
      "Reset environment\n",
      "Episode reward: 2554.5378\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2229285 7.190122  7.2260246 5.6112933 7.054079  7.215604 ]\n",
      "Reset environment\n",
      "Episode reward: 2884.5674\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.224567  7.1917    7.2277217 5.613156  7.0555315 7.2172446]\n",
      "Reset environment\n",
      "Episode reward: 3199.7454\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.226621  7.193759  7.229761  5.615389  7.057365  7.2192993]\n",
      "Reset environment\n",
      "Episode reward: 2147.3103\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2279224 7.1950555 7.231066  5.616837  7.0585136 7.2206   ]\n",
      "Reset environment\n",
      "Episode reward: 2035.1272\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2291155 7.1962466 7.2322555 5.6181803 7.0595584 7.2217946]\n",
      "Reset environment\n",
      "Episode reward: -590.8297\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2283597 7.195515  7.231483  5.617262  7.0589147 7.2210402]\n",
      "Reset environment\n",
      "Episode reward: 3586.6562\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.230593  7.197786  7.2336717 5.6197257 7.0608997 7.223274 ]\n",
      "Reset environment\n",
      "Episode reward: 3398.2905\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2327337 7.1999393 7.2357965 5.622087  7.0628085 7.2254133]\n",
      "Reset environment\n",
      "Episode reward: 2479.457\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2342    7.2014074 7.2372575 5.623753  7.064084  7.226882 ]\n",
      "Reset environment\n",
      "Episode reward: 2570.2092\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.235874  7.2031493 7.238864  5.625624  7.0656004 7.228561 ]\n",
      "Reset environment\n",
      "Episode reward: 1218.2522\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2369547 7.2042294 7.23994   5.6268783 7.06652   7.22964  ]\n",
      "Reset environment\n",
      "Episode reward: 3004.423\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.238831  7.2060814 7.241834  5.6289515 7.068183  7.231518 ]\n",
      "Reset environment\n",
      "Episode reward: -398.01917\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2380157 7.2053742 7.24092   5.628341  7.0673575 7.2307105]\n",
      "Reset environment\n",
      "Episode reward: 1954.5164\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.239603  7.2069607 7.242507  5.630126  7.06874   7.2322974]\n",
      "Reset environment\n",
      "Episode reward: 895.50476\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2401333 7.207519  7.2430105 5.6306305 7.0692315 7.232834 ]\n",
      "Reset environment\n",
      "Episode reward: 3624.119\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2424316 7.209837  7.245287  5.633158  7.0712805 7.2351313]\n",
      "Reset environment\n",
      "Episode reward: 4092.3354\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.245003  7.2124305 7.247837  5.6360197 7.073548  7.2376995]\n",
      "Reset environment\n",
      "Episode reward: 2545.6587\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2464867 7.2139597 7.249275  5.6376853 7.0748715 7.2391844]\n",
      "Reset environment\n",
      "Episode reward: 3044.1204\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.248341  7.215782  7.251158  5.6397514 7.076511  7.241039 ]\n",
      "Reset environment\n",
      "Episode reward: 2041.8446\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2500396 7.217478  7.252858  5.641625  7.078012  7.242737 ]\n",
      "Reset environment\n",
      "Episode reward: 1752.6583\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2510266 7.2184515 7.2538557 5.6427426 7.078885  7.243725 ]\n",
      "Reset environment\n",
      "Episode reward: 3900.8972\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.253528  7.2209454 7.256369  5.6455173 7.08111   7.2462287]\n",
      "Reset environment\n",
      "Episode reward: 4887.5083\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.256588  7.2240033 7.2594256 5.6488686 7.0838327 7.2492914]\n",
      "Reset environment\n",
      "Episode reward: 2026.393\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.258227  7.2256327 7.261076  5.650708  7.0852714 7.2509284]\n",
      "Reset environment\n",
      "Episode reward: -731.51483\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.25732   7.2247376 7.2601676 5.6498003 7.0844226 7.250024 ]\n",
      "Reset environment\n",
      "Episode reward: 3656.0764\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.259639  7.2270513 7.262486  5.652351  7.0864806 7.2523413]\n",
      "Reset environment\n",
      "Episode reward: 1880.0775\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2607236 7.2281275 7.263577  5.6535754 7.087433  7.253427 ]\n",
      "Reset environment\n",
      "Episode reward: 1703.5798\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2621717 7.2295737 7.26502   5.6551886 7.0887065 7.2548757]\n",
      "Reset environment\n",
      "Episode reward: 4484.583\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.26505   7.2324424 7.2679005 5.6583595 7.0912557 7.2577505]\n",
      "Reset environment\n",
      "Episode reward: 4502.9463\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.267984  7.2353864 7.2708197 5.6615615 7.093891  7.2606835]\n",
      "Reset environment\n",
      "Episode reward: 1929.4563\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.269098  7.2365127 7.271921  5.6628003 7.09488   7.2618   ]\n",
      "Reset environment\n",
      "Episode reward: -468.4621\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.268076  7.2352715 7.2711196 5.661979  7.0938563 7.260775 ]\n",
      "Reset environment\n",
      "Episode reward: 3883.3406\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2705464 7.2377334 7.2735934 5.6647115 7.0960402 7.263244 ]\n",
      "Reset environment\n",
      "Episode reward: 2325.2222\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.271918  7.239088  7.2749796 5.6662407 7.097264  7.2646127]\n",
      "Reset environment\n",
      "Episode reward: 5685.4404\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.275646  7.2428303 7.2786956 5.670314  7.1006107 7.2683415]\n",
      "Reset environment\n",
      "Episode reward: 3525.5112\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2778387 7.2449927 7.2809114 5.6727343 7.1025515 7.270534 ]\n",
      "Reset environment\n",
      "Episode reward: 3704.0046\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.280164  7.2473454 7.283205  5.6752896 7.104608  7.2728577]\n",
      "Reset environment\n",
      "Episode reward: 5846.169\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.283989  7.2511806 7.2870197 5.679482  7.1080394 7.2766857]\n",
      "Reset environment\n",
      "Episode reward: 5069.13\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2872696 7.2544785 7.2902856 5.683094  7.1109705 7.279971 ]\n",
      "Reset environment\n",
      "Episode reward: 4594.5303\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2901373 7.2573414 7.293153  5.686257  7.1135054 7.2828393]\n",
      "Reset environment\n",
      "Episode reward: 3642.022\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2923803 7.2595563 7.2954226 5.6887445 7.1154847 7.285084 ]\n",
      "Reset environment\n",
      "Episode reward: 2072.648\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2940745 7.261252  7.297117  5.6906366 7.1169853 7.286778 ]\n",
      "Reset environment\n",
      "Episode reward: 3442.6528\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.296234  7.2634244 7.299266  5.693029  7.1189084 7.2889357]\n",
      "Reset environment\n",
      "Episode reward: 1969.3027\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2972856 7.2645135 7.300276  5.6942368 7.119837  7.289984 ]\n",
      "Reset environment\n",
      "Episode reward: 1349.8655\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.2984834 7.2657156 7.3014717 5.69558   7.120889  7.291184 ]\n",
      "Reset environment\n",
      "Episode reward: 2126.9211\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3002224 7.267459  7.303204  5.6975193 7.1224294 7.2929235]\n",
      "Reset environment\n",
      "Episode reward: 5555.536\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3038163 7.271071  7.3067822 5.7014585 7.1256313 7.296517 ]\n",
      "Reset environment\n",
      "Episode reward: 1841.5277\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3048882 7.272162  7.307838  5.7026587 7.1265807 7.2975903]\n",
      "Reset environment\n",
      "Episode reward: 1850.0911\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3064265 7.2736974 7.3093767 5.70438   7.1279254 7.2991276]\n",
      "Reset environment\n",
      "Episode reward: 4481.0454\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3093095 7.2765923 7.3122478 5.7075253 7.1305    7.30201  ]\n",
      "Reset environment\n",
      "Episode reward: 1915.0245\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3104053 7.277694  7.313337  5.708774  7.13146   7.3031063]\n",
      "Reset environment\n",
      "Episode reward: 5194.1377\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3137636 7.281053  7.31669   5.712442  7.134442  7.3064623]\n",
      "Reset environment\n",
      "Episode reward: 2734.711\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.315216  7.282575  7.318077  5.7141356 7.1357126 7.3079157]\n",
      "Reset environment\n",
      "Episode reward: 4165.6074\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.317894  7.2852483 7.3207636 5.7170815 7.138097  7.3105917]\n",
      "Reset environment\n",
      "Episode reward: -415.107\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3173137 7.284718  7.320139  5.7163973 7.1375875 7.310013 ]\n",
      "Reset environment\n",
      "Episode reward: 3392.7485\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3194356 7.286855  7.322247  5.7187133 7.1394763 7.3121357]\n",
      "Reset environment\n",
      "Episode reward: 1736.7643\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3204083 7.2878327 7.3232107 5.7198253 7.1403303 7.3131065]\n",
      "Reset environment\n",
      "Episode reward: 2808.2\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.322108  7.2895536 7.3248835 5.721695  7.141832  7.3148036]\n",
      "Reset environment\n",
      "Episode reward: 2101.6829\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.32383   7.2912736 7.3266063 5.723598  7.1433487 7.316525 ]\n",
      "Reset environment\n",
      "Episode reward: 1929.2959\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.324902  7.2923675 7.3276577 5.724821  7.1442895 7.3176   ]\n",
      "Reset environment\n",
      "Episode reward: 1824.0975\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.326218  7.2936673 7.328994  5.726296  7.145476  7.3189197]\n",
      "Reset environment\n",
      "Episode reward: 1941.1903\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3273263 7.2947903 7.330087  5.7275543 7.1464543 7.3200293]\n",
      "Reset environment\n",
      "Episode reward: 2348.1545\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3286963 7.296189  7.3314276 5.7290993 7.147656  7.321399 ]\n",
      "Reset environment\n",
      "Episode reward: 3297.524\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.330671 7.298159 7.333398 5.731294 7.149386 7.323374]\n",
      "Reset environment\n",
      "Episode reward: 1500.9951\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.331457  7.298944  7.3341813 5.7322235 7.150049  7.324161 ]\n",
      "Reset environment\n",
      "Episode reward: 1912.2667\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3323636 7.2999234 7.335019  5.733305  7.150843  7.3250694]\n",
      "Reset environment\n",
      "Episode reward: 2454.287\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.333795  7.301326  7.336475  5.7349167 7.152101  7.3265   ]\n",
      "Reset environment\n",
      "Episode reward: 2171.9658\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3355627 7.303099  7.3382316 5.7368712 7.153667  7.328267 ]\n",
      "Reset environment\n",
      "Episode reward: -3.756012\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3349385 7.3026385 7.3374696 5.736304  7.1530805 7.3276496]\n",
      "Reset environment\n",
      "Episode reward: 2201.8364\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.336213  7.3039303 7.338728  5.7377357 7.1542015 7.3289256]\n",
      "Reset environment\n",
      "Episode reward: 1996.3232\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3373537 7.305089  7.339849  5.7390103 7.1552124 7.3300686]\n",
      "Reset environment\n",
      "Episode reward: 1843.3741\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3383875 7.3061    7.340904  5.740167  7.1561294 7.331102 ]\n",
      "Reset environment\n",
      "Episode reward: 2756.4734\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.340074  7.3077917 7.3425803 5.742035  7.157625  7.3327894]\n",
      "Reset environment\n",
      "Episode reward: 1999.4615\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.341215  7.308963  7.3436875 5.743313  7.1586328 7.333933 ]\n",
      "Reset environment\n",
      "Episode reward: 996.4783\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.341843  7.309569  7.3443375 5.7440166 7.1592326 7.3345637]\n",
      "Reset environment\n",
      "Episode reward: 4626.6934\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3448324 7.3125668 7.3473153 5.7472663 7.161909  7.3375516]\n",
      "Reset environment\n",
      "Episode reward: 2574.9941\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.346334  7.3140674 7.348815  5.748911  7.1632376 7.3390536]\n",
      "Reset environment\n",
      "Episode reward: 2564.519\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.347818  7.3155875 7.3502545 5.7505603 7.1645465 7.3405366]\n",
      "Reset environment\n",
      "Episode reward: 1793.4811\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3488326 7.316595  7.3512745 5.7517185 7.165428  7.341552 ]\n",
      "Reset environment\n",
      "Episode reward: 3529.7288\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3510485 7.3188357 7.353474  5.754148  7.16741   7.343768 ]\n",
      "Reset environment\n",
      "Episode reward: 705.559\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.351126  7.3187575 7.3537107 5.7544336 7.1674447 7.3438497]\n",
      "Reset environment\n",
      "Episode reward: 4682.194\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.354105  7.321711  7.3567147 5.757708  7.1700954 7.346831 ]\n",
      "Reset environment\n",
      "Episode reward: 1918.6086\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3551965 7.322811  7.357799  5.7589517 7.1710577 7.347923 ]\n",
      "Reset environment\n",
      "Episode reward: 2887.2305\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.356882  7.3245444 7.359435  5.7608404 7.172557  7.3496113]\n",
      "Reset environment\n",
      "Episode reward: 1829.7832\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.35792   7.3255873 7.3604693 5.76202   7.173467  7.3506503]\n",
      "Reset environment\n",
      "Episode reward: 2015.1134\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3590946 7.326755  7.361651  5.763337  7.174503  7.3518267]\n",
      "Reset environment\n",
      "Episode reward: 2016.2009\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.360713  7.328374  7.363269  5.7651544 7.17592   7.3534455]\n",
      "Reset environment\n",
      "Episode reward: 1385.2848\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.361944  7.329607  7.3644977 5.766527  7.1770034 7.3546762]\n",
      "Reset environment\n",
      "Episode reward: 2108.206\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.363659  7.331324  7.3662076 5.7684326 7.1785192 7.3563905]\n",
      "Reset environment\n",
      "Episode reward: 3621.2368\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.365923  7.333602  7.3684545 5.7709246 7.1805267 7.3586545]\n",
      "Reset environment\n",
      "Episode reward: 725.0525\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.366096  7.333629  7.368777  5.771312  7.1806526 7.358832 ]\n",
      "Reset environment\n",
      "Episode reward: 2086.0923\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3677864 7.335325  7.3704615 5.7731957 7.182141  7.360522 ]\n",
      "Reset environment\n",
      "Episode reward: -583.9488\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3668313 7.334464  7.369418  5.7720976 7.1812983 7.359572 ]\n",
      "Reset environment\n",
      "Episode reward: 2112.5752\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.368095  7.3357244 7.3706846 5.773516  7.1824136 7.3608365]\n",
      "Reset environment\n",
      "Episode reward: 5245.5625\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.371487  7.339119  7.374071  5.777223  7.1854463 7.3642297]\n",
      "Reset environment\n",
      "Episode reward: 1342.2897\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3726773 7.3403087 7.375261  5.7785516 7.186488  7.36542  ]\n",
      "Reset environment\n",
      "Episode reward: 3746.7734\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3749337 7.34258   7.3774977 5.781069  7.188469  7.367676 ]\n",
      "Reset environment\n",
      "Episode reward: 4165.328\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3776007 7.345257  7.3801527 5.783975  7.190852  7.3703437]\n",
      "Reset environment\n",
      "Episode reward: -624.5435\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3767776 7.3445    7.379276  5.7830215 7.190128  7.3695283]\n",
      "Reset environment\n",
      "Episode reward: 2726.6455\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3782988 7.34596   7.380859  5.7847524 7.1914806 7.3710494]\n",
      "Reset environment\n",
      "Episode reward: 4423.8423\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.381025  7.348677  7.3835797 5.787743  7.193887  7.3737764]\n",
      "Reset environment\n",
      "Episode reward: 2122.4197\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3822455 7.3498826 7.384816  5.789129  7.1949654 7.3749967]\n",
      "Reset environment\n",
      "Episode reward: 3324.6194\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3842726 7.351928  7.3868303 5.7913866 7.1967654 7.377027 ]\n",
      "Reset environment\n",
      "Episode reward: 1118.6299\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3848224 7.352466  7.3873878 5.7920256 7.1972466 7.3775754]\n",
      "Reset environment\n",
      "Episode reward: 1755.6533\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.385823  7.353489  7.3883677 5.793162  7.1981378 7.378577 ]\n",
      "Reset environment\n",
      "Episode reward: 2308.2368\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3868957 7.354503  7.389489  5.794433  7.1990733 7.3796487]\n",
      "Reset environment\n",
      "Episode reward: 1824.2168\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3879266 7.3555155 7.390539  5.7955995 7.1999764 7.38068  ]\n",
      "Reset environment\n",
      "Episode reward: 4451.6064\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.390746  7.358342  7.393341  5.7987075 7.202487  7.3834996]\n",
      "Reset environment\n",
      "Episode reward: 2439.705\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.392159  7.359726  7.3947806 5.8003016 7.203735  7.384912 ]\n",
      "Reset environment\n",
      "Episode reward: 3725.31\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.3944926 7.362074  7.3970947 5.8028445 7.205812  7.387242 ]\n",
      "Reset environment\n",
      "Episode reward: 1326.7499\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.395211  7.3627987 7.3978057 5.803663  7.2064514 7.38796  ]\n",
      "Reset environment\n",
      "Episode reward: 402.28482\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.395058  7.362759  7.397551  5.803539  7.2063255 7.387813 ]\n",
      "Reset environment\n",
      "Episode reward: 3529.0286\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.397241  7.364934  7.3997345 5.805951  7.2082534 7.389993 ]\n",
      "Reset environment\n",
      "Episode reward: 2123.3025\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.398959  7.3666525 7.4014506 5.807848  7.209774  7.391711 ]\n",
      "Reset environment\n",
      "Episode reward: 4340.239\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4015903 7.369283  7.404086  5.8107786 7.21209   7.394346 ]\n",
      "Reset environment\n",
      "Episode reward: 3967.9268\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.403969  7.3716583 7.4064627 5.8134313 7.2141814 7.3967237]\n",
      "Reset environment\n",
      "Episode reward: 1874.3662\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4050446 7.3727236 7.407551  5.81464   7.215135  7.3977976]\n",
      "Reset environment\n",
      "Episode reward: 5743.6226\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.408741  7.3764133 7.411257  5.818684  7.218434  7.4014974]\n",
      "Reset environment\n",
      "Episode reward: 2642.8682\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4102592 7.377891  7.412811  5.8203883 7.219785  7.403015 ]\n",
      "Reset environment\n",
      "Episode reward: 2331.8523\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.411428  7.37899   7.4140377 5.8217626 7.220802  7.404184 ]\n",
      "Reset environment\n",
      "Episode reward: 2030.0933\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.413065  7.380627  7.415674  5.8236046 7.2222433 7.405824 ]\n",
      "Reset environment\n",
      "Episode reward: 6082.8657\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.417035  7.384588  7.4196515 5.8279195 7.2257886 7.4097924]\n",
      "Reset environment\n",
      "Episode reward: 3338.0981\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4190955 7.3866534 7.421703  5.8301916 7.227619  7.4118543]\n",
      "Reset environment\n",
      "Episode reward: 4563.8286\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4219975 7.3895416 7.424617  5.8333836 7.2301946 7.4147573]\n",
      "Reset environment\n",
      "Episode reward: 5473.204\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4254246 7.3929787 7.4280186 5.837117  7.2332306 7.4181833]\n",
      "Reset environment\n",
      "Episode reward: 3691.8728\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.427778  7.395328  7.430373  5.839684  7.2353272 7.4205375]\n",
      "Reset environment\n",
      "Episode reward: 4264.2637\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.430387  7.3979397 7.4329796 5.842564  7.237624  7.4231477]\n",
      "Reset environment\n",
      "Episode reward: 3633.846\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4326606 7.4002275 7.435239  5.845054  7.2396507 7.425422 ]\n",
      "Reset environment\n",
      "Episode reward: 2169.938\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.433883  7.401476  7.4364386 5.846431  7.2407265 7.4266467]\n",
      "Reset environment\n",
      "Episode reward: 4045.7214\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4363866 7.403955  7.4389615 5.8491955 7.242949  7.42915  ]\n",
      "Reset environment\n",
      "Episode reward: 620.9227\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4367957 7.404358  7.439369  5.849638  7.2433367 7.4295597]\n",
      "Reset environment\n",
      "Episode reward: 214.3873\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.436399  7.4038634 7.4390736 5.849203  7.2430325 7.429161 ]\n",
      "Reset environment\n",
      "Episode reward: 5009.2754\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4395056 7.406971  7.44218   5.8526053 7.2457867 7.432268 ]\n",
      "Reset environment\n",
      "Episode reward: 220.7397\n",
      "Total Steps: 6\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4394827 7.406949  7.442157  5.8526025 7.245758  7.4322453]\n",
      "Reset environment\n",
      "Episode reward: 1967.9529\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4406013 7.408085  7.4432535 5.853851  7.2467475 7.4333625]\n",
      "Reset environment\n",
      "Episode reward: 1753.116\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.441508  7.40904   7.44411   5.8548994 7.2475505 7.4342732]\n",
      "Reset environment\n",
      "Episode reward: 2896.3633\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4432034 7.410735  7.445801  5.8567476 7.2490535 7.4359694]\n",
      "Reset environment\n",
      "Episode reward: 1869.7029\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4442434 7.4117503 7.446859  5.857908  7.2499685 7.4370055]\n",
      "Reset environment\n",
      "Episode reward: 2497.1433\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4457145 7.413202  7.4483457 5.8595495 7.2512617 7.4384766]\n",
      "Reset environment\n",
      "Episode reward: 4096.868\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4482102 7.415694  7.450842  5.862297  7.253474  7.440977 ]\n",
      "Reset environment\n",
      "Episode reward: 1822.938\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4492335 7.416739  7.451844  5.8634367 7.254385  7.442002 ]\n",
      "Reset environment\n",
      "Episode reward: 1886.1084\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.45032   7.417829  7.452925  5.8646593 7.2553487 7.4430866]\n",
      "Reset environment\n",
      "Episode reward: 2623.2805\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4518137 7.4193225 7.4544177 5.8663483 7.2566586 7.444581 ]\n",
      "Reset environment\n",
      "Episode reward: 3331.5034\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4538264 7.4213014 7.4564567 5.8685765 7.258443  7.4465933]\n",
      "Reset environment\n",
      "Episode reward: 3574.2244\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4559546 7.423431  7.45858   5.870925  7.2603188 7.4487247]\n",
      "Reset environment\n",
      "Episode reward: 1533.5807\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.456811  7.424299  7.459419  5.871899  7.261075  7.4495816]\n",
      "Reset environment\n",
      "Episode reward: 4552.0713\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4596176 7.427103  7.4622273 5.874965  7.263568  7.4523907]\n",
      "Reset environment\n",
      "Episode reward: 132.85715\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.459282  7.4268923 7.461781  5.8747005 7.263275  7.452064 ]\n",
      "Reset environment\n",
      "Episode reward: 1502.8134\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4601173 7.4277287 7.4626117 5.8756347 7.264013  7.4528985]\n",
      "Reset environment\n",
      "Episode reward: 1468.0276\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.460934  7.4285436 7.463428  5.8765564 7.2647347 7.453714 ]\n",
      "Reset environment\n",
      "Episode reward: 3836.3635\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4633107 7.43093   7.4657917 5.87918   7.2668457 7.456091 ]\n",
      "Reset environment\n",
      "Episode reward: 4013.6096\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.465827  7.4334564 7.4682794 5.881951  7.269087  7.458608 ]\n",
      "Reset environment\n",
      "Episode reward: 2457.7832\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.467261  7.4348764 7.4697223 5.883553  7.2703485 7.460043 ]\n",
      "Reset environment\n",
      "Episode reward: 1938.5215\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.468366  7.435976  7.470835  5.884793  7.2713265 7.4611526]\n",
      "Reset environment\n",
      "Episode reward: 3278.6245\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.470361  7.4379964 7.4728036 5.8869944 7.2731013 7.4631467]\n",
      "Reset environment\n",
      "Episode reward: 1937.8796\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.471906  7.4395394 7.474351  5.8887258 7.274446  7.4646935]\n",
      "Reset environment\n",
      "Episode reward: 1509.4374\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4727354 7.4403825 7.475162  5.8896694 7.275177  7.4655247]\n",
      "Reset environment\n",
      "Episode reward: 4592.83\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4756355 7.4432926 7.4780593 5.8928523 7.277754  7.468425 ]\n",
      "Reset environment\n",
      "Episode reward: 445.21698\n",
      "Total Steps: 16\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4757385 7.4433975 7.4781604 5.893012  7.277827  7.4685287]\n",
      "Reset environment\n",
      "Episode reward: -586.95056\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4747105 7.442489  7.477043  5.8918853 7.2769265 7.467507 ]\n",
      "Reset environment\n",
      "Episode reward: 3335.844\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4766803 7.4444275 7.479038  5.8940907 7.2787023 7.4694805]\n",
      "Reset environment\n",
      "Episode reward: 2749.0435\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4783316 7.4460955 7.480671  5.895908  7.2801714 7.4711285]\n",
      "Reset environment\n",
      "Episode reward: 1757.1189\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4793215 7.447085  7.48166   5.897029  7.281043  7.472119 ]\n",
      "Reset environment\n",
      "Episode reward: 3230.5554\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4812326 7.449007  7.4835744 5.899136  7.2827406 7.474033 ]\n",
      "Reset environment\n",
      "Episode reward: 1696.4578\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4821973 7.449986  7.484532  5.9002256 7.2836056 7.4749956]\n",
      "Reset environment\n",
      "Episode reward: 2179.7441\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.483484  7.4512787 7.48582   5.9016676 7.284746  7.4762836]\n",
      "Reset environment\n",
      "Episode reward: 1482.2249\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.484298  7.4521084 7.486609  5.9025817 7.285466  7.477099 ]\n",
      "Reset environment\n",
      "Episode reward: 3536.968\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4864807 7.4543166 7.4887686 5.904982  7.2874246 7.4792824]\n",
      "Reset environment\n",
      "Episode reward: 2057.2407\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4876404 7.455441  7.4899626 5.9062824 7.2884545 7.480445 ]\n",
      "Reset environment\n",
      "Episode reward: 3741.7292\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4899607 7.4577527 7.4922853 5.908834  7.2905097 7.482763 ]\n",
      "Reset environment\n",
      "Episode reward: 1882.3413\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.491032  7.458832  7.4933515 5.9100437 7.2914586 7.4838347]\n",
      "Reset environment\n",
      "Episode reward: 3153.1162\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.492916  7.4606915 7.4952545 5.9121304 7.2931237 7.4857206]\n",
      "Reset environment\n",
      "Episode reward: 5551.7354\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.4963493 7.4641213 7.4986806 5.91592   7.296165  7.489154 ]\n",
      "Reset environment\n",
      "Episode reward: 1685.2515\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.497122  7.464962  7.4993963 5.916849  7.296855  7.4899287]\n",
      "Reset environment\n",
      "Episode reward: 4424.8564\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.499824  7.4676676 7.5020967 5.91981   7.2992444 7.492634 ]\n",
      "Reset environment\n",
      "Episode reward: 1253.2435\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5002756 7.468024  7.502643  5.920394  7.299669  7.493089 ]\n",
      "Reset environment\n",
      "Episode reward: 2882.8972\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5020127 7.469782  7.504364  5.922304  7.301221  7.4948297]\n",
      "Reset environment\n",
      "Episode reward: 4639.6826\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5049067 7.472689  7.507234  5.925477  7.3038006 7.497723 ]\n",
      "Reset environment\n",
      "Episode reward: 2679.239\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.506323  7.4740396 7.5087113 5.927116  7.30506   7.4991393]\n",
      "Reset environment\n",
      "Episode reward: 2743.5908\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5079217 7.4756217 7.510339  5.928912  7.30649   7.500737 ]\n",
      "Reset environment\n",
      "Episode reward: 5520.759\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.511446  7.479148  7.5138516 5.9327593 7.309665  7.5042624]\n",
      "Reset environment\n",
      "Episode reward: 1807.1196\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5124106 7.48007   7.51485   5.9338555 7.31052   7.505226 ]\n",
      "Reset environment\n",
      "Episode reward: 2362.1611\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.513775  7.4814477 7.516199  5.9353757 7.311725  7.506589 ]\n",
      "Reset environment\n",
      "Episode reward: 2470.8638\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5152564 7.482936  7.517677  5.937011  7.313056  7.5080748]\n",
      "Reset environment\n",
      "Episode reward: 5672.9595\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5188785 7.486573  7.5212727 5.940986  7.3163085 7.5117006]\n",
      "Reset environment\n",
      "Episode reward: 3125.8489\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.520692  7.488387  7.523084  5.943006  7.3179064 7.5135145]\n",
      "Reset environment\n",
      "Episode reward: 5308.241\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.524064  7.4917746 7.5264373 5.946689  7.320927  7.51689  ]\n",
      "Reset environment\n",
      "Episode reward: 1354.5067\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.525235  7.492947  7.5276093 5.9480166 7.3219585 7.5180626]\n",
      "Reset environment\n",
      "Episode reward: 2254.464\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5265822 7.4942794 7.5289645 5.9494977 7.32316   7.51941  ]\n",
      "Reset environment\n",
      "Episode reward: 659.62085\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5265923 7.494187  7.5290833 5.949555  7.323205  7.5194254]\n",
      "Reset environment\n",
      "Episode reward: 3024.2834\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5283628 7.495918  7.5308785 5.95153   7.3247695 7.5211973]\n",
      "Reset environment\n",
      "Episode reward: 3434.6064\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.530256  7.4978585 7.532719  5.953664  7.326465  7.523093 ]\n",
      "Reset environment\n",
      "Episode reward: 4735.889\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5332165 7.500837  7.535663  5.956926  7.3291225 7.526057 ]\n",
      "Reset environment\n",
      "Episode reward: 2715.727\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.534791  7.5023665 7.537267  5.9586744 7.330503  7.5276318]\n",
      "Reset environment\n",
      "Episode reward: 5173.6104\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5385303 7.50611   7.5410094 5.9627695 7.3338428 7.5313783]\n",
      "Reset environment\n",
      "Episode reward: 2593.9553\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5397944 7.5074434 7.542207  5.96426   7.3349447 7.5326476]\n",
      "Reset environment\n",
      "Episode reward: 4714.651\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5426397 7.5103235 7.5450315 5.967404  7.3374634 7.535495 ]\n",
      "Reset environment\n",
      "Episode reward: 2395.865\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.544027  7.511698  7.54643   5.9689593 7.33868   7.536881 ]\n",
      "Reset environment\n",
      "Episode reward: 1982.6898\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5451484 7.512836  7.5475326 5.9702206 7.339675  7.5380044]\n",
      "Reset environment\n",
      "Episode reward: 374.8129\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5451922 7.512865  7.547603  5.970173  7.3397417 7.5380554]\n",
      "Reset environment\n",
      "Episode reward: 2905.7441\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.546919  7.514587  7.5493374 5.9721007 7.341266  7.539779 ]\n",
      "Reset environment\n",
      "Episode reward: 2910.5398\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.548659  7.5163116 7.5510855 5.974036  7.34281   7.541521 ]\n",
      "Reset environment\n",
      "Episode reward: 2890.7988\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5503993 7.5180564 7.5528173 5.9759717 7.344353  7.543265 ]\n",
      "Reset environment\n",
      "Episode reward: 3846.1292\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5527844 7.520431  7.5551996 5.9785895 7.346482  7.545645 ]\n",
      "Reset environment\n",
      "Episode reward: 3394.436\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.554765  7.522412  7.557188  5.98078   7.3482347 7.5476284]\n",
      "Reset environment\n",
      "Episode reward: 5176.4224\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5580277 7.5256824 7.560454  5.984363  7.3511295 7.5508943]\n",
      "Reset environment\n",
      "Episode reward: 1497.9618\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5588613 7.5265155 7.5612864 5.9853077 7.351867  7.551728 ]\n",
      "Reset environment\n",
      "Episode reward: 2073.4111\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.56001   7.5276423 7.562452  5.9865966 7.3528805 7.552877 ]\n",
      "Reset environment\n",
      "Episode reward: 2226.2046\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5610957 7.5288014 7.5634646 5.987876  7.353829  7.553962 ]\n",
      "Reset environment\n",
      "Episode reward: 2017.5297\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5621443 7.5299025 7.5644665 5.9890776 7.354755  7.5550117]\n",
      "Reset environment\n",
      "Episode reward: 1357.2622\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5633135 7.5310726 7.565635  5.990391  7.355789  7.556184 ]\n",
      "Reset environment\n",
      "Episode reward: 4222.8027\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5658393 7.5335965 7.5681624 5.993185  7.358014  7.5587106]\n",
      "Reset environment\n",
      "Episode reward: 1111.7886\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5662994 7.533966  7.568723  5.9937596 7.3584633 7.559175 ]\n",
      "Reset environment\n",
      "Episode reward: -359.8846\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.565782  7.5334573 7.568196  5.993366  7.3579946 7.5586586]\n",
      "Reset environment\n",
      "Episode reward: 3219.7478\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.567743  7.535422  7.5701437 5.9955244 7.3597317 7.5606217]\n",
      "Reset environment\n",
      "Episode reward: 1375.509\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5689325 7.5366096 7.571332  5.996851  7.3607774 7.561814 ]\n",
      "Reset environment\n",
      "Episode reward: 2067.2197\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.570082  7.53775   7.5724797 5.998163  7.3617773 7.5629606]\n",
      "Reset environment\n",
      "Episode reward: 2483.5906\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5714927 7.539184  7.573871  5.999766  7.3630214 7.564372 ]\n",
      "Reset environment\n",
      "Episode reward: 1835.319\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5727596 7.540476  7.5751033 6.001149  7.364189  7.56564  ]\n",
      "Reset environment\n",
      "Episode reward: 5223.7563\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.575985  7.5436974 7.5783315 6.00466   7.3670583 7.568867 ]\n",
      "Reset environment\n",
      "Episode reward: 3153.2473\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.577876  7.545604  7.5801964 6.0067525 7.368741  7.570761 ]\n",
      "Reset environment\n",
      "Episode reward: 2726.5273\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5794845 7.547222  7.581795  6.008563  7.370163  7.5723686]\n",
      "Reset environment\n",
      "Episode reward: 2569.5286\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.580878  7.5485597 7.583243  6.0101395 7.371397  7.5737596]\n",
      "Reset environment\n",
      "Episode reward: 3087.588\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5826654 7.550349  7.585028  6.0121136 7.3729863 7.5755467]\n",
      "Reset environment\n",
      "Episode reward: 3466.0955\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5847583 7.5524335 7.587124  6.014448  7.374833  7.5776424]\n",
      "Reset environment\n",
      "Episode reward: 5062.356\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5879416 7.55563   7.5902905 6.017939  7.377695  7.580824 ]\n",
      "Reset environment\n",
      "Episode reward: 1142.3783\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5885034 7.5561852 7.5908594 6.01859   7.378188  7.581386 ]\n",
      "Reset environment\n",
      "Episode reward: 4193.722\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5910926 7.558778  7.5934434 6.021442  7.3804984 7.5839777]\n",
      "Reset environment\n",
      "Episode reward: 3251.8574\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.592978  7.5606656 7.5953298 6.023548  7.382165  7.585865 ]\n",
      "Reset environment\n",
      "Episode reward: 2186.396\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.594698  7.5623903 7.5970516 6.0254583 7.383701  7.5875864]\n",
      "Reset environment\n",
      "Episode reward: 3505.4866\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.59683   7.5645094 7.5991926 6.0278096 7.3855963 7.5897155]\n",
      "Reset environment\n",
      "Episode reward: 1735.1333\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.5977664 7.5654435 7.6001315 6.0288897 7.3864117 7.5906544]\n",
      "Reset environment\n",
      "Episode reward: 2027.6787\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.599368  7.567047  7.6017303 6.03068   7.3878307 7.592259 ]\n",
      "Reset environment\n",
      "Episode reward: 2231.0813\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.600634  7.5683084 7.603     6.0321054 7.3889437 7.593526 ]\n",
      "Reset environment\n",
      "Episode reward: 2282.9177\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6019297 7.5696177 7.6042805 6.0335536 7.3900933 7.594822 ]\n",
      "Reset environment\n",
      "Episode reward: 2599.57\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6034646 7.57114   7.6058235 6.035252  7.3914447 7.5963583]\n",
      "Reset environment\n",
      "Episode reward: 711.236\n",
      "Total Steps: 26\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6037292 7.5714045 7.606085  6.0355997 7.391661  7.596622 ]\n",
      "Reset environment\n",
      "Episode reward: 3284.9805\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6056395 7.5733156 7.607993  6.0377026 7.393354  7.598532 ]\n",
      "Reset environment\n",
      "Episode reward: 3354.1453\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6076546 7.575304  7.610028  6.039928  7.395139  7.6005454]\n",
      "Reset environment\n",
      "Episode reward: 2143.1968\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.608866  7.576525  7.6112304 6.041286  7.3962097 7.6017556]\n",
      "Reset environment\n",
      "Episode reward: 2889.4824\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6105785 7.578235  7.612948  6.0431895 7.397728  7.603471 ]\n",
      "Reset environment\n",
      "Episode reward: 3392.1125\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6125927 7.5802712 7.614946  6.045421  7.3995285 7.605483 ]\n",
      "Reset environment\n",
      "Episode reward: 2118.614\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6142592 7.581945  7.616605  6.0472803 7.4010196 7.60715  ]\n",
      "Reset environment\n",
      "Episode reward: 4015.8523\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6167154 7.5843787 7.6190786 6.049969  7.4031982 7.6096025]\n",
      "Reset environment\n",
      "Episode reward: 2925.2964\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6183167 7.5860143 7.6206512 6.0517683 7.4046063 7.6112037]\n",
      "Reset environment\n",
      "Episode reward: 2632.2275\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.619744  7.587469  7.622029  6.0533805 7.405877  7.61263  ]\n",
      "Reset environment\n",
      "Episode reward: 2136.8381\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.621437  7.58916   7.6237235 6.055257  7.407379  7.6143236]\n",
      "Reset environment\n",
      "Episode reward: 3383.6882\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6234946 7.5912247 7.6257668 6.0575233 7.409208  7.6163793]\n",
      "Reset environment\n",
      "Episode reward: 1570.0026\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.62428   7.5919743 7.626584  6.0584283 7.4098964 7.617165 ]\n",
      "Reset environment\n",
      "Episode reward: 2424.1663\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.625681  7.5933795 7.62798   6.059998  7.41115   7.6185665]\n",
      "Reset environment\n",
      "Episode reward: 3035.6995\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6274877 7.5951924 7.629775  6.061994  7.4127655 7.6203747]\n",
      "Reset environment\n",
      "Episode reward: 1887.1743\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6284685 7.5962234 7.6307063 6.0631204 7.4136357 7.621358 ]\n",
      "Reset environment\n",
      "Episode reward: 2031.5958\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6300726 7.597824  7.632305  6.064921  7.4150643 7.6229625]\n",
      "Reset environment\n",
      "Episode reward: 4265.9644\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6326013 7.6003594 7.6348248 6.067727  7.4172883 7.625492 ]\n",
      "Reset environment\n",
      "Episode reward: 583.8668\n",
      "Total Steps: 21\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6327834 7.6005425 7.635007  6.0679765 7.417434  7.6256742]\n",
      "Reset environment\n",
      "Episode reward: 2095.2646\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6344357 7.6021957 7.636657  6.069806  7.418886  7.6273274]\n",
      "Reset environment\n",
      "Episode reward: 4844.288\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6374345 7.60519   7.6396484 6.0731106 7.4215364 7.630323 ]\n",
      "Reset environment\n",
      "Episode reward: 1986.7056\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.638513  7.606249  7.640741  6.0743365 7.422489  7.6314015]\n",
      "Reset environment\n",
      "Episode reward: 2238.6416\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6397705 7.607532  7.641968  6.075738  7.4236    7.632661 ]\n",
      "Reset environment\n",
      "Episode reward: 2337.7224\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6414423 7.6092076 7.6436377 6.077602  7.4250937 7.634334 ]\n",
      "Reset environment\n",
      "Episode reward: 3061.961\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.643217  7.61098   7.645413  6.079571  7.4266696 7.6361103]\n",
      "Reset environment\n",
      "Episode reward: 243.11545\n",
      "Total Steps: 8\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6431985 7.6109614 7.6453934 6.0795784 7.4266424 7.6360917]\n",
      "Reset environment\n",
      "Episode reward: 2142.0544\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.644356  7.6121526 7.6465173 6.08089   7.4276576 7.6372523]\n",
      "Reset environment\n",
      "Episode reward: 1598.2983\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.645199  7.6130214 7.6473393 6.0818553 7.4284077 7.638099 ]\n",
      "Reset environment\n",
      "Episode reward: 2790.382\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.646825  7.6146693 7.648939  6.0836487 7.4298477 7.639725 ]\n",
      "Reset environment\n",
      "Episode reward: 2242.5327\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6481175 7.6159606 7.650232  6.085108  7.431009  7.6410184]\n",
      "Reset environment\n",
      "Episode reward: 4758.9204\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.651048  7.6189036 7.6531506 6.0883517 7.4336424 7.643949 ]\n",
      "Reset environment\n",
      "Episode reward: 2749.2295\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.652649  7.620509  7.654744  6.0901494 7.435068  7.6455503]\n",
      "Reset environment\n",
      "Episode reward: 3811.5806\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.654986  7.622855  7.657072  6.0927114 7.4371734 7.647889 ]\n",
      "Reset environment\n",
      "Episode reward: 4235.4087\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.657538  7.6254025 7.6596236 6.095495  7.4394255 7.65044  ]\n",
      "Reset environment\n",
      "Episode reward: 4208.2637\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.660129  7.627989  7.662217  6.0983367 7.441739  7.653027 ]\n",
      "Reset environment\n",
      "Episode reward: -262.2766\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6596227 7.627492  7.661707  6.097642  7.441309  7.652522 ]\n",
      "Reset environment\n",
      "Episode reward: 3453.0718\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6617093 7.6295776 7.6637964 6.0999312 7.4431615 7.654609 ]\n",
      "Reset environment\n",
      "Episode reward: 2532.1592\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.663093  7.6309967 7.665139  6.1014843 7.4443846 7.655993 ]\n",
      "Reset environment\n",
      "Episode reward: 2279.1885\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6644297 7.63232   7.6664767 6.102963  7.4455776 7.657329 ]\n",
      "Reset environment\n",
      "Episode reward: 2498.1467\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6658297 7.633755  7.6678405 6.1045303 7.446815  7.6587296]\n",
      "Reset environment\n",
      "Episode reward: 1384.0698\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6670127 7.63494   7.66902   6.1058483 7.44787   7.6599107]\n",
      "Reset environment\n",
      "Episode reward: 4951.4146\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6700873 7.638019  7.672088  6.10922   7.450627  7.6629863]\n",
      "Reset environment\n",
      "Episode reward: 3593.1873\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6722345 7.640139  7.6742473 6.111593  7.452531  7.6651354]\n",
      "Reset environment\n",
      "Episode reward: 4046.643\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.674732  7.642636  7.6767483 6.1143284 7.4547596 7.6676354]\n",
      "Reset environment\n",
      "Episode reward: 5242.0273\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.678004  7.6459117 7.6800184 6.1179085 7.4577026 7.670911 ]\n",
      "Reset environment\n",
      "Episode reward: 1840.7842\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6790104 7.64692   7.681025  6.1190505 7.4585805 7.671918 ]\n",
      "Reset environment\n",
      "Episode reward: 2207.324\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6802506 7.6481805 7.6822453 6.120419  7.4596825 7.6731577]\n",
      "Reset environment\n",
      "Episode reward: 5107.1426\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6834006 7.6513495 7.6853786 6.123906  7.4624724 7.6763077]\n",
      "Reset environment\n",
      "Episode reward: 2198.57\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6846485 7.652592  7.6866307 6.12531   7.463568  7.677557 ]\n",
      "Reset environment\n",
      "Episode reward: 573.7114\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.684924  7.6528726 7.686901  6.125528  7.463815  7.677837 ]\n",
      "Reset environment\n",
      "Episode reward: 1357.8285\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.686073  7.6540227 7.6880393 6.1268406 7.4648213 7.678983 ]\n",
      "Reset environment\n",
      "Episode reward: 3327.0994\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6880083 7.655978  7.689949  6.128991  7.46653   7.6809144]\n",
      "Reset environment\n",
      "Episode reward: 4652.7817\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6908927 7.6588726 7.6928163 6.1321616 7.4691195 7.6837974]\n",
      "Reset environment\n",
      "Episode reward: 1860.5491\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6923785 7.660358  7.6943035 6.1338224 7.4704347 7.6852837]\n",
      "Reset environment\n",
      "Episode reward: 5357.4893\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.6957254 7.6636996 7.69764   6.1374674 7.473429  7.688623 ]\n",
      "Reset environment\n",
      "Episode reward: 2639.8643\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.697209 7.665213 7.699081 6.139118 7.474735 7.690107]\n",
      "Reset environment\n",
      "Episode reward: 2603.546\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.698631  7.666596  7.700551  6.1407266 7.476007  7.6915283]\n",
      "Reset environment\n",
      "Episode reward: 4293.8193\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7012467 7.6692014 7.7031713 6.143603  7.478339  7.6941457]\n",
      "Reset environment\n",
      "Episode reward: 2079.852\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7024226 7.670374  7.7043495 6.1449165 7.4793878 7.695323 ]\n",
      "Reset environment\n",
      "Episode reward: 5616.8384\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7059236 7.6738853 7.707827  6.148751  7.4825444 7.698822 ]\n",
      "Reset environment\n",
      "Episode reward: 2502.1204\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.707394  7.675367  7.70928   6.1503634 7.483852  7.700294 ]\n",
      "Reset environment\n",
      "Episode reward: 2400.5571\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.708362  7.676395  7.7101836 6.1515718 7.484668  7.7012644]\n",
      "Reset environment\n",
      "Episode reward: 2893.8616\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7100344 7.6780863 7.711842  6.1534357 7.486156  7.7029405]\n",
      "Reset environment\n",
      "Episode reward: 2842.9556\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.711559  7.6796503 7.7133336 6.1551766 7.487509  7.7044683]\n",
      "Reset environment\n",
      "Episode reward: 3557.7856\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.71362   7.68171   7.715396  6.1574607 7.4893155 7.7065315]\n",
      "Reset environment\n",
      "Episode reward: 2400.7324\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7149854 7.683086  7.716746  6.158977  7.490527  7.7078967]\n",
      "Reset environment\n",
      "Episode reward: 2603.434\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7163067 7.6843634 7.7181144 6.1604953 7.491703  7.70922  ]\n",
      "Reset environment\n",
      "Episode reward: -144.30792\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.715818  7.68379   7.7177105 6.159974  7.491256  7.7087326]\n",
      "Reset environment\n",
      "Episode reward: 3086.9995\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7175784 7.6855493 7.719478  6.1619368 7.4928193 7.7104955]\n",
      "Reset environment\n",
      "Episode reward: 3380.7397\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7195907 7.687562  7.7214847 6.164156  7.4945927 7.7125015]\n",
      "Reset environment\n",
      "Episode reward: 3566.5383\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7217107 7.689697  7.72358   6.1664996 7.4964848 7.714624 ]\n",
      "Reset environment\n",
      "Episode reward: 1216.9836\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7227325 7.690718  7.724599  6.1676674 7.4973783 7.7156444]\n",
      "Reset environment\n",
      "Episode reward: 1397.5963\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.723483 7.691468 7.725348 6.168519 7.498048 7.716395]\n",
      "Reset environment\n",
      "Episode reward: 2988.4387\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7252655 7.6932483 7.72713   6.170473  7.4996414 7.7181783]\n",
      "Reset environment\n",
      "Episode reward: 3166.4832\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.727122  7.695077  7.72901   6.1725307 7.5012894 7.720036 ]\n",
      "Reset environment\n",
      "Episode reward: 1349.8937\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7282624 7.696219  7.7301507 6.1738167 7.5023046 7.7211757]\n",
      "Reset environment\n",
      "Episode reward: 4357.6475\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.730903  7.6988554 7.7328005 6.1767454 7.5046544 7.7238173]\n",
      "Reset environment\n",
      "Episode reward: 3247.3362\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7328615 7.7008057 7.734764  6.178898  7.5063844 7.7257757]\n",
      "Reset environment\n",
      "Episode reward: 1413.84\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7336097 7.7015443 7.735517  6.1797476 7.5070496 7.726524 ]\n",
      "Reset environment\n",
      "Episode reward: 1746.2053\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.73501   7.7029486 7.7369165 6.1813188 7.5083055 7.7279243]\n",
      "Reset environment\n",
      "Episode reward: 4265.2153\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7376256 7.705576  7.7395215 6.1842012 7.510651  7.730544 ]\n",
      "Reset environment\n",
      "Episode reward: 2712.729\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7391567 7.70713   7.741027  6.185906  7.512009  7.7320743]\n",
      "Reset environment\n",
      "Episode reward: 2526.3682\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7405276 7.708498  7.742397  6.18745   7.513208  7.7334456]\n",
      "Reset environment\n",
      "Episode reward: 3763.1626\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7427955 7.7107806 7.7446465 6.1899486 7.515244  7.735714 ]\n",
      "Reset environment\n",
      "Episode reward: 2787.201\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7443495 7.712283  7.746243  6.191683  7.516626  7.737269 ]\n",
      "Reset environment\n",
      "Episode reward: 2097.4492\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7454815 7.7133856 7.747399  6.192954  7.5176096 7.7383976]\n",
      "Reset environment\n",
      "Episode reward: 4899.541\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7483964 7.7162914 7.7503204 6.1961584 7.520195  7.7413154]\n",
      "Reset environment\n",
      "Episode reward: 2265.5317\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.749668  7.7175727 7.75158   6.1975846 7.521315  7.742586 ]\n",
      "Reset environment\n",
      "Episode reward: 2089.124\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.750911  7.718783  7.752854  6.198944  7.5224657 7.74383  ]\n",
      "Reset environment\n",
      "Episode reward: 3541.5059\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7530417 7.7209206 7.754968  6.201282  7.5243835 7.7459617]\n",
      "Reset environment\n",
      "Episode reward: 1712.9568\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.754416  7.722297  7.7563415 6.202818  7.5256033 7.7473373]\n",
      "Reset environment\n",
      "Episode reward: 1379.9648\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.755581  7.723463  7.7575016 6.2041173 7.5266433 7.748504 ]\n",
      "Reset environment\n",
      "Episode reward: 3466.6694\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7574887 7.72533   7.7594476 6.2062793 7.5283103 7.7504153]\n",
      "Reset environment\n",
      "Episode reward: 1647.3789\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7583833 7.726227  7.760342  6.2072964 7.5291023 7.7513113]\n",
      "Reset environment\n",
      "Episode reward: 2721.8003\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.759966  7.7278156 7.76192   6.209062  7.530521  7.7528954]\n",
      "Reset environment\n",
      "Episode reward: 3862.6711\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.762299  7.7301393 7.7642593 6.2116303 7.532593  7.755231 ]\n",
      "Reset environment\n",
      "Episode reward: 1322.5149\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7634134 7.731256  7.765372  6.212899  7.5335746 7.7563486]\n",
      "Reset environment\n",
      "Episode reward: 2734.3792\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.765001  7.732837  7.766967  6.214657  7.534972  7.7579355]\n",
      "Reset environment\n",
      "Episode reward: 2484.2358\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7663803 7.734245  7.7683244 6.216194  7.5362    7.7593184]\n",
      "Reset environment\n",
      "Episode reward: 2565.8994\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.767838  7.7356777 7.769796  6.217814  7.5374894 7.7607703]\n",
      "Reset environment\n",
      "Episode reward: 4692.5376\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.770636  7.738477  7.772591  6.220879  7.539957  7.7635703]\n",
      "Reset environment\n",
      "Episode reward: 1354.2823\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7717733 7.7396173 7.7737265 6.2221665 7.540969  7.7647095]\n",
      "Reset environment\n",
      "Episode reward: 1838.663\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.773208  7.7410493 7.7751603 6.2237773 7.5422344 7.7661433]\n",
      "Reset environment\n",
      "Episode reward: 2793.4258\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.774865  7.7427125 7.7768054 6.225594  7.543708  7.7677984]\n",
      "Reset environment\n",
      "Episode reward: 2291.006\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7761555 7.7439914 7.778111  6.2270427 7.544852  7.7690883]\n",
      "Reset environment\n",
      "Episode reward: -683.7468\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.775267  7.7431087 7.7772193 6.2261996 7.5439587 7.7682023]\n",
      "Reset environment\n",
      "Episode reward: 5249.302\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.77851   7.7463603 7.7804456 6.229765  7.546829  7.7714477]\n",
      "Reset environment\n",
      "Episode reward: 3546.303\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7806106 7.7484717 7.7825346 6.232083  7.5487037 7.7735496]\n",
      "Reset environment\n",
      "Episode reward: 3958.8784\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7830105 7.750876  7.7849255 6.2347183 7.550854  7.7759495]\n",
      "Reset environment\n",
      "Episode reward: 1103.8701\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.783425  7.7513766 7.785262  6.235193  7.551244  7.7763753]\n",
      "Reset environment\n",
      "Episode reward: 2083.9927\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7845507 7.7525387 7.7863526 6.2364507 7.5522447 7.7775025]\n",
      "Reset environment\n",
      "Episode reward: 5046.304\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7875714 7.755566  7.789364  6.2397547 7.5549116 7.7805243]\n",
      "Reset environment\n",
      "Episode reward: 2325.5996\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7890306 7.756989  7.790853  6.241422  7.5562205 7.7819834]\n",
      "Reset environment\n",
      "Episode reward: 2985.6802\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.790762  7.75874   7.792571  6.2433333 7.5577683 7.783715 ]\n",
      "Reset environment\n",
      "Episode reward: 2173.855\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.792441  7.760421  7.7942457 6.2451982 7.559267  7.785393 ]\n",
      "Reset environment\n",
      "Episode reward: 4878.2603\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7954316 7.763425  7.7972317 6.248476  7.5619664 7.788385 ]\n",
      "Reset environment\n",
      "Episode reward: 2083.257\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.796642  7.764639  7.7984366 6.249817  7.5630364 7.789595 ]\n",
      "Reset environment\n",
      "Episode reward: 1706.9375\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.797457  7.7655096 7.799187  6.250771  7.5637608 7.7904115]\n",
      "Reset environment\n",
      "Episode reward: 1888.8289\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7989483 7.767     7.8006725 6.2524276 7.565096  7.791901 ]\n",
      "Reset environment\n",
      "Episode reward: 3526.848\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8009734 7.7690244 7.8026977 6.2546563 7.5668745 7.793927 ]\n",
      "Reset environment\n",
      "Episode reward: -346.14697\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.7999725 7.7681303 7.8016024 6.253751  7.56596   7.7929406]\n",
      "Reset environment\n",
      "Episode reward: 2232.6804\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8012476 7.769373  7.802914  6.2551746 7.5671134 7.7942142]\n",
      "Reset environment\n",
      "Episode reward: 1903.8352\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8022113 7.7702894 7.8039136 6.2562733 7.56796   7.795177 ]\n",
      "Reset environment\n",
      "Episode reward: 1948.8499\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.803717  7.7717943 7.8054132 6.2579765 7.5692954 7.7966824]\n",
      "Reset environment\n",
      "Episode reward: 3686.9565\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.805828  7.773899  7.807517  6.2603245 7.5711513 7.7987905]\n",
      "Reset environment\n",
      "Episode reward: -274.42355\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8050203 7.77325   7.8065715 6.2595077 7.5704    7.7979894]\n",
      "Reset environment\n",
      "Episode reward: 2646.2012\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.806427  7.7746086 7.8080254 6.261097  7.57165   7.799396 ]\n",
      "Reset environment\n",
      "Episode reward: 616.5831\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.806265  7.7745843 7.8077245 6.2611823 7.5714684 7.799241 ]\n",
      "Reset environment\n",
      "Episode reward: 1924.5046\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8073525 7.775671  7.808812  6.2623878 7.5724325 7.800329 ]\n",
      "Reset environment\n",
      "Episode reward: 2111.4407\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8089857 7.777303  7.8104434 6.264205  7.573884  7.801962 ]\n",
      "Reset environment\n",
      "Episode reward: 2113.354\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.810182  7.7785053 7.8116355 6.265536  7.5749607 7.8031588]\n",
      "Reset environment\n",
      "Episode reward: 1728.177\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8111095 7.779434  7.812559  6.2665873 7.57578   7.8040867]\n",
      "Reset environment\n",
      "Episode reward: 3043.441\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.812865  7.781191  7.814309  6.2685504 7.577343  7.8058414]\n",
      "Reset environment\n",
      "Episode reward: -945.4022\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8115606 7.7800364 7.8128777 6.267154  7.5761538 7.804548 ]\n",
      "Reset environment\n",
      "Episode reward: 4552.5024\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.814321  7.782798  7.815635  6.2701902 7.57862   7.8073087]\n",
      "Reset environment\n",
      "Episode reward: 2470.663\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.815763  7.7842383 7.817076  6.271781  7.5799    7.8087506]\n",
      "Reset environment\n",
      "Episode reward: 2137.9395\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.816937  7.785436  7.818236  6.2731037 7.5809417 7.809928 ]\n",
      "Reset environment\n",
      "Episode reward: 2013.5923\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.818502  7.7870016 7.8197975 6.274844  7.5823426 7.8114924]\n",
      "Reset environment\n",
      "Episode reward: 3045.6667\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8201756 7.7886124 7.8215218 6.2767143 7.5838466 7.813168 ]\n",
      "Reset environment\n",
      "Episode reward: 2036.7385\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.821119  7.7896094 7.822408  6.2778277 7.5846715 7.8141046]\n",
      "Reset environment\n",
      "Episode reward: 5264.2896\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8243494 7.79284   7.8256392 6.2813673 7.587569  7.81734  ]\n",
      "Reset environment\n",
      "Episode reward: 775.16223\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.824654  7.7931385 7.825951  6.2817416 7.5878253 7.817645 ]\n",
      "Reset environment\n",
      "Episode reward: 5021.89\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8277636 7.7962456 7.8290653 6.285127  7.590608  7.8207545]\n",
      "Reset environment\n",
      "Episode reward: 4346.3403\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.830318  7.7988014 7.831619  6.287925  7.5928698 7.823309 ]\n",
      "Reset environment\n",
      "Episode reward: 4787.3896\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.833249 7.801732 7.834554 6.291123 7.595478 7.826243]\n",
      "Reset environment\n",
      "Episode reward: 856.2374\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8336215 7.802105  7.8349266 6.291571  7.5958037 7.8266153]\n",
      "Reset environment\n",
      "Episode reward: 2361.923\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8349304 7.8034024 7.8362465 6.293052  7.596938  7.8279257]\n",
      "Reset environment\n",
      "Episode reward: 4921.6226\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8379135 7.8063936 7.839217  6.296367  7.5996165 7.83091  ]\n",
      "Reset environment\n",
      "Episode reward: 4311.275\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.84043   7.808908  7.841733  6.2991223 7.6018434 7.8334274]\n",
      "Reset environment\n",
      "Episode reward: 3574.941\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8425975 7.8110847 7.8438826 6.3014793 7.6037655 7.835597 ]\n",
      "Reset environment\n",
      "Episode reward: 4124.6157\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8450723 7.813572  7.8463435 6.3042    7.6059937 7.838073 ]\n",
      "Reset environment\n",
      "Episode reward: 2209.1086\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.846215  7.814663  7.8475266 6.3055053 7.6070004 7.8392158]\n",
      "Reset environment\n",
      "Episode reward: 2171.413\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.84788   7.8163342 7.849187  6.30736   7.608496  7.840882 ]\n",
      "Reset environment\n",
      "Episode reward: 272.5844\n",
      "Total Steps: 9\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8478737 7.816328  7.8491774 6.3073835 7.6084757 7.840875 ]\n",
      "Reset environment\n",
      "Episode reward: 2856.6472\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8494487 7.817905  7.8507466 6.309147  7.609875  7.842451 ]\n",
      "Reset environment\n",
      "Episode reward: 2035.8037\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.851     7.819457  7.852293  6.3108854 7.6112294 7.844002 ]\n",
      "Reset environment\n",
      "Episode reward: 2136.1968\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.852062  7.820472  7.853403  6.3121104 7.612169  7.845065 ]\n",
      "Reset environment\n",
      "Episode reward: 2094.3213\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.853126  7.8214846 7.8545084 6.3133163 7.6131134 7.8461275]\n",
      "Reset environment\n",
      "Episode reward: 4500.4395\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.85577   7.8241315 7.857149  6.3162165 7.61546   7.8487735]\n",
      "Reset environment\n",
      "Episode reward: 3195.431\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.857681  7.826052  7.8590474 6.318307  7.6171455 7.8506837]\n",
      "Reset environment\n",
      "Episode reward: 5674.902\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.861153  7.8295307 7.8625064 6.322109  7.62024   7.8541555]\n",
      "Reset environment\n",
      "Episode reward: 2980.2805\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.862873  7.831263  7.8642125 6.32402   7.6217766 7.8558764]\n",
      "Reset environment\n",
      "Episode reward: 4236.633\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8654323 7.833817  7.866774  6.326833  7.624056  7.8584356]\n",
      "Reset environment\n",
      "Episode reward: 2002.1931\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8659086 7.834227  7.8673067 6.327507  7.6244097 7.858912 ]\n",
      "Reset environment\n",
      "Episode reward: 2447.6824\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.867193  7.8355436 7.868547  6.3289657 7.625555  7.8601956]\n",
      "Reset environment\n",
      "Episode reward: 2352.232\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.86851   7.8368683 7.8698506 6.33044   7.626713  7.8615127]\n",
      "Reset environment\n",
      "Episode reward: 3017.072\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8702087 7.8385344 7.8715773 6.332342  7.628212  7.863213 ]\n",
      "Reset environment\n",
      "Episode reward: 2184.3672\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8712945 7.8396587 7.8726287 6.3336134 7.629168  7.8642993]\n",
      "Reset environment\n",
      "Episode reward: 2601.6226\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8727226 7.841098  7.8740444 6.3351994 7.630446  7.865727 ]\n",
      "Reset environment\n",
      "Episode reward: 2121.0774\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.874353  7.8427267 7.8756714 6.337004  7.63189   7.8673553]\n",
      "Reset environment\n",
      "Episode reward: 3929.2285\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8769636 7.845332  7.878292  6.3398566 7.634251  7.869969 ]\n",
      "Reset environment\n",
      "Episode reward: 5052.7104\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.880039  7.8484006 7.8813634 6.3432093 7.636985  7.873044 ]\n",
      "Reset environment\n",
      "Episode reward: 3471.326\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.882068  7.850405  7.8834095 6.345443  7.638787  7.87507  ]\n",
      "Reset environment\n",
      "Episode reward: 3629.1782\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8841753 7.852525  7.8855042 6.347795  7.6406803 7.877178 ]\n",
      "Reset environment\n",
      "Episode reward: 3266.305\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.886082  7.8544173 7.887423  6.3498955 7.6423726 7.879085 ]\n",
      "Reset environment\n",
      "Episode reward: 2029.2931\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.887189  7.855526  7.888529  6.3511324 7.643361  7.880192 ]\n",
      "Reset environment\n",
      "Episode reward: 3333.0566\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.889109  7.8574553 7.8904324 6.353253  7.645082  7.882111 ]\n",
      "Reset environment\n",
      "Episode reward: 3392.8333\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.891085  7.859425  7.8924108 6.355446  7.6468396 7.884087 ]\n",
      "Reset environment\n",
      "Episode reward: 2020.896\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8921995 7.8605433 7.8935184 6.356694  7.647833  7.885202 ]\n",
      "Reset environment\n",
      "Episode reward: 3032.6277\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.893937  7.8623013 7.8952446 6.358615  7.649387  7.88694  ]\n",
      "Reset environment\n",
      "Episode reward: 2970.817\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8956842 7.864038  7.896996  6.3605356 7.650939  7.888687 ]\n",
      "Reset environment\n",
      "Episode reward: 2716.247\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.897199  7.865529  7.8985367 6.362218  7.6522923 7.890205 ]\n",
      "Reset environment\n",
      "Episode reward: 2247.609\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.8984523 7.866788  7.8997855 6.3636303 7.653413  7.89146  ]\n",
      "Reset environment\n",
      "Episode reward: 2973.4734\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9001865 7.868531  7.9015083 6.365538  7.6549416 7.8931966]\n",
      "Reset environment\n",
      "Episode reward: 2329.515\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.901425  7.869775  7.9027457 6.3669224 7.6560507 7.894435 ]\n",
      "Reset environment\n",
      "Episode reward: 4397.6143\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9040394 7.872386  7.9053516 6.3698    7.658346  7.897047 ]\n",
      "Reset environment\n",
      "Episode reward: 1330.8762\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.904715  7.873063  7.9060273 6.370576  7.658949  7.897724 ]\n",
      "Reset environment\n",
      "Episode reward: 2188.8997\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.906379  7.874729  7.907693  6.372418  7.660441  7.8993897]\n",
      "Reset environment\n",
      "Episode reward: 3659.8962\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9085054 7.876867  7.9097867 6.3747582 7.6623263 7.9015117]\n",
      "Reset environment\n",
      "Episode reward: 5530.57\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9118733 7.880232  7.913159  6.3784513 7.6653447 7.9048786]\n",
      "Reset environment\n",
      "Episode reward: 3085.1702\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.913576  7.8818936 7.9148993 6.380355  7.666856  7.906583 ]\n",
      "Reset environment\n",
      "Episode reward: 4897.3623\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.916476  7.8847895 7.9177914 6.383514  7.6694345 7.909482 ]\n",
      "Reset environment\n",
      "Episode reward: 1639.5083\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9173646 7.885677  7.9186797 6.384521  7.670223  7.910372 ]\n",
      "Reset environment\n",
      "Episode reward: 1566.2672\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9181743 7.886491  7.9194913 6.38545   7.670933  7.911186 ]\n",
      "Reset environment\n",
      "Episode reward: 3660.9763\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.920325  7.8886285 7.9216537 6.387814  7.6728506 7.9133377]\n",
      "Reset environment\n",
      "Episode reward: 4504.078\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9230385 7.891353  7.9243584 6.390802  7.675302  7.916053 ]\n",
      "Reset environment\n",
      "Episode reward: 3231.079\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9249306 7.893225  7.9262695 6.3928804 7.67699   7.917945 ]\n",
      "Reset environment\n",
      "Episode reward: 3698.0818\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.92713   7.895405  7.9284873 6.395279  7.6789503 7.920145 ]\n",
      "Reset environment\n",
      "Episode reward: 2286.7307\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9282455 7.8965793 7.9295526 6.3965654 7.67993   7.92126  ]\n",
      "Reset environment\n",
      "Episode reward: 4052.592\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.930658  7.8989964 7.9319596 6.399224  7.6820884 7.923672 ]\n",
      "Reset environment\n",
      "Episode reward: 3959.8748\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9330306 7.9013643 7.9343295 6.401812  7.6841865 7.92604  ]\n",
      "Reset environment\n",
      "Episode reward: 2375.268\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9343324 7.9026475 7.9356456 6.4032707 7.6853294 7.9273396]\n",
      "Reset environment\n",
      "Episode reward: 1884.99\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.935805  7.9041224 7.937118  6.4049263 7.6866326 7.928812 ]\n",
      "Reset environment\n",
      "Episode reward: 2689.1296\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.937366  7.9056835 7.9386864 6.406652  7.6880264 7.930376 ]\n",
      "Reset environment\n",
      "Episode reward: 2255.4824\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9386125 7.906908  7.9399457 6.4080443 7.689133  7.931619 ]\n",
      "Reset environment\n",
      "Episode reward: 4625.1104\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.941412  7.9097066 7.942744  6.411089  7.6916223 7.9344196]\n",
      "Reset environment\n",
      "Episode reward: 2777.618\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.942897  7.911124  7.944281  6.4127665 7.6929417 7.9359026]\n",
      "Reset environment\n",
      "Episode reward: 2748.2817\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.944398  7.9126544 7.945752  6.414449  7.6942687 7.937401 ]\n",
      "Reset environment\n",
      "Episode reward: 4191.531\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.946823  7.9150825 7.948176  6.4171042 7.696434  7.9398265]\n",
      "Reset environment\n",
      "Episode reward: 5283.3843\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9500437 7.9182982 7.951396  6.4206133 7.699308  7.9430504]\n",
      "Reset environment\n",
      "Episode reward: 1611.4402\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9509015 7.919146  7.9522624 6.421579  7.7000585 7.9439087]\n",
      "Reset environment\n",
      "Episode reward: 5694.1304\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.954365  7.922595  7.9557295 6.4253983 7.703155  7.9473686]\n",
      "Reset environment\n",
      "Episode reward: 2802.6238\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9559546 7.92417   7.957326  6.427164  7.7045465 7.9489584]\n",
      "Reset environment\n",
      "Episode reward: 2532.7014\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9573665 7.925589  7.9587326 6.4287305 7.705808  7.950375 ]\n",
      "Reset environment\n",
      "Episode reward: 2339.8818\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.958544  7.9268026 7.959872  6.4300714 7.706851  7.951551 ]\n",
      "Reset environment\n",
      "Episode reward: 3368.034\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9604974 7.928768  7.961816  6.432236  7.708587  7.9535036]\n",
      "Reset environment\n",
      "Episode reward: 1801.8389\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.961363  7.929596  7.9627156 6.433229  7.7093396 7.9543705]\n",
      "Reset environment\n",
      "Episode reward: 3292.607\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.963214  7.931413  7.9645977 6.4352746 7.710995  7.956223 ]\n",
      "Reset environment\n",
      "Episode reward: 1391.2971\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9643536 7.9325533 7.9657354 6.436558  7.7120085 7.957363 ]\n",
      "Reset environment\n",
      "Episode reward: 1891.3324\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.965369  7.93357   7.966754  6.437701  7.7129135 7.9583793]\n",
      "Reset environment\n",
      "Episode reward: 5595.9727\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9687815 7.93699   7.970162  6.4414263 7.7160087 7.9617934]\n",
      "Reset environment\n",
      "Episode reward: 3126.5852\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9706054 7.938809  7.9719877 6.443423  7.7176304 7.963615 ]\n",
      "Reset environment\n",
      "Episode reward: 5387.328\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9738817 7.942081  7.9752674 6.446997  7.7205453 7.9668903]\n",
      "Reset environment\n",
      "Episode reward: 2080.369\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.975468  7.943663  7.9768486 6.448756  7.7219663 7.9684763]\n",
      "Reset environment\n",
      "Episode reward: 2724.6074\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9770446 7.9452543 7.9784102 6.4504914 7.723362  7.9700527]\n",
      "Reset environment\n",
      "Episode reward: 1381.5085\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9781923 7.9464045 7.979556  6.4517646 7.724384  7.9712014]\n",
      "Reset environment\n",
      "Episode reward: 3498.9375\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9802337 7.9484267 7.981616  6.454016  7.7261925 7.9732437]\n",
      "Reset environment\n",
      "Episode reward: 3950.2507\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.982477  7.950686  7.983852  6.4565215 7.72819   7.975493 ]\n",
      "Reset environment\n",
      "Episode reward: 2109.381\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.984076  7.9522815 7.98545   6.4582934 7.7296085 7.9770894]\n",
      "Reset environment\n",
      "Episode reward: 2867.4133\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.985735  7.9539423 7.987099  6.4601274 7.7310967 7.9787483]\n",
      "Reset environment\n",
      "Episode reward: 2265.1025\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.98702   7.955216  7.9883986 6.4615445 7.732255  7.9800334]\n",
      "Reset environment\n",
      "Episode reward: 2033.635\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9880342 7.956189  7.989449  6.4627094 7.733151  7.9810467]\n",
      "Reset environment\n",
      "Episode reward: 3123.914\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9898205 7.9580064 7.9912014 6.4646764 7.734739  7.9828315]\n",
      "Reset environment\n",
      "Episode reward: 1545.4932\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9904943 7.9587197 7.991837  6.4654727 7.7353315 7.9835057]\n",
      "Reset environment\n",
      "Episode reward: -45.74997\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.9899774 7.958123  7.991395  6.465048  7.7348657 7.98299  ]\n",
      "Reset environment\n",
      "Episode reward: 2118.271\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.99108   7.9592514 7.9924726 6.4662895 7.735843  7.9840956]\n",
      "Reset environment\n",
      "Episode reward: 2692.6165\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.992559  7.960735  7.993949  6.4679213 7.7371526 7.9855757]\n",
      "Reset environment\n",
      "Episode reward: 2046.4783\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.994116  7.9622955 7.995505  6.4696517 7.738529  7.987136 ]\n",
      "Reset environment\n",
      "Episode reward: 4678.018\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.996936  7.9650874 7.998341  6.4727263 7.741043  7.9899535]\n",
      "Reset environment\n",
      "Episode reward: -214.41306\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.996444  7.9645443 7.9978995 6.472103  7.740573  7.9894633]\n",
      "Reset environment\n",
      "Episode reward: 2113.9346\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [7.998054  7.966154  7.9995074 6.47388   7.7419996 7.991074 ]\n",
      "Reset environment\n",
      "Episode reward: 3900.773\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.000317  7.9684134 8.001768  6.4763846 7.7439895 7.993336 ]\n",
      "Reset environment\n",
      "Episode reward: 3593.5605\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.002391  7.9704986 8.003825  6.4786754 7.7458415 7.995408 ]\n",
      "Reset environment\n",
      "Episode reward: 1835.8025\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.0034    7.971523  8.004818  6.4798026 7.7467422 7.996421 ]\n",
      "Reset environment\n",
      "Episode reward: 1917.7335\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.004421  7.9725585 8.005824  6.4809775 7.747647  7.9974427]\n",
      "Reset environment\n",
      "Episode reward: -404.52386\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.003754  7.971924  8.005128  6.4800854 7.747069  7.996781 ]\n",
      "Reset environment\n",
      "Episode reward: -579.03326\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.002892  7.971123  8.004207  6.4791694 7.746283  7.9959216]\n",
      "Reset environment\n",
      "Episode reward: 1809.7222\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.003806  7.9720187 8.005145  6.480207  7.747093  7.9968367]\n",
      "Reset environment\n",
      "Episode reward: 2294.5186\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.005093  7.973313  8.006415  6.481628  7.748233  7.9981236]\n",
      "Reset environment\n",
      "Episode reward: 2184.2795\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.006202  7.9743853 8.007563  6.4828887 7.749216  7.9992313]\n",
      "Reset environment\n",
      "Episode reward: -198.91391\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.005656  7.9737678 8.00708   6.4822493 7.7487445 7.998686 ]\n",
      "Reset environment\n",
      "Episode reward: 2013.945\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.007176  7.975287  8.008593  6.4839506 7.7500978 8.000206 ]\n",
      "Reset environment\n",
      "Episode reward: 2304.7708\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.008416 7.976547 8.009805 6.485348 7.751192 8.001447]\n",
      "Reset environment\n",
      "Episode reward: 1330.2902\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.0090885 7.977212  8.01048   6.4861174 7.7517877 8.002119 ]\n",
      "Reset environment\n",
      "Episode reward: -164.9722\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.00863   7.9768133 8.009961  6.48556   7.7513905 8.001657 ]\n",
      "Reset environment\n",
      "Episode reward: 5552.4355\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.011979  7.980171  8.013309  6.4892206 7.7543764 8.005008 ]\n",
      "Reset environment\n",
      "Episode reward: 3458.9634\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.013941  7.982114  8.0152855 6.491398  7.7561007 8.00697  ]\n",
      "Reset environment\n",
      "Episode reward: 2692.5535\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.015479  7.983657  8.016826  6.4930916 7.757475  8.0085125]\n",
      "Reset environment\n",
      "Episode reward: 1736.149\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.016833  7.98501   8.018175  6.4946003 7.7586703 8.009867 ]\n",
      "Reset environment\n",
      "Episode reward: 1980.5162\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.0183325 7.9865108 8.019674  6.4962854 7.760001  8.011366 ]\n",
      "Reset environment\n",
      "Episode reward: 2149.6396\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.0199585 7.988137  8.021301  6.498085  7.7614474 8.012992 ]\n",
      "Reset environment\n",
      "Episode reward: 4197.4727\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.022436  7.99062   8.023766  6.5008225 7.763658  8.01547  ]\n",
      "Reset environment\n",
      "Episode reward: 4748.544\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.025176  7.9933505 8.026505  6.5038285 7.7660756 8.01821  ]\n",
      "Reset environment\n",
      "Episode reward: 2065.689\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.02631   7.99448   8.027641  6.5050917 7.767079  8.019344 ]\n",
      "Reset environment\n",
      "Episode reward: 4615.628\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.029078  7.9972553 8.030391  6.5080876 7.76957   8.022117 ]\n",
      "Reset environment\n",
      "Episode reward: 2054.4426\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.029966  7.998191  8.031235  6.509147  7.7703333 8.023005 ]\n",
      "Reset environment\n",
      "Episode reward: 3194.7468\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.031774  8.000009  8.033024  6.5111594 7.7719393 8.024814 ]\n",
      "Reset environment\n",
      "Episode reward: 2701.2964\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.033271 8.001473 8.034536 6.512833 7.773255 8.026308]\n",
      "Reset environment\n",
      "Episode reward: 2020.9089\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.034815 8.003019 8.036079 6.514547 7.774625 8.027853]\n",
      "Reset environment\n",
      "Episode reward: -162.84369\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.034141  8.002474  8.035272  6.513872  7.7740054 8.027185 ]\n",
      "Reset environment\n",
      "Episode reward: 3075.6257\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.035903  8.004248  8.037018  6.5158134 7.7755866 8.028949 ]\n",
      "Reset environment\n",
      "Episode reward: 2905.8225\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.037553  8.005874  8.038686  6.5176373 7.777049  8.030598 ]\n",
      "Reset environment\n",
      "Episode reward: 1760.1608\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.038476 8.006793 8.039611 6.518686 7.777856 8.03152 ]\n",
      "Reset environment\n",
      "Episode reward: 1365.9736\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.039594  8.007911  8.040729  6.5199475 7.778848  8.032638 ]\n",
      "Reset environment\n",
      "Episode reward: 4835.3643\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.042477  8.0107975 8.043608  6.5231094 7.7813964 8.035521 ]\n",
      "Reset environment\n",
      "Episode reward: 2711.1313\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.044001 8.01232  8.045132 6.524809 7.782754 8.037045]\n",
      "Reset environment\n",
      "Episode reward: 1763.1611\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.044923  8.013245  8.046053  6.525859  7.7835684 8.037968 ]\n",
      "Reset environment\n",
      "Episode reward: 1756.0747\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.04582   8.014162  8.046935  6.5268884 7.784362  8.038868 ]\n",
      "Reset environment\n",
      "Episode reward: 1489.9044\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.046541  8.014884  8.047652  6.5277376 7.78498   8.039588 ]\n",
      "Reset environment\n",
      "Episode reward: 3638.6375\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.048643  8.016977  8.049763  6.5300746 7.7868514 8.041688 ]\n",
      "Reset environment\n",
      "Episode reward: 1994.4862\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.050145  8.018477  8.051264  6.5317416 7.7881837 8.04319  ]\n",
      "Reset environment\n",
      "Episode reward: 3002.212\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.051754 8.020053 8.052901 6.533544 7.789623 8.044798]\n",
      "Reset environment\n",
      "Episode reward: 1928.2588\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.052775 8.021094 8.053914 6.534693 7.790535 8.045821]\n",
      "Reset environment\n",
      "Episode reward: 3937.1194\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.055072  8.023401  8.056208  6.537235  7.7926106 8.048122 ]\n",
      "Reset environment\n",
      "Episode reward: 4861.989\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.057962  8.026301  8.059083  6.5403967 7.795218  8.051013 ]\n",
      "Reset environment\n",
      "Episode reward: 3193.3142\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.059768  8.028121  8.060871  6.5423946 7.7968264 8.052816 ]\n",
      "Reset environment\n",
      "Episode reward: 1640.7524\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.060631  8.028992  8.061729  6.5433764 7.7976    8.053681 ]\n",
      "Reset environment\n",
      "Episode reward: 911.51025\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.060885 8.029172 8.062054 6.543667 7.797861 8.053941]\n",
      "Reset environment\n",
      "Episode reward: 4097.9424\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.063258  8.031568  8.064409  6.546287  7.7999954 8.056314 ]\n",
      "Reset environment\n",
      "Episode reward: 1577.8545\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.064461  8.032771  8.065613  6.5476646 7.8010564 8.05752  ]\n",
      "Reset environment\n",
      "Episode reward: 1681.5222\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.065342  8.033684  8.066468  6.548665  7.8018417 8.058402 ]\n",
      "Reset environment\n",
      "Episode reward: 2452.4075\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.06663   8.035015  8.067716  6.5501227 7.8029785 8.059691 ]\n",
      "Reset environment\n",
      "Episode reward: 3765.531\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.068805  8.037163  8.069908  6.552504  7.8048897 8.061863 ]\n",
      "Reset environment\n",
      "Episode reward: -1550.4136\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.066945 8.035472 8.067896 6.550546 7.803166 8.060019]\n",
      "Reset environment\n",
      "Episode reward: 2062.6812\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.067975 8.036503 8.068926 6.551718 7.804076 8.061049]\n",
      "Reset environment\n",
      "Episode reward: 1762.4026\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.068913  8.037418  8.069879  6.5527525 7.8049097 8.061984 ]\n",
      "Reset environment\n",
      "Episode reward: 977.60144\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.069123 8.03751  8.070215 6.553117 7.805111 8.062202]\n",
      "Reset environment\n",
      "Episode reward: 1372.8687\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.070252 8.038639 8.071347 6.554379 7.806098 8.063332]\n",
      "Reset environment\n",
      "Episode reward: 5433.141\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.073547  8.041936  8.074644  6.557956  7.8090353 8.066629 ]\n",
      "Reset environment\n",
      "Episode reward: 2988.7644\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.075234  8.043633  8.076318  6.5598235 7.810543  8.0683155]\n",
      "Reset environment\n",
      "Episode reward: 2603.7856\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.076618  8.045051  8.077667  6.561373  7.8117704 8.0697   ]\n",
      "Reset environment\n",
      "Episode reward: 2349.6313\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.07785   8.0463085 8.078879  6.562765  7.812861  8.070933 ]\n",
      "Reset environment\n",
      "Episode reward: 1077.7236\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.078142  8.046691  8.079084  6.563125  7.8131337 8.071226 ]\n",
      "Reset environment\n",
      "Episode reward: 3094.6182\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.079885  8.048435  8.080822  6.5650673 7.814695  8.072969 ]\n",
      "Reset environment\n",
      "Episode reward: 3159.2783\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.081732  8.050295  8.082651  6.5670805 7.816334  8.074819 ]\n",
      "Reset environment\n",
      "Episode reward: 3590.9612\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.083799  8.052367  8.084713  6.5693674 7.818189  8.07689  ]\n",
      "Reset environment\n",
      "Episode reward: 2203.1223\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.084993  8.053569  8.085896  6.5706964 7.81925   8.078086 ]\n",
      "Reset environment\n",
      "Episode reward: 2067.6365\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.086554  8.055129  8.087452  6.5724254 7.8206463 8.079643 ]\n",
      "Reset environment\n",
      "Episode reward: 3994.1646\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.088889  8.057445  8.089807  6.574977  7.8227334 8.08198  ]\n",
      "Reset environment\n",
      "Episode reward: 5238.117\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.092032 8.060588 8.092931 6.578397 7.825542 8.085121]\n",
      "Reset environment\n",
      "Episode reward: 2392.639\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.093345 8.061882 8.094257 6.579853 7.826712 8.086435]\n",
      "Reset environment\n",
      "Episode reward: 3127.299\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.095095  8.063616  8.096026  6.5817986 7.8282638 8.088188 ]\n",
      "Reset environment\n",
      "Episode reward: 1850.501\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.096049  8.06459   8.096964  6.5828695 7.8291163 8.089145 ]\n",
      "Reset environment\n",
      "Episode reward: 946.61035\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.096466  8.065015  8.097377  6.5833616 7.8294797 8.089562 ]\n",
      "Reset environment\n",
      "Episode reward: 2957.336\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.09813   8.066651  8.099067  6.585187  7.8309646 8.091225 ]\n",
      "Reset environment\n",
      "Episode reward: 1834.1058\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.099113 8.067641 8.100037 6.586298 7.831834 8.09221 ]\n",
      "Reset environment\n",
      "Episode reward: 4087.6665\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.101492 8.070012 8.102425 6.588936 7.833954 8.094587]\n",
      "Reset environment\n",
      "Episode reward: 2575.9304\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.102945  8.071477  8.103857  6.590543  7.8352394 8.096045 ]\n",
      "Reset environment\n",
      "Episode reward: 4320.57\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.105495  8.074036  8.106397  6.5933466 7.8375425 8.098596 ]\n",
      "Reset environment\n",
      "Episode reward: 2416.0205\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.10727   8.075811  8.108172  6.595304  7.8391247 8.100371 ]\n",
      "Reset environment\n",
      "Episode reward: 2918.805\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.10892   8.077466  8.109813  6.597141  7.8405776 8.102019 ]\n",
      "Reset environment\n",
      "Episode reward: 1956.3378\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.109892  8.078405  8.110821  6.598257  7.8414297 8.102991 ]\n",
      "Reset environment\n",
      "Episode reward: 2354.2827\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.111131 8.079653 8.112055 6.599646 7.842546 8.104234]\n",
      "Reset environment\n",
      "Episode reward: 2601.508\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.112497  8.081052  8.113385  6.6011686 7.843754  8.105599 ]\n",
      "Reset environment\n",
      "Episode reward: 4920.2217\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.115395  8.083977  8.116265  6.6043587 7.8463345 8.108497 ]\n",
      "Reset environment\n",
      "Episode reward: 1342.7504\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.116482  8.085065  8.117351  6.60558   7.8473034 8.109587 ]\n",
      "Reset environment\n",
      "Episode reward: 2104.4648\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.1176   8.086193 8.118462 6.606838 7.848302 8.110707]\n",
      "Reset environment\n",
      "Episode reward: 3493.015\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.1196165 8.088208  8.120475  6.6090536 7.8500867 8.1127205]\n",
      "Reset environment\n",
      "Episode reward: 3240.3022\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.121382  8.090002  8.122203  6.6110134 7.851648  8.114487 ]\n",
      "Reset environment\n",
      "Episode reward: 3931.4817\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.123661  8.092285  8.124477  6.6135244 7.8536925 8.116767 ]\n",
      "Reset environment\n",
      "Episode reward: 1700.4512\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.124533  8.093152  8.125354  6.614508  7.8544564 8.117639 ]\n",
      "Reset environment\n",
      "Episode reward: 408.1873\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.124273 8.092986 8.125006 6.614281 7.854213 8.117381]\n",
      "Reset environment\n",
      "Episode reward: 935.81305\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.12468   8.093395  8.12541   6.614768  7.8545685 8.117787 ]\n",
      "Reset environment\n",
      "Episode reward: 4786.6685\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.127518  8.096232  8.1282425 6.617862  7.8571196 8.120625 ]\n",
      "Reset environment\n",
      "Episode reward: 2744.6772\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.128946  8.097617  8.129711  6.6194773 7.858401  8.122055 ]\n",
      "Reset environment\n",
      "Episode reward: 1699.4514\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.129835  8.0985155 8.130589  6.6204767 7.859191  8.122943 ]\n",
      "Reset environment\n",
      "Episode reward: 2864.314\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.131455  8.100131  8.132217  6.622268  7.8606143 8.124564 ]\n",
      "Reset environment\n",
      "Episode reward: 3202.3735\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.13327   8.101944  8.134035  6.6242795 7.862234  8.12638  ]\n",
      "Reset environment\n",
      "Episode reward: 2410.3867\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.134574  8.103258  8.135321  6.6257424 7.863391  8.127685 ]\n",
      "Reset environment\n",
      "Episode reward: 2896.535\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.136166 8.10482  8.136946 6.627501 7.864818 8.129276]\n",
      "Reset environment\n",
      "Episode reward: 2707.1848\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.1376095 8.1062355 8.13842   6.6291094 7.8661113 8.130722 ]\n",
      "Reset environment\n",
      "Episode reward: 5841.1055\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.14101   8.109635  8.141825  6.63281   7.8691206 8.134123 ]\n",
      "Reset environment\n",
      "Episode reward: 2474.918\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.142394 8.111015 8.143211 6.634336 7.870347 8.135507]\n",
      "Reset environment\n",
      "Episode reward: 1617.6923\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.143195  8.111837  8.143989  6.6352444 7.871058  8.136309 ]\n",
      "Reset environment\n",
      "Episode reward: 4977.877\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.146111 8.114742 8.146906 6.638444 7.87364  8.139219]\n",
      "Reset environment\n",
      "Episode reward: 1817.0736\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.1469345 8.115517  8.147774  6.639399  7.8743577 8.140042 ]\n",
      "Reset environment\n",
      "Episode reward: 76.08075\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.145803  8.114183  8.146853  6.638403  7.8732514 8.138921 ]\n",
      "Reset environment\n",
      "Episode reward: 1951.1372\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.14727   8.115654  8.148317  6.6400366 7.8745766 8.140389 ]\n",
      "Reset environment\n",
      "Episode reward: 2485.974\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.148652  8.117057  8.149675  6.6415687 7.875816  8.141772 ]\n",
      "Reset environment\n",
      "Episode reward: 3859.5208\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.15082  8.119226 8.151839 6.643952 7.877738 8.143941]\n",
      "Reset environment\n",
      "Episode reward: 2230.5337\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.152003 8.12044  8.152992 6.645275 7.87878  8.145124]\n",
      "Reset environment\n",
      "Episode reward: 2769.8267\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.153531  8.121974  8.154518  6.646987  7.8801556 8.146657 ]\n",
      "Reset environment\n",
      "Episode reward: 1586.4557\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.154753  8.123198  8.155738  6.6483626 7.8812366 8.147878 ]\n",
      "Reset environment\n",
      "Episode reward: 1518.5126\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.155537  8.123989  8.156517  6.6492615 7.8819375 8.148662 ]\n",
      "Reset environment\n",
      "Episode reward: 2720.036\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.156918  8.125322  8.157945  6.65083   7.8831735 8.1500435]\n",
      "Reset environment\n",
      "Episode reward: 2170.8042\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.157913  8.126379  8.158888  6.6519923 7.8840437 8.151043 ]\n",
      "Reset environment\n",
      "Episode reward: 3065.1594\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.159647 8.128104 8.160629 6.653913 7.885572 8.152779]\n",
      "Reset environment\n",
      "Episode reward: 1939.7751\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.160671  8.129115  8.161672  6.6550617 7.8864894 8.153804 ]\n",
      "Reset environment\n",
      "Episode reward: 4353.9316\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.163127  8.131573  8.164134  6.6577544 7.888675  8.156262 ]\n",
      "Reset environment\n",
      "Episode reward: 1684.1383\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.16399   8.132435  8.164997  6.6587343 7.889441  8.157125 ]\n",
      "Reset environment\n",
      "Episode reward: 2336.38\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.16518   8.13365   8.166148  6.66008   7.8904734 8.158317 ]\n",
      "Reset environment\n",
      "Episode reward: 2214.4136\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.166376  8.134844  8.167345  6.6614285 7.8915377 8.159514 ]\n",
      "Reset environment\n",
      "Episode reward: 3198.9072\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.168188  8.136662  8.169152  6.6634307 7.8931766 8.161326 ]\n",
      "Reset environment\n",
      "Episode reward: 2010.2169\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.169251  8.137728  8.170215  6.664631  7.8941197 8.162391 ]\n",
      "Reset environment\n",
      "Episode reward: 3300.969\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.171124  8.139596  8.172092  6.6666875 7.8957877 8.164264 ]\n",
      "Reset environment\n",
      "Episode reward: 1906.5205\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.171976  8.140515  8.17288   6.6677    7.8965516 8.165112 ]\n",
      "Reset environment\n",
      "Episode reward: 5377.4014\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.1751995 8.143738  8.176098  6.671213  7.899426  8.168334 ]\n",
      "Reset environment\n",
      "Episode reward: 2368.4722\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.176381  8.144907  8.177293  6.6725674 7.900454  8.169517 ]\n",
      "Reset environment\n",
      "Episode reward: 2659.0276\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.177829  8.14637   8.178722  6.674182  7.9017534 8.170963 ]\n",
      "Reset environment\n",
      "Episode reward: 1844.489\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.178707  8.147196  8.1796465 6.6751976 7.9025316 8.171843 ]\n",
      "Reset environment\n",
      "Episode reward: 385.51096\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.17852   8.146891  8.179586  6.6752057 7.9022956 8.171664 ]\n",
      "Reset environment\n",
      "Episode reward: 2201.439\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.180149  8.148517  8.181216  6.677007  7.9037523 8.173294 ]\n",
      "Reset environment\n",
      "Episode reward: 3133.199\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.181914 8.15026  8.182996 6.678951 7.905312 8.175057]\n",
      "Reset environment\n",
      "Episode reward: 1354.8806\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.183004  8.151354  8.184084  6.6801777 7.90628   8.176147 ]\n",
      "Reset environment\n",
      "Episode reward: 2063.5886\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.184537  8.152887  8.185612  6.6818852 7.90765   8.17768  ]\n",
      "Reset environment\n",
      "Episode reward: 2761.9492\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.186034  8.154358  8.187134  6.683547  7.9089847 8.1791725]\n",
      "Reset environment\n",
      "Episode reward: 2589.7039\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.187392  8.155677  8.188532  6.685074  7.9101925 8.180533 ]\n",
      "Reset environment\n",
      "Episode reward: 4022.2769\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.189776  8.158058  8.19092   6.6876717 7.9123096 8.182919 ]\n",
      "Reset environment\n",
      "Episode reward: 2112.4788\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.190838  8.159121  8.191981  6.6888638 7.913258  8.183981 ]\n",
      "Reset environment\n",
      "Episode reward: 249.70364\n",
      "Total Steps: 8\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.190819  8.1591015 8.191961  6.68887   7.91323   8.183962 ]\n",
      "Reset environment\n",
      "Episode reward: 1702.4994\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.191696 8.159962 8.192854 6.689856 7.914014 8.18484 ]\n",
      "Reset environment\n",
      "Episode reward: -694.11334\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.19077   8.159049  8.191924  6.6888947 7.91314   8.183916 ]\n",
      "Reset environment\n",
      "Episode reward: 1378.6139\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.191884 8.160164 8.193035 6.690142 7.914129 8.185031]\n",
      "Reset environment\n",
      "Episode reward: 1477.4203\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.19264  8.160924 8.193792 6.691001 7.914803 8.18579 ]\n",
      "Reset environment\n",
      "Episode reward: 2229.84\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.193847  8.162137  8.194992  6.692347  7.9158764 8.186997 ]\n",
      "Reset environment\n",
      "Episode reward: 1682.0519\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.194626  8.162954  8.195735  6.6932583 7.9165606 8.187777 ]\n",
      "Reset environment\n",
      "Episode reward: 1595.9441\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.195448  8.1637745 8.196558  6.6941967 7.917287  8.188601 ]\n",
      "Reset environment\n",
      "Episode reward: 3971.0\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.197742  8.166063  8.198841  6.696717  7.9193444 8.19089  ]\n",
      "Reset environment\n",
      "Episode reward: -691.03827\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.196829  8.165153  8.197925  6.6957617 7.918468  8.189976 ]\n",
      "Reset environment\n",
      "Episode reward: 2000.6296\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.197835  8.166125  8.198964  6.696896  7.9193583 8.190984 ]\n",
      "Reset environment\n",
      "Episode reward: 216.89859\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.197491 8.165911 8.19849  6.696618 7.919052 8.190652]\n",
      "Reset environment\n",
      "Episode reward: 1943.6318\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.198411  8.166786  8.199455  6.697685  7.9198604 8.191572 ]\n",
      "Reset environment\n",
      "Episode reward: 1810.5184\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.19937   8.167728  8.200432  6.69876   7.9207177 8.192533 ]\n",
      "Reset environment\n",
      "Episode reward: 3682.5972\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.201515  8.169883  8.202563  6.701108  7.9226437 8.194675 ]\n",
      "Reset environment\n",
      "Episode reward: 2284.3308\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.202785  8.171148  8.2038355 6.702504  7.923777  8.195946 ]\n",
      "Reset environment\n",
      "Episode reward: 4468.6665\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.205363  8.173722  8.206426  6.7053423 7.926094  8.198528 ]\n",
      "Reset environment\n",
      "Episode reward: 2728.3853\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.206817  8.175218  8.207836  6.706962  7.9273896 8.199984 ]\n",
      "Reset environment\n",
      "Episode reward: 2461.4968\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.208116  8.176555  8.2091    6.708416  7.9285426 8.2012825]\n",
      "Reset environment\n",
      "Episode reward: 3053.0537\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.209831  8.178243  8.210832  6.7102942 7.930064  8.202999 ]\n",
      "Reset environment\n",
      "Episode reward: 1463.5638\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.210545  8.17895   8.211551  6.711108  7.9306974 8.203712 ]\n",
      "Reset environment\n",
      "Episode reward: -340.83243\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.209926  8.17833   8.210931  6.7105927 7.9301367 8.203094 ]\n",
      "Reset environment\n",
      "Episode reward: 1957.9828\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.210953  8.179365  8.211947  6.7117457 7.931046  8.204122 ]\n",
      "Reset environment\n",
      "Episode reward: 4624.032\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.213647 8.182053 8.214648 6.714702 7.93346  8.206818]\n",
      "Reset environment\n",
      "Episode reward: 3484.3086\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.215663  8.184052  8.216672  6.7168827 7.935262  8.20883  ]\n",
      "Reset environment\n",
      "Episode reward: 1899.7228\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.216651  8.185039  8.21766   6.7180004 7.936141  8.209821 ]\n",
      "Reset environment\n",
      "Episode reward: 3303.759\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.218478  8.1868725 8.21947   6.7200284 7.937769  8.211646 ]\n",
      "Reset environment\n",
      "Episode reward: 2003.8955\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.219546  8.187952  8.220524  6.7212243 7.938719  8.212717 ]\n",
      "Reset environment\n",
      "Episode reward: 2436.7883\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.220828  8.189268  8.221779  6.722658  7.9398603 8.213998 ]\n",
      "Reset environment\n",
      "Episode reward: 2534.7126\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.222207 8.190652 8.223157 6.724197 7.941094 8.215382]\n",
      "Reset environment\n",
      "Episode reward: 3475.207\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.2241535 8.192569  8.225131  6.726351  7.942824  8.217328 ]\n",
      "Reset environment\n",
      "Episode reward: 2997.7417\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.225838  8.194229  8.226833  6.7281976 7.944322  8.219011 ]\n",
      "Reset environment\n",
      "Episode reward: 2693.887\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.22726   8.195649  8.2282505 6.7297745 7.945587  8.22043  ]\n",
      "Reset environment\n",
      "Episode reward: 2160.7278\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.228844  8.197228  8.229837  6.7315316 7.946993  8.222014 ]\n",
      "Reset environment\n",
      "Episode reward: 1565.2026\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.229636 8.198018 8.230627 6.732435 7.947694 8.222806]\n",
      "Reset environment\n",
      "Episode reward: 4178.096\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.232042 8.200406 8.233046 6.735073 7.949837 8.225213]\n",
      "Reset environment\n",
      "Episode reward: 2531.8264\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.233457  8.201816  8.234462  6.7366323 7.951092  8.226626 ]\n",
      "Reset environment\n",
      "Episode reward: -922.8071\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.232125  8.20063   8.232988  6.7352595 7.9498825 8.225306 ]\n",
      "Reset environment\n",
      "Episode reward: 4313.915\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.234597  8.203111  8.235452  6.7379947 7.9520946 8.227776 ]\n",
      "Reset environment\n",
      "Episode reward: 1509.9521\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.235369  8.203879  8.236225  6.738871  7.9527826 8.228546 ]\n",
      "Reset environment\n",
      "Episode reward: 1948.6823\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.23637   8.204879  8.237229  6.7400074 7.9536614 8.229547 ]\n",
      "Reset environment\n",
      "Episode reward: 3260.4536\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.238205  8.206689  8.239082  6.7420263 7.9552937 8.231382 ]\n",
      "Reset environment\n",
      "Episode reward: 660.1233\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.237706  8.206044  8.238728  6.741678  7.9547973 8.230885 ]\n",
      "Reset environment\n",
      "Episode reward: 2533.7542\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.239062  8.207398  8.240085  6.743206  7.9560013 8.232242 ]\n",
      "Reset environment\n",
      "Episode reward: 2345.2637\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.240248  8.208584  8.241269  6.7445426 7.957042  8.233427 ]\n",
      "Reset environment\n",
      "Episode reward: 5251.4824\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.243351  8.211685  8.244373  6.747931  7.9598255 8.23653  ]\n",
      "Reset environment\n",
      "Episode reward: 3003.9727\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.244984  8.213352  8.245968  6.7497287 7.9612627 8.238163 ]\n",
      "Reset environment\n",
      "Episode reward: 3043.3516\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.246625  8.214995  8.247609  6.7515388 7.962743  8.239804 ]\n",
      "Reset environment\n",
      "Episode reward: 3609.3574\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.248685  8.2170515 8.249672  6.7538004 7.964584  8.241865 ]\n",
      "Reset environment\n",
      "Episode reward: 2155.1226\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.250259  8.218629  8.251241  6.7555614 7.9659934 8.2434435]\n",
      "Reset environment\n",
      "Episode reward: 2180.8833\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.251441 8.219792 8.252432 6.756858 7.967049 8.244624]\n",
      "Reset environment\n",
      "Episode reward: 1708.9165\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.2522955 8.220632  8.253299  6.7578135 7.9678087 8.245477 ]\n",
      "Reset environment\n",
      "Episode reward: 2942.2302\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.253879  8.2221775 8.254917  6.7595716 7.9692173 8.247059 ]\n",
      "Reset environment\n",
      "Episode reward: 1536.2032\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.254647  8.22295   8.255682  6.760448  7.9699006 8.24783  ]\n",
      "Reset environment\n",
      "Episode reward: 3149.6353\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.256309  8.224658  8.25729   6.7623124 7.9713783 8.249491 ]\n",
      "Reset environment\n",
      "Episode reward: 3668.7927\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.258402 8.226759 8.259381 6.76462  7.973245 8.25158 ]\n",
      "Reset environment\n",
      "Episode reward: 3450.584\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.260316  8.228666  8.261303  6.766748  7.9749465 8.253496 ]\n",
      "Reset environment\n",
      "Episode reward: 4800.584\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.263125  8.231466  8.264113  6.7698073 7.977448  8.256304 ]\n",
      "Reset environment\n",
      "Episode reward: 4033.0676\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.265328 8.233668 8.266319 6.772246 7.979401 8.25851 ]\n",
      "Reset environment\n",
      "Episode reward: 3518.2107\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.267306  8.23564   8.268302  6.774431  7.9811673 8.260488 ]\n",
      "Reset environment\n",
      "Episode reward: 1277.3185\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.267924 8.236257 8.268924 6.775141 7.981718 8.261107]\n",
      "Reset environment\n",
      "Episode reward: 2959.041\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.269553  8.237904  8.270536  6.7769375 7.9831786 8.262736 ]\n",
      "Reset environment\n",
      "Episode reward: 2497.18\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.2708845 8.239258  8.271844  6.7784233 7.9843698 8.2640705]\n",
      "Reset environment\n",
      "Episode reward: 4807.925\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.273679 8.242068 8.27463  6.781469 7.986887 8.266867]\n",
      "Reset environment\n",
      "Episode reward: 1933.4719\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.2747    8.2430935 8.275642  6.7826095 7.987801  8.267888 ]\n",
      "Reset environment\n",
      "Episode reward: 4883.52\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.277446 8.245837 8.278393 6.785596 7.99023  8.270637]\n",
      "Reset environment\n",
      "Episode reward: 1719.7184\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.278362  8.2467575 8.279296  6.7866225 7.991051  8.27155  ]\n",
      "Reset environment\n",
      "Episode reward: 506.056\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.278164 8.246462 8.279192 6.786434 7.99091  8.271358]\n",
      "Reset environment\n",
      "Episode reward: 1842.4058\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.279135 8.247432 8.280159 6.787527 7.991767 8.272329]\n",
      "Reset environment\n",
      "Episode reward: 2823.991\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.280573 8.248816 8.28164  6.78914  7.993055 8.273768]\n",
      "Reset environment\n",
      "Episode reward: 4987.0776\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.28389   8.252154  8.284938  6.7927938 7.9960456 8.277085 ]\n",
      "Reset environment\n",
      "Episode reward: 2482.8086\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.285235 8.253514 8.286271 6.794287 7.997242 8.278431]\n",
      "Reset environment\n",
      "Episode reward: 1493.2272\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.285982 8.254253 8.28702  6.79513  7.997903 8.279179]\n",
      "Reset environment\n",
      "Episode reward: 5259.669\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.289091  8.257344  8.290143  6.7985163 8.000675  8.282286 ]\n",
      "Reset environment\n",
      "Episode reward: 3071.0325\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.290762  8.258981  8.291846  6.8003635 8.002158  8.283958 ]\n",
      "Reset environment\n",
      "Episode reward: 2786.5017\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.292212  8.26039   8.293328  6.8019834 8.003435  8.285408 ]\n",
      "Reset environment\n",
      "Episode reward: 2450.8472\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.2935505 8.261728  8.294675  6.803458  8.004627  8.286747 ]\n",
      "Reset environment\n",
      "Episode reward: 2019.1289\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.295027 8.263196 8.296155 6.805104 8.005933 8.288224]\n",
      "Reset environment\n",
      "Episode reward: 1808.0188\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.295908 8.264046 8.297069 6.806097 8.006714 8.289105]\n",
      "Reset environment\n",
      "Episode reward: 2258.8643\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.297112  8.265231  8.29828   6.8074284 8.007777  8.290307 ]\n",
      "Reset environment\n",
      "Episode reward: 4758.7617\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.299882 8.267996 8.301041 6.810448 8.010245 8.293078]\n",
      "Reset environment\n",
      "Episode reward: 5866.713\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.303357  8.2714405 8.30453   6.814237  8.013348  8.296552 ]\n",
      "Reset environment\n",
      "Episode reward: 5144.117\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.306323 8.274417 8.307486 6.817517 8.016025 8.299522]\n",
      "Reset environment\n",
      "Episode reward: 5689.232\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.309675  8.277761  8.310845  6.8211694 8.01902   8.3028755]\n",
      "Reset environment\n",
      "Episode reward: 1318.3286\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.310311 8.2784   8.311482 6.821902 8.019587 8.303513]\n",
      "Reset environment\n",
      "Episode reward: 769.33435\n",
      "Total Steps: 30\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.310578  8.278669  8.311747  6.8222528 8.019806  8.303779 ]\n",
      "Reset environment\n",
      "Episode reward: 4753.31\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.31333  8.281414 8.314495 6.825255 8.022248 8.306528]\n",
      "Reset environment\n",
      "Episode reward: 2114.6257\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.314405  8.2824745 8.315582  6.826477  8.023192  8.307603 ]\n",
      "Reset environment\n",
      "Episode reward: 5077.0723\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.317362 8.285422 8.318549 6.829714 8.025837 8.310558]\n",
      "Reset environment\n",
      "Episode reward: 3225.1038\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.319082 8.287183 8.320231 6.831614 8.027366 8.31228 ]\n",
      "Reset environment\n",
      "Episode reward: 1761.3715\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.319863 8.287885 8.321075 6.832497 8.028098 8.313065]\n",
      "Reset environment\n",
      "Episode reward: 2312.4448\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.321534  8.289555  8.322749  6.8343472 8.029597  8.314736 ]\n",
      "Reset environment\n",
      "Episode reward: 2064.1255\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.323033  8.291056  8.324244  6.8360243 8.030929  8.316235 ]\n",
      "Reset environment\n",
      "Episode reward: 3951.302\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.325277 8.293289 8.326497 6.838494 8.032937 8.318476]\n",
      "Reset environment\n",
      "Episode reward: 1343.4872\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.326332 8.294342 8.327549 6.839685 8.03387  8.319528]\n",
      "Reset environment\n",
      "Episode reward: 2848.1147\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.327932 8.295947 8.329135 6.841423 8.035305 8.321129]\n",
      "Reset environment\n",
      "Episode reward: 2577.4976\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.329175  8.297141  8.330423  6.8428464 8.036419  8.322373 ]\n",
      "Reset environment\n",
      "Episode reward: 2520.2905\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.33053   8.298486  8.331788  6.8443685 8.037621  8.3237295]\n",
      "Reset environment\n",
      "Episode reward: 2245.297\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.331685  8.299653  8.332928  6.8456693 8.038645  8.324886 ]\n",
      "Reset environment\n",
      "Episode reward: 5115.172\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.334638 8.302602 8.335886 6.848911 8.041276 8.327839]\n",
      "Reset environment\n",
      "Episode reward: 2589.4236\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.335958  8.303953  8.337173  6.8503904 8.04244   8.329159 ]\n",
      "Reset environment\n",
      "Episode reward: 2081.2004\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.336988  8.305014  8.338178  6.8515525 8.043347  8.330193 ]\n",
      "Reset environment\n",
      "Episode reward: 2711.6042\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.338482  8.306511  8.339671  6.8532133 8.044664  8.331683 ]\n",
      "Reset environment\n",
      "Episode reward: 1370.2357\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.339559 8.30759  8.340747 6.85442  8.045632 8.332761]\n",
      "Reset environment\n",
      "Episode reward: 1660.8982\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.340363 8.308414 8.341523 6.855337 8.046338 8.333566]\n",
      "Reset environment\n",
      "Episode reward: 5595.8774\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.34361  8.311678 8.344756 6.858912 8.049271 8.336814]\n",
      "Reset environment\n",
      "Episode reward: 1923.7407\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.345031 8.313101 8.346175 6.860488 8.050537 8.338235]\n",
      "Reset environment\n",
      "Episode reward: 925.07153\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.345236 8.313414 8.34629  6.86074  8.050749 8.338449]\n",
      "Reset environment\n",
      "Episode reward: 2051.659\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.346284  8.31446   8.347337  6.8619323 8.051673  8.339497 ]\n",
      "Reset environment\n",
      "Episode reward: 3279.5654\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.348157  8.316328  8.349219  6.8639774 8.053347  8.341372 ]\n",
      "Reset environment\n",
      "Episode reward: 2360.867\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.349435 8.317629 8.35048  6.865396 8.0545   8.342651]\n",
      "Reset environment\n",
      "Episode reward: 1849.0457\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.350402  8.31861   8.35144   6.8664746 8.055365  8.343621 ]\n",
      "Reset environment\n",
      "Episode reward: 2661.852\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.35184  8.320057 8.352867 6.868066 8.056649 8.345061]\n",
      "Reset environment\n",
      "Episode reward: 1176.6807\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.352352  8.320555  8.353393  6.8686676 8.057097  8.345574 ]\n",
      "Reset environment\n",
      "Episode reward: 2906.43\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.353916 8.322143 8.354937 6.870395 8.058496 8.347141]\n",
      "Reset environment\n",
      "Episode reward: 2725.1772\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.355318 8.323584 8.356301 6.871964 8.059744 8.348545]\n",
      "Reset environment\n",
      "Episode reward: 2148.3945\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.356457  8.324746  8.357424  6.873234  8.0607605 8.349686 ]\n",
      "Reset environment\n",
      "Episode reward: 2331.3362\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.35773   8.326014  8.3587    6.8746386 8.061888  8.35096  ]\n",
      "Reset environment\n",
      "Episode reward: 4143.303\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.360078 8.328354 8.361044 6.877237 8.063978 8.353304]\n",
      "Reset environment\n",
      "Episode reward: 1410.6797\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.36076   8.329037  8.361727  6.8780246 8.06458   8.353987 ]\n",
      "Reset environment\n",
      "Episode reward: 2250.3193\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.3619    8.330203  8.36284   6.8793197 8.065592  8.355129 ]\n",
      "Reset environment\n",
      "Episode reward: 755.8368\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.361938 8.33033  8.362806 6.87932  8.06568  8.355174]\n",
      "Reset environment\n",
      "Episode reward: 2294.7502\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.363058  8.331408  8.363957  6.8805914 8.066662  8.356296 ]\n",
      "Reset environment\n",
      "Episode reward: 2390.7341\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.364346  8.332696  8.365244  6.8820314 8.067807  8.357585 ]\n",
      "Reset environment\n",
      "Episode reward: 5095.6035\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.367303  8.335632  8.368217  6.8852663 8.070446  8.360539 ]\n",
      "Reset environment\n",
      "Episode reward: 1808.897\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.36866   8.336986  8.369571  6.8867736 8.071647  8.361896 ]\n",
      "Reset environment\n",
      "Episode reward: 3348.2964\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.370509 8.338818 8.371432 6.88881  8.073284 8.363743]\n",
      "Reset environment\n",
      "Episode reward: 2314.7158\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.371737  8.340038  8.372667  6.8901772 8.07437   8.364971 ]\n",
      "Reset environment\n",
      "Episode reward: 2433.3088\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.372964  8.341223  8.373925  6.8915534 8.075464  8.366199 ]\n",
      "Reset environment\n",
      "Episode reward: 2862.5242\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.374481  8.342712  8.375471  6.8932405 8.076805  8.367713 ]\n",
      "Reset environment\n",
      "Episode reward: -80.0137\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.374063  8.342278  8.375069  6.8927045 8.076453  8.367298 ]\n",
      "Reset environment\n",
      "Episode reward: 1967.4374\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.374992  8.343251  8.375956  6.8936844 8.077302  8.368234 ]\n",
      "Reset environment\n",
      "Episode reward: 3476.4404\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.37692  8.345193 8.377864 6.895809 8.079038 8.370162]\n",
      "Reset environment\n",
      "Episode reward: 4659.6206\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.379588 8.347864 8.380519 6.898723 8.081425 8.372831]\n",
      "Reset environment\n",
      "Episode reward: 1467.2736\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.380309  8.3485775 8.381251  6.899545  8.082065  8.373553 ]\n",
      "Reset environment\n",
      "Episode reward: 1872.106\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.38124   8.349541  8.3821535 6.9005833 8.08289   8.374487 ]\n",
      "Reset environment\n",
      "Episode reward: 2164.3115\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.382265  8.350513  8.383225  6.9017553 8.083796  8.375514 ]\n",
      "Reset environment\n",
      "Episode reward: 3183.1252\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.383764 8.352077 8.384679 6.903476 8.085116 8.37701 ]\n",
      "Reset environment\n",
      "Episode reward: 2559.533\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.385091 8.35343  8.385983 6.904952 8.086302 8.37834 ]\n",
      "Reset environment\n",
      "Episode reward: 2222.1484\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.386684  8.355027  8.3875675 6.9067273 8.087717  8.379934 ]\n",
      "Reset environment\n",
      "Episode reward: 4201.3696\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.389077  8.357432  8.389945  6.9093595 8.089849  8.382326 ]\n",
      "Reset environment\n",
      "Episode reward: 1407.8552\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.389733 8.358064 8.39062  6.910101 8.09043  8.38298 ]\n",
      "Reset environment\n",
      "Episode reward: 5363.369\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.392817  8.361141  8.393708  6.9134884 8.093177  8.386061 ]\n",
      "Reset environment\n",
      "Episode reward: -86.19382\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.392269 8.360711 8.393049 6.912984 8.092675 8.385518]\n",
      "Reset environment\n",
      "Episode reward: 1631.2545\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.393058 8.36147  8.393869 6.913892 8.093431 8.386311]\n",
      "Reset environment\n",
      "Episode reward: 1737.841\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.3938265 8.362296  8.39458   6.9148035 8.094111  8.38708  ]\n",
      "Reset environment\n",
      "Episode reward: 2328.3276\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.394989  8.3635    8.395712  6.9161186 8.095138  8.388246 ]\n",
      "Reset environment\n",
      "Episode reward: 489.70395\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.394898 8.363512 8.395519 6.916048 8.095061 8.388158]\n",
      "Reset environment\n",
      "Episode reward: 2779.2092\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.396311 8.364971 8.396889 6.917629 8.096313 8.38957 ]\n",
      "Reset environment\n",
      "Episode reward: 3164.568\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.398067  8.366732  8.39864   6.9195647 8.097871  8.391331 ]\n",
      "Reset environment\n",
      "Episode reward: 2453.903\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.399369  8.368033  8.399936  6.9210176 8.099036  8.392632 ]\n",
      "Reset environment\n",
      "Episode reward: 2652.257\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.400724 8.369358 8.40131  6.92254  8.100233 8.393987]\n",
      "Reset environment\n",
      "Episode reward: 1658.9054\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.401669  8.37028   8.4022665 6.9235153 8.101106  8.394932 ]\n",
      "Reset environment\n",
      "Episode reward: 3700.6787\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.403756  8.372381  8.404343  6.925795  8.1029625 8.397019 ]\n",
      "Reset environment\n",
      "Episode reward: 3121.8418\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.405472  8.374077  8.406072  6.9276857 8.104487  8.398735 ]\n",
      "Reset environment\n",
      "Episode reward: 3347.1833\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.407248  8.375854  8.407844  6.9296513 8.106063  8.400511 ]\n",
      "Reset environment\n",
      "Episode reward: 3165.97\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.408972 8.377559 8.409582 6.931559 8.107593 8.402236]\n",
      "Reset environment\n",
      "Episode reward: 3351.7808\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.410777 8.379366 8.411384 6.933535 8.109217 8.404042]\n",
      "Reset environment\n",
      "Episode reward: 2437.7046\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.411986  8.380541  8.412619  6.9349036 8.1102705 8.4052515]\n",
      "Reset environment\n",
      "Episode reward: 2732.0312\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.41346   8.382023  8.414085  6.9365435 8.1115885 8.406726 ]\n",
      "Reset environment\n",
      "Episode reward: 4078.8845\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.415772  8.384339  8.416393  6.9390807 8.113671  8.409039 ]\n",
      "Reset environment\n",
      "Episode reward: 5630.484\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.419035  8.387612  8.419649  6.9426675 8.116583  8.412304 ]\n",
      "Reset environment\n",
      "Episode reward: 2499.8264\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.420385  8.388944  8.421013  6.9441633 8.117776  8.413653 ]\n",
      "Reset environment\n",
      "Episode reward: 5452.818\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.423544 8.39211  8.424161 6.947595 8.120591 8.416808]\n",
      "Reset environment\n",
      "Episode reward: 4533.4775\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.42603  8.3946   8.42664  6.950332 8.122789 8.419293]\n",
      "Reset environment\n",
      "Episode reward: 4983.418\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.428915 8.397482 8.429519 6.953456 8.125363 8.42218 ]\n",
      "Reset environment\n",
      "Episode reward: 3290.7595\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.430725  8.399286  8.431335  6.9554434 8.126971  8.423992 ]\n",
      "Reset environment\n",
      "Episode reward: 2201.2886\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.431877  8.40043   8.4324875 6.956724  8.127986  8.425144 ]\n",
      "Reset environment\n",
      "Episode reward: 1865.7496\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.432727  8.401239  8.433373  6.9577065 8.128738  8.425994 ]\n",
      "Reset environment\n",
      "Episode reward: 1315.6842\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.433172  8.401597  8.433909  6.9582386 8.129161  8.42644  ]\n",
      "Reset environment\n",
      "Episode reward: 1302.4229\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.433898 8.402312 8.434645 6.958994 8.129837 8.427168]\n",
      "Reset environment\n",
      "Episode reward: 1885.4644\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.434849 8.40326  8.435599 6.96006  8.130684 8.42812 ]\n",
      "Reset environment\n",
      "Episode reward: 3230.2175\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.436629 8.405036 8.437375 6.962023 8.132264 8.429898]\n",
      "Reset environment\n",
      "Episode reward: 2076.367\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.437694  8.406099  8.438439  6.963222  8.133207  8.4309635]\n",
      "Reset environment\n",
      "Episode reward: 1767.3042\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.4389925 8.407398  8.439738  6.9646797 8.134358  8.432263 ]\n",
      "Reset environment\n",
      "Episode reward: 3256.4321\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.440771 8.409171 8.441517 6.966648 8.135957 8.434042]\n",
      "Reset environment\n",
      "Episode reward: 2443.8088\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.442103 8.410501 8.442856 6.968103 8.137151 8.435377]\n",
      "Reset environment\n",
      "Episode reward: 2862.199\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.4436035 8.412029  8.444328  6.969767  8.138489  8.436877 ]\n",
      "Reset environment\n",
      "Episode reward: 2312.4685\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.4448185 8.413249  8.445536  6.9711356 8.13957   8.438092 ]\n",
      "Reset environment\n",
      "Episode reward: 2420.88\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.446063  8.4144745 8.446802  6.9725323 8.140666  8.439338 ]\n",
      "Reset environment\n",
      "Episode reward: 3075.7617\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.447724  8.41615   8.44845   6.9743657 8.142154  8.441    ]\n",
      "Reset environment\n",
      "Episode reward: 2475.1206\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.449038  8.417471  8.449758  6.9758296 8.1433115 8.442315 ]\n",
      "Reset environment\n",
      "Episode reward: 5002.21\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.452302 8.420757 8.453009 6.979409 8.14623  8.445582]\n",
      "Reset environment\n",
      "Episode reward: 5083.1836\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.455217  8.423686  8.455911  6.9825897 8.148836  8.448499 ]\n",
      "Reset environment\n",
      "Episode reward: 1677.5383\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.4560585 8.424537  8.456746  6.98353   8.149586  8.449342 ]\n",
      "Reset environment\n",
      "Episode reward: 1859.6508\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.456986  8.425481  8.457658  6.9845877 8.150408  8.450271 ]\n",
      "Reset environment\n",
      "Episode reward: 1706.4197\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.458261  8.426757  8.458935  6.9860187 8.151545  8.451548 ]\n",
      "Reset environment\n",
      "Episode reward: 1386.059\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.458913 8.427409 8.459587 6.986773 8.15212  8.452201]\n",
      "Reset environment\n",
      "Episode reward: 3468.7686\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.460839  8.429345  8.461504  6.9888864 8.153841  8.454126 ]\n",
      "Reset environment\n",
      "Episode reward: 5059.3125\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.463746  8.432257  8.464397  6.9920573 8.156432  8.457035 ]\n",
      "Reset environment\n",
      "Episode reward: 2081.681\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.46482  8.433345 8.465449 6.993265 8.157393 8.45811 ]\n",
      "Reset environment\n",
      "Episode reward: 1972.802\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.465776 8.434271 8.466436 6.994345 8.158242 8.459066]\n",
      "Reset environment\n",
      "Episode reward: 1669.9897\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.466569 8.43503  8.467261 6.995234 8.158951 8.459862]\n",
      "Reset environment\n",
      "Episode reward: 1243.5511\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.467159  8.4356165 8.4678545 6.9959073 8.159474  8.460452 ]\n",
      "Reset environment\n",
      "Episode reward: 2948.6594\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.468763 8.437225 8.469454 6.997673 8.160912 8.462056]\n",
      "Reset environment\n",
      "Episode reward: 4881.5864\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.471563 8.44002  8.472256 7.000708 8.163418 8.464855]\n",
      "Reset environment\n",
      "Episode reward: 2219.1868\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.472734  8.441191  8.473426  7.0020227 8.164456  8.466029 ]\n",
      "Reset environment\n",
      "Episode reward: 2556.6963\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.474052  8.442487  8.474767  7.0034914 8.165622  8.467348 ]\n",
      "Reset environment\n",
      "Episode reward: 2187.9927\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.475104  8.443495  8.47586   7.0046897 8.166555  8.468404 ]\n",
      "Reset environment\n",
      "Episode reward: 1300.1895\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.476115 8.444505 8.47687  7.005853 8.16744  8.469414]\n",
      "Reset environment\n",
      "Episode reward: 1401.9022\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.476748  8.445131  8.477509  7.0065975 8.167992  8.470052 ]\n",
      "Reset environment\n",
      "Episode reward: 2182.0742\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.477874  8.446246  8.478642  7.0078597 8.168997  8.471177 ]\n",
      "Reset environment\n",
      "Episode reward: 2111.6729\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.478965 8.44733  8.479742 7.009073 8.169972 8.472271]\n",
      "Reset environment\n",
      "Episode reward: 4942.5845\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.482212 8.450596 8.482973 7.012632 8.172907 8.475517]\n",
      "Reset environment\n",
      "Episode reward: 458.98068\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.482085  8.450563  8.482757  7.0124755 8.172805  8.4754   ]\n",
      "Reset environment\n",
      "Episode reward: 5728.5557\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.485276 8.453756 8.485949 7.015962 8.175634 8.478593]\n",
      "Reset environment\n",
      "Episode reward: 3473.6018\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.487206  8.455694  8.487865  7.018082  8.1773615 8.480521 ]\n",
      "Reset environment\n",
      "Episode reward: 2032.2828\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.488673 8.457162 8.489326 7.019704 8.178675 8.481987]\n",
      "Reset environment\n",
      "Episode reward: 1790.669\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.489987  8.458476  8.490637  7.0211616 8.179854  8.483298 ]\n",
      "Reset environment\n",
      "Episode reward: 1033.7278\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.4903965 8.45889   8.491042  7.0216694 8.1802    8.48371  ]\n",
      "Reset environment\n",
      "Episode reward: 1370.9362\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.491464  8.459958  8.492107  7.0228615 8.181146  8.4847765]\n",
      "Reset environment\n",
      "Episode reward: 2459.731\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.492644  8.461098  8.49332   7.0242114 8.182186  8.485958 ]\n",
      "Reset environment\n",
      "Episode reward: 2175.946\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.493737 8.462155 8.494443 7.025427 8.183149 8.487052]\n",
      "Reset environment\n",
      "Episode reward: 851.87585\n",
      "Total Steps: 30\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.494063 8.462482 8.494762 7.02583  8.183425 8.487378]\n",
      "Reset environment\n",
      "Episode reward: 2539.567\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.495341  8.463732  8.496069  7.0272613 8.184553  8.488655 ]\n",
      "Reset environment\n",
      "Episode reward: 2534.9297\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.496603 8.464958 8.497357 7.028672 8.185665 8.489916]\n",
      "Reset environment\n",
      "Episode reward: 4424.548\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.499025  8.467393  8.499774  7.0313196 8.187816  8.492338 ]\n",
      "Reset environment\n",
      "Episode reward: -1213.5222\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.497297  8.465425  8.498283  7.0297136 8.186149  8.490616 ]\n",
      "Reset environment\n",
      "Episode reward: 1850.1432\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.498279  8.4664135 8.499258  7.030803  8.187026  8.491599 ]\n",
      "Reset environment\n",
      "Episode reward: 2024.3296\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.499332 8.467468 8.500306 7.031976 8.187958 8.492653]\n",
      "Reset environment\n",
      "Episode reward: 3326.929\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.501127  8.469244  8.502116  7.0339584 8.189549  8.494446 ]\n",
      "Reset environment\n",
      "Episode reward: 2971.2837\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.50272   8.470822  8.50372   7.0357246 8.190959  8.496037 ]\n",
      "Reset environment\n",
      "Episode reward: 2720.46\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.504149  8.472232  8.505166  7.037314  8.1922245 8.497466 ]\n",
      "Reset environment\n",
      "Episode reward: 1842.2871\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.505081 8.473167 8.506094 7.038361 8.193053 8.4984  ]\n",
      "Reset environment\n",
      "Episode reward: 2507.7827\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.506423  8.47451   8.507427  7.0398474 8.194252  8.49974  ]\n",
      "Reset environment\n",
      "Episode reward: 1160.856\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.50691   8.475037  8.507885  7.0403557 8.194694  8.500234 ]\n",
      "Reset environment\n",
      "Episode reward: 2143.5562\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.508448  8.476573  8.509419  7.0420465 8.196072  8.501771 ]\n",
      "Reset environment\n",
      "Episode reward: 1394.6715\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.509527 8.477651 8.510498 7.043243 8.197036 8.50285 ]\n",
      "Reset environment\n",
      "Episode reward: 2057.712\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.510584  8.478713  8.511547  7.0444245 8.197976  8.50391  ]\n",
      "Reset environment\n",
      "Episode reward: 1708.2058\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.511421  8.47956   8.512368  7.0453568 8.198727  8.504749 ]\n",
      "Reset environment\n",
      "Episode reward: 5107.7246\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.514349  8.482482  8.515299  7.0485306 8.201345  8.507678 ]\n",
      "Reset environment\n",
      "Episode reward: -340.79346\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.5136795 8.481776  8.514675  7.047774  8.20077   8.507009 ]\n",
      "Reset environment\n",
      "Episode reward: 2372.2937\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.514812  8.482941  8.515768  7.0490527 8.201755  8.508142 ]\n",
      "Reset environment\n",
      "Episode reward: 3953.5027\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.516943  8.485069  8.5178995 7.051393  8.20365   8.510274 ]\n",
      "Reset environment\n",
      "Episode reward: 3289.3835\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.518729  8.486841  8.519699  7.0533586 8.205237  8.512059 ]\n",
      "Reset environment\n",
      "Episode reward: 3905.7156\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.520898  8.489019  8.521854  7.0557423 8.2071905 8.514231 ]\n",
      "Reset environment\n",
      "Episode reward: 2946.9707\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.522475  8.490629  8.523399  7.0574718 8.208602  8.515809 ]\n",
      "Reset environment\n",
      "Episode reward: 1633.152\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.523286 8.491443 8.524208 7.058387 8.209318 8.51662 ]\n",
      "Reset environment\n",
      "Episode reward: 1988.3568\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.52429   8.492431  8.525222  7.059515  8.2101965 8.517622 ]\n",
      "Reset environment\n",
      "Episode reward: 1932.7032\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.525034  8.493227  8.525925  7.0603423 8.210881  8.5183735]\n",
      "Reset environment\n",
      "Episode reward: 2965.5354\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.526566 8.494783 8.527416 7.062042 8.212237 8.519907]\n",
      "Reset environment\n",
      "Episode reward: 3387.5574\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.528453  8.496663  8.52931   7.0640907 8.213932  8.521794 ]\n",
      "Reset environment\n",
      "Episode reward: 2042.148\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.529355  8.497603  8.530171  7.0651274 8.214726  8.522695 ]\n",
      "Reset environment\n",
      "Episode reward: 1658.5259\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.5301695 8.498424  8.530977  7.0660567 8.215449  8.52351  ]\n",
      "Reset environment\n",
      "Episode reward: 4842.767\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.532891 8.501129 8.533715 7.069037 8.217875 8.526232]\n",
      "Reset environment\n",
      "Episode reward: 1559.83\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.53368   8.501921  8.534498  7.0699277 8.218583  8.52702  ]\n",
      "Reset environment\n",
      "Episode reward: 1755.1974\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.534558 8.502803 8.535376 7.070912 8.219368 8.527902]\n",
      "Reset environment\n",
      "Episode reward: 2061.9717\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.535626  8.503873  8.536441  7.0721064 8.220321  8.52897  ]\n",
      "Reset environment\n",
      "Episode reward: 2985.9946\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.537242  8.505493  8.538048  7.0738797 8.221764  8.530586 ]\n",
      "Reset environment\n",
      "Episode reward: 2296.9429\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.538433 8.506687 8.539239 7.075208 8.222825 8.531778]\n",
      "Reset environment\n",
      "Episode reward: 4090.2656\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.540699  8.508963  8.5414915 7.077677  8.22485   8.534045 ]\n",
      "Reset environment\n",
      "Episode reward: 4881.72\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.543461  8.511738  8.544242  7.0806603 8.227329  8.536809 ]\n",
      "Reset environment\n",
      "Episode reward: 2603.5486\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.544809 8.513106 8.545574 7.082148 8.228538 8.538158]\n",
      "Reset environment\n",
      "Episode reward: 1855.1412\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.545731  8.514013  8.546509  7.0831757 8.229345  8.539081 ]\n",
      "Reset environment\n",
      "Episode reward: 3328.3113\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.547475 8.515758 8.548256 7.085102 8.230903 8.540825]\n",
      "Reset environment\n",
      "Episode reward: 2423.709\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.548753  8.517034  8.549538  7.0865507 8.232029  8.542103 ]\n",
      "Reset environment\n",
      "Episode reward: 1782.5907\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.549625 8.517912 8.550407 7.087543 8.232803 8.542976]\n",
      "Reset environment\n",
      "Episode reward: -397.92532\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.548961  8.517212  8.549768  7.0867457 8.232231  8.542312 ]\n",
      "Reset environment\n",
      "Episode reward: 1662.0043\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.549757  8.518026  8.550545  7.0876484 8.232935  8.543109 ]\n",
      "Reset environment\n",
      "Episode reward: 1827.4446\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.5506735 8.5189705 8.551434  7.088669  8.233757  8.544025 ]\n",
      "Reset environment\n",
      "Episode reward: 4529.7427\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.553224  8.521517  8.553981  7.0914464 8.23603   8.546577 ]\n",
      "Reset environment\n",
      "Episode reward: 1356.818\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.553657 8.521872 8.554497 7.091963 8.236447 8.547015]\n",
      "Reset environment\n",
      "Episode reward: 1381.0884\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.554728 8.522941 8.555564 7.093147 8.237398 8.548086]\n",
      "Reset environment\n",
      "Episode reward: -384.66248\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.55378   8.52212   8.554489  7.0921764 8.236525  8.547145 ]\n",
      "Reset environment\n",
      "Episode reward: 5566.577\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.556969  8.525312  8.557676  7.0956407 8.239396  8.550337 ]\n",
      "Reset environment\n",
      "Episode reward: 2114.5198\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.558077 8.526427 8.55877  7.096864 8.240385 8.551447]\n",
      "Reset environment\n",
      "Episode reward: 1375.9034\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.559144  8.5274935 8.5598345 7.098045  8.241328  8.552515 ]\n",
      "Reset environment\n",
      "Episode reward: 4295.971\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.561474  8.52983   8.5621605 7.100597  8.243408  8.554845 ]\n",
      "Reset environment\n",
      "Episode reward: 1365.5419\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.562045 8.530375 8.562769 7.101197 8.243965 8.555421]\n",
      "Reset environment\n",
      "Episode reward: 3528.803\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.563993  8.532336  8.564709  7.1033163 8.2457    8.55737  ]\n",
      "Reset environment\n",
      "Episode reward: 2129.7883\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.565075 8.533394 8.565804 7.10451  8.24665  8.558448]\n",
      "Reset environment\n",
      "Episode reward: 180.35403\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.564771 8.533058 8.565537 7.104126 8.246436 8.558155]\n",
      "Reset environment\n",
      "Episode reward: 3183.2449\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.566453  8.534717  8.567233  7.1059823 8.247927  8.559834 ]\n",
      "Reset environment\n",
      "Episode reward: 2470.7205\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.567712  8.535955  8.568517  7.1073995 8.249038  8.561093 ]\n",
      "Reset environment\n",
      "Episode reward: 930.7333\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.567637 8.535706 8.568602 7.107525 8.248905 8.561028]\n",
      "Reset environment\n",
      "Episode reward: 5195.7207\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.570586  8.538651  8.571558  7.1107354 8.251552  8.563976 ]\n",
      "Reset environment\n",
      "Episode reward: 1361.9629\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.571634  8.5397    8.57261   7.1119046 8.25248   8.565028 ]\n",
      "Reset environment\n",
      "Episode reward: 5554.793\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.574816 8.542874 8.575795 7.115354 8.255353 8.56821 ]\n",
      "Reset environment\n",
      "Episode reward: 5455.083\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.577807  8.545864  8.578789  7.1186185 8.257999  8.571206 ]\n",
      "Reset environment\n",
      "Episode reward: 2739.864\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.57928   8.547346  8.580251  7.120247  8.259296  8.5726795]\n",
      "Reset environment\n",
      "Episode reward: 2232.6838\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.580431 8.548508 8.581396 7.121528 8.260331 8.573832]\n",
      "Reset environment\n",
      "Episode reward: 1350.0293\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.581455  8.549534  8.58242   7.1226783 8.26124   8.574857 ]\n",
      "Reset environment\n",
      "Episode reward: 2130.8591\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.582556  8.550639  8.5835085 7.123897  8.262217  8.575957 ]\n",
      "Reset environment\n",
      "Episode reward: 3788.898\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.584633  8.552725  8.585577  7.1261744 8.264088  8.578034 ]\n",
      "Reset environment\n",
      "Episode reward: 3021.8577\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.586135  8.5541725 8.587113  7.1278625 8.265422  8.579536 ]\n",
      "Reset environment\n",
      "Episode reward: 2013.4216\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.587063  8.55507   8.58808   7.1289177 8.266246  8.580464 ]\n",
      "Reset environment\n",
      "Episode reward: 5486.7227\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.590171  8.5581875 8.591182  7.1323166 8.26905   8.583573 ]\n",
      "Reset environment\n",
      "Episode reward: 2141.3474\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.591259 8.559279 8.592268 7.133527 8.270027 8.584663]\n",
      "Reset environment\n",
      "Episode reward: 3678.795\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.593294 8.561322 8.594289 7.135743 8.271844 8.586696]\n",
      "Reset environment\n",
      "Episode reward: 2292.28\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.5945015 8.562537  8.595482  7.137076  8.272921  8.587904 ]\n",
      "Reset environment\n",
      "Episode reward: 4759.3486\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.59718  8.565227 8.598157 7.14001  8.27532  8.590585]\n",
      "Reset environment\n",
      "Episode reward: 2098.941\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.598228 8.566269 8.599212 7.141184 8.276241 8.591634]\n",
      "Reset environment\n",
      "Episode reward: 4077.3618\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.600375 8.568415 8.601359 7.143558 8.278134 8.593779]\n",
      "Reset environment\n",
      "Episode reward: 2159.2869\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.601896  8.56994   8.602873  7.1452394 8.279488  8.595299 ]\n",
      "Reset environment\n",
      "Episode reward: 2033.9841\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.6029215 8.57098   8.603886  7.1463795 8.280412  8.596327 ]\n",
      "Reset environment\n",
      "Episode reward: 3029.6775\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.604543 8.572613 8.605483 7.148153 8.281863 8.597948]\n",
      "Reset environment\n",
      "Episode reward: 2752.1965\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.605971  8.57403   8.606917  7.1497436 8.283123  8.599377 ]\n",
      "Reset environment\n",
      "Episode reward: 2800.9182\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.607459  8.575516  8.608401  7.1513934 8.284441  8.600865 ]\n",
      "Reset environment\n",
      "Episode reward: 2816.0205\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.608874  8.576924  8.609832  7.1529875 8.285691  8.602283 ]\n",
      "Reset environment\n",
      "Episode reward: 1352.1943\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.609912  8.577958  8.610867  7.154133  8.2866125 8.603318 ]\n",
      "Reset environment\n",
      "Episode reward: 1451.4539\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.611028 8.579076 8.61198  7.155372 8.287611 8.604435]\n",
      "Reset environment\n",
      "Episode reward: 1871.1489\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.612375  8.580422  8.613323  7.156867  8.288815  8.6057825]\n",
      "Reset environment\n",
      "Episode reward: 1019.2489\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.612567  8.580507  8.613617  7.1571765 8.289001  8.605978 ]\n",
      "Reset environment\n",
      "Episode reward: 3537.8796\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.614509 8.582448 8.615563 7.1593   8.290744 8.607923]\n",
      "Reset environment\n",
      "Episode reward: 2189.4272\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.6156435 8.583562  8.6167145 7.160556  8.29175   8.6090555]\n",
      "Reset environment\n",
      "Episode reward: 2891.1877\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.617205  8.585119  8.6182785 7.1622596 8.293145  8.610618 ]\n",
      "Reset environment\n",
      "Episode reward: 4598.683\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.619758 8.58768  8.620824 7.165059 8.295447 8.613174]\n",
      "Reset environment\n",
      "Episode reward: 2094.4102\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.620723  8.588608  8.621822  7.1661544 8.296297  8.614141 ]\n",
      "Reset environment\n",
      "Episode reward: 1961.0522\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.621614  8.589501  8.622709  7.1671834 8.297069  8.615033 ]\n",
      "Reset environment\n",
      "Episode reward: 2124.2793\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.622688  8.5905905 8.623767  7.1683807 8.298026  8.61611  ]\n",
      "Reset environment\n",
      "Episode reward: 1655.7351\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.623897  8.591802  8.624973  7.1697235 8.299113  8.617318 ]\n",
      "Reset environment\n",
      "Episode reward: 2007.3063\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.6249   8.592803 8.625979 7.170839 8.300011 8.618321]\n",
      "Reset environment\n",
      "Episode reward: 6678.682\n",
      "Total Steps: 229\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.628636 8.596558 8.629682 7.174946 8.303315 8.622057]\n",
      "Reset environment\n",
      "Episode reward: 3197.3223\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.630256  8.598178  8.631298  7.1767445 8.304746  8.623675 ]\n",
      "Reset environment\n",
      "Episode reward: 4112.5913\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.632452  8.600375  8.6334915 7.179166  8.306701  8.625874 ]\n",
      "Reset environment\n",
      "Episode reward: 637.1499\n",
      "Total Steps: 22\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.632646 8.60057  8.633685 7.179426 8.30686  8.626069]\n",
      "Reset environment\n",
      "Episode reward: 2197.17\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.633546  8.60149   8.634571  7.1805053 8.307629  8.626968 ]\n",
      "Reset environment\n",
      "Episode reward: 3123.7056\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.635259 8.603214 8.636277 7.182369 8.309152 8.628684]\n",
      "Reset environment\n",
      "Episode reward: 5662.9976\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.638459  8.606421  8.639471  7.1858487 8.312039  8.63189  ]\n",
      "Reset environment\n",
      "Episode reward: 3169.2659\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.64015   8.608133  8.641143  7.1877036 8.313554  8.633585 ]\n",
      "Reset environment\n",
      "Episode reward: 2841.1199\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.641521 8.609457 8.642563 7.189257 8.314779 8.634954]\n",
      "Reset environment\n",
      "Episode reward: 4475.0874\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.643917  8.611858  8.644947  7.1919007 8.316904  8.63735  ]\n",
      "Reset environment\n",
      "Episode reward: 771.06616\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.644095  8.6121235 8.6450405 7.192102  8.317069  8.63753  ]\n",
      "Reset environment\n",
      "Episode reward: 3100.992\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.64567   8.613733  8.646587  7.1938443 8.3184805 8.639102 ]\n",
      "Reset environment\n",
      "Episode reward: 2949.9468\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.647239 8.615305 8.64815  7.195588 8.319872 8.640673]\n",
      "Reset environment\n",
      "Episode reward: 3061.677\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.648882 8.616958 8.649776 7.19738  8.321344 8.642319]\n",
      "Reset environment\n",
      "Episode reward: 5260.6777\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.652279 8.620338 8.653188 7.201074 8.324398 8.645718]\n",
      "Reset environment\n",
      "Episode reward: 1725.955\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.653127  8.621185  8.654035  7.202024  8.32515   8.6465645]\n",
      "Reset environment\n",
      "Episode reward: 1402.3167\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.654189  8.622251  8.655093  7.2032113 8.326094  8.647628 ]\n",
      "Reset environment\n",
      "Episode reward: 2637.54\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.655529  8.623603  8.656415  7.2047005 8.327288  8.648967 ]\n",
      "Reset environment\n",
      "Episode reward: 1754.9427\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.656299 8.624341 8.657222 7.205592 8.32797  8.649738]\n",
      "Reset environment\n",
      "Episode reward: 2084.8425\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.657306 8.625325 8.658244 7.206725 8.328854 8.650745]\n",
      "Reset environment\n",
      "Episode reward: -231.6148\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.656442  8.624322  8.657509  7.2059026 8.32807   8.649882 ]\n",
      "Reset environment\n",
      "Episode reward: 2738.5972\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.657746  8.625667  8.658765  7.2073708 8.3292265 8.651186 ]\n",
      "Reset environment\n",
      "Episode reward: 2094.612\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.659218  8.627135  8.660236  7.2089796 8.330536  8.6526575]\n",
      "Reset environment\n",
      "Episode reward: 3169.7705\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.660918 8.628832 8.661939 7.210842 8.332061 8.654357]\n",
      "Reset environment\n",
      "Episode reward: 5105.328\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.663675 8.631594 8.664691 7.213873 8.334525 8.657115]\n",
      "Reset environment\n",
      "Episode reward: 3220.941\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.6653185 8.633237  8.666339  7.2156878 8.335976  8.658764 ]\n",
      "Reset environment\n",
      "Episode reward: 4077.2505\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.667548  8.635435  8.668585  7.2181163 8.3379545 8.660995 ]\n",
      "Reset environment\n",
      "Episode reward: 1903.0863\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.668497  8.636378  8.6695385 7.219169  8.338796  8.661943 ]\n",
      "Reset environment\n",
      "Episode reward: 3654.573\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.670479 8.638367 8.671508 7.22134  8.340575 8.663926]\n",
      "Reset environment\n",
      "Episode reward: 1906.1409\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.671427 8.639323 8.672444 7.222402 8.341416 8.664877]\n",
      "Reset environment\n",
      "Episode reward: 3909.5518\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.673594  8.641499  8.674593  7.2247615 8.343359  8.667046 ]\n",
      "Reset environment\n",
      "Episode reward: 1638.9889\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.674398  8.64232   8.6753845 7.2256675 8.344079  8.667854 ]\n",
      "Reset environment\n",
      "Episode reward: 2879.874\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.675726 8.643586 8.676757 7.227175 8.34525  8.669184]\n",
      "Reset environment\n",
      "Episode reward: 2195.8098\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.677278  8.645134  8.6783    7.2288766 8.34663   8.670734 ]\n",
      "Reset environment\n",
      "Episode reward: 2859.819\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.6787615 8.646628  8.679776  7.230508  8.347971  8.672223 ]\n",
      "Reset environment\n",
      "Episode reward: 2389.6826\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.679871 8.647686 8.680922 7.231757 8.34896  8.673333]\n",
      "Reset environment\n",
      "Episode reward: 1295.8506\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.680841 8.648655 8.681886 7.232854 8.349803 8.674299]\n",
      "Reset environment\n",
      "Episode reward: 2188.1814\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.681904 8.64974  8.682932 7.234043 8.350749 8.675362]\n",
      "Reset environment\n",
      "Episode reward: 5268.9404\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.684833  8.6526785 8.685853  7.237263  8.353393  8.678292 ]\n",
      "Reset environment\n",
      "Episode reward: 2768.4778\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.686327  8.654178  8.687333  7.2388906 8.354733  8.679786 ]\n",
      "Reset environment\n",
      "Episode reward: 2010.8278\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.687344  8.655198  8.688347  7.2400236 8.355637  8.680803 ]\n",
      "Reset environment\n",
      "Episode reward: -114.78354\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.686666  8.654365  8.687829  7.2394423 8.355005  8.680131 ]\n",
      "Reset environment\n",
      "Episode reward: 4917.4736\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.689397  8.657106  8.690549  7.2424035 8.357452  8.682864 ]\n",
      "Reset environment\n",
      "Episode reward: 3113.042\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.691004 8.658671 8.692185 7.244172 8.358863 8.684469]\n",
      "Reset environment\n",
      "Episode reward: 2050.9978\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.692051  8.659729  8.69322   7.2453394 8.359787  8.685517 ]\n",
      "Reset environment\n",
      "Episode reward: 3325.9722\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.693841  8.661505  8.695022  7.2473016 8.361385  8.687308 ]\n",
      "Reset environment\n",
      "Episode reward: 3068.543\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.695507  8.663168  8.696691  7.2491264 8.362861  8.688974 ]\n",
      "Reset environment\n",
      "Episode reward: 2039.9221\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.696471  8.664159  8.697623  7.2502103 8.363708  8.689944 ]\n",
      "Reset environment\n",
      "Episode reward: 2918.025\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.697946  8.665633  8.699101  7.2518516 8.365013  8.69142  ]\n",
      "Reset environment\n",
      "Episode reward: 3553.4717\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.699856  8.667534  8.701016  7.2539473 8.366722  8.693331 ]\n",
      "Reset environment\n",
      "Episode reward: 5247.6533\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.702802 8.670483 8.703946 7.257155 8.369357 8.696274]\n",
      "Reset environment\n",
      "Episode reward: 2296.6218\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.703813  8.671445  8.705     7.2583222 8.370258  8.697287 ]\n",
      "Reset environment\n",
      "Episode reward: 2038.6199\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.704766 8.672398 8.705954 7.259401 8.371103 8.698241]\n",
      "Reset environment\n",
      "Episode reward: -381.05792\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.704087  8.671735  8.705252  7.2585087 8.370521  8.697566 ]\n",
      "Reset environment\n",
      "Episode reward: 1314.8462\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.705079 8.672727 8.706242 7.259623 8.3714   8.698558]\n",
      "Reset environment\n",
      "Episode reward: 5679.454\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.708201 8.67585  8.709353 7.263011 8.374187 8.70168 ]\n",
      "Reset environment\n",
      "Episode reward: 2079.1426\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.709646 8.677294 8.710797 7.264606 8.375483 8.703125]\n",
      "Reset environment\n",
      "Episode reward: 4799.515\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.712291 8.679948 8.71343  7.267481 8.377867 8.705774]\n",
      "Reset environment\n",
      "Episode reward: 3657.8567\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.714261 8.681908 8.715404 7.269635 8.379632 8.707742]\n",
      "Reset environment\n",
      "Episode reward: 1999.7009\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.715661  8.68331   8.7168045 7.271181  8.380892  8.709144 ]\n",
      "Reset environment\n",
      "Episode reward: 3423.878\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.717476  8.685139  8.718603  7.2731733 8.382519  8.7109585]\n",
      "Reset environment\n",
      "Episode reward: 1894.0005\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.71835   8.685978  8.719508  7.2741566 8.383291  8.711834 ]\n",
      "Reset environment\n",
      "Episode reward: 2439.638\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.719629  8.687251  8.720784  7.2755632 8.384424  8.713112 ]\n",
      "Reset environment\n",
      "Episode reward: 3786.8843\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.7216835 8.68928   8.722859  7.2778144 8.386248  8.715167 ]\n",
      "Reset environment\n",
      "Episode reward: 2263.5825\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.722784  8.690405  8.723934  7.2790356 8.38723   8.716269 ]\n",
      "Reset environment\n",
      "Episode reward: 628.5028\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.722653 8.690183 8.723888 7.278915 8.387138 8.716141]\n",
      "Reset environment\n",
      "Episode reward: 3297.669\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.724337 8.691864 8.725574 7.280787 8.388618 8.717824]\n",
      "Reset environment\n",
      "Episode reward: 2063.7673\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.725299  8.69279   8.726575  7.2818804 8.389477  8.718787 ]\n",
      "Reset environment\n",
      "Episode reward: 4669.086\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.727797 8.695302 8.729065 7.284609 8.391701 8.721287]\n",
      "Reset environment\n",
      "Episode reward: 4659.366\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.730289  8.697793  8.731555  7.2873135 8.393913  8.723782 ]\n",
      "Reset environment\n",
      "Episode reward: 4040.5476\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.73248   8.7       8.733735  7.2897263 8.395882  8.725975 ]\n",
      "Reset environment\n",
      "Episode reward: 2133.5583\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.73356   8.701066  8.734831  7.2909317 8.396843  8.727055 ]\n",
      "Reset environment\n",
      "Episode reward: 1983.865\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.73452   8.702041  8.73577   7.2919965 8.397702  8.728012 ]\n",
      "Reset environment\n",
      "Episode reward: 3077.483\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.736133  8.703666  8.737368  7.2937727 8.399152  8.729625 ]\n",
      "Reset environment\n",
      "Episode reward: 1972.2748\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.737124 8.704652 8.738368 7.294871 8.400043 8.730617]\n",
      "Reset environment\n",
      "Episode reward: 2347.2314\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.738264  8.705821  8.739469  7.2961535 8.401042  8.731756 ]\n",
      "Reset environment\n",
      "Episode reward: 2369.1428\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.739428 8.707007 8.740609 7.297443 8.402086 8.732919]\n",
      "Reset environment\n",
      "Episode reward: 5940.925\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.7427635 8.710336  8.743943  7.301094  8.405043  8.736255 ]\n",
      "Reset environment\n",
      "Episode reward: 2138.5103\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.743832 8.711421 8.744996 7.302284 8.406006 8.737325]\n",
      "Reset environment\n",
      "Episode reward: 4077.9878\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.746042  8.713641  8.747192  7.3047214 8.408006  8.739536 ]\n",
      "Reset environment\n",
      "Episode reward: 1967.834\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.747431 8.715032 8.748583 7.306245 8.409257 8.740926]\n",
      "Reset environment\n",
      "Episode reward: -401.74908\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.746772 8.71434  8.747948 7.305304 8.408662 8.740264]\n",
      "Reset environment\n",
      "Episode reward: 1892.7424\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.748101  8.715669  8.749271  7.3067884 8.409848  8.741591 ]\n",
      "Reset environment\n",
      "Episode reward: 5387.576\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.751133 8.718694 8.752314 7.310078 8.412573 8.744622]\n",
      "Reset environment\n",
      "Episode reward: 1839.3647\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.752022 8.719583 8.753198 7.311082 8.413359 8.745511]\n",
      "Reset environment\n",
      "Episode reward: 4029.372\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.754214  8.721761  8.755396  7.3134828 8.415323  8.747698 ]\n",
      "Reset environment\n",
      "Episode reward: 4495.73\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.756694  8.724247  8.757862  7.3161874 8.417548  8.750179 ]\n",
      "Reset environment\n",
      "Episode reward: 5072.38\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.759514 8.727064 8.760692 7.319258 8.420073 8.752998]\n",
      "Reset environment\n",
      "Episode reward: 2923.3215\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.760997  8.7285795 8.762146  7.320895  8.42139   8.754484 ]\n",
      "Reset environment\n",
      "Episode reward: 1795.6133\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.761824 8.729438 8.762936 7.321832 8.422118 8.75531 ]\n",
      "Reset environment\n",
      "Episode reward: 2143.7244\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.7633095 8.7309265 8.764423  7.3234754 8.423443  8.756798 ]\n",
      "Reset environment\n",
      "Episode reward: 4752.8906\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.765955 8.733563 8.76707  7.326348 8.425809 8.759441]\n",
      "Reset environment\n",
      "Episode reward: 1745.9288\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.766804 8.734406 8.767925 7.327298 8.426566 8.760291]\n",
      "Reset environment\n",
      "Episode reward: -386.1078\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.766092  8.733663  8.767232  7.3264017 8.425948  8.759579 ]\n",
      "Reset environment\n",
      "Episode reward: 2278.8206\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.767256  8.734808  8.768407  7.3276944 8.426974  8.760739 ]\n",
      "Reset environment\n",
      "Episode reward: 3965.5537\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.769344 8.736901 8.77049  7.329989 8.428823 8.762827]\n",
      "Reset environment\n",
      "Episode reward: 2919.107\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.77081  8.738333 8.77199  7.331619 8.430119 8.764295]\n",
      "Reset environment\n",
      "Episode reward: 2604.455\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.772153 8.739665 8.773337 7.333094 8.431303 8.765637]\n",
      "Reset environment\n",
      "Episode reward: 3418.13\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.773972  8.741491  8.775149  7.3350954 8.432924  8.767456 ]\n",
      "Reset environment\n",
      "Episode reward: 1992.638\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.775343  8.742865  8.776519  7.3366375 8.434138  8.768827 ]\n",
      "Reset environment\n",
      "Episode reward: 324.64395\n",
      "Total Steps: 12\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.77536   8.742881  8.776534  7.3366914 8.434136  8.768843 ]\n",
      "Reset environment\n",
      "Episode reward: 276.83743\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.775268  8.742803  8.776429  7.3364854 8.434077  8.768752 ]\n",
      "Reset environment\n",
      "Episode reward: 5094.052\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.778089  8.74562   8.779258  7.3395643 8.436614  8.771577 ]\n",
      "Reset environment\n",
      "Episode reward: 2944.9077\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.779593  8.747158  8.780731  7.3412366 8.437948  8.773085 ]\n",
      "Reset environment\n",
      "Episode reward: 1973.678\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.78059   8.748164  8.781722  7.3423395 8.438831  8.774081 ]\n",
      "Reset environment\n",
      "Episode reward: 3133.268\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.782242 8.749809 8.783374 7.344148 8.440305 8.775733]\n",
      "Reset environment\n",
      "Episode reward: 3975.3625\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.784384  8.751953  8.785514  7.3465033 8.442232  8.777878 ]\n",
      "Reset environment\n",
      "Episode reward: 5197.57\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.787156  8.754719  8.788285  7.3495502 8.444692  8.780651 ]\n",
      "Reset environment\n",
      "Episode reward: 3624.2522\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.789077 8.756656 8.790193 7.351652 8.446412 8.782574]\n",
      "Reset environment\n",
      "Episode reward: 2000.1252\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.790036  8.757588  8.791173  7.3527203 8.447257  8.783534 ]\n",
      "Reset environment\n",
      "Episode reward: 5267.639\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.792965  8.760522  8.794098  7.3558903 8.449901  8.786462 ]\n",
      "Reset environment\n",
      "Episode reward: -409.34756\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.792027  8.759459  8.793283  7.3549385 8.449033  8.785528 ]\n",
      "Reset environment\n",
      "Episode reward: 1821.8818\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.792916 8.760364 8.794154 7.355934 8.449827 8.78642 ]\n",
      "Reset environment\n",
      "Episode reward: 1237.55\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.793456 8.76089  8.794702 7.356555 8.450305 8.78696 ]\n",
      "Reset environment\n",
      "Episode reward: 3629.8777\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.795383  8.762805  8.796643  7.3586464 8.45201   8.788886 ]\n",
      "Reset environment\n",
      "Episode reward: 2018.7039\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.796391  8.763819  8.7976465 7.3597603 8.452901  8.789896 ]\n",
      "Reset environment\n",
      "Episode reward: 2584.861\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.797679 8.765121 8.798918 7.361213 8.454042 8.791183]\n",
      "Reset environment\n",
      "Episode reward: 4385.3228\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.800053  8.7674885 8.801296  7.3638177 8.456168  8.793556 ]\n",
      "Reset environment\n",
      "Episode reward: 1543.5906\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.800747  8.7682085 8.801966  7.364607  8.45679   8.794254 ]\n",
      "Reset environment\n",
      "Episode reward: 3581.0457\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.802689  8.770153  8.803903  7.3667293 8.458503  8.796195 ]\n",
      "Reset environment\n",
      "Episode reward: 4218.896\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.804945 8.772401 8.806162 7.369213 8.460516 8.798452]\n",
      "Reset environment\n",
      "Episode reward: 1919.2567\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.805895 8.773349 8.80711  7.370275 8.461354 8.799399]\n",
      "Reset environment\n",
      "Episode reward: 2282.2634\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.806971 8.774455 8.808158 7.37149  8.462308 8.80048 ]\n",
      "Reset environment\n",
      "Episode reward: 1885.2927\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.807845  8.775297  8.809061  7.3724756 8.463089  8.801355 ]\n",
      "Reset environment\n",
      "Episode reward: 447.05423\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.807709 8.775103 8.808981 7.372299 8.462997 8.801223]\n",
      "Reset environment\n",
      "Episode reward: 1826.6327\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.808241 8.775714 8.809438 7.373004 8.463469 8.801761]\n",
      "Reset environment\n",
      "Episode reward: 4713.912\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.810727 8.778206 8.811921 7.375733 8.465691 8.804245]\n",
      "Reset environment\n",
      "Episode reward: 3432.34\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.812556 8.780027 8.81375  7.377731 8.467334 8.806071]\n",
      "Reset environment\n",
      "Episode reward: -330.53955\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.811954 8.779415 8.81314  7.377184 8.466806 8.805469]\n",
      "Reset environment\n",
      "Episode reward: 5790.2983\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.815096  8.782557  8.8162775 7.380599  8.469598  8.808609 ]\n",
      "Reset environment\n",
      "Episode reward: 5017.9204\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.817865 8.78532  8.819054 7.383619 8.472079 8.811381]\n",
      "Reset environment\n",
      "Episode reward: 2989.9373\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.819395  8.7868395 8.820592  7.3853145 8.473427  8.812912 ]\n",
      "Reset environment\n",
      "Episode reward: 4627.6997\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.821927  8.789369  8.823113  7.3880677 8.475697  8.815441 ]\n",
      "Reset environment\n",
      "Episode reward: 2353.09\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.823083 8.790506 8.824274 7.389357 8.476712 8.816599]\n",
      "Reset environment\n",
      "Episode reward: 3626.2268\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.825011 8.792443 8.826187 7.391478 8.478431 8.818527]\n",
      "Reset environment\n",
      "Episode reward: 4205.521\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.827281  8.794721  8.828448  7.3939643 8.480463  8.8208   ]\n",
      "Reset environment\n",
      "Episode reward: 1760.322\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.828006  8.795415  8.829205  7.3948126 8.481097  8.8215275]\n",
      "Reset environment\n",
      "Episode reward: 3065.8765\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.82956   8.796965  8.830755  7.3965163 8.48248   8.823081 ]\n",
      "Reset environment\n",
      "Episode reward: 1832.1587\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.830392  8.79782   8.831567  7.3974695 8.483216  8.823915 ]\n",
      "Reset environment\n",
      "Episode reward: 2208.915\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.831493  8.798924  8.832661  7.3987017 8.484194  8.825013 ]\n",
      "Reset environment\n",
      "Episode reward: 6352.172\n",
      "Total Steps: 217\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.835043 8.802475 8.836212 7.402574 8.487379 8.828562]\n",
      "Reset environment\n",
      "Episode reward: 5273.177\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.837963 8.805389 8.839135 7.405747 8.489995 8.83148 ]\n",
      "Reset environment\n",
      "Episode reward: 4938.63\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.8407   8.808124 8.841873 7.408714 8.492442 8.834215]\n",
      "Reset environment\n",
      "Episode reward: 1951.8845\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.841649  8.809078  8.84282   7.4097757 8.493288  8.835167 ]\n",
      "Reset environment\n",
      "Episode reward: 3077.6707\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.843268  8.810683  8.844454  7.4115705 8.494721  8.836788 ]\n",
      "Reset environment\n",
      "Episode reward: 2150.4226\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.844754  8.812164  8.845941  7.4132075 8.496034  8.838274 ]\n",
      "Reset environment\n",
      "Episode reward: 2707.612\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.846132  8.813521  8.847343  7.4147277 8.497264  8.839652 ]\n",
      "Reset environment\n",
      "Episode reward: 2164.2522\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.847217  8.814597  8.8484335 7.4159293 8.498218  8.840736 ]\n",
      "Reset environment\n",
      "Episode reward: 1596.2751\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.847981 8.815376 8.849183 7.416794 8.498894 8.841503]\n",
      "Reset environment\n",
      "Episode reward: 2410.8972\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.849164  8.81658   8.850343  7.4181027 8.499953  8.842685 ]\n",
      "Reset environment\n",
      "Episode reward: 3635.914\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.851109 8.818532 8.852282 7.420239 8.501689 8.84463 ]\n",
      "Reset environment\n",
      "Episode reward: 1759.7253\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.851811  8.819288  8.852935  7.4210763 8.502313  8.845332 ]\n",
      "Reset environment\n",
      "Episode reward: 4197.0537\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.853988  8.821468  8.85511   7.423461  8.5042515 8.847511 ]\n",
      "Reset environment\n",
      "Episode reward: 2235.435\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.855078 8.822589 8.856171 7.424678 8.505221 8.848606]\n",
      "Reset environment\n",
      "Episode reward: 2342.123\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.85611   8.823672  8.857147  7.4258685 8.506121  8.849639 ]\n",
      "Reset environment\n",
      "Episode reward: 2360.8767\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.857318  8.824875  8.858358  7.4271946 8.507202  8.850845 ]\n",
      "Reset environment\n",
      "Episode reward: 2143.1973\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.85878  8.826346 8.85981  7.428814 8.508514 8.852305]\n",
      "Reset environment\n",
      "Episode reward: 2672.7063\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.860174  8.82773   8.861214  7.4303393 8.509762  8.853699 ]\n",
      "Reset environment\n",
      "Episode reward: 3917.5674\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.862257  8.829798  8.863307  7.4326115 8.511623  8.8557825]\n",
      "Reset environment\n",
      "Episode reward: 1407.4023\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.862929  8.830466  8.86398   7.4333706 8.512222  8.856456 ]\n",
      "Reset environment\n",
      "Episode reward: 4300.648\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.86523   8.832774  8.866264  7.4358883 8.514265  8.858754 ]\n",
      "Reset environment\n",
      "Episode reward: 1381.0309\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.866255  8.833799  8.867287  7.4370246 8.515178  8.859782 ]\n",
      "Reset environment\n",
      "Episode reward: 1809.99\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.867118  8.834666  8.868146  7.4379992 8.515945  8.860645 ]\n",
      "Reset environment\n",
      "Episode reward: 2100.189\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.868118 8.835664 8.869143 7.43911  8.516831 8.861648]\n",
      "Reset environment\n",
      "Episode reward: 5718.6587\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.871177  8.838732  8.872195  7.4424405 8.519576  8.864705 ]\n",
      "Reset environment\n",
      "Episode reward: 3141.6807\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.872803 8.840358 8.873824 7.444241 8.521029 8.866334]\n",
      "Reset environment\n",
      "Episode reward: 3706.4583\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.874807  8.842357  8.875834  7.4464235 8.522801  8.8683405]\n",
      "Reset environment\n",
      "Episode reward: 2855.622\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.87621   8.843784  8.877199  7.4479666 8.524038  8.869742 ]\n",
      "Reset environment\n",
      "Episode reward: 1653.4781\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.876959  8.844565  8.87791   7.4488134 8.524702  8.870493 ]\n",
      "Reset environment\n",
      "Episode reward: 4647.1714\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.879504 8.847098 8.880457 7.451577 8.526992 8.873034]\n",
      "Reset environment\n",
      "Episode reward: 2085.6084\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.880426  8.84807   8.881337  7.4526477 8.527803  8.873958 ]\n",
      "Reset environment\n",
      "Episode reward: 3116.0112\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.88206  8.849711 8.882959 7.454437 8.529262 8.875591]\n",
      "Reset environment\n",
      "Episode reward: 2060.9268\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.883473  8.851128  8.884362  7.4560122 8.530511  8.877005 ]\n",
      "Reset environment\n",
      "Episode reward: 5045.4663\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.886223 8.853867 8.887125 7.459002 8.532969 8.879755]\n",
      "Reset environment\n",
      "Episode reward: 2913.7288\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.887692  8.855303  8.888618  7.4606256 8.534273  8.881222 ]\n",
      "Reset environment\n",
      "Episode reward: 1431.301\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.888355  8.855983  8.889266  7.4613748 8.534869  8.881887 ]\n",
      "Reset environment\n",
      "Episode reward: 2271.0742\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.889514  8.857148  8.890423  7.4626617 8.535914  8.883047 ]\n",
      "Reset environment\n",
      "Episode reward: 5027.385\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.892189  8.859821  8.893101  7.4655614 8.538322  8.885723 ]\n",
      "Reset environment\n",
      "Episode reward: 1388.4263\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.893224  8.860856  8.8941345 7.466702  8.539238  8.886757 ]\n",
      "Reset environment\n",
      "Episode reward: 1629.3152\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.893982  8.861615  8.894891  7.467557  8.5399065 8.887514 ]\n",
      "Reset environment\n",
      "Episode reward: -356.50122\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.893359  8.860971  8.894279  7.4669695 8.539356  8.88689  ]\n",
      "Reset environment\n",
      "Episode reward: 3020.241\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.894912  8.862523  8.895831  7.4686804 8.540742  8.888444 ]\n",
      "Reset environment\n",
      "Episode reward: 5512.0874\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.897981  8.865587  8.898905  7.4720016 8.543503  8.891514 ]\n",
      "Reset environment\n",
      "Episode reward: -540.95703\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.89703  8.864549 8.898047 7.470969 8.54263  8.890569]\n",
      "Reset environment\n",
      "Episode reward: 2331.2263\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.898141 8.86569  8.89912  7.47221  8.543609 8.891678]\n",
      "Reset environment\n",
      "Episode reward: 1890.464\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.899068 8.866623 8.900036 7.473251 8.544432 8.892605]\n",
      "Reset environment\n",
      "Episode reward: 1978.1163\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.900422  8.867974  8.901391  7.4747586 8.545637  8.893959 ]\n",
      "Reset environment\n",
      "Episode reward: -356.3003\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.899819 8.867382 8.900768 7.474096 8.545078 8.893356]\n",
      "Reset environment\n",
      "Episode reward: 3382.4172\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.901594 8.869141 8.902551 7.476032 8.546657 8.895131]\n",
      "Reset environment\n",
      "Episode reward: 5674.3735\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.904692  8.872257  8.905637  7.4794183 8.549456  8.8982315]\n",
      "Reset environment\n",
      "Episode reward: 904.1211\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.904897 8.872525 8.905788 7.479627 8.549641 8.898439]\n",
      "Reset environment\n",
      "Episode reward: 2699.761\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.906314  8.873939  8.907208  7.4811788 8.5508995 8.899859 ]\n",
      "Reset environment\n",
      "Episode reward: 3170.2617\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.907975  8.8756075 8.908857  7.483004  8.552394  8.901522 ]\n",
      "Reset environment\n",
      "Episode reward: 4462.053\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.910385 8.878016 8.911267 7.485631 8.554546 8.903932]\n",
      "Reset environment\n",
      "Episode reward: 4272.953\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.9126835 8.880308  8.913569  7.488137  8.556607  8.906231 ]\n",
      "Reset environment\n",
      "Episode reward: 1555.8589\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.913415 8.881057 8.914284 7.488963 8.557263 8.906964]\n",
      "Reset environment\n",
      "Episode reward: 2767.2693\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.914792  8.882409  8.915686  7.4904904 8.558491  8.90834  ]\n",
      "Reset environment\n",
      "Episode reward: 5290.899\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.917584  8.885196  8.918485  7.4935384 8.560975  8.911133 ]\n",
      "Reset environment\n",
      "Episode reward: 2388.278\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.918809 8.886395 8.919723 7.494874 8.562066 8.912354]\n",
      "Reset environment\n",
      "Episode reward: 2017.0879\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.92018   8.887767  8.921098  7.4964104 8.563283  8.913727 ]\n",
      "Reset environment\n",
      "Episode reward: 2911.816\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.921643 8.88924  8.922554 7.498026 8.564582 8.915192]\n",
      "Reset environment\n",
      "Episode reward: 1676.8759\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.922833 8.890431 8.923744 7.499349 8.565631 8.916384]\n",
      "Reset environment\n",
      "Episode reward: 2667.735\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.924156 8.891788 8.925034 7.500813 8.566804 8.91771 ]\n",
      "Reset environment\n",
      "Episode reward: -406.39807\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.923258  8.8910055 8.924014  7.4998393 8.56598   8.91682  ]\n",
      "Reset environment\n",
      "Episode reward: 2812.5742\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.924721  8.8924675 8.925476  7.5014424 8.567275  8.918284 ]\n",
      "Reset environment\n",
      "Episode reward: 2826.4778\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.926186 8.893942 8.926933 7.503046 8.56858  8.919751]\n",
      "Reset environment\n",
      "Episode reward: 2014.615\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.927135  8.894915  8.927855  7.5041084 8.56942   8.9207   ]\n",
      "Reset environment\n",
      "Episode reward: 2991.3467\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.92864  8.896444 8.929326 7.505769 8.570753 8.922206]\n",
      "Reset environment\n",
      "Episode reward: 2319.8608\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.92973  8.897501 8.930446 7.506987 8.571714 8.923298]\n",
      "Reset environment\n",
      "Episode reward: 1361.7471\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.930737 8.898512 8.93145  7.508098 8.572618 8.924304]\n",
      "Reset environment\n",
      "Episode reward: 2816.718\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.932159 8.899953 8.932857 7.509666 8.573887 8.925728]\n",
      "Reset environment\n",
      "Episode reward: 2018.9027\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.933061  8.90081   8.933794  7.5106916 8.574687  8.92663  ]\n",
      "Reset environment\n",
      "Episode reward: 1669.1654\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.933841 8.901589 8.934572 7.51158  8.575371 8.927409]\n",
      "Reset environment\n",
      "Episode reward: 1900.9025\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.934765 8.902508 8.935501 7.512605 8.57619  8.928332]\n",
      "Reset environment\n",
      "Episode reward: 2369.9204\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.935876 8.903659 8.936578 7.513863 8.577177 8.929446]\n",
      "Reset environment\n",
      "Episode reward: 1855.6641\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.936766  8.904527  8.937478  7.5148506 8.577962  8.930337 ]\n",
      "Reset environment\n",
      "Episode reward: 3394.7317\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.938525  8.906266  8.939248  7.5167775 8.579519  8.932094 ]\n",
      "Reset environment\n",
      "Episode reward: 3388.3276\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.940303  8.9080515 8.941007  7.518711  8.581105  8.93387  ]\n",
      "Reset environment\n",
      "Episode reward: 2727.487\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.941647 8.909364 8.942376 7.520198 8.582285 8.935216]\n",
      "Reset environment\n",
      "Episode reward: 1782.4972\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.942498 8.910214 8.943227 7.521145 8.583042 8.936068]\n",
      "Reset environment\n",
      "Episode reward: 1674.0262\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.943245  8.910986  8.943953  7.5219913 8.583698  8.936814 ]\n",
      "Reset environment\n",
      "Episode reward: 1664.6517\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.944065  8.9118    8.944775  7.5229015 8.584428  8.937635 ]\n",
      "Reset environment\n",
      "Episode reward: 3568.1873\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.945934  8.913649  8.946656  7.5249553 8.586086  8.939506 ]\n",
      "Reset environment\n",
      "Episode reward: 2232.244\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.947072  8.914777  8.9478    7.5262165 8.587098  8.940643 ]\n",
      "Reset environment\n",
      "Episode reward: 713.1736\n",
      "Total Steps: 22\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.947319  8.915026  8.948045  7.5265217 8.587311  8.940891 ]\n",
      "Reset environment\n",
      "Episode reward: 1128.1539\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.947811 8.915512 8.948539 7.527083 8.587747 8.941382]\n",
      "Reset environment\n",
      "Episode reward: 1805.0513\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.948646 8.91632  8.949398 7.528026 8.588488 8.942215]\n",
      "Reset environment\n",
      "Episode reward: 4292.6733\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.950962  8.918634  8.9517145 7.530543  8.590555  8.944534 ]\n",
      "Reset environment\n",
      "Episode reward: 3702.027\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.952854 8.920535 8.953601 7.532625 8.592266 8.946427]\n",
      "Reset environment\n",
      "Episode reward: 1978.2986\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.953818  8.921506  8.954551  7.5337057 8.593117  8.9473915]\n",
      "Reset environment\n",
      "Episode reward: 2144.9631\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.954891 8.922576 8.955626 7.534901 8.59407  8.948463]\n",
      "Reset environment\n",
      "Episode reward: 4886.9404\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.957545  8.92522   8.958281  7.5377903 8.596444  8.951116 ]\n",
      "Reset environment\n",
      "Episode reward: 4198.4453\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.959701  8.927376  8.960436  7.5401497 8.5983715 8.953272 ]\n",
      "Reset environment\n",
      "Episode reward: 1304.2421\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.960282  8.927944  8.96103   7.5408063 8.598887  8.953855 ]\n",
      "Reset environment\n",
      "Episode reward: 2301.3538\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.96128   8.928902  8.962061  7.5419683 8.599766  8.954851 ]\n",
      "Reset environment\n",
      "Episode reward: 4018.787\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.963436  8.931065  8.96421   7.5443172 8.601702  8.957007 ]\n",
      "Reset environment\n",
      "Episode reward: 2396.0085\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.964569  8.932216  8.965322  7.5455894 8.602704  8.95814  ]\n",
      "Reset environment\n",
      "Episode reward: 1332.1805\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.965552 8.933201 8.966303 7.546678 8.603569 8.959125]\n",
      "Reset environment\n",
      "Episode reward: 2146.888\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.966422 8.934016 8.967227 7.547691 8.604338 8.959997]\n",
      "Reset environment\n",
      "Episode reward: 2280.9375\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.967605 8.935206 8.968396 7.549011 8.605395 8.961182]\n",
      "Reset environment\n",
      "Episode reward: 2249.4722\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.968672 8.936295 8.969439 7.550196 8.606342 8.96225 ]\n",
      "Reset environment\n",
      "Episode reward: 2036.5592\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.969598  8.937187  8.970386  7.5512414 8.607153  8.963176 ]\n",
      "Reset environment\n",
      "Episode reward: 1605.1488\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.970035 8.937706 8.970751 7.551824 8.607544 8.963621]\n",
      "Reset environment\n",
      "Episode reward: 1334.8077\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.970628 8.938299 8.971343 7.552502 8.608065 8.964216]\n",
      "Reset environment\n",
      "Episode reward: 1362.277\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.971255 8.938911 8.971978 7.553208 8.608626 8.964842]\n",
      "Reset environment\n",
      "Episode reward: 1856.9808\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.972136 8.939811 8.972839 7.554192 8.609411 8.965722]\n",
      "Reset environment\n",
      "Episode reward: 3043.7896\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.973676  8.941375  8.974354  7.5558915 8.610784  8.967265 ]\n",
      "Reset environment\n",
      "Episode reward: 1876.726\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.974582  8.942281  8.975253  7.5568905 8.611587  8.968172 ]\n",
      "Reset environment\n",
      "Episode reward: 5213.592\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.977413 8.945124 8.978079 7.55997  8.614143 8.971004]\n",
      "Reset environment\n",
      "Episode reward: 3088.9963\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.97896  8.946698 8.979599 7.561681 8.61552  8.972551]\n",
      "Reset environment\n",
      "Episode reward: -405.90482\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.978301  8.946001  8.978962  7.5608444 8.614911  8.971895 ]\n",
      "Reset environment\n",
      "Episode reward: 1669.8184\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.979068 8.946789 8.979704 7.56171  8.615593 8.972665]\n",
      "Reset environment\n",
      "Episode reward: 3156.5508\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.9806595 8.94842   8.981254  7.5634584 8.617009  8.974257 ]\n",
      "Reset environment\n",
      "Episode reward: 3392.4038\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.982392  8.95015   8.982991  7.5653825 8.618559  8.97599  ]\n",
      "Reset environment\n",
      "Episode reward: 3611.0305\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.984286 8.952038 8.984885 7.56745  8.620257 8.977883]\n",
      "Reset environment\n",
      "Episode reward: 303.62653\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.983765  8.951634  8.984253  7.5671153 8.619757  8.977371 ]\n",
      "Reset environment\n",
      "Episode reward: 2245.1064\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.984872  8.952741  8.985362  7.568345  8.620738  8.9784775]\n",
      "Reset environment\n",
      "Episode reward: 1340.4194\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.985853  8.953728  8.9863405 7.5694413 8.621606  8.979462 ]\n",
      "Reset environment\n",
      "Episode reward: 2408.3376\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.987013 8.954876 8.987517 7.570735 8.622638 8.980623]\n",
      "Reset environment\n",
      "Episode reward: 2110.7295\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.988438  8.9563    8.988932  7.5723104 8.62389   8.982047 ]\n",
      "Reset environment\n",
      "Episode reward: 3976.821\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.990536 8.958414 8.991017 7.574613 8.625772 8.984148]\n",
      "Reset environment\n",
      "Episode reward: 3528.4368\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.992357  8.960218  8.992854  7.576602  8.6273985 8.985971 ]\n",
      "Reset environment\n",
      "Episode reward: 2378.0334\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.993493  8.96133   8.994009  7.5778675 8.628394  8.987105 ]\n",
      "Reset environment\n",
      "Episode reward: 4065.9524\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.995631  8.963457  8.996157  7.5802217 8.6303    8.989246 ]\n",
      "Reset environment\n",
      "Episode reward: 2232.7195\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.996729 8.96457  8.99724  7.581429 8.631285 8.990347]\n",
      "Reset environment\n",
      "Episode reward: 2906.7017\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [8.998191 8.966054 8.998676 7.583039 8.632591 8.991811]\n",
      "Reset environment\n",
      "Episode reward: 5833.079\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.001378 8.969237 9.001872 7.586513 8.63545  8.994998]\n",
      "Reset environment\n",
      "Episode reward: 4959.482\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.004047  8.971922  9.004524  7.5894203 8.637847  8.997667 ]\n",
      "Reset environment\n",
      "Episode reward: 4632.1025\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.006535 8.974394 9.007015 7.592125 8.640072 9.000153]\n",
      "Reset environment\n",
      "Episode reward: 1152.2732\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.006828  8.974615  9.00738   7.5924716 8.640361  9.000451 ]\n",
      "Reset environment\n",
      "Episode reward: 1816.3903\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.007662 8.975466 9.008195 7.593409 8.641099 9.001287]\n",
      "Reset environment\n",
      "Episode reward: 5016.973\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.010395 8.978192 9.010933 7.596379 8.643549 9.004021]\n",
      "Reset environment\n",
      "Episode reward: 2164.9458\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.011446 8.979255 9.011971 7.597541 8.644493 9.005074]\n",
      "Reset environment\n",
      "Episode reward: 4674.7876\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.013961  8.981767  9.014488  7.6002846 8.646746  9.007588 ]\n",
      "Reset environment\n",
      "Episode reward: 1124.0033\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.014424  8.982224  9.014956  7.6008277 8.647153  9.008052 ]\n",
      "Reset environment\n",
      "Episode reward: 2219.0264\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.015374  8.9832325 9.015865  7.601933  8.647988  9.009    ]\n",
      "Reset environment\n",
      "Episode reward: 2739.7964\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.016716  8.984566  9.017221  7.6034393 8.649177  9.010341 ]\n",
      "Reset environment\n",
      "Episode reward: 2358.569\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.017797  8.985616  9.018339  7.6046576 8.650138  9.011425 ]\n",
      "Reset environment\n",
      "Episode reward: 2047.8575\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.018728 8.986506 9.019304 7.605708 8.65096  9.012357]\n",
      "Reset environment\n",
      "Episode reward: 3569.907\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.020522  8.988301  9.021102  7.6076894 8.652542  9.014153 ]\n",
      "Reset environment\n",
      "Episode reward: 2583.9648\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.0217085 8.989441  9.022321  7.6090164 8.653604  9.01534  ]\n",
      "Reset environment\n",
      "Episode reward: 1863.9143\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.022586  8.990321  9.023207  7.6099997 8.654383  9.016218 ]\n",
      "Reset environment\n",
      "Episode reward: 1358.7388\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.02358   8.991314  9.0241995 7.6111083 8.655262  9.017211 ]\n",
      "Reset environment\n",
      "Episode reward: 2816.2202\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.024906  8.992601  9.025567  7.6125894 8.656456  9.018539 ]\n",
      "Reset environment\n",
      "Episode reward: 3822.3762\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.026937 8.994633 9.027585 7.61481  8.65827  9.020565]\n",
      "Reset environment\n",
      "Episode reward: 5384.4414\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.029846  8.997536  9.030502  7.6179814 8.660882  9.023476 ]\n",
      "Reset environment\n",
      "Episode reward: 3751.442\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.031832  8.999529  9.0324745 7.620141  8.662665  9.025462 ]\n",
      "Reset environment\n",
      "Episode reward: 1988.9906\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.032801 9.000486 9.033445 7.621218 8.663518 9.02643 ]\n",
      "Reset environment\n",
      "Episode reward: 1741.3994\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.033491  9.001228  9.034085  7.6220345 8.664131  9.02712  ]\n",
      "Reset environment\n",
      "Episode reward: 2839.877\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.034937  9.002666  9.035538  7.6236186 8.665416  9.028565 ]\n",
      "Reset environment\n",
      "Episode reward: 2238.9126\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.036029 9.003769 9.036616 7.624824 8.666389 9.029657]\n",
      "Reset environment\n",
      "Episode reward: 582.38306\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.035778 9.00342  9.036455 7.62457  8.666199 9.02941 ]\n",
      "Reset environment\n",
      "Episode reward: 3827.923\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.037692 9.005304 9.038386 7.626687 8.667904 9.031326]\n",
      "Reset environment\n",
      "Episode reward: 4091.978\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.039846 9.007475 9.04052  7.629041 8.669847 9.033481]\n",
      "Reset environment\n",
      "Episode reward: 2848.0657\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.041278 9.008888 9.041962 7.630613 8.671119 9.034911]\n",
      "Reset environment\n",
      "Episode reward: 1841.3501\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.042154 9.009765 9.042832 7.631589 8.671894 9.035785]\n",
      "Reset environment\n",
      "Episode reward: 4579.4316\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.044526 9.012149 9.0452   7.634172 8.674022 9.038157]\n",
      "Reset environment\n",
      "Episode reward: 3372.1177\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.046262  9.013881  9.046945  7.6360774 8.675585  9.039894 ]\n",
      "Reset environment\n",
      "Episode reward: 3143.7053\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.047699  9.01526   9.048435  7.6377044 8.676866  9.041335 ]\n",
      "Reset environment\n",
      "Episode reward: 3167.3882\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.049324  9.016894  9.050053  7.6394944 8.678324  9.042964 ]\n",
      "Reset environment\n",
      "Episode reward: 4642.6987\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.051806  9.019366  9.052542  7.6421905 8.680542  9.045446 ]\n",
      "Reset environment\n",
      "Episode reward: 1768.7308\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.053024  9.020581  9.053755  7.6435356 8.681627  9.046662 ]\n",
      "Reset environment\n",
      "Episode reward: 2955.821\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.05452   9.022084  9.055246  7.6451902 8.682961  9.048164 ]\n",
      "Reset environment\n",
      "Episode reward: 2014.0544\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.055412  9.022948  9.056165  7.6461987 8.683745  9.049056 ]\n",
      "Reset environment\n",
      "Episode reward: 4340.368\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.057727 9.025252 9.058487 7.648728 8.685821 9.051371]\n",
      "Reset environment\n",
      "Episode reward: 1772.8077\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.058415  9.025981  9.059137  7.6495366 8.686416  9.052059 ]\n",
      "Reset environment\n",
      "Episode reward: 2154.5835\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.059421  9.027004  9.060131  7.6506677 8.687311  9.053066 ]\n",
      "Reset environment\n",
      "Episode reward: 3736.1924\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.061297 9.028883 9.062006 7.652723 8.688992 9.054943]\n",
      "Reset environment\n",
      "Episode reward: 4059.761\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.063416  9.030998  9.06413   7.6550403 8.690887  9.05706  ]\n",
      "Reset environment\n",
      "Episode reward: 1999.7054\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.064473  9.032037  9.0652    7.6561756 8.691841  9.058119 ]\n",
      "Reset environment\n",
      "Episode reward: 1722.4244\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.065284  9.032848  9.066011  7.6570954 8.692556  9.058929 ]\n",
      "Reset environment\n",
      "Episode reward: 2101.1921\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.0666895 9.034247  9.067415  7.6586475 8.693805  9.06033  ]\n",
      "Reset environment\n",
      "Episode reward: 5220.5234\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.069479  9.037052  9.070192  7.6616964 8.696311  9.063121 ]\n",
      "Reset environment\n",
      "Episode reward: 2297.937\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.070639  9.0381975 9.071363  7.662984  8.697348  9.064281 ]\n",
      "Reset environment\n",
      "Episode reward: 5817.049\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.073805  9.04137   9.074516  7.6664205 8.700193  9.067446 ]\n",
      "Reset environment\n",
      "Episode reward: 3165.146\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.075447  9.042996  9.076168  7.6681986 8.701651  9.069088 ]\n",
      "Reset environment\n",
      "Episode reward: 2584.6675\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.076745  9.044305  9.0774555 7.669626  8.702802  9.070386 ]\n",
      "Reset environment\n",
      "Episode reward: 5755.32\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.079865 9.047414 9.080556 7.673019 8.705591 9.073499]\n",
      "Reset environment\n",
      "Episode reward: 3181.7632\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.081541 9.049086 9.082233 7.674829 8.707085 9.075172]\n",
      "Reset environment\n",
      "Episode reward: 5318.1577\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.084421  9.051972  9.085099  7.677946  8.709659  9.0780525]\n",
      "Reset environment\n",
      "Episode reward: 2033.0387\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.085401 9.052953 9.086069 7.679031 8.710513 9.079028]\n",
      "Reset environment\n",
      "Episode reward: 3618.4346\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.087167  9.054729  9.08783   7.6809998 8.712101  9.080795 ]\n",
      "Reset environment\n",
      "Episode reward: 235.25766\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.086974 9.054527 9.087653 7.680692 8.711934 9.080609]\n",
      "Reset environment\n",
      "Episode reward: 2352.8008\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.088128  9.055675  9.088811  7.6819663 8.712954  9.081763 ]\n",
      "Reset environment\n",
      "Episode reward: 1328.8425\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.08872   9.056275  9.0893955 7.6826468 8.71348   9.082355 ]\n",
      "Reset environment\n",
      "Episode reward: 3975.2078\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.090804  9.058355  9.091475  7.6849146 8.715359  9.084433 ]\n",
      "Reset environment\n",
      "Episode reward: 2671.0073\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.092072  9.0596285 9.092737  7.6863236 8.716478  9.085701 ]\n",
      "Reset environment\n",
      "Episode reward: 1814.7319\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.093334  9.06089   9.093989  7.6877093 8.717599  9.086961 ]\n",
      "Reset environment\n",
      "Episode reward: 366.1351\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.09309   9.060567  9.093819  7.687417  8.717392  9.0867195]\n",
      "Reset environment\n",
      "Episode reward: 4390.0044\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.095411  9.062889  9.096143  7.6899695 8.719472  9.089041 ]\n",
      "Reset environment\n",
      "Episode reward: 558.9088\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.095327 9.062892 9.095978 7.689842 8.719405 9.088961]\n",
      "Reset environment\n",
      "Episode reward: 2023.8602\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.096306  9.0638685 9.096952  7.6909204 8.720271  9.08994  ]\n",
      "Reset environment\n",
      "Episode reward: 2544.5464\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.097565  9.065135  9.098199  7.6923084 8.721387  9.091202 ]\n",
      "Reset environment\n",
      "Episode reward: 4327.979\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.099753  9.067327  9.100385  7.6947217 8.723324  9.09339  ]\n",
      "Reset environment\n",
      "Episode reward: 4012.044\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.10181  9.069393 9.102436 7.696993 8.725162 9.095449]\n",
      "Reset environment\n",
      "Episode reward: 2785.1648\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.10314  9.070691 9.103788 7.698483 8.726325 9.096778]\n",
      "Reset environment\n",
      "Episode reward: 2542.9736\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.104412 9.07197  9.105047 7.699878 8.727452 9.098052]\n",
      "Reset environment\n",
      "Episode reward: 2566.3542\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.10571   9.073277  9.106337  7.7013044 8.728607  9.099351 ]\n",
      "Reset environment\n",
      "Episode reward: 1997.8888\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.107053  9.074623  9.107677  7.7027974 8.7298    9.100694 ]\n",
      "Reset environment\n",
      "Episode reward: 3419.8633\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.108788 9.076361 9.109398 7.704715 8.731341 9.102428]\n",
      "Reset environment\n",
      "Episode reward: 1443.8737\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.10944   9.077015  9.110048  7.7054434 8.731916  9.103081 ]\n",
      "Reset environment\n",
      "Episode reward: 2864.3809\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.11071   9.078345  9.111288  7.7068977 8.733067  9.104355 ]\n",
      "Reset environment\n",
      "Episode reward: 5357.121\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.113583  9.081216  9.114161  7.7100263 8.735645  9.107228 ]\n",
      "Reset environment\n",
      "Episode reward: 3948.457\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.1156435 9.0832815 9.116212  7.712271  8.737498  9.109286 ]\n",
      "Reset environment\n",
      "Episode reward: 1616.3907\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.11641   9.084064  9.116962  7.7131267 8.738183  9.110054 ]\n",
      "Reset environment\n",
      "Episode reward: 4354.412\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.118716  9.086374  9.1192465 7.7156196 8.740243  9.112362 ]\n",
      "Reset environment\n",
      "Episode reward: 2617.6313\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.119991  9.0876665 9.120505  7.717028  8.741384  9.113638 ]\n",
      "Reset environment\n",
      "Episode reward: 2756.0813\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.12131  9.089013 9.121795 7.718486 8.742551 9.114957]\n",
      "Reset environment\n",
      "Episode reward: 5358.0723\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.124571  9.0923    9.125039  7.7220383 8.745489  9.118225 ]\n",
      "Reset environment\n",
      "Episode reward: 1443.1694\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.125227 9.092958 9.125694 7.722784 8.746067 9.118883]\n",
      "Reset environment\n",
      "Episode reward: 2021.5432\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.126578  9.094311  9.127032  7.7242804 8.747264  9.120231 ]\n",
      "Reset environment\n",
      "Episode reward: 1772.9617\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.127426  9.095163  9.127874  7.7252197 8.748021  9.1210785]\n",
      "Reset environment\n",
      "Episode reward: 1967.3585\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.128749 9.096482 9.129191 7.726683 8.749202 9.122397]\n",
      "Reset environment\n",
      "Episode reward: 2979.1177\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.130186  9.097889  9.130654  7.7282677 8.75049   9.123837 ]\n",
      "Reset environment\n",
      "Episode reward: 1382.427\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.131181 9.098882 9.131646 7.729384 8.751369 9.124831]\n",
      "Reset environment\n",
      "Episode reward: 2047.0153\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.132551  9.100251  9.133017  7.7308955 8.752597  9.126202 ]\n",
      "Reset environment\n",
      "Episode reward: 1447.8398\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.133208  9.100907  9.133671  7.7316422 8.7531805 9.12686  ]\n",
      "Reset environment\n",
      "Episode reward: 1389.4663\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.13369   9.101337  9.1342    7.7322206 8.753599  9.127343 ]\n",
      "Reset environment\n",
      "Episode reward: 2295.336\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.13471   9.102332  9.135252  7.7333713 8.754503  9.128365 ]\n",
      "Reset environment\n",
      "Episode reward: 1379.137\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.135704  9.103327  9.136245  7.7344656 8.755388  9.129358 ]\n",
      "Reset environment\n",
      "Episode reward: 2084.8923\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.136646  9.104296  9.137154  7.7355165 8.756227  9.130301 ]\n",
      "Reset environment\n",
      "Episode reward: 1771.1699\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.137482 9.105136 9.137987 7.736448 8.756972 9.13114 ]\n",
      "Reset environment\n",
      "Episode reward: 1796.6228\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.138345 9.105989 9.138856 7.73741  8.757732 9.132003]\n",
      "Reset environment\n",
      "Episode reward: 3188.119\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.139973  9.107613  9.140489  7.7391925 8.759185  9.133633 ]\n",
      "Reset environment\n",
      "Episode reward: 1954.3936\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.140877 9.108495 9.141415 7.7402   8.759993 9.134537]\n",
      "Reset environment\n",
      "Episode reward: 4724.4307\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.143384 9.111004 9.143915 7.742926 8.762236 9.137042]\n",
      "Reset environment\n",
      "Episode reward: 2690.7153\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.144678  9.112266  9.145234  7.7443595 8.76337   9.138335 ]\n",
      "Reset environment\n",
      "Episode reward: 2904.2224\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.14613  9.113733 9.146663 7.745948 8.764654 9.139787]\n",
      "Reset environment\n",
      "Episode reward: 2932.3762\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.147621 9.115219 9.148165 7.747593 8.765987 9.141277]\n",
      "Reset environment\n",
      "Episode reward: 3620.4807\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.149473  9.117043  9.150045  7.7495947 8.767633  9.14313  ]\n",
      "Reset environment\n",
      "Episode reward: 3422.9927\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.151223  9.118799  9.151791  7.7515173 8.769204  9.144885 ]\n",
      "Reset environment\n",
      "Episode reward: 2249.021\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.152354  9.119936  9.152915  7.7527585 8.770227  9.146016 ]\n",
      "Reset environment\n",
      "Episode reward: 5433.31\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.15568  9.123257 9.15624  7.75636  8.773222 9.149341]\n",
      "Reset environment\n",
      "Episode reward: 2204.3533\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.157156  9.124727  9.157717  7.757969  8.7745285 9.150814 ]\n",
      "Reset environment\n",
      "Episode reward: 5157.9097\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.15989  9.127474 9.160437 7.760942 8.776964 9.15355 ]\n",
      "Reset environment\n",
      "Episode reward: 5022.756\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.162492  9.130074  9.16303   7.7637663 8.779261  9.156152 ]\n",
      "Reset environment\n",
      "Episode reward: 3195.285\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.164027  9.131645  9.164524  7.7654824 8.780635  9.157692 ]\n",
      "Reset environment\n",
      "Episode reward: 2212.4548\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.165051 9.132692 9.165524 7.766622 8.781543 9.158717]\n",
      "Reset environment\n",
      "Episode reward: 6126.5815\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.168278  9.135912  9.168755  7.7701187 8.784409  9.161943 ]\n",
      "Reset environment\n",
      "Episode reward: 2580.626\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.16952   9.13712   9.170014  7.771492  8.7855215 9.163185 ]\n",
      "Reset environment\n",
      "Episode reward: 2716.2354\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.170735  9.138377  9.171197  7.7728577 8.786604  9.164397 ]\n",
      "Reset environment\n",
      "Episode reward: 2235.338\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.171767  9.1394415 9.172199  7.773994  8.787523  9.165433 ]\n",
      "Reset environment\n",
      "Episode reward: 1310.6641\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.171998 9.139606 9.172479 7.774321 8.787738 9.165669]\n",
      "Reset environment\n",
      "Episode reward: 2543.0776\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.173198  9.140809  9.173673  7.7756405 8.78881   9.166871 ]\n",
      "Reset environment\n",
      "Episode reward: 5100.498\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.175927  9.143528  9.176406  7.7785993 8.791255  9.169603 ]\n",
      "Reset environment\n",
      "Episode reward: 2108.2534\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.176958 9.144562 9.177435 7.779762 8.792171 9.170635]\n",
      "Reset environment\n",
      "Episode reward: 3824.5417\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.178934  9.146555  9.179395  7.7819185 8.793935  9.172613 ]\n",
      "Reset environment\n",
      "Episode reward: 2460.8354\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.180187  9.147799  9.180652  7.78329   8.7950535 9.173866 ]\n",
      "Reset environment\n",
      "Episode reward: 406.6462\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.179936 9.147638 9.180307 7.783002 8.794846 9.173618]\n",
      "Reset environment\n",
      "Episode reward: 2392.4504\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.18113   9.148824  9.181516  7.7843404 8.795911  9.174814 ]\n",
      "Reset environment\n",
      "Episode reward: 1236.8158\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.181679  9.149376  9.182059  7.7849636 8.796396  9.175364 ]\n",
      "Reset environment\n",
      "Episode reward: 1826.7053\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.182933  9.150627  9.183312  7.7863426 8.797513  9.1766205]\n",
      "Reset environment\n",
      "Episode reward: 4830.9907\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.185471  9.153177  9.18584   7.7891283 8.799791  9.179159 ]\n",
      "Reset environment\n",
      "Episode reward: 2077.9421\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.186856  9.154561  9.187222  7.7906547 8.801024  9.180546 ]\n",
      "Reset environment\n",
      "Episode reward: 2593.8262\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.188035 9.155773 9.188369 7.791976 8.802067 9.181724]\n",
      "Reset environment\n",
      "Episode reward: 2768.0579\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.189371  9.157137  9.1896715 7.793452  8.80325   9.18306  ]\n",
      "Reset environment\n",
      "Episode reward: 2402.2515\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.190947  9.158707  9.19124   7.7951803 8.804645  9.184629 ]\n",
      "Reset environment\n",
      "Episode reward: 4948.3115\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.193568  9.161334  9.193857  7.7980385 8.806998  9.187253 ]\n",
      "Reset environment\n",
      "Episode reward: 1587.8326\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.194218 9.161996 9.194488 7.798701 8.807592 9.187907]\n",
      "Reset environment\n",
      "Episode reward: 2229.291\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.19523  9.162945 9.195545 7.799807 8.808554 9.18892 ]\n",
      "Reset environment\n",
      "Episode reward: 2753.14\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.19653  9.164207 9.196878 7.801242 8.809721 9.190222]\n",
      "Reset environment\n",
      "Episode reward: 2658.1318\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.197772 9.165415 9.198149 7.802624 8.810831 9.191464]\n",
      "Reset environment\n",
      "Episode reward: 3435.224\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.199514  9.1671505 9.19989   7.8045487 8.812378  9.193205 ]\n",
      "Reset environment\n",
      "Episode reward: 2214.265\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.200571  9.168212  9.200939  7.8057404 8.813316  9.194262 ]\n",
      "Reset environment\n",
      "Episode reward: 2395.445\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.201605  9.169285  9.201926  7.8069158 8.814213  9.195297 ]\n",
      "Reset environment\n",
      "Episode reward: 2245.1646\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.202672  9.170348  9.203     7.8081264 8.8151455 9.196364 ]\n",
      "Reset environment\n",
      "Episode reward: 2902.4177\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.204096  9.171792  9.204418  7.8097086 8.816414  9.197791 ]\n",
      "Reset environment\n",
      "Episode reward: 2199.3503\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.20556   9.173258  9.205876  7.8113112 8.817716  9.199253 ]\n",
      "Reset environment\n",
      "Episode reward: 3833.753\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.207442 9.175151 9.207746 7.813388 8.819401 9.201136]\n",
      "Reset environment\n",
      "Episode reward: 3997.5867\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.209493  9.177194  9.209802  7.8156314 8.821234  9.203186 ]\n",
      "Reset environment\n",
      "Episode reward: 2063.8162\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.210438  9.178156  9.210735  7.8166895 8.82208   9.204132 ]\n",
      "Reset environment\n",
      "Episode reward: 4910.0986\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.213022  9.180735  9.213331  7.8195167 8.824395  9.2067175]\n",
      "Reset environment\n",
      "Episode reward: 1423.4213\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.213625  9.181339  9.213928  7.8202195 8.824917  9.207323 ]\n",
      "Reset environment\n",
      "Episode reward: 5075.7095\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.216315  9.184026  9.216624  7.8231425 8.827311  9.210014 ]\n",
      "Reset environment\n",
      "Episode reward: 2590.655\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.217607  9.185319  9.217912  7.8245664 8.828458  9.211306 ]\n",
      "Reset environment\n",
      "Episode reward: 4252.376\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.219828  9.187549  9.220122  7.8269625 8.830443  9.2135315]\n",
      "Reset environment\n",
      "Episode reward: 5355.478\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.222666 9.190398 9.222951 7.830066 8.832996 9.216375]\n",
      "Reset environment\n",
      "Episode reward: 1902.6718\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.223935 9.19167  9.224222 7.831472 8.83413  9.217651]\n",
      "Reset environment\n",
      "Episode reward: 1450.3909\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.224572 9.192288 9.224878 7.832191 8.834694 9.218288]\n",
      "Reset environment\n",
      "Episode reward: 3481.2488\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.226301 9.194017 9.226602 7.83407  8.83624  9.22002 ]\n",
      "Reset environment\n",
      "Episode reward: 5116.0684\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.229395 9.197119 9.229681 7.837419 8.839033 9.223112]\n",
      "Reset environment\n",
      "Episode reward: 4182.017\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.231581  9.199289  9.231882  7.8397956 8.840989  9.225295 ]\n",
      "Reset environment\n",
      "Episode reward: 4835.9746\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.234132  9.201832  9.234431  7.8425713 8.843263  9.227844 ]\n",
      "Reset environment\n",
      "Episode reward: 1936.6157\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.235023  9.202734  9.235315  7.8435655 8.844062  9.228735 ]\n",
      "Reset environment\n",
      "Episode reward: 2975.8003\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.236514  9.204235  9.236799  7.8452153 8.845385  9.230229 ]\n",
      "Reset environment\n",
      "Episode reward: 740.1234\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.236529  9.20418   9.236873  7.8452044 8.845418  9.2302475]\n",
      "Reset environment\n",
      "Episode reward: 4972.647\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.239188  9.206834  9.239528  7.8480873 8.847803  9.232906 ]\n",
      "Reset environment\n",
      "Episode reward: 2533.213\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.240268  9.207957  9.240566  7.8493104 8.848754  9.233982 ]\n",
      "Reset environment\n",
      "Episode reward: 2190.0479\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.241312 9.20901  9.241604 7.850463 8.849671 9.235028]\n",
      "Reset environment\n",
      "Episode reward: 4787.183\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.243834  9.211538  9.244113  7.8532205 8.851928  9.237546 ]\n",
      "Reset environment\n",
      "Episode reward: 5758.1763\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.246906  9.214605  9.247191  7.8565526 8.854683  9.240618 ]\n",
      "Reset environment\n",
      "Episode reward: 3804.3782\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.248862  9.216568  9.24913   7.8586817 8.856417  9.242573 ]\n",
      "Reset environment\n",
      "Episode reward: 2276.402\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.249935  9.217666  9.250176  7.8598695 8.857382  9.2436495]\n",
      "Reset environment\n",
      "Episode reward: 2988.311\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.251283 9.219053 9.251489 7.861381 8.858592 9.245001]\n",
      "Reset environment\n",
      "Episode reward: 1884.5858\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.25216   9.2199335 9.252358  7.862365  8.85937   9.245877 ]\n",
      "Reset environment\n",
      "Episode reward: 1785.483\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.2529335 9.22068   9.253158  7.8632417 8.86006   9.246653 ]\n",
      "Reset environment\n",
      "Episode reward: 2710.707\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.254271  9.222001  9.254503  7.8647013 8.861243  9.247989 ]\n",
      "Reset environment\n",
      "Episode reward: 2984.8413\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.255762 9.223486 9.255995 7.866339 8.862575 9.249478]\n",
      "Reset environment\n",
      "Episode reward: 1744.685\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.2565565 9.224259  9.256803  7.867216  8.863274  9.250273 ]\n",
      "Reset environment\n",
      "Episode reward: 1611.2341\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.257305  9.225     9.257556  7.8680496 8.863946  9.251021 ]\n",
      "Reset environment\n",
      "Episode reward: 1858.6116\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.258112  9.225787  9.258383  7.8689694 8.864659  9.251828 ]\n",
      "Reset environment\n",
      "Episode reward: 4213.8496\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.260322  9.22799   9.260595  7.8713827 8.866639  9.254038 ]\n",
      "Reset environment\n",
      "Episode reward: 2325.2676\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.261839 9.229511 9.262103 7.87304  8.868002 9.255553]\n",
      "Reset environment\n",
      "Episode reward: 3842.9373\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.263824  9.231495  9.26409   7.8752117 8.869779  9.25754  ]\n",
      "Reset environment\n",
      "Episode reward: 2197.9814\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.26482   9.232518  9.265062  7.8763175 8.87066   9.258535 ]\n",
      "Reset environment\n",
      "Episode reward: 1136.2881\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.265296  9.23299   9.265542  7.8768663 8.871076  9.259014 ]\n",
      "Reset environment\n",
      "Episode reward: 2291.6003\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.266255  9.234003  9.266447  7.8779774 8.871927  9.259972 ]\n",
      "Reset environment\n",
      "Episode reward: 4725.808\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.268733  9.236478  9.268928  7.8806705 8.87414   9.262448 ]\n",
      "Reset environment\n",
      "Episode reward: 2490.3716\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.269914 9.23768  9.270082 7.881983 8.875185 9.263625]\n",
      "Reset environment\n",
      "Episode reward: 3643.5012\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.271754  9.239533  9.2719145 7.884002  8.876819  9.265466 ]\n",
      "Reset environment\n",
      "Episode reward: 2225.9404\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.2731905 9.240969  9.273349  7.8855886 8.878093  9.266901 ]\n",
      "Reset environment\n",
      "Episode reward: 3033.1655\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.274709  9.242476  9.274881  7.8872595 8.879441  9.268419 ]\n",
      "Reset environment\n",
      "Episode reward: 5922.615\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.277876  9.245643  9.278041  7.8906946 8.882292  9.271587 ]\n",
      "Reset environment\n",
      "Episode reward: 2951.0742\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.279352  9.247128  9.2795105 7.892314  8.883617  9.273067 ]\n",
      "Reset environment\n",
      "Episode reward: 6598.8696\n",
      "Total Steps: 226\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.282879  9.250649  9.283041  7.8961544 8.886772  9.276592 ]\n",
      "Reset environment\n",
      "Episode reward: 4984.9536\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.2858715 9.253652  9.286024  7.899423  8.889446  9.279589 ]\n",
      "Reset environment\n",
      "Episode reward: 2335.917\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.286942 9.254751 9.28706  7.900621 8.890399 9.280661]\n",
      "Reset environment\n",
      "Episode reward: 4733.5396\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.289322 9.257132 9.289442 7.903228 8.892507 9.28304 ]\n",
      "Reset environment\n",
      "Episode reward: 354.65775\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.288937  9.25662   9.289179  7.9029922 8.892109  9.282658 ]\n",
      "Reset environment\n",
      "Episode reward: 2486.5981\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.290146 9.257844 9.290369 7.904317 8.893188 9.283867]\n",
      "Reset environment\n",
      "Episode reward: 1471.5009\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.290819  9.258522  9.291035  7.9050736 8.89379   9.284542 ]\n",
      "Reset environment\n",
      "Episode reward: 5369.231\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.294047 9.261769 9.294249 7.908585 8.89669  9.287772]\n",
      "Reset environment\n",
      "Episode reward: 5657.2603\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.296944  9.26466   9.297145  7.9117556 8.899255  9.290672 ]\n",
      "Reset environment\n",
      "Episode reward: 5214.903\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.300077  9.267807  9.300272  7.9151654 8.902067  9.293807 ]\n",
      "Reset environment\n",
      "Episode reward: 1657.7926\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.301218  9.268939  9.301407  7.9164186 8.903071  9.294946 ]\n",
      "Reset environment\n",
      "Episode reward: 3724.7073\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.303114  9.270824  9.303314  7.9184823 8.904758  9.296842 ]\n",
      "Reset environment\n",
      "Episode reward: 901.08215\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.3034525 9.271161  9.303655  7.9188833 8.905052  9.29718  ]\n",
      "Reset environment\n",
      "Episode reward: 2004.2068\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.304797 9.272506 9.304988 7.920354 8.906251 9.298525]\n",
      "Reset environment\n",
      "Episode reward: -374.05676\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.304008  9.271776  9.304138  7.9195714 8.905538  9.297737 ]\n",
      "Reset environment\n",
      "Episode reward: 2130.3137\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.305403 9.273171 9.305532 7.9211   8.906786 9.299131]\n",
      "Reset environment\n",
      "Episode reward: 979.3274\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.305773  9.273551  9.305889  7.9215407 8.907106  9.299502 ]\n",
      "Reset environment\n",
      "Episode reward: 2568.2283\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.307016  9.274804  9.307124  7.9229083 8.908204  9.300749 ]\n",
      "Reset environment\n",
      "Episode reward: 2724.566\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.308374  9.2761545 9.308486  7.9243846 8.909423  9.302103 ]\n",
      "Reset environment\n",
      "Episode reward: 2321.8633\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.309379 9.277113 9.309523 7.925516 8.910316 9.303105]\n",
      "Reset environment\n",
      "Episode reward: 1917.8254\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.310249  9.277982  9.310391  7.9265037 8.911076  9.303976 ]\n",
      "Reset environment\n",
      "Episode reward: 2114.799\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.311526  9.279259  9.311659  7.9279165 8.912202  9.305249 ]\n",
      "Reset environment\n",
      "Episode reward: 1773.8539\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.31233   9.280081  9.312441  7.9288106 8.912919  9.306054 ]\n",
      "Reset environment\n",
      "Episode reward: 1664.7496\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.313087 9.280822 9.313212 7.92965  8.913598 9.30681 ]\n",
      "Reset environment\n",
      "Episode reward: 5655.785\n",
      "Total Steps: 223\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.3164835 9.284209  9.316616  7.933324  8.916645  9.310206 ]\n",
      "Reset environment\n",
      "Episode reward: 3161.1582\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.318049 9.285763 9.318197 7.935033 8.91803  9.31177 ]\n",
      "Reset environment\n",
      "Episode reward: 4007.365\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.320107  9.287838  9.320241  7.937279  8.9198675 9.313828 ]\n",
      "Reset environment\n",
      "Episode reward: 2010.4801\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.321024 9.288761 9.321147 7.938306 8.92068  9.314747]\n",
      "Reset environment\n",
      "Episode reward: 2048.252\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.322     9.28971   9.322137  7.9393916 8.921539  9.315721 ]\n",
      "Reset environment\n",
      "Episode reward: 2030.5945\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.322934 9.290646 9.323071 7.940458 8.922363 9.316656]\n",
      "Reset environment\n",
      "Episode reward: 2309.663\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.324019  9.291746  9.324144  7.9416595 8.923337  9.317741 ]\n",
      "Reset environment\n",
      "Episode reward: 1909.8513\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.324905  9.292626  9.325023  7.9426436 8.924117  9.318623 ]\n",
      "Reset environment\n",
      "Episode reward: 2050.7449\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.325755  9.293532  9.32583   7.9436274 8.924874  9.319475 ]\n",
      "Reset environment\n",
      "Episode reward: 1367.6182\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.326306 9.294056 9.326406 7.944259 8.925363 9.320026]\n",
      "Reset environment\n",
      "Episode reward: 2443.491\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.327478  9.295236  9.327567  7.9455557 8.926406  9.3211975]\n",
      "Reset environment\n",
      "Episode reward: 1644.3405\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.328238 9.296006 9.328318 7.946404 8.927084 9.321957]\n",
      "Reset environment\n",
      "Episode reward: 2205.905\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.3292465 9.297043  9.329297  7.9475384 8.927977  9.322968 ]\n",
      "Reset environment\n",
      "Episode reward: 1727.1323\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.329909  9.297653  9.330005  7.9483175 8.928562  9.32363  ]\n",
      "Reset environment\n",
      "Episode reward: 3748.113\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.331735  9.2994795 9.331828  7.9503236 8.930188  9.325456 ]\n",
      "Reset environment\n",
      "Episode reward: 3570.137\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.333549  9.3012705 9.333657  7.952298  8.931802  9.327266 ]\n",
      "Reset environment\n",
      "Episode reward: 1602.6896\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.334278  9.302014  9.3343725 7.953127  8.932453  9.327999 ]\n",
      "Reset environment\n",
      "Episode reward: 5487.43\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.337176  9.304905  9.3372755 7.956276  8.935041  9.330896 ]\n",
      "Reset environment\n",
      "Episode reward: 2608.2236\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.338407  9.3061495 9.338493  7.95765   8.936134  9.3321295]\n",
      "Reset environment\n",
      "Episode reward: 4716.723\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.340857  9.308606  9.340935  7.9603186 8.938333  9.334581 ]\n",
      "Reset environment\n",
      "Episode reward: 1084.8354\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.341243 9.308961 9.341349 7.960687 8.938719 9.334967]\n",
      "Reset environment\n",
      "Episode reward: 2093.418\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.342631 9.310349 9.342731 7.962206 8.939951 9.336351]\n",
      "Reset environment\n",
      "Episode reward: 2786.367\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.34399  9.311704 9.344093 7.963702 8.941164 9.337712]\n",
      "Reset environment\n",
      "Episode reward: 3690.9248\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.346078  9.313777  9.346187  7.9659467 8.943062  9.339797 ]\n",
      "Reset environment\n",
      "Episode reward: 2217.312\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.34713   9.314814  9.347247  7.9671235 8.943991  9.34085  ]\n",
      "Reset environment\n",
      "Episode reward: 3001.7893\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.348349  9.316073  9.348435  7.9685183 8.945086  9.3420725]\n",
      "Reset environment\n",
      "Episode reward: 5540.557\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.3512745 9.318998  9.351358  7.971677  8.947704  9.344995 ]\n",
      "Reset environment\n",
      "Episode reward: -369.46692\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.35047   9.318236  9.350505  7.9708753 8.946964  9.344192 ]\n",
      "Reset environment\n",
      "Episode reward: 2716.7595\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.35171  9.31945  9.351774 7.972255 8.948072 9.345433]\n",
      "Reset environment\n",
      "Episode reward: 4211.732\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.353777 9.321525 9.353835 7.974513 8.949925 9.347502]\n",
      "Reset environment\n",
      "Episode reward: 1836.4814\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.354609  9.322364  9.354652  7.9754453 8.950663  9.348332 ]\n",
      "Reset environment\n",
      "Episode reward: 3787.1462\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.356524  9.3242855 9.356552  7.9775486 8.95238   9.350243 ]\n",
      "Reset environment\n",
      "Episode reward: 2473.3174\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.357704 9.325458 9.357732 7.978846 8.953425 9.351423]\n",
      "Reset environment\n",
      "Episode reward: 3687.9653\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.359526 9.327268 9.359567 7.980848 8.955042 9.353246]\n",
      "Reset environment\n",
      "Episode reward: 1378.7278\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.360506  9.32824   9.360542  7.9819226 8.955911  9.354222 ]\n",
      "Reset environment\n",
      "Episode reward: 2019.9589\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.361334 9.329022 9.3614   7.982862 8.956636 9.35505 ]\n",
      "Reset environment\n",
      "Episode reward: 2319.1409\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.362327  9.32998   9.362425  7.9839845 8.957514  9.356043 ]\n",
      "Reset environment\n",
      "Episode reward: 3315.3533\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.36391   9.331567  9.364011  7.9857364 8.958924  9.357628 ]\n",
      "Reset environment\n",
      "Episode reward: 2454.307\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.365038 9.332668 9.365154 7.986981 8.959938 9.358755]\n",
      "Reset environment\n",
      "Episode reward: 5178.229\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.367792 9.335413 9.367905 7.989953 8.962397 9.361509]\n",
      "Reset environment\n",
      "Episode reward: 1761.3247\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.368545  9.336137  9.368684  7.9908004 8.96306   9.362261 ]\n",
      "Reset environment\n",
      "Episode reward: 129.76624\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.368274 9.33588  9.368385 7.990388 8.962836 9.361992]\n",
      "Reset environment\n",
      "Episode reward: 2732.0\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.369536  9.337113  9.369673  7.9917893 8.963947  9.363252 ]\n",
      "Reset environment\n",
      "Episode reward: 5139.914\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.372225 9.339802 9.372357 7.994698 8.966346 9.365939]\n",
      "Reset environment\n",
      "Episode reward: 2057.85\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.373205  9.340784  9.373329  7.9957857 8.967218  9.366919 ]\n",
      "Reset environment\n",
      "Episode reward: 2589.9282\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.374441 9.342016 9.374567 7.997149 8.968319 9.368156]\n",
      "Reset environment\n",
      "Episode reward: 4636.297\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.376833 9.344426 9.376944 7.999725 8.970458 9.370553]\n",
      "Reset environment\n",
      "Episode reward: 4547.549\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.379165 9.346756 9.379263 8.002249 8.972532 9.372884]\n",
      "Reset environment\n",
      "Episode reward: 1853.8453\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.380038  9.347625  9.38013   8.0032215 8.973306  9.373757 ]\n",
      "Reset environment\n",
      "Episode reward: 3731.4216\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.381836 9.349425 9.38192  8.005202 8.974912 9.375556]\n",
      "Reset environment\n",
      "Episode reward: 4991.653\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.38443  9.352005 9.384526 8.008022 8.977248 9.378148]\n",
      "Reset environment\n",
      "Episode reward: 5248.6416\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.387146 9.354725 9.387225 8.010976 8.979682 9.380862]\n",
      "Reset environment\n",
      "Episode reward: 2138.1624\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.387909 9.355539 9.387947 8.011893 8.980356 9.381628]\n",
      "Reset environment\n",
      "Episode reward: 1852.0319\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.388753 9.356398 9.388773 8.012823 8.981105 9.382471]\n",
      "Reset environment\n",
      "Episode reward: 2078.4312\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.390098 9.357739 9.39012  8.014322 8.982305 9.383816]\n",
      "Reset environment\n",
      "Episode reward: 2770.774\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.391294 9.358888 9.391355 8.015675 8.983367 9.385011]\n",
      "Reset environment\n",
      "Episode reward: 3883.096\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.393238 9.360829 9.3933   8.01783  8.985106 9.386955]\n",
      "Reset environment\n",
      "Episode reward: 2069.6235\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.394231 9.361832 9.394287 8.018932 8.986004 9.387951]\n",
      "Reset environment\n",
      "Episode reward: 2069.6973\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.395178 9.362787 9.395221 8.019991 8.986852 9.388902]\n",
      "Reset environment\n",
      "Episode reward: 1193.507\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.395622 9.363234 9.395663 8.020526 8.987223 9.389346]\n",
      "Reset environment\n",
      "Episode reward: 1055.2241\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.395791  9.363338  9.395891  8.0206995 8.987421  9.389519 ]\n",
      "Reset environment\n",
      "Episode reward: 1846.114\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.397006 9.364556 9.397103 8.02205  8.988493 9.390735]\n",
      "Reset environment\n",
      "Episode reward: 1329.0605\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.397573 9.36513  9.397664 8.022703 8.988991 9.391302]\n",
      "Reset environment\n",
      "Episode reward: 4613.4673\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.399948 9.367517 9.400028 8.025309 8.991125 9.39368 ]\n",
      "Reset environment\n",
      "Episode reward: 2142.5186\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.400948 9.368492 9.401052 8.026417 8.992019 9.394681]\n",
      "Reset environment\n",
      "Episode reward: 5378.7764\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.403762  9.3713045 9.40387   8.029465  8.994532  9.397498 ]\n",
      "Reset environment\n",
      "Episode reward: 4773.233\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.406219 9.373755 9.406334 8.03214  8.996728 9.399956]\n",
      "Reset environment\n",
      "Episode reward: 2145.062\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.407246 9.374794 9.407352 8.033286 8.997647 9.400983]\n",
      "Reset environment\n",
      "Episode reward: 2140.8323\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.40818  9.375757 9.408255 8.034329 8.998475 9.40192 ]\n",
      "Reset environment\n",
      "Episode reward: 1640.9939\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.408909 9.376469 9.408993 8.035139 8.999118 9.402648]\n",
      "Reset environment\n",
      "Episode reward: 2157.9287\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.409937 9.377508 9.410011 8.036291 9.000033 9.403679]\n",
      "Reset environment\n",
      "Episode reward: 1993.8591\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.410677 9.378294 9.410716 8.037172 9.00069  9.40442 ]\n",
      "Reset environment\n",
      "Episode reward: 332.86185\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.4105015 9.378166  9.410493  8.036886  9.000528  9.404254 ]\n",
      "Reset environment\n",
      "Episode reward: 4813.038\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.412991 9.380647 9.412986 8.039599 9.002766 9.406746]\n",
      "Reset environment\n",
      "Episode reward: 4997.827\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.415553 9.383221 9.415533 8.042396 9.005069 9.409309]\n",
      "Reset environment\n",
      "Episode reward: 2527.1067\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.416692 9.384333 9.416701 8.043667 9.006071 9.410448]\n",
      "Reset environment\n",
      "Episode reward: 2564.826\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.417942 9.385579 9.417955 8.045032 9.007204 9.411697]\n",
      "Reset environment\n",
      "Episode reward: 3230.0857\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.419477  9.3871355 9.419469  8.0467415 9.008566  9.41324  ]\n",
      "Reset environment\n",
      "Episode reward: 4918.8003\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.421951 9.389608 9.42194  8.049414 9.010765 9.415712]\n",
      "Reset environment\n",
      "Episode reward: 1512.396\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.4226265 9.390277  9.422616  8.050169  9.011357  9.4163885]\n",
      "Reset environment\n",
      "Episode reward: 2136.851\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.423529  9.39114   9.4235525 8.051186  9.012162  9.41729  ]\n",
      "Reset environment\n",
      "Episode reward: 640.4103\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.423444 9.39098  9.423525 8.051049 9.012106 9.417209]\n",
      "Reset environment\n",
      "Episode reward: 2293.2898\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.42451  9.392032 9.424606 8.052238 9.013045 9.418277]\n",
      "Reset environment\n",
      "Episode reward: 2080.1504\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.425502 9.393021 9.4256   8.053341 9.013926 9.419269]\n",
      "Reset environment\n",
      "Episode reward: 2958.127\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.42694   9.394471  9.427019  8.054926  9.0152025 9.420707 ]\n",
      "Reset environment\n",
      "Episode reward: 2220.0503\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.427917 9.39548  9.427956 8.056032 9.016066 9.421684]\n",
      "Reset environment\n",
      "Episode reward: 1759.3522\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.428711 9.39629  9.428734 8.05692  9.016777 9.422479]\n",
      "Reset environment\n",
      "Episode reward: 5357.916\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.431491 9.399062 9.431512 8.059936 9.019256 9.425251]\n",
      "Reset environment\n",
      "Episode reward: 1379.3676\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.432466  9.40004   9.432487  8.0610075 9.020114  9.426228 ]\n",
      "Reset environment\n",
      "Episode reward: 2173.5852\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.433471 9.401034 9.433503 8.062129 9.021006 9.427233]\n",
      "Reset environment\n",
      "Episode reward: 2502.349\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.434684 9.402246 9.434718 8.063461 9.022087 9.428448]\n",
      "Reset environment\n",
      "Episode reward: 3300.722\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.436284 9.403842 9.436322 8.065227 9.023523 9.430049]\n",
      "Reset environment\n",
      "Episode reward: 3840.1934\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.438151 9.405708 9.438188 8.067273 9.025181 9.431917]\n",
      "Reset environment\n",
      "Episode reward: 2359.4446\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.439318 9.406875 9.439349 8.06857  9.026216 9.433085]\n",
      "Reset environment\n",
      "Episode reward: 1686.0659\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.440101 9.407659 9.440129 8.069438 9.02691  9.433871]\n",
      "Reset environment\n",
      "Episode reward: 2233.2578\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.441054 9.40865  9.441029 8.07046  9.02777  9.434826]\n",
      "Reset environment\n",
      "Episode reward: 4476.146\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.443323 9.410923 9.443278 8.072923 9.029786 9.437095]\n",
      "Reset environment\n",
      "Episode reward: 1859.846\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.444545 9.412146 9.444502 8.074272 9.03088  9.438317]\n",
      "Reset environment\n",
      "Episode reward: 2324.4568\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.445632 9.413217 9.445597 8.075473 9.031841 9.439402]\n",
      "Reset environment\n",
      "Episode reward: 3011.3965\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.447103 9.414694 9.447062 8.077092 9.033153 9.440874]\n",
      "Reset environment\n",
      "Episode reward: 2935.321\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.448467 9.416027 9.448455 8.0786   9.034372 9.442235]\n",
      "Reset environment\n",
      "Episode reward: 1707.6011\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.44962  9.417176 9.449604 8.079863 9.035387 9.443386]\n",
      "Reset environment\n",
      "Episode reward: 2897.0889\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.451022 9.418571 9.451009 8.081402 9.036632 9.444787]\n",
      "Reset environment\n",
      "Episode reward: 4696.8267\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.453422 9.420963 9.453394 8.084018 9.038782 9.447177]\n",
      "Reset environment\n",
      "Episode reward: 3192.3342\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.45494  9.422464 9.45492  8.085693 9.040121 9.448693]\n",
      "Reset environment\n",
      "Episode reward: 2032.8003\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.456267 9.423791 9.45624  8.087157 9.041296 9.45002 ]\n",
      "Reset environment\n",
      "Episode reward: 2247.63\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.45732  9.424834 9.457296 8.088319 9.042236 9.451073]\n",
      "Reset environment\n",
      "Episode reward: 2280.3147\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.458786 9.4263   9.458756 8.089932 9.043539 9.452537]\n",
      "Reset environment\n",
      "Episode reward: 2808.4019\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.460129 9.427651 9.460089 8.091421 9.044742 9.453881]\n",
      "Reset environment\n",
      "Episode reward: 2046.5024\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.461467 9.428991 9.461427 8.092893 9.045927 9.455218]\n",
      "Reset environment\n",
      "Episode reward: 3805.6423\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.463366 9.430882 9.46333  8.094969 9.047613 9.457114]\n",
      "Reset environment\n",
      "Episode reward: 5809.0176\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.466408 9.433912 9.466368 8.098263 9.050339 9.460154]\n",
      "Reset environment\n",
      "Episode reward: 4022.3687\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.468418 9.435925 9.468372 8.100462 9.052132 9.462165]\n",
      "Reset environment\n",
      "Episode reward: 1601.3142\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.469159 9.436663 9.469112 8.101282 9.05279  9.462908]\n",
      "Reset environment\n",
      "Episode reward: 1357.483\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.470106 9.43761  9.470055 8.102329 9.053621 9.463855]\n",
      "Reset environment\n",
      "Episode reward: 5827.655\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.47314  9.440633 9.473094 8.105622 9.056352 9.466885]\n",
      "Reset environment\n",
      "Episode reward: 2170.734\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.474079 9.441603 9.474001 8.106681 9.057189 9.467825]\n",
      "Reset environment\n",
      "Episode reward: 2226.9211\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.474888 9.44235  9.474855 8.107642 9.057892 9.468633]\n",
      "Reset environment\n",
      "Episode reward: 4947.2104\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.477439 9.444908 9.477398 8.110405 9.060182 9.471185]\n",
      "Reset environment\n",
      "Episode reward: 3874.525\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.479387 9.446856 9.479342 8.112534 9.061912 9.473128]\n",
      "Reset environment\n",
      "Episode reward: 5665.17\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.482303  9.4497795 9.48225   8.115722  9.064521  9.476041 ]\n",
      "Reset environment\n",
      "Episode reward: 5348.5747\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.485119 9.452583 9.485065 8.118753 9.067041 9.47885 ]\n",
      "Reset environment\n",
      "Episode reward: 2755.1453\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.486354 9.453849 9.486266 8.120131 9.068139 9.480086]\n",
      "Reset environment\n",
      "Episode reward: 3271.2437\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.487968  9.455454  9.487885  8.1219015 9.06959   9.4817   ]\n",
      "Reset environment\n",
      "Episode reward: 2523.392\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.489043 9.456565 9.488924 8.123107 9.07055  9.482776]\n",
      "Reset environment\n",
      "Episode reward: 3502.1147\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.490767 9.458281 9.490643 8.124995 9.072086 9.484495]\n",
      "Reset environment\n",
      "Episode reward: 1640.1285\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.491349 9.458904 9.491176 8.125686 9.072597 9.485081]\n",
      "Reset environment\n",
      "Episode reward: 2691.2659\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.492641 9.460201 9.492457 8.127118 9.073757 9.486374]\n",
      "Reset environment\n",
      "Episode reward: 5442.7993\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.495441  9.462997  9.495263  8.130174  9.0762615 9.489174 ]\n",
      "Reset environment\n",
      "Episode reward: 1606.7838\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.496143 9.463697 9.495967 8.130964 9.076878 9.489877]\n",
      "Reset environment\n",
      "Episode reward: 3222.307\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.497645 9.465198 9.49747  8.132628 9.078215 9.491379]\n",
      "Reset environment\n",
      "Episode reward: 1766.2958\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.498438 9.466008 9.498248 8.133509 9.078922 9.492174]\n",
      "Reset environment\n",
      "Episode reward: 4281.557\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.500593 9.468156 9.500407 8.135861 9.08084  9.494327]\n",
      "Reset environment\n",
      "Episode reward: 1484.8743\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.501186 9.468719 9.501027 8.136455 9.081404 9.49492 ]\n",
      "Reset environment\n",
      "Episode reward: 2989.014\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.502663 9.4702   9.502495 8.138066 9.082719 9.496397]\n",
      "Reset environment\n",
      "Episode reward: 5890.8887\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.505725 9.473255 9.505561 8.141384 9.085468 9.499458]\n",
      "Reset environment\n",
      "Episode reward: 3109.4578\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.507234 9.474768 9.507058 8.143047 9.086813 9.500964]\n",
      "Reset environment\n",
      "Episode reward: 4951.2554\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.509758  9.4773035 9.50957   8.14578   9.089064  9.503489 ]\n",
      "Reset environment\n",
      "Episode reward: 1697.5269\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.510516 9.478079 9.510309 8.146624 9.089745 9.504249]\n",
      "Reset environment\n",
      "Episode reward: 2184.7144\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.511452 9.478976 9.511276 8.14762  9.090609 9.505187]\n",
      "Reset environment\n",
      "Episode reward: 3108.1821\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.513004  9.480527  9.512824  8.149326  9.091996  9.5067425]\n",
      "Reset environment\n",
      "Episode reward: 4405.863\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.515244 9.482777 9.515057 8.15174  9.093997 9.508986]\n",
      "Reset environment\n",
      "Episode reward: 2095.3591\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.516181  9.483735  9.515972  8.152777  9.0948305 9.509928 ]\n",
      "Reset environment\n",
      "Episode reward: 5293.077\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.518885 9.486449 9.518666 8.155734 9.097258 9.512632]\n",
      "Reset environment\n",
      "Episode reward: 939.0839\n",
      "Total Steps: 30\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.519237 9.486801 9.519014 8.156155 9.097567 9.512986]\n",
      "Reset environment\n",
      "Episode reward: 4531.4775\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.521531 9.489103 9.521305 8.158661 9.099626 9.515281]\n",
      "Reset environment\n",
      "Episode reward: 3811.5483\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.523416 9.490999 9.523176 8.160715 9.101303 9.517162]\n",
      "Reset environment\n",
      "Episode reward: 3735.747\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.525192  9.492772  9.524955  8.162664  9.1028805 9.518939 ]\n",
      "Reset environment\n",
      "Episode reward: 4307.392\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.52738  9.494953 9.527136 8.165031 9.104834 9.521122]\n",
      "Reset environment\n",
      "Episode reward: 1066.432\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.527798 9.495378 9.527543 8.165522 9.105198 9.521541]\n",
      "Reset environment\n",
      "Episode reward: 4331.6377\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.529988  9.4975605 9.5297365 8.167899  9.107178  9.523728 ]\n",
      "Reset environment\n",
      "Episode reward: 2630.374\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.531281  9.498849  9.531034  8.169301  9.108333  9.5250225]\n",
      "Reset environment\n",
      "Episode reward: 3808.446\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.533197  9.500755  9.53296   8.171373  9.110041  9.5269375]\n",
      "Reset environment\n",
      "Episode reward: 4378.043\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.535408 9.502957 9.535176 8.173788 9.112036 9.529152]\n",
      "Reset environment\n",
      "Episode reward: 5326.8975\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.538    9.505552 9.537777 8.176625 9.114341 9.53175 ]\n",
      "Reset environment\n",
      "Episode reward: 3233.858\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.539558 9.507084 9.539355 8.178333 9.115717 9.533304]\n",
      "Reset environment\n",
      "Episode reward: 2057.193\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.540449 9.507977 9.540239 8.179322 9.116499 9.534194]\n",
      "Reset environment\n",
      "Episode reward: 3993.3953\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.54234  9.509851 9.542149 8.181415 9.118171 9.536087]\n",
      "Reset environment\n",
      "Episode reward: 1355.7573\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.54278   9.510334  9.542545  8.181947  9.118561  9.5365305]\n",
      "Reset environment\n",
      "Episode reward: 1378.7819\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.54306  9.510687 9.542762 8.182237 9.118827 9.53682 ]\n",
      "Reset environment\n",
      "Episode reward: 2233.123\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.544075 9.511693 9.543791 8.183375 9.119722 9.537837]\n",
      "Reset environment\n",
      "Episode reward: 2671.685\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.545352  9.512978  9.545064  8.184783  9.1208515 9.539117 ]\n",
      "Reset environment\n",
      "Episode reward: 3035.5256\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.546779 9.514437 9.546453 8.186359 9.122109 9.540544]\n",
      "Reset environment\n",
      "Episode reward: 2511.655\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.54797  9.515619 9.547652 8.187663 9.123176 9.541733]\n",
      "Reset environment\n",
      "Episode reward: 2024.394\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.548896 9.516564 9.548556 8.188692 9.124004 9.542661]\n",
      "Reset environment\n",
      "Episode reward: 2082.6548\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.550218  9.51788   9.549881  8.190146  9.12518   9.5439825]\n",
      "Reset environment\n",
      "Episode reward: 2244.4832\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.551251 9.518905 9.55091  8.191284 9.126092 9.545012]\n",
      "Reset environment\n",
      "Episode reward: 1356.9004\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.552191 9.519846 9.551843 8.192324 9.126916 9.545952]\n",
      "Reset environment\n",
      "Episode reward: 1834.7443\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.552989 9.52067  9.552613 8.193213 9.127624 9.546752]\n",
      "Reset environment\n",
      "Episode reward: 2058.7178\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.553935 9.52162  9.553555 8.194263 9.128457 9.547697]\n",
      "Reset environment\n",
      "Episode reward: 2887.7793\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.555299  9.523     9.554901  8.195773  9.1296625 9.549062 ]\n",
      "Reset environment\n",
      "Episode reward: 2480.9204\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.556402 9.524132 9.555971 8.197006 9.130643 9.550168]\n",
      "Reset environment\n",
      "Episode reward: 576.89575\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.556203 9.524031 9.555678 8.196807 9.130477 9.549978]\n",
      "Reset environment\n",
      "Episode reward: 2103.9978\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.55714  9.524989 9.556596 8.197844 9.131304 9.550918]\n",
      "Reset environment\n",
      "Episode reward: 2884.8726\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.558459 9.526297 9.557934 8.199311 9.132465 9.552238]\n",
      "Reset environment\n",
      "Episode reward: 1890.8104\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.559264  9.527123  9.558717  8.200216  9.1331835 9.553044 ]\n",
      "Reset environment\n",
      "Episode reward: 5659.8784\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.562141  9.5300045 9.561581  8.203352  9.135767  9.555916 ]\n",
      "Reset environment\n",
      "Episode reward: 2677.3333\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.563411 9.531285 9.562841 8.204749 9.136892 9.557186]\n",
      "Reset environment\n",
      "Episode reward: 4494.047\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.565678 9.533562 9.565101 8.207224 9.138915 9.559451]\n",
      "Reset environment\n",
      "Episode reward: 1844.8445\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.566325  9.534255  9.56571   8.208004  9.139473  9.5601015]\n",
      "Reset environment\n",
      "Episode reward: 4538.118\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.568548  9.536479  9.5679245 8.2104225 9.141457  9.562323 ]\n",
      "Reset environment\n",
      "Episode reward: 303.92233\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.56845   9.536381  9.567814  8.210234  9.1413765 9.562224 ]\n",
      "Reset environment\n",
      "Episode reward: 2657.044\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.569508 9.537486 9.568828 8.211458 9.142316 9.563287]\n",
      "Reset environment\n",
      "Episode reward: 3814.5464\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.571398 9.539379 9.57071  8.213537 9.143995 9.565178]\n",
      "Reset environment\n",
      "Episode reward: 4560.4604\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.57371  9.541698 9.573012 8.216048 9.14607  9.56749 ]\n",
      "Reset environment\n",
      "Episode reward: 1429.2632\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.57432  9.542306 9.57362  8.216744 9.146603 9.568098]\n",
      "Reset environment\n",
      "Episode reward: 3187.9377\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.57579   9.54377   9.5750885 8.218358  9.14792   9.569566 ]\n",
      "Reset environment\n",
      "Episode reward: 3611.8735\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.577573 9.545556 9.576859 8.220289 9.14951  9.571349]\n",
      "Reset environment\n",
      "Episode reward: 2246.7915\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.578475 9.546425 9.5778   8.221327 9.150318 9.572251]\n",
      "Reset environment\n",
      "Episode reward: 1574.141\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.579078 9.546991 9.578434 8.222024 9.150851 9.572855]\n",
      "Reset environment\n",
      "Episode reward: 2194.8699\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.580482 9.5484   9.579831 8.223565 9.152094 9.574261]\n",
      "Reset environment\n",
      "Episode reward: 2905.3767\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.581892 9.549801 9.581248 8.225102 9.153348 9.575671]\n",
      "Reset environment\n",
      "Episode reward: 1969.1946\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.582765 9.55066  9.582134 8.226069 9.154115 9.576545]\n",
      "Reset environment\n",
      "Episode reward: 3100.3262\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.584262 9.552148 9.583644 8.227703 9.155448 9.578042]\n",
      "Reset environment\n",
      "Episode reward: 3427.5227\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.585942 9.553838 9.58531  8.229549 9.156941 9.579723]\n",
      "Reset environment\n",
      "Episode reward: 2255.8987\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.587011 9.554903 9.586382 8.230718 9.157894 9.580791]\n",
      "Reset environment\n",
      "Episode reward: 3620.93\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.588793  9.5566845 9.588164  8.232669  9.159496  9.582572 ]\n",
      "Reset environment\n",
      "Episode reward: 1410.1855\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.589767 9.557657 9.589137 8.233741 9.160358 9.583547]\n",
      "Reset environment\n",
      "Episode reward: 5495.144\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.592472  9.5603485 9.591846  8.236696  9.162767  9.58625  ]\n",
      "Reset environment\n",
      "Episode reward: 2432.426\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.593444 9.561374 9.59278  8.237824 9.163643 9.587229]\n",
      "Reset environment\n",
      "Episode reward: 1880.3433\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.594272  9.562217  9.593592  8.238748  9.164377  9.5880575]\n",
      "Reset environment\n",
      "Episode reward: 1265.0101\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.594799  9.562753  9.594107  8.2393465 9.16484   9.588586 ]\n",
      "Reset environment\n",
      "Episode reward: 2050.1555\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.596092 9.564052 9.595388 8.240784 9.165978 9.589879]\n",
      "Reset environment\n",
      "Episode reward: 2058.5361\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.597407  9.5653715 9.596702  8.242241  9.16714   9.591195 ]\n",
      "Reset environment\n",
      "Episode reward: 4967.824\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.599919 9.567873 9.599217 8.244973 9.169404 9.593705]\n",
      "Reset environment\n",
      "Episode reward: 4107.62\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.601985 9.569938 9.601277 8.247211 9.171244 9.595771]\n",
      "Reset environment\n",
      "Episode reward: 3306.0112\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.603582 9.571522 9.602883 8.248975 9.172676 9.597366]\n",
      "Reset environment\n",
      "Episode reward: 2296.1543\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.604687 9.572622 9.603992 8.250182 9.17366  9.598471]\n",
      "Reset environment\n",
      "Episode reward: 2151.64\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.60565  9.573608 9.604937 8.251251 9.174516 9.599434]\n",
      "Reset environment\n",
      "Episode reward: 2171.102\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.606685 9.574655 9.605965 8.2524   9.175458 9.600471]\n",
      "Reset environment\n",
      "Episode reward: 1330.0864\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.607598 9.575568 9.606876 8.253423 9.176257 9.601386]\n",
      "Reset environment\n",
      "Episode reward: 4690.4653\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.609968 9.577931 9.609246 8.255999 9.178389 9.603755]\n",
      "Reset environment\n",
      "Episode reward: 2094.3616\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.611312  9.579275  9.610579  8.257473  9.1795845 9.605099 ]\n",
      "Reset environment\n",
      "Episode reward: 2821.5024\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.612611  9.5806055 9.611844  8.258915  9.180745  9.606401 ]\n",
      "Reset environment\n",
      "Episode reward: 1980.7936\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.613859 9.581855 9.61309  8.260309 9.181848 9.607649]\n",
      "Reset environment\n",
      "Episode reward: 4233.5664\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.615954 9.583961 9.615176 8.2626   9.183723 9.609747]\n",
      "Reset environment\n",
      "Episode reward: 4568.6084\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.618224 9.586217 9.617444 8.265082 9.185755 9.612013]\n",
      "Reset environment\n",
      "Episode reward: 1756.216\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.618999  9.5869875 9.618214  8.265942  9.186431  9.612786 ]\n",
      "Reset environment\n",
      "Episode reward: 3291.3325\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.620543 9.588504 9.619781 8.267631 9.187806 9.614331]\n",
      "Reset environment\n",
      "Episode reward: 2097.6863\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.621476 9.589432 9.620726 8.268677 9.188639 9.615266]\n",
      "Reset environment\n",
      "Episode reward: 4623.2007\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.623758 9.591714 9.623006 8.27119  9.190674 9.617547]\n",
      "Reset environment\n",
      "Episode reward: 541.04443\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.623847 9.591796 9.623094 8.271224 9.190754 9.617638]\n",
      "Reset environment\n",
      "Episode reward: 2686.5603\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.625126 9.593086 9.624365 8.272642 9.191896 9.618918]\n",
      "Reset environment\n",
      "Episode reward: 1717.781\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.625861  9.593842  9.625079  8.273472  9.1925535 9.619655 ]\n",
      "Reset environment\n",
      "Episode reward: 2108.5552\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.626694 9.594656 9.625924 8.27442  9.193327 9.620495]\n",
      "Reset environment\n",
      "Episode reward: 4812.103\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.6291    9.597052  9.628338  8.277053  9.1954975 9.6229   ]\n",
      "Reset environment\n",
      "Episode reward: 3376.0586\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.630757  9.598704  9.629995  8.278872  9.196975  9.6245575]\n",
      "Reset environment\n",
      "Episode reward: 3021.0596\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.632229 9.60019  9.63146  8.28049  9.198296 9.62603 ]\n",
      "Reset environment\n",
      "Episode reward: 2395.9116\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.6331    9.601104  9.632286  8.281517  9.199068  9.6269045]\n",
      "Reset environment\n",
      "Episode reward: 1305.6709\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.633653 9.601654 9.632834 8.282146 9.199556 9.627457]\n",
      "Reset environment\n",
      "Episode reward: 3957.533\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.635634 9.603641 9.63481  8.284295 9.201333 9.62944 ]\n",
      "Reset environment\n",
      "Episode reward: 2382.9019\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.6366825 9.604661  9.635883  8.285467  9.20227   9.630487 ]\n",
      "Reset environment\n",
      "Episode reward: 3193.7715\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.638158 9.606121 9.637361 8.287112 9.203576 9.63196 ]\n",
      "Reset environment\n",
      "Episode reward: 2370.6794\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.639276  9.607244  9.6384735 8.288331  9.204566  9.633078 ]\n",
      "Reset environment\n",
      "Episode reward: 1884.3922\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.640029 9.607963 9.639249 8.289181 9.20523  9.63383 ]\n",
      "Reset environment\n",
      "Episode reward: 5295.9424\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.643101  9.6110525 9.642308  8.292524  9.207997  9.636906 ]\n",
      "Reset environment\n",
      "Episode reward: 1917.9364\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.644343 9.612297 9.64355  8.293891 9.209102 9.638149]\n",
      "Reset environment\n",
      "Episode reward: 2369.8735\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.645399 9.613372 9.644584 8.295053 9.210047 9.639205]\n",
      "Reset environment\n",
      "Episode reward: 2333.6355\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.646451 9.614433 9.645627 8.296219 9.210999 9.640258]\n",
      "Reset environment\n",
      "Episode reward: 2630.0078\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.6476145 9.615568  9.646821  8.297512  9.212032  9.641424 ]\n",
      "Reset environment\n",
      "Episode reward: 2234.656\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.648598 9.616525 9.647832 8.298603 9.212909 9.642407]\n",
      "Reset environment\n",
      "Episode reward: -420.47662\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.647641 9.615651 9.646801 8.297617 9.212097 9.641461]\n",
      "Reset environment\n",
      "Episode reward: 1648.0209\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.648349 9.616377 9.647488 8.298403 9.212727 9.642171]\n",
      "Reset environment\n",
      "Episode reward: 2337.51\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.649432  9.617473  9.648562  8.299595  9.2136965 9.643255 ]\n",
      "Reset environment\n",
      "Episode reward: 1378.4323\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.650369 9.618408 9.649498 8.300648 9.214519 9.64419 ]\n",
      "Reset environment\n",
      "Episode reward: 2212.3503\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.651769 9.619804 9.650891 8.302177 9.215765 9.645591]\n",
      "Reset environment\n",
      "Episode reward: 2244.6287\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.652794 9.620832 9.651917 8.30332  9.216672 9.64662 ]\n",
      "Reset environment\n",
      "Episode reward: 3440.1326\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.654466 9.622501 9.65359  8.305154 9.218169 9.648291]\n",
      "Reset environment\n",
      "Episode reward: 1693.0223\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.655163 9.623225 9.654262 8.30594  9.218786 9.648991]\n",
      "Reset environment\n",
      "Episode reward: 4393.047\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.657352  9.6254015 9.656458  8.308325  9.220764  9.651179 ]\n",
      "Reset environment\n",
      "Episode reward: 5837.768\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.660355 9.6284   9.659452 8.311575 9.223437 9.654179]\n",
      "Reset environment\n",
      "Episode reward: 2072.119\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.661289 9.629343 9.660382 8.312615 9.224266 9.655115]\n",
      "Reset environment\n",
      "Episode reward: 2598.8567\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.662497 9.630535 9.6616   8.31396  9.225334 9.656321]\n",
      "Reset environment\n",
      "Episode reward: 2062.6536\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.663376 9.631441 9.662455 8.314955 9.226118 9.657202]\n",
      "Reset environment\n",
      "Episode reward: 1363.3356\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.663943 9.631984 9.663037 8.315587 9.226676 9.657769]\n",
      "Reset environment\n",
      "Episode reward: -135.2391\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.663394 9.631373 9.662547 8.314952 9.226178 9.65722 ]\n",
      "Reset environment\n",
      "Episode reward: 4835.5576\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.665845 9.633817 9.665002 8.317603 9.228378 9.659671]\n",
      "Reset environment\n",
      "Episode reward: 2873.6187\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.667095 9.635025 9.666289 8.31901  9.229506 9.660921]\n",
      "Reset environment\n",
      "Episode reward: 2619.8967\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.66834  9.636257 9.667544 8.320367 9.23062  9.662166]\n",
      "Reset environment\n",
      "Episode reward: 4102.745\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.670375 9.638287 9.669574 8.322587 9.232443 9.6642  ]\n",
      "Reset environment\n",
      "Episode reward: 2139.857\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.671729 9.639635 9.670925 8.324073 9.233649 9.665552]\n",
      "Reset environment\n",
      "Episode reward: 1061.9437\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.671936 9.639782 9.671176 8.324275 9.233874 9.66576 ]\n",
      "Reset environment\n",
      "Episode reward: 2790.4688\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.673263 9.641109 9.672495 8.325735 9.235048 9.667085]\n",
      "Reset environment\n",
      "Episode reward: 1792.3175\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.674062  9.641906  9.6732855 8.326626  9.235749  9.667884 ]\n",
      "Reset environment\n",
      "Episode reward: 1378.6184\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.674996 9.642839 9.674216 8.327665 9.236577 9.668822]\n",
      "Reset environment\n",
      "Episode reward: 2004.6582\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.675889 9.643742 9.675102 8.328664 9.237376 9.669718]\n",
      "Reset environment\n",
      "Episode reward: 1786.471\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.676707 9.644553 9.675922 8.329574 9.238102 9.670537]\n",
      "Reset environment\n",
      "Episode reward: 5379.536\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.679428 9.647274 9.67864  8.332526 9.240543 9.673256]\n",
      "Reset environment\n",
      "Episode reward: 2279.6687\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.680493 9.648325 9.679709 8.333697 9.241476 9.67432 ]\n",
      "Reset environment\n",
      "Episode reward: 1128.6472\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.680957 9.648785 9.680172 8.334222 9.241882 9.674783]\n",
      "Reset environment\n",
      "Episode reward: 3825.3452\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.682824 9.650641 9.682046 8.336258 9.243554 9.676651]\n",
      "Reset environment\n",
      "Episode reward: 4087.495\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.684857 9.652688 9.684069 8.338476 9.245383 9.678683]\n",
      "Reset environment\n",
      "Episode reward: 1993.0103\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.685728 9.653574 9.684924 8.339438 9.246154 9.679553]\n",
      "Reset environment\n",
      "Episode reward: 1754.7054\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.686469  9.654301  9.6856785 8.34028   9.246804  9.680294 ]\n",
      "Reset environment\n",
      "Episode reward: 6144.0063\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.68964   9.657467  9.688844  8.343706  9.2496395 9.683463 ]\n",
      "Reset environment\n",
      "Episode reward: 2430.4578\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.691152 9.658975 9.690356 8.345369 9.250978 9.684975]\n",
      "Reset environment\n",
      "Episode reward: 1563.6458\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.691828 9.659653 9.691031 8.346129 9.251575 9.685652]\n",
      "Reset environment\n",
      "Episode reward: 1385.9287\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.692769 9.660596 9.691971 8.34717  9.252408 9.686592]\n",
      "Reset environment\n",
      "Episode reward: 5527.216\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.695588 9.663411 9.694797 8.350215 9.254935 9.689412]\n",
      "Reset environment\n",
      "Episode reward: 2865.0955\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.696925  9.664769  9.6961155 8.351699  9.256132  9.690751 ]\n",
      "Reset environment\n",
      "Episode reward: 2600.9219\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.698141 9.665989 9.697322 8.353043 9.257207 9.691967]\n",
      "Reset environment\n",
      "Episode reward: 5286.6597\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.700692  9.668543  9.699874  8.355835  9.2594595 9.694525 ]\n",
      "Reset environment\n",
      "Episode reward: 3590.0193\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.702403 9.670245 9.70159  8.357723 9.261    9.696236]\n",
      "Reset environment\n",
      "Episode reward: 1764.1345\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.703556 9.671397 9.702741 8.358988 9.262019 9.697387]\n",
      "Reset environment\n",
      "Episode reward: 2266.9858\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.704966 9.672797 9.704139 8.36053  9.263262 9.698787]\n",
      "Reset environment\n",
      "Episode reward: 3316.7441\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.7064495 9.674246  9.705652  8.362174  9.264594  9.700272 ]\n",
      "Reset environment\n",
      "Episode reward: 1792.1003\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.707241 9.675041 9.706437 8.36306  9.265294 9.701063]\n",
      "Reset environment\n",
      "Episode reward: 4061.8506\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.709241  9.6770525 9.708427  8.365226  9.267075  9.703067 ]\n",
      "Reset environment\n",
      "Episode reward: 2488.9265\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.710326 9.678113 9.709537 8.366435 9.268055 9.704154]\n",
      "Reset environment\n",
      "Episode reward: 3945.022\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.712256  9.680051  9.711457  8.3685255 9.269769  9.706086 ]\n",
      "Reset environment\n",
      "Episode reward: 2233.435\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.713166 9.680927 9.712402 8.369552 9.270576 9.707   ]\n",
      "Reset environment\n",
      "Episode reward: 3422.7917\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.714701 9.682482 9.713922 8.371244 9.271944 9.708534]\n",
      "Reset environment\n",
      "Episode reward: 2344.414\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.71573  9.683524 9.714934 8.372393 9.272863 9.709563]\n",
      "Reset environment\n",
      "Episode reward: 2001.0161\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.717    9.684794 9.716208 8.373789 9.273993 9.710835]\n",
      "Reset environment\n",
      "Episode reward: 1601.4851\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.717698 9.685494 9.716906 8.374575 9.274608 9.711534]\n",
      "Reset environment\n",
      "Episode reward: 4150.8623\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.719648 9.687442 9.718853 8.376722 9.276332 9.713483]\n",
      "Reset environment\n",
      "Episode reward: 2244.3254\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.720721 9.68851  9.719926 8.377904 9.277282 9.714557]\n",
      "Reset environment\n",
      "Episode reward: 1842.6002\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.721507  9.689293  9.720719  8.378794  9.277973  9.7153425]\n",
      "Reset environment\n",
      "Episode reward: 4387.364\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.723693 9.691477 9.722905 8.381178 9.279927 9.71753 ]\n",
      "Reset environment\n",
      "Episode reward: 1846.1466\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.724522 9.692293 9.72374  8.382093 9.280655 9.718358]\n",
      "Reset environment\n",
      "Episode reward: 1844.9092\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.725651  9.6934185 9.724865  8.383382  9.281647  9.719485 ]\n",
      "Reset environment\n",
      "Episode reward: 1271.3909\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.726498 9.694264 9.72571  8.384343 9.282379 9.720332]\n",
      "Reset environment\n",
      "Episode reward: 5183.164\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.729079 9.696842 9.728299 8.387166 9.284701 9.722914]\n",
      "Reset environment\n",
      "Episode reward: 1944.1293\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.729802 9.697515 9.72906  8.388    9.285344 9.723637]\n",
      "Reset environment\n",
      "Episode reward: 2349.9285\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.730886  9.698596  9.730148  8.3891945 9.286303  9.724722 ]\n",
      "Reset environment\n",
      "Episode reward: 2144.9834\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.732222 9.699927 9.731493 8.390676 9.287485 9.726057]\n",
      "Reset environment\n",
      "Episode reward: 1496.0146\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.732872 9.700586 9.732132 8.391405 9.288064 9.726708]\n",
      "Reset environment\n",
      "Episode reward: 4892.151\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.7353325 9.7030525 9.734589  8.3940735 9.290263  9.729169 ]\n",
      "Reset environment\n",
      "Episode reward: 604.14764\n",
      "Total Steps: 20\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.735485  9.703209  9.7347355 8.394275  9.290386  9.729321 ]\n",
      "Reset environment\n",
      "Episode reward: 2763.2139\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.73675  9.704496 9.735977 8.395682 9.291518 9.730584]\n",
      "Reset environment\n",
      "Episode reward: 1317.2578\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.737635  9.705381  9.736862  8.396675  9.2922945 9.731469 ]\n",
      "Reset environment\n",
      "Episode reward: 2221.381\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.7385845 9.706298  9.737836  8.397738  9.293132  9.732419 ]\n",
      "Reset environment\n",
      "Episode reward: 3678.5764\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.740363 9.708061 9.739629 8.399671 9.294706 9.734202]\n",
      "Reset environment\n",
      "Episode reward: 2771.9048\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.741653  9.709335  9.74093   8.4010935 9.295853  9.735493 ]\n",
      "Reset environment\n",
      "Episode reward: 2052.0166\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.742582 9.710267 9.741855 8.402127 9.296678 9.736425]\n",
      "Reset environment\n",
      "Episode reward: 1631.6836\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.743297 9.710965 9.742579 8.402908 9.297318 9.73714 ]\n",
      "Reset environment\n",
      "Episode reward: 5431.6323\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.746044 9.71371  9.745323 8.405883 9.299781 9.739886]\n",
      "Reset environment\n",
      "Episode reward: 4713.777\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.748299 9.715961 9.747572 8.408345 9.301773 9.742139]\n",
      "Reset environment\n",
      "Episode reward: 1319.1434\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.749187 9.716846 9.748458 8.409334 9.302551 9.743029]\n",
      "Reset environment\n",
      "Episode reward: 2961.4526\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.750603 9.718272 9.74986  8.410875 9.303804 9.744447]\n",
      "Reset environment\n",
      "Episode reward: 4926.646\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.753064 9.720727 9.752323 8.413537 9.306012 9.746909]\n",
      "Reset environment\n",
      "Episode reward: 1710.745\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.753704 9.721411 9.752924 8.414284 9.306581 9.747551]\n",
      "Reset environment\n",
      "Episode reward: 2829.1492\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.754964 9.722643 9.754209 8.415672 9.30769  9.74881 ]\n",
      "Reset environment\n",
      "Episode reward: 1736.3962\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.755721 9.723396 9.754963 8.416511 9.308354 9.749569]\n",
      "Reset environment\n",
      "Episode reward: 1630.539\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.75625  9.723967 9.755448 8.417153 9.308808 9.7501  ]\n",
      "Reset environment\n",
      "Episode reward: 4644.799\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.75853  9.726237 9.757732 8.419651 9.310852 9.752382]\n",
      "Reset environment\n",
      "Episode reward: 5840.9424\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.761466 9.729175 9.760675 8.422863 9.313494 9.755326]\n",
      "Reset environment\n",
      "Episode reward: 4835.4688\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.763871 9.731573 9.763081 8.425475 9.315649 9.757728]\n",
      "Reset environment\n",
      "Episode reward: 3239.1606\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.765415 9.733107 9.764627 8.427152 9.317028 9.759274]\n",
      "Reset environment\n",
      "Episode reward: 1454.2603\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.766031  9.733715  9.765251  8.427846  9.317572  9.7598915]\n",
      "Reset environment\n",
      "Episode reward: -133.9429\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.765558 9.733255 9.764768 8.427194 9.31717  9.759421]\n",
      "Reset environment\n",
      "Episode reward: 4726.6206\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.767929 9.735626 9.767135 8.429768 9.31928  9.761793]\n",
      "Reset environment\n",
      "Episode reward: 1702.5723\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.768659 9.736354 9.767863 8.43058  9.31992  9.762523]\n",
      "Reset environment\n",
      "Episode reward: 296.26968\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.768248 9.736047 9.767352 8.430183 9.31956  9.762121]\n",
      "Reset environment\n",
      "Episode reward: 1259.1251\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.768773 9.736575 9.767873 8.430785 9.320017 9.76265 ]\n",
      "Reset environment\n",
      "Episode reward: 1587.8759\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.769444 9.737256 9.768533 8.431542 9.320617 9.763324]\n",
      "Reset environment\n",
      "Episode reward: 3534.6108\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.771112 9.738916 9.770205 8.433389 9.322095 9.764991]\n",
      "Reset environment\n",
      "Episode reward: 49.954987\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.770542 9.738438 9.76954  8.432708 9.321574 9.764427]\n",
      "Reset environment\n",
      "Episode reward: 3185.915\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.772045 9.739939 9.771047 8.434349 9.322911 9.765934]\n",
      "Reset environment\n",
      "Episode reward: 5828.1353\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.774948 9.74285  9.773936 8.437523 9.325511 9.76884 ]\n",
      "Reset environment\n",
      "Episode reward: 2373.656\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.775849  9.743718  9.7748785 8.43858   9.326313  9.769743 ]\n",
      "Reset environment\n",
      "Episode reward: 2769.7246\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.777009 9.744917 9.776009 8.439874 9.327337 9.770902]\n",
      "Reset environment\n",
      "Episode reward: 2186.1714\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.77794   9.745825  9.7769575 8.440905  9.328155  9.771831 ]\n",
      "Reset environment\n",
      "Episode reward: 2550.198\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.779025 9.746949 9.778005 8.442126 9.32912  9.772919]\n",
      "Reset environment\n",
      "Episode reward: 2261.333\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.779981 9.747927 9.778933 8.443198 9.329959 9.773875]\n",
      "Reset environment\n",
      "Episode reward: 3748.907\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.781777 9.749714 9.780741 8.445168 9.331563 9.775674]\n",
      "Reset environment\n",
      "Episode reward: 2100.299\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.783107 9.751043 9.782069 8.446635 9.33274  9.777005]\n",
      "Reset environment\n",
      "Episode reward: 1987.4097\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.783988 9.751915 9.782959 8.447616 9.333519 9.777886]\n",
      "Reset environment\n",
      "Episode reward: 3148.8748\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.785488  9.753424  9.7844515 8.449248  9.334847  9.779388 ]\n",
      "Reset environment\n",
      "Episode reward: 1699.685\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.786212 9.754148 9.785175 8.45007  9.335492 9.780112]\n",
      "Reset environment\n",
      "Episode reward: 401.41895\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.785878  9.753714  9.78494   8.449872  9.3351555 9.779781 ]\n",
      "Reset environment\n",
      "Episode reward: 2116.3953\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.786831 9.754664 9.78589  8.450923 9.33599  9.780734]\n",
      "Reset environment\n",
      "Episode reward: 1412.9791\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.787787 9.755618 9.786845 8.451977 9.336833 9.781689]\n",
      "Reset environment\n",
      "Episode reward: 4875.752\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.790233 9.758056 9.789298 8.454626 9.339031 9.784132]\n",
      "Reset environment\n",
      "Episode reward: -83.27051\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.789784 9.757586 9.788866 8.454005 9.338623 9.783684]\n",
      "Reset environment\n",
      "Episode reward: 1703.7534\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.790527 9.758323 9.789609 8.454832 9.339277 9.784425]\n",
      "Reset environment\n",
      "Episode reward: 1431.507\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.791138 9.758929 9.790221 8.455528 9.339818 9.785035]\n",
      "Reset environment\n",
      "Episode reward: 3362.2026\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.79274  9.760521 9.791836 8.457261 9.341238 9.786639]\n",
      "Reset environment\n",
      "Episode reward: -198.37955\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.792225 9.759991 9.791336 8.456563 9.340786 9.786125]\n",
      "Reset environment\n",
      "Episode reward: 1891.2363\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.793026 9.76077  9.792151 8.457456 9.341491 9.786924]\n",
      "Reset environment\n",
      "Episode reward: -346.23633\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.792324 9.760128 9.79139  8.456762 9.340838 9.786226]\n",
      "Reset environment\n",
      "Episode reward: 3248.4365\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.79375   9.761585  9.7927885 8.458327  9.342105  9.787648 ]\n",
      "Reset environment\n",
      "Episode reward: 2156.3008\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.795092 9.76292  9.794132 8.459796 9.3433   9.788992]\n",
      "Reset environment\n",
      "Episode reward: 360.09036\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.7947445 9.762485  9.793852  8.459397  9.343034  9.78865  ]\n",
      "Reset environment\n",
      "Episode reward: 3684.8176\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.796464 9.764206 9.79557  8.461265 9.344572 9.790371]\n",
      "Reset environment\n",
      "Episode reward: 2755.949\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.79775  9.765502 9.796845 8.46268  9.345711 9.791658]\n",
      "Reset environment\n",
      "Episode reward: 3019.5337\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.799176 9.766931 9.798259 8.464244 9.346973 9.793082]\n",
      "Reset environment\n",
      "Episode reward: 1328.3834\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.800057 9.767808 9.799134 8.46523  9.347742 9.793964]\n",
      "Reset environment\n",
      "Episode reward: 2361.9167\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.800995  9.768705  9.8001    8.466301  9.3485775 9.794904 ]\n",
      "Reset environment\n",
      "Episode reward: 3900.633\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.802877 9.7706   9.801975 8.468352 9.350256 9.79679 ]\n",
      "Reset environment\n",
      "Episode reward: 1403.6763\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.803824 9.771549 9.80292  8.469398 9.351091 9.797737]\n",
      "Reset environment\n",
      "Episode reward: 1356.7875\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.804742 9.772455 9.803831 8.470396 9.351893 9.79865 ]\n",
      "Reset environment\n",
      "Episode reward: -192.3378\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.803863 9.771486 9.803029 8.469422 9.351147 9.797773]\n",
      "Reset environment\n",
      "Episode reward: 2427.2466\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.804999  9.772629  9.804162  8.47068   9.3521595 9.798911 ]\n",
      "Reset environment\n",
      "Episode reward: 2635.5823\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.806185 9.773833 9.805328 8.471976 9.353212 9.800099]\n",
      "Reset environment\n",
      "Episode reward: 5494.3823\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.8089075 9.776553  9.808052  8.474933  9.355665  9.80282  ]\n",
      "Reset environment\n",
      "Episode reward: 1083.7198\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.8093195 9.776963  9.808465  8.475412  9.356025  9.803232 ]\n",
      "Reset environment\n",
      "Episode reward: -33.23166\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.808728 9.776299 9.807932 8.474905 9.355484 9.802636]\n",
      "Reset environment\n",
      "Episode reward: 57.266144\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.80804  9.775494 9.807363 8.474272 9.35488  9.801945]\n",
      "Reset environment\n",
      "Episode reward: 2142.725\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.809365 9.776822 9.808688 8.475734 9.356047 9.803271]\n",
      "Reset environment\n",
      "Episode reward: 3009.5356\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.810743  9.7781725 9.81009   8.477252  9.357263  9.804649 ]\n",
      "Reset environment\n",
      "Episode reward: 1383.9142\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.811681 9.779113 9.811029 8.478288 9.358093 9.805588]\n",
      "Reset environment\n",
      "Episode reward: 1880.3242\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.812368 9.779757 9.811757 8.479083 9.358708 9.806276]\n",
      "Reset environment\n",
      "Episode reward: 1803.2698\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.813148  9.780526  9.81254   8.479957  9.359393  9.8070545]\n",
      "Reset environment\n",
      "Episode reward: 2152.9673\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.814494 9.781876 9.813883 8.481431 9.360586 9.8084  ]\n",
      "Reset environment\n",
      "Episode reward: 2466.6409\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.815579 9.782973 9.814946 8.482633 9.36155  9.809485]\n",
      "Reset environment\n",
      "Episode reward: 2718.8013\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.816836 9.78423  9.81621  8.484016 9.362664 9.81074 ]\n",
      "Reset environment\n",
      "Episode reward: 1749.3633\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.817473  9.784918  9.816802  8.48476   9.363235  9.8113785]\n",
      "Reset environment\n",
      "Episode reward: 1792.9623\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.818134  9.7856245 9.817419  8.485535  9.363819  9.812039 ]\n",
      "Reset environment\n",
      "Episode reward: 1547.2212\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.818808 9.786294 9.818095 8.486281 9.364409 9.812714]\n",
      "Reset environment\n",
      "Episode reward: 2763.2993\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.8199625 9.7874155 9.8192835 8.487581  9.365452  9.8138685]\n",
      "Reset environment\n",
      "Episode reward: 2118.1487\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.820936 9.788401 9.82025  8.488666 9.366334 9.814841]\n",
      "Reset environment\n",
      "Episode reward: 2380.152\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.822045 9.789519 9.821346 8.489905 9.367323 9.815953]\n",
      "Reset environment\n",
      "Episode reward: 2023.05\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.822664  9.790195  9.8219185 8.490678  9.367858  9.816573 ]\n",
      "Reset environment\n",
      "Episode reward: 3334.9136\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.824239 9.79178  9.823477 8.492407 9.369262 9.81815 ]\n",
      "Reset environment\n",
      "Episode reward: 2622.4805\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.825456  9.792982  9.824706  8.4937525 9.370348  9.819366 ]\n",
      "Reset environment\n",
      "Episode reward: 2080.946\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.826305 9.793806 9.825581 8.494713 9.371091 9.820216]\n",
      "Reset environment\n",
      "Episode reward: 1867.0309\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.827084 9.794606 9.826338 8.495591 9.371778 9.820993]\n",
      "Reset environment\n",
      "Episode reward: 2534.1948\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.828223 9.795759 9.827464 8.496848 9.372799 9.822133]\n",
      "Reset environment\n",
      "Episode reward: 1598.9236\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.828859 9.796422 9.828077 8.497568 9.373365 9.822773]\n",
      "Reset environment\n",
      "Episode reward: 1514.8423\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.829462  9.797049  9.828649  8.498253  9.3738985 9.823378 ]\n",
      "Reset environment\n",
      "Episode reward: 2671.5605\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.830679  9.798254  9.829877  8.499579  9.3749695 9.8245945]\n",
      "Reset environment\n",
      "Episode reward: 5401.4966\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.83339  9.80097  9.832576 8.502519 9.377397 9.827308]\n",
      "Reset environment\n",
      "Episode reward: 4120.463\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.835378 9.802951 9.83456  8.50469  9.379174 9.829295]\n",
      "Reset environment\n",
      "Episode reward: 2167.9143\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.836727 9.804299 9.835903 8.506167 9.380356 9.830643]\n",
      "Reset environment\n",
      "Episode reward: 5148.1826\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.839274 9.806845 9.838454 8.508943 9.382642 9.833195]\n",
      "Reset environment\n",
      "Episode reward: 821.70386\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.839367 9.80689  9.838584 8.508992 9.382752 9.833291]\n",
      "Reset environment\n",
      "Episode reward: 5974.3193\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.842268 9.809819 9.841462 8.512167 9.385326 9.836193]\n",
      "Reset environment\n",
      "Episode reward: 2361.0522\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.843333 9.810886 9.842516 8.513355 9.386265 9.837255]\n",
      "Reset environment\n",
      "Episode reward: 2938.438\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.844694 9.812256 9.843872 8.514852 9.387474 9.838619]\n",
      "Reset environment\n",
      "Episode reward: 2382.6602\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.845778 9.813347 9.84495  8.516052 9.388429 9.839707]\n",
      "Reset environment\n",
      "Episode reward: 2819.065\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.847078 9.814663 9.846239 8.517482 9.389582 9.841008]\n",
      "Reset environment\n",
      "Episode reward: 2714.8062\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.848301  9.815915  9.847434  8.5187645 9.3907175 9.842234 ]\n",
      "Reset environment\n",
      "Episode reward: 2553.1187\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.84935  9.817    9.848449 8.519937 9.391648 9.843281]\n",
      "Reset environment\n",
      "Episode reward: 2706.8452\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.850354 9.818056 9.84941  8.521102 9.392542 9.844279]\n",
      "Reset environment\n",
      "Episode reward: 2250.6804\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.8513   9.818972 9.850383 8.522155 9.39339  9.845223]\n",
      "Reset environment\n",
      "Episode reward: 5453.1885\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.854021 9.821686 9.853107 8.525101 9.395827 9.84794 ]\n",
      "Reset environment\n",
      "Episode reward: 1917.6455\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.855237 9.8229   9.85432  8.526433 9.396903 9.849156]\n",
      "Reset environment\n",
      "Episode reward: 2544.7988\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.856348 9.823976 9.855454 8.527665 9.3979   9.850267]\n",
      "Reset environment\n",
      "Episode reward: 3357.8196\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.857941 9.825568 9.857039 8.529402 9.399309 9.851863]\n",
      "Reset environment\n",
      "Episode reward: 1932.9703\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.858759 9.826414 9.857828 8.530318 9.400041 9.852681]\n",
      "Reset environment\n",
      "Episode reward: -621.7175\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.857687 9.825242 9.856853 8.529172 9.399067 9.851615]\n",
      "Reset environment\n",
      "Episode reward: 2286.4773\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.858698 9.82625  9.857868 8.530293 9.399961 9.852625]\n",
      "Reset environment\n",
      "Episode reward: 181.14633\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.858425 9.825945 9.857622 8.529889 9.399735 9.852352]\n",
      "Reset environment\n",
      "Episode reward: 2532.3037\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.859535 9.827073 9.858709 8.531117 9.400724 9.853464]\n",
      "Reset environment\n",
      "Episode reward: 759.78394\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.859726 9.827253 9.858913 8.531285 9.400905 9.853657]\n",
      "Reset environment\n",
      "Episode reward: 3721.8254\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.861504 9.829032 9.86068  8.533233 9.40249  9.855437]\n",
      "Reset environment\n",
      "Episode reward: 1653.4213\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.862179 9.829726 9.861335 8.533985 9.403091 9.856116]\n",
      "Reset environment\n",
      "Episode reward: 2029.3622\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.863438 9.83098  9.862596 8.535372 9.404219 9.857377]\n",
      "Reset environment\n",
      "Episode reward: 2190.6072\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.864318 9.83189  9.863444 8.536362 9.404983 9.858258]\n",
      "Reset environment\n",
      "Episode reward: 1437.2379\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.864673 9.832199 9.86384  8.536823 9.405296 9.858616]\n",
      "Reset environment\n",
      "Episode reward: 3022.9683\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.8659525 9.833441  9.865161  8.538258  9.406458  9.859899 ]\n",
      "Reset environment\n",
      "Episode reward: 176.84549\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.86559  9.833009 9.864865 8.53782  9.406145 9.859537]\n",
      "Reset environment\n",
      "Episode reward: 1952.1499\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.866422 9.833819 9.865718 8.538747 9.406889 9.86037 ]\n",
      "Reset environment\n",
      "Episode reward: 4515.1826\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.868622 9.836028 9.867905 8.541125 9.408834 9.862569]\n",
      "Reset environment\n",
      "Episode reward: 2111.3533\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.86993   9.837342  9.8692045 8.542567  9.409989  9.863879 ]\n",
      "Reset environment\n",
      "Episode reward: 1653.1273\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.870589 9.838026 9.869841 8.543318 9.410574 9.864542]\n",
      "Reset environment\n",
      "Episode reward: 2532.6729\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.871709  9.839133  9.8709755 8.544554  9.411569  9.865661 ]\n",
      "Reset environment\n",
      "Episode reward: 5558.4707\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.874456 9.841893 9.873715 8.547535 9.414035 9.868409]\n",
      "Reset environment\n",
      "Episode reward: 2692.464\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.875675  9.8431015 9.874945  8.548872  9.4151125 9.869627 ]\n",
      "Reset environment\n",
      "Episode reward: 3219.0583\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.87716  9.844574 9.876436 8.550502 9.416424 9.871113]\n",
      "Reset environment\n",
      "Episode reward: 3234.8784\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.87863  9.846043 9.877903 8.552121 9.417747 9.872583]\n",
      "Reset environment\n",
      "Episode reward: 2285.574\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.879624 9.847017 9.878914 8.553226 9.418623 9.873578]\n",
      "Reset environment\n",
      "Episode reward: 1196.3307\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.879797 9.847132 9.879146 8.553388 9.418817 9.873753]\n",
      "Reset environment\n",
      "Episode reward: 3398.9487\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.881382 9.848732 9.880716 8.555125 9.420222 9.875339]\n",
      "Reset environment\n",
      "Episode reward: 2168.476\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.882325 9.849681 9.881663 8.556195 9.421059 9.876281]\n",
      "Reset environment\n",
      "Episode reward: 2040.6519\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.88322  9.850573 9.882556 8.557201 9.421851 9.877175]\n",
      "Reset environment\n",
      "Episode reward: 2134.4785\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.884152 9.851522 9.883471 8.558226 9.422678 9.87811 ]\n",
      "Reset environment\n",
      "Episode reward: 1621.636\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.88484  9.852204 9.884161 8.559    9.423277 9.878798]\n",
      "Reset environment\n",
      "Episode reward: 2240.5676\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.885814 9.853196 9.885116 8.560082 9.424147 9.879774]\n",
      "Reset environment\n",
      "Episode reward: 1816.4388\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.886605 9.853968 9.885922 8.560961 9.424846 9.880565]\n",
      "Reset environment\n",
      "Episode reward: -309.8987\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.8857355 9.853191  9.884956  8.560066  9.424051  9.879701 ]\n",
      "Reset environment\n",
      "Episode reward: 2861.1687\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.88708  9.854543 9.886289 8.561536 9.425248 9.881042]\n",
      "Reset environment\n",
      "Episode reward: 1316.8281\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.887614 9.855079 9.886821 8.56214  9.425716 9.881576]\n",
      "Reset environment\n",
      "Episode reward: 1206.154\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.888087 9.855551 9.887295 8.562681 9.426128 9.882049]\n",
      "Reset environment\n",
      "Episode reward: 2094.8083\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.889042 9.856497 9.88825  8.563735 9.426975 9.883001]\n",
      "Reset environment\n",
      "Episode reward: 2026.6162\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.889775 9.85718  9.88903  8.564594 9.42763  9.883736]\n",
      "Reset environment\n",
      "Episode reward: 1312.23\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.890304 9.857722 9.889546 8.565194 9.428101 9.884263]\n",
      "Reset environment\n",
      "Episode reward: 2184.0103\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.891089 9.858462 9.890374 8.566119 9.428795 9.885049]\n",
      "Reset environment\n",
      "Episode reward: 4319.193\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.893184 9.86056  9.89246  8.568406 9.430655 9.887141]\n",
      "Reset environment\n",
      "Episode reward: 4841.5874\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.895574  9.862944  9.894851  8.5709915 9.432792  9.88953  ]\n",
      "Reset environment\n",
      "Episode reward: 1568.9653\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.8962755 9.863654  9.895542  8.571772  9.433414  9.890234 ]\n",
      "Reset environment\n",
      "Episode reward: 113.63315\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.895894  9.863279  9.895152  8.571255  9.433114  9.8898535]\n",
      "Reset environment\n",
      "Episode reward: 1079.5651\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.895889 9.863347 9.89507  8.571316 9.433101 9.889853]\n",
      "Reset environment\n",
      "Episode reward: 6012.1113\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.898879 9.866326 9.89806  8.574557 9.435775 9.892841]\n",
      "Reset environment\n",
      "Episode reward: 2973.6677\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.900238 9.867674 9.899425 8.576055 9.436982 9.894202]\n",
      "Reset environment\n",
      "Episode reward: 2329.461\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.901253 9.868695 9.900431 8.57718  9.437883 9.895218]\n",
      "Reset environment\n",
      "Episode reward: 2078.4106\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.902152 9.869585 9.901337 8.578183 9.438681 9.896119]\n",
      "Reset environment\n",
      "Episode reward: 5091.591\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.904671  9.872099  9.903858  8.580903  9.4409485 9.898637 ]\n",
      "Reset environment\n",
      "Episode reward: 3093.0593\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.906082 9.873496 9.905282 8.582455 9.442202 9.900049]\n",
      "Reset environment\n",
      "Episode reward: 3374.921\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.9076805 9.875105  9.906875  8.584205  9.443629  9.901651 ]\n",
      "Reset environment\n",
      "Episode reward: 2333.5198\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.908496 9.875976 9.90764  8.585175 9.444344 9.90247 ]\n",
      "Reset environment\n",
      "Episode reward: 2075.5\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.909271 9.876786 9.908379 8.586062 9.445012 9.903245]\n",
      "Reset environment\n",
      "Episode reward: 2779.169\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.910539 9.87806  9.909638 8.587449 9.446142 9.904514]\n",
      "Reset environment\n",
      "Episode reward: 2268.8584\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.911563 9.879097 9.910657 8.588583 9.447055 9.90554 ]\n",
      "Reset environment\n",
      "Episode reward: 2145.3948\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.912499 9.880044 9.911577 8.589622 9.44789  9.906479]\n",
      "Reset environment\n",
      "Episode reward: 5939.8486\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.91546  9.883012 9.914521 8.592827 9.450541 9.909438]\n",
      "Reset environment\n",
      "Episode reward: 3796.6191\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.917249 9.8848   9.916314 8.594793 9.452145 9.911227]\n",
      "Reset environment\n",
      "Episode reward: 3008.518\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.918641  9.88619   9.917708  8.596323  9.4533825 9.91262  ]\n",
      "Reset environment\n",
      "Episode reward: 2750.3384\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.919669 9.887285 9.91869  8.597537 9.454295 9.913649]\n",
      "Reset environment\n",
      "Episode reward: 1973.6178\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.920899  9.888511  9.919914  8.598889  9.4553795 9.91488  ]\n",
      "Reset environment\n",
      "Episode reward: 3554.0244\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.922551 9.890151 9.921565 8.600697 9.456848 9.916532]\n",
      "Reset environment\n",
      "Episode reward: 3741.7253\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.924333 9.891934 9.923339 8.602628 9.458431 9.918313]\n",
      "Reset environment\n",
      "Episode reward: 3825.6223\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.926132 9.89372  9.925148 8.604595 9.46003  9.920113]\n",
      "Reset environment\n",
      "Episode reward: 1965.0465\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.926875 9.894432 9.925923 8.605441 9.460692 9.920857]\n",
      "Reset environment\n",
      "Episode reward: -579.5182\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.92606  9.893644 9.925077 8.604398 9.459932 9.920043]\n",
      "Reset environment\n",
      "Episode reward: 1991.6667\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.926893 9.894458 9.925926 8.605317 9.460659 9.920877]\n",
      "Reset environment\n",
      "Episode reward: 2559.8926\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.928058 9.895618 9.927095 8.606602 9.4617   9.922043]\n",
      "Reset environment\n",
      "Episode reward: 3969.7185\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.929936 9.897497 9.928979 8.608674 9.463397 9.923923]\n",
      "Reset environment\n",
      "Episode reward: 1835.7352\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.931067  9.898629  9.930109  8.609938  9.46439   9.9250555]\n",
      "Reset environment\n",
      "Episode reward: 3701.7349\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.932774 9.900345 9.931808 8.611797 9.46592  9.926763]\n",
      "Reset environment\n",
      "Episode reward: 2025.288\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.933625 9.901182 9.932677 8.612742 9.466669 9.927616]\n",
      "Reset environment\n",
      "Episode reward: 2601.5527\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.934722 9.902305 9.933749 8.613955 9.467637 9.928715]\n",
      "Reset environment\n",
      "Episode reward: 3243.503\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.936234 9.903832 9.93525  8.615615 9.468998 9.930226]\n",
      "Reset environment\n",
      "Episode reward: 2265.451\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.936999 9.904651 9.935971 8.616534 9.469665 9.930992]\n",
      "Reset environment\n",
      "Episode reward: 95.4725\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.936459 9.904204 9.935335 8.615887 9.469166 9.93046 ]\n",
      "Reset environment\n",
      "Episode reward: 2964.3286\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.937773  9.905503  9.9366665 8.617344  9.470318  9.931775 ]\n",
      "Reset environment\n",
      "Episode reward: 2145.0222\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.939078 9.906803 9.937968 8.618785 9.471475 9.933076]\n",
      "Reset environment\n",
      "Episode reward: 2008.7585\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.9399395 9.907634  9.938853  8.61974   9.472245  9.933937 ]\n",
      "Reset environment\n",
      "Episode reward: -468.7499\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.939159 9.90686  9.938065 8.61863  9.471538 9.933157]\n",
      "Reset environment\n",
      "Episode reward: 6367.3027\n",
      "Total Steps: 217\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.942245  9.9099455 9.941143  8.621967  9.474293  9.936243 ]\n",
      "Reset environment\n",
      "Episode reward: 1798.8768\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.9430065 9.910692  9.941916  8.622813  9.474966  9.937004 ]\n",
      "Reset environment\n",
      "Episode reward: 3761.417\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.94472  9.912405 9.943625 8.624676 9.476498 9.93872 ]\n",
      "Reset environment\n",
      "Episode reward: 2910.8616\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.946073 9.913742 9.944985 8.626153 9.477701 9.940071]\n",
      "Reset environment\n",
      "Episode reward: 4477.92\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.948166 9.915843 9.947076 8.628431 9.479582 9.942166]\n",
      "Reset environment\n",
      "Episode reward: 4523.218\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.950284  9.917958  9.949189  8.630729  9.481472  9.9442835]\n",
      "Reset environment\n",
      "Episode reward: 1730.857\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.9510145 9.918703  9.949901  8.631541  9.482117  9.945014 ]\n",
      "Reset environment\n",
      "Episode reward: 4941.331\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.953444 9.921122 9.952331 8.634161 9.484297 9.947437]\n",
      "Reset environment\n",
      "Episode reward: 5061.0503\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.955912  9.923581  9.9548025 8.636831  9.48651   9.949904 ]\n",
      "Reset environment\n",
      "Episode reward: 1650.4874\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.956614 9.924278 9.955507 8.637612 9.487132 9.950607]\n",
      "Reset environment\n",
      "Episode reward: 4822.0957\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.958981 9.92664  9.957875 8.640178 9.489245 9.952973]\n",
      "Reset environment\n",
      "Episode reward: 1168.5234\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.959265  9.926951  9.958113  8.640405  9.489508  9.9532585]\n",
      "Reset environment\n",
      "Episode reward: -2.5758057\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.95878   9.926528  9.957558  8.639797  9.4890585 9.952775 ]\n",
      "Reset environment\n",
      "Episode reward: 6446.929\n",
      "Total Steps: 219\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.961892 9.929623 9.960683 8.643178 9.491855 9.955886]\n",
      "Reset environment\n",
      "Episode reward: 289.4629\n",
      "Total Steps: 9\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.9618845 9.929615  9.960674  8.643195  9.4918375 9.955876 ]\n",
      "Reset environment\n",
      "Episode reward: 5691.192\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.964567 9.932311 9.963358 8.646125 9.494215 9.958564]\n",
      "Reset environment\n",
      "Episode reward: 1654.3751\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.965256 9.932996 9.964052 8.6469   9.494818 9.959252]\n",
      "Reset environment\n",
      "Episode reward: 1516.0464\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.965667  9.933345  9.9645195 8.647364  9.495223  9.959666 ]\n",
      "Reset environment\n",
      "Episode reward: 1645.0842\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.966387  9.9340725 9.96523   8.648164  9.495871  9.960386 ]\n",
      "Reset environment\n",
      "Episode reward: 4541.789\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.968595  9.93627   9.9674425 8.650541  9.497845  9.962595 ]\n",
      "Reset environment\n",
      "Episode reward: 640.66284\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.968602 9.936235 9.967487 8.650481 9.497861 9.962604]\n",
      "Reset environment\n",
      "Episode reward: -341.1632\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.96794  9.935543 9.966858 8.649635 9.497252 9.961942]\n",
      "Reset environment\n",
      "Episode reward: 1633.3868\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.968625 9.936223 9.96755  8.650403 9.497859 9.962627]\n",
      "Reset environment\n",
      "Episode reward: 3500.441\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.970275 9.937876 9.96919  8.652205 9.499321 9.964279]\n",
      "Reset environment\n",
      "Episode reward: 6017.3633\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.973147  9.94076   9.9720545 8.655343  9.501926  9.96715  ]\n",
      "Reset environment\n",
      "Episode reward: 4911.1064\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.97555  9.94316  9.974453 8.657938 9.504058 9.969552]\n",
      "Reset environment\n",
      "Episode reward: 1577.0991\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.976162 9.943742 9.975093 8.658629 9.504598 9.970164]\n",
      "Reset environment\n",
      "Episode reward: 3721.356\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.977938 9.945525 9.97686  8.660551 9.506172 9.971941]\n",
      "Reset environment\n",
      "Episode reward: 1861.4114\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.978564 9.946188 9.977452 8.661286 9.506717 9.972568]\n",
      "Reset environment\n",
      "Episode reward: 2035.1698\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.979403 9.947014 9.978305 8.662242 9.507445 9.973406]\n",
      "Reset environment\n",
      "Episode reward: 4949.2217\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.981824 9.949432 9.980714 8.664855 9.509593 9.975828]\n",
      "Reset environment\n",
      "Episode reward: 2439.7993\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.982845 9.950479 9.9817   8.665985 9.510497 9.976852]\n",
      "Reset environment\n",
      "Episode reward: 1533.4062\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.983481 9.951109 9.982339 8.66671  9.511058 9.977488]\n",
      "Reset environment\n",
      "Episode reward: 2346.6594\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.984512  9.952157  9.9833555 8.667858  9.511974  9.978519 ]\n",
      "Reset environment\n",
      "Episode reward: 5529.945\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.987237 9.954878 9.986076 8.670805 9.514407 9.98124 ]\n",
      "Reset environment\n",
      "Episode reward: 804.991\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.987487  9.9551325 9.986327  8.671124  9.514619  9.981491 ]\n",
      "Reset environment\n",
      "Episode reward: 4177.5615\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.989483  9.957119  9.988328  8.6732855 9.516406  9.983487 ]\n",
      "Reset environment\n",
      "Episode reward: 1789.2146\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.990239 9.957876 9.989082 8.674117 9.517067 9.984245]\n",
      "Reset environment\n",
      "Episode reward: 3052.5825\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.991576 9.959177 9.990447 8.675586 9.518248 9.985583]\n",
      "Reset environment\n",
      "Episode reward: 2102.5051\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.992876 9.960477 9.991739 8.677004 9.519392 9.986886]\n",
      "Reset environment\n",
      "Episode reward: 5801.7017\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.995713 9.963326 9.994567 8.680094 9.521918 9.989726]\n",
      "Reset environment\n",
      "Episode reward: 2764.036\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.996892 9.964533 9.995721 8.681402 9.522972 9.990905]\n",
      "Reset environment\n",
      "Episode reward: 3359.2896\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [9.998477 9.96611  9.997309 8.683123 9.524388 9.992489]\n",
      "Reset environment\n",
      "Episode reward: 3451.9492\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.000112  9.967752  9.998937  8.684909  9.525839  9.994124]\n",
      "Reset environment\n",
      "Episode reward: 1781.4305\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.000919  9.968565  9.999734  8.685805  9.526558  9.994933]\n",
      "Reset environment\n",
      "Episode reward: 1994.2928\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.001733  9.969344 10.000572  8.686713  9.527292  9.995747]\n",
      "Reset environment\n",
      "Episode reward: 3323.921\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.003293  9.970913 10.002124  8.68843   9.528677  9.997305]\n",
      "Reset environment\n",
      "Episode reward: 1343.1492\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.003839  9.971451 10.002677  8.68904   9.529162  9.997851]\n",
      "Reset environment\n",
      "Episode reward: 1980.4166\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.005062  9.972664 10.003895  8.690374  9.530241  9.999073]\n",
      "Reset environment\n",
      "Episode reward: 2428.5479\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.006518  9.974125 10.005342  8.691974  9.531528 10.000532]\n",
      "Reset environment\n",
      "Episode reward: 1712.8473\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.007199  9.974824 10.006002  8.692735  9.532126 10.001215]\n",
      "Reset environment\n",
      "Episode reward: 886.05414\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.0067835  9.974294  10.00571    8.692443   9.531705  10.000803 ]\n",
      "Reset environment\n",
      "Episode reward: 3001.2988\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.008082  9.975561 10.007032  8.693872  9.532876 10.002103]\n",
      "Reset environment\n",
      "Episode reward: 1919.3718\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.008893   9.976364  10.007843   8.694779   9.5335865 10.002913 ]\n",
      "Reset environment\n",
      "Episode reward: 3775.6404\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.010671  9.978133 10.009612  8.696703  9.535173 10.004687]\n",
      "Reset environment\n",
      "Episode reward: 4714.8125\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.012936  9.980386 10.011882  8.699173  9.537203 10.006952]\n",
      "Reset environment\n",
      "Episode reward: 4645.53\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.015155  9.982601 10.014105  8.701592  9.539196 10.009173]\n",
      "Reset environment\n",
      "Episode reward: 2011.253\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.016026  9.983473 10.014975  8.702564  9.539955 10.010044]\n",
      "Reset environment\n",
      "Episode reward: 2116.0295\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.016971  9.984397 10.015932  8.703593  9.540791 10.010986]\n",
      "Reset environment\n",
      "Episode reward: 2716.002\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.018151  9.985545 10.017134  8.704894  9.541827 10.012167]\n",
      "Reset environment\n",
      "Episode reward: 1111.9937\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.01847    9.985841  10.017471   8.705239   9.542156  10.0124855]\n",
      "Reset environment\n",
      "Episode reward: 2442.527\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.0195    9.986838 10.018526  8.706383  9.543066 10.013517]\n",
      "Reset environment\n",
      "Episode reward: 1279.28\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.019944  9.987254 10.018998  8.706898  9.543458 10.013963]\n",
      "Reset environment\n",
      "Episode reward: 2350.2393\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.020964   9.988285  10.020002   8.7080345  9.54436   10.014984 ]\n",
      "Reset environment\n",
      "Episode reward: 1514.1973\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.021924  9.989242 10.020961  8.709105  9.545191 10.015944]\n",
      "Reset environment\n",
      "Episode reward: 1585.9371\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.022591  9.989913 10.021625  8.70986   9.545779 10.016611]\n",
      "Reset environment\n",
      "Episode reward: 2130.088\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.023882  9.9912   10.022921  8.711279  9.546925 10.017903]\n",
      "Reset environment\n",
      "Episode reward: 4383.0815\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.025971   9.9932995 10.024999   8.71355    9.548786  10.019993 ]\n",
      "Reset environment\n",
      "Episode reward: 4515.724\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.028126  9.995459 10.027144  8.715891  9.550709 10.022146]\n",
      "Reset environment\n",
      "Episode reward: 2051.2617\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.028981   9.996294  10.028016   8.7168455  9.551456  10.023002 ]\n",
      "Reset environment\n",
      "Episode reward: 5253.7046\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.031436  9.998758 10.03046   8.719516  9.553664 10.025457]\n",
      "Reset environment\n",
      "Episode reward: 2600.948\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.032563  9.999903 10.031561  8.720761  9.554661 10.026582]\n",
      "Reset environment\n",
      "Episode reward: 1400.189\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.033477 10.000817 10.03247   8.721768  9.555461 10.027494]\n",
      "Reset environment\n",
      "Episode reward: 2006.4263\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.034335 10.001678 10.033327  8.722737  9.556215 10.028352]\n",
      "Reset environment\n",
      "Episode reward: 2539.2986\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.035485 10.002836 10.034473  8.724015  9.557232 10.029503]\n",
      "Reset environment\n",
      "Episode reward: 1986.4958\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.036108  10.003517  10.0350485  8.724778   9.557776  10.030131 ]\n",
      "Reset environment\n",
      "Episode reward: 2399.9712\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.037081 10.004454 10.036054  8.725864  9.558638 10.031106]\n",
      "Reset environment\n",
      "Episode reward: 5395.194\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.039704 10.007075 10.038672  8.728701  9.56098  10.033729]\n",
      "Reset environment\n",
      "Episode reward: 2394.8223\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.040805 10.008172 10.03977   8.729909  9.561959 10.034829]\n",
      "Reset environment\n",
      "Episode reward: 2763.7368\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.042056 10.009433 10.041013  8.731277  9.563068 10.036084]\n",
      "Reset environment\n",
      "Episode reward: 4052.9187\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.043968 10.011333 10.042926  8.733359  9.564772 10.037995]\n",
      "Reset environment\n",
      "Episode reward: 2691.6655\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.045285 10.012642 10.044246  8.734787  9.565956 10.039312]\n",
      "Reset environment\n",
      "Episode reward: 3691.273\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.047    10.014346 10.045973  8.736657  9.567476 10.041028]\n",
      "Reset environment\n",
      "Episode reward: 2309.5515\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.048002 10.015352 10.046968  8.737779  9.568342 10.04203 ]\n",
      "Reset environment\n",
      "Episode reward: 3665.3953\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.049652 10.017005 10.048621  8.739588  9.569823 10.043685]\n",
      "Reset environment\n",
      "Episode reward: 1708.2643\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.050354 10.017716 10.049313  8.740382  9.570453 10.044392]\n",
      "Reset environment\n",
      "Episode reward: 1829.2767\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.051502 10.018864 10.050456  8.741632  9.571463 10.045541]\n",
      "Reset environment\n",
      "Episode reward: 2041.2234\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.052312 10.019642 10.051296  8.74254   9.572194 10.046351]\n",
      "Reset environment\n",
      "Episode reward: 5230.789\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.054829  10.022153  10.053803   8.745268   9.57441   10.0488615]\n",
      "Reset environment\n",
      "Episode reward: 3250.1284\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.056299 10.023604 10.055288  8.746876  9.575711 10.050333]\n",
      "Reset environment\n",
      "Episode reward: 1803.5969\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.057078  10.0243845 10.056063   8.747747   9.576392  10.051112 ]\n",
      "Reset environment\n",
      "Episode reward: 1981.6248\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.058258  10.025566  10.057238   8.7490635  9.577437  10.05229  ]\n",
      "Reset environment\n",
      "Episode reward: 2799.9504\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.059452  10.026791  10.0583935  8.750388   9.578491  10.053486 ]\n",
      "Reset environment\n",
      "Episode reward: 4403.7617\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.061573 10.028918 10.060503  8.752659  9.580366 10.055608]\n",
      "Reset environment\n",
      "Episode reward: 2126.8132\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.062424 10.029736 10.061379  8.753618  9.581112 10.056458]\n",
      "Reset environment\n",
      "Episode reward: 3706.7517\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.06412   10.031441  10.063059   8.75548    9.5826235 10.058158 ]\n",
      "Reset environment\n",
      "Episode reward: 4820.9033\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.066451 10.033767 10.06539   8.758011  9.584705 10.060489]\n",
      "Reset environment\n",
      "Episode reward: 1893.6163\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.067605 10.034916 10.066537  8.759285  9.585718 10.061643]\n",
      "Reset environment\n",
      "Episode reward: -338.43152\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.066991  10.034309  10.0659275  8.758586   9.585179  10.06103  ]\n",
      "Reset environment\n",
      "Episode reward: 1646.2089\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.067689 10.035009 10.066618  8.759356  9.585797 10.061729]\n",
      "Reset environment\n",
      "Episode reward: 1881.5819\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.068832 10.036156 10.067763  8.760624  9.586803 10.062874]\n",
      "Reset environment\n",
      "Episode reward: 2029.5186\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.069717 10.037042 10.06864   8.761586  9.587578 10.063758]\n",
      "Reset environment\n",
      "Episode reward: 1943.3586\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.0709   10.038223 10.069818  8.762901  9.588627 10.06494 ]\n",
      "Reset environment\n",
      "Episode reward: 1622.6583\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.071607 10.038926 10.070529  8.763688  9.589255 10.065647]\n",
      "Reset environment\n",
      "Episode reward: 1304.4608\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.072144 10.039463 10.071066  8.764297  9.589729 10.066188]\n",
      "Reset environment\n",
      "Episode reward: 5906.921\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.075025 10.042332 10.073952  8.767432  9.592324 10.069066]\n",
      "Reset environment\n",
      "Episode reward: 2194.019\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.07599  10.043309 10.074908  8.768512  9.593186 10.070033]\n",
      "Reset environment\n",
      "Episode reward: 2545.6096\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.077076 10.04439  10.075998  8.769723  9.594143 10.071122]\n",
      "Reset environment\n",
      "Episode reward: 2028.0206\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.077826 10.045181 10.076711  8.770588  9.59481  10.071874]\n",
      "Reset environment\n",
      "Episode reward: 2145.496\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.079119 10.046473 10.078009  8.772008  9.595957 10.073167]\n",
      "Reset environment\n",
      "Episode reward: 5821.369\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.081951  10.0493145 10.080832   8.775083   9.5984955 10.076    ]\n",
      "Reset environment\n",
      "Episode reward: 2429.6536\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.082983 10.050324 10.08188   8.776223  9.599406 10.077032]\n",
      "Reset environment\n",
      "Episode reward: 2745.0547\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.084097 10.051406 10.08303   8.777485  9.600402 10.078147]\n",
      "Reset environment\n",
      "Episode reward: 1938.5367\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.085282  10.052593  10.084212   8.7787895  9.601445  10.079332 ]\n",
      "Reset environment\n",
      "Episode reward: 1573.9794\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.085936 10.053261 10.084847  8.779518  9.602032 10.079987]\n",
      "Reset environment\n",
      "Episode reward: 4799.0635\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.088157 10.055485 10.087059  8.781942  9.603989 10.082208]\n",
      "Reset environment\n",
      "Episode reward: 1842.6458\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.088941 10.056258 10.087851  8.78281   9.604687 10.082991]\n",
      "Reset environment\n",
      "Episode reward: 1501.6622\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.089584 10.056898 10.0885    8.783525  9.60526  10.083634]\n",
      "Reset environment\n",
      "Episode reward: 1388.8777\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.090492 10.057812 10.089404  8.784532  9.606054 10.084542]\n",
      "Reset environment\n",
      "Episode reward: 3573.5986\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.092173 10.059499 10.091077  8.786355  9.607541 10.086225]\n",
      "Reset environment\n",
      "Episode reward: 2342.5105\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.093131 10.060483 10.092008  8.78741   9.608378 10.087185]\n",
      "Reset environment\n",
      "Episode reward: 2552.5325\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.094121 10.061513 10.092962  8.78852   9.609258 10.088176]\n",
      "Reset environment\n",
      "Episode reward: 2351.8945\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.095174 10.062579 10.094007  8.789685  9.610205 10.08923 ]\n",
      "Reset environment\n",
      "Episode reward: 1660.8735\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.095911 10.063321 10.094734  8.790501  9.610855 10.089966]\n",
      "Reset environment\n",
      "Episode reward: 5360.0757\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.098501 10.065907 10.097311  8.793317  9.613142 10.092549]\n",
      "Reset environment\n",
      "Episode reward: 2634.4834\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.099701  10.067116  10.098506   8.794633   9.6142235 10.093748 ]\n",
      "Reset environment\n",
      "Episode reward: 3011.844\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.101111 10.068528 10.099903  8.796177  9.615493 10.095155]\n",
      "Reset environment\n",
      "Episode reward: 4914.1553\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.103455 10.070888 10.10224   8.798726  9.617595 10.097501]\n",
      "Reset environment\n",
      "Episode reward: 2504.366\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.104498 10.071951 10.103248  8.799875  9.618512 10.098543]\n",
      "Reset environment\n",
      "Episode reward: 2012.8976\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.105379 10.072824 10.104136  8.800853  9.619297 10.099425]\n",
      "Reset environment\n",
      "Episode reward: 3277.4265\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.10691  10.074365 10.105654  8.802513  9.620666 10.100956]\n",
      "Reset environment\n",
      "Episode reward: 2019.2836\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.108131  10.075586  10.1068735  8.803862   9.621742  10.102178 ]\n",
      "Reset environment\n",
      "Episode reward: 1654.072\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.10865  10.07606  10.107431  8.804482  9.622207 10.102695]\n",
      "Reset environment\n",
      "Episode reward: 4172.43\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.110632 10.078053 10.109402  8.806629  9.623975 10.104677]\n",
      "Reset environment\n",
      "Episode reward: 2101.2188\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.111543 10.078954 10.110314  8.807634  9.624775 10.105589]\n",
      "Reset environment\n",
      "Episode reward: 4649.57\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.11369  10.08109  10.112459  8.809957  9.626683 10.107735]\n",
      "Reset environment\n",
      "Episode reward: 2050.2285\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.114918 10.082319 10.113685  8.811315  9.627763 10.108963]\n",
      "Reset environment\n",
      "Episode reward: 1371.4025\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.115808 10.083206 10.114572  8.812305  9.628542 10.109852]\n",
      "Reset environment\n",
      "Episode reward: 2944.1062\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.117094 10.084493 10.115856  8.813705  9.629682 10.111137]\n",
      "Reset environment\n",
      "Episode reward: 601.62463\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.116845 10.084344 10.115508  8.813423  9.629466 10.110893]\n",
      "Reset environment\n",
      "Episode reward: 2580.5215\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.117829  10.085295  10.1165285  8.814549   9.630341  10.111877 ]\n",
      "Reset environment\n",
      "Episode reward: 4986.8447\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.120233  10.0876875 10.1189375  8.81716    9.632494  10.114284 ]\n",
      "Reset environment\n",
      "Episode reward: 1189.8354\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.120684 10.088152 10.119374  8.817671  9.632894 10.114737]\n",
      "Reset environment\n",
      "Episode reward: 4832.3267\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.122888  10.090368  10.121572   8.8200865  9.634859  10.116941 ]\n",
      "Reset environment\n",
      "Episode reward: 1358.9521\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.123771 10.09125  10.122452  8.821062  9.635637 10.117825]\n",
      "Reset environment\n",
      "Episode reward: 4606.504\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.12597   10.093451  10.1246395  8.823421   9.637589  10.120023 ]\n",
      "Reset environment\n",
      "Episode reward: 5092.6562\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.128422  10.095896  10.1270895  8.826076   9.639788  10.122472 ]\n",
      "Reset environment\n",
      "Episode reward: 1657.6965\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.12905  10.096553 10.12769   8.826782  9.640346 10.123101]\n",
      "Reset environment\n",
      "Episode reward: 2641.7668\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.13004   10.097502  10.128711   8.8279085  9.641239  10.124094 ]\n",
      "Reset environment\n",
      "Episode reward: 2566.28\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.131097 10.098585 10.12974   8.829091  9.642169 10.125153]\n",
      "Reset environment\n",
      "Episode reward: -137.06784\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.130581  10.098097  10.1291895  8.82839    9.641709  10.124637 ]\n",
      "Reset environment\n",
      "Episode reward: 3990.667\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.132452 10.099968 10.131061  8.830423  9.643382 10.12651 ]\n",
      "Reset environment\n",
      "Episode reward: 1788.9746\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.133208 10.10072  10.131819  8.831252  9.644048 10.127266]\n",
      "Reset environment\n",
      "Episode reward: 1616.0306\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.133875  10.101394  10.13248    8.832013   9.644639  10.1279335]\n",
      "Reset environment\n",
      "Episode reward: 4424.702\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.135963 10.103492 10.134558  8.834289  9.646509 10.130022]\n",
      "Reset environment\n",
      "Episode reward: 2807.5173\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.137231  10.104754  10.135826   8.83567    9.647633  10.1312895]\n",
      "Reset environment\n",
      "Episode reward: 4455.2466\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.13933  10.106855 10.137922  8.837967  9.649505 10.133388]\n",
      "Reset environment\n",
      "Episode reward: 1383.6255\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.1402235 10.107748  10.138815   8.838952   9.650289  10.13428  ]\n",
      "Reset environment\n",
      "Episode reward: 1761.9924\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.14132  10.108844 10.139912  8.840157  9.651253 10.135381]\n",
      "Reset environment\n",
      "Episode reward: 2526.9104\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.142433 10.109951 10.141028  8.841394  9.652237 10.136493]\n",
      "Reset environment\n",
      "Episode reward: 240.3659\n",
      "Total Steps: 6\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.142413 10.109931 10.141008  8.841391  9.652208 10.136472]\n",
      "Reset environment\n",
      "Episode reward: 1690.8147\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.1434555 10.110972  10.142053   8.842546   9.653126  10.137513 ]\n",
      "Reset environment\n",
      "Episode reward: 2094.5947\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.144722 10.112235 10.143318  8.843932  9.654246 10.138778]\n",
      "Reset environment\n",
      "Episode reward: 3778.4097\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.146471 10.113977 10.145072  8.845838  9.655807 10.140528]\n",
      "Reset environment\n",
      "Episode reward: 2199.1746\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.147355 10.114865 10.145954  8.846821  9.656578 10.141413]\n",
      "Reset environment\n",
      "Episode reward: 1976.2554\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.148179 10.1157   10.146764  8.847752  9.657307 10.142237]\n",
      "Reset environment\n",
      "Episode reward: 5350.844\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.150754  10.118281  10.149338   8.850539   9.6596155 10.144815 ]\n",
      "Reset environment\n",
      "Episode reward: 1617.0421\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.151413 10.118942 10.149997  8.851286  9.660194 10.145475]\n",
      "Reset environment\n",
      "Episode reward: 2396.5962\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.152501 10.120026 10.151085  8.852472  9.661166 10.146563]\n",
      "Reset environment\n",
      "Episode reward: 1348.9932\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.153039  10.120575  10.1516075  8.85307    9.661648  10.1471   ]\n",
      "Reset environment\n",
      "Episode reward: 2643.0205\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.1541605 10.121673  10.152752   8.854308   9.662641  10.148222 ]\n",
      "Reset environment\n",
      "Episode reward: 3251.1748\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.155647  10.123153  10.1542425  8.855927   9.663969  10.149709 ]\n",
      "Reset environment\n",
      "Episode reward: 1535.5806\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.156215  10.123751  10.1547785  8.856571   9.664471  10.150276 ]\n",
      "Reset environment\n",
      "Episode reward: 4083.8967\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.158138 10.125667 10.156697  8.858649  9.666185 10.152197]\n",
      "Reset environment\n",
      "Episode reward: 2117.7717\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.159053  10.126581  10.157606   8.859665   9.666986  10.1531105]\n",
      "Reset environment\n",
      "Episode reward: 4495.2627\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.161173 10.128696 10.159731  8.861979  9.668888 10.155232]\n",
      "Reset environment\n",
      "Episode reward: 1858.1995\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.161947 10.129465 10.160504  8.862848  9.66956  10.156008]\n",
      "Reset environment\n",
      "Episode reward: 6475.785\n",
      "Total Steps: 220\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.165014 10.132532 10.163571  8.866162  9.6723   10.159077]\n",
      "Reset environment\n",
      "Episode reward: 4299.8135\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.167055 10.134566 10.165607  8.868373  9.674129 10.161118]\n",
      "Reset environment\n",
      "Episode reward: 2506.1177\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.168095 10.135604 10.166646  8.869518  9.675043 10.162158]\n",
      "Reset environment\n",
      "Episode reward: 4927.682\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.170471 10.137977 10.169023  8.872076  9.677156 10.164533]\n",
      "Reset environment\n",
      "Episode reward: 2071.385\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.171686  10.139184  10.170246   8.873436   9.678229  10.1657505]\n",
      "Reset environment\n",
      "Episode reward: 1384.9521\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.172582 10.140078 10.171137  8.874427  9.679011 10.166642]\n",
      "Reset environment\n",
      "Episode reward: 5667.54\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.175296  10.142797  10.173838   8.8773775  9.681445  10.169355 ]\n",
      "Reset environment\n",
      "Episode reward: 2241.112\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.176245  10.1437235 10.174806   8.878424   9.682292  10.170302 ]\n",
      "Reset environment\n",
      "Episode reward: 6019.774\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.1791725 10.146659  10.177716   8.8815975  9.684907  10.173229 ]\n",
      "Reset environment\n",
      "Episode reward: 1352.5627\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.180044 10.147532 10.178587  8.882564  9.685666 10.174103]\n",
      "Reset environment\n",
      "Episode reward: 2740.2524\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.181255 10.148754 10.17978   8.883898  9.68674  10.175315]\n",
      "Reset environment\n",
      "Episode reward: 1858.2372\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.18202  10.149516 10.18055   8.884751  9.687416 10.176082]\n",
      "Reset environment\n",
      "Episode reward: 2495.9216\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.183126 10.150627 10.181647  8.885963  9.688381 10.177188]\n",
      "Reset environment\n",
      "Episode reward: 2765.5215\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.1843   10.15178  10.182835  8.887273  9.68942  10.178361]\n",
      "Reset environment\n",
      "Episode reward: 1981.9513\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.1854925 10.152967  10.184024   8.888585   9.690475  10.179555 ]\n",
      "Reset environment\n",
      "Episode reward: 1434.1046\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.185797 10.153318 10.184303  8.888859  9.690762 10.179858]\n",
      "Reset environment\n",
      "Episode reward: 5084.004\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.188215 10.155733 10.18671   8.891489  9.692921 10.182273]\n",
      "Reset environment\n",
      "Episode reward: 2071.4333\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.189112 10.156627 10.187604  8.892481  9.693707 10.183168]\n",
      "Reset environment\n",
      "Episode reward: 1637.7968\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.189723 10.157265 10.188186  8.893172  9.694245 10.183782]\n",
      "Reset environment\n",
      "Episode reward: 3212.3662\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.19117  10.158704 10.189637  8.89476   9.695539 10.18523 ]\n",
      "Reset environment\n",
      "Episode reward: -128.65326\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.190508 10.158133 10.188888  8.894225  9.694883 10.184575]\n",
      "Reset environment\n",
      "Episode reward: 1381.7506\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.191406  10.159033  10.189785   8.8952055  9.69567   10.185475 ]\n",
      "Reset environment\n",
      "Episode reward: 5453.408\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.194003  10.1616335 10.192376   8.898031   9.697982  10.188073 ]\n",
      "Reset environment\n",
      "Episode reward: 1692.6746\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.19471  10.162349 10.193072  8.898826  9.698612 10.188781]\n",
      "Reset environment\n",
      "Episode reward: 2633.2876\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.195868  10.163502  10.194241   8.900098   9.6996355 10.18994  ]\n",
      "Reset environment\n",
      "Episode reward: 2664.251\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.197044 10.164662 10.195429  8.901389  9.700676 10.191116]\n",
      "Reset environment\n",
      "Episode reward: 3207.7986\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.198483  10.166092  10.196872   8.9029665  9.701958  10.192558 ]\n",
      "Reset environment\n",
      "Episode reward: 4552.642\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.200605 10.168204 10.199     8.905281  9.703858 10.194678]\n",
      "Reset environment\n",
      "Episode reward: 1761.8112\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.201272 10.168895 10.199638  8.906034  9.704448 10.195345]\n",
      "Reset environment\n",
      "Episode reward: 5620.599\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.2039585 10.1715765 10.202328   8.908956   9.706857  10.198034 ]\n",
      "Reset environment\n",
      "Episode reward: 1517.3994\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.204581 10.172184 10.202964  8.909652  9.707412 10.198658]\n",
      "Reset environment\n",
      "Episode reward: 1566.5493\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.205179 10.172757 10.20358   8.910317  9.707941 10.199256]\n",
      "Reset environment\n",
      "Episode reward: 1882.1509\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.205974 10.173565 10.204359  8.911207  9.708654 10.200051]\n",
      "Reset environment\n",
      "Episode reward: 4512.7866\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.208027 10.175621 10.206405  8.913435  9.710484 10.202105]\n",
      "Reset environment\n",
      "Episode reward: 2117.4072\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.209282  10.17687   10.207663   8.914813   9.7115965 10.2033615]\n",
      "Reset environment\n",
      "Episode reward: 1380.5237\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.210172  10.177762  10.2085495  8.915799   9.712376  10.204251 ]\n",
      "Reset environment\n",
      "Episode reward: -537.1499\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.209346 10.176926 10.20773   8.914721  9.71163  10.203424]\n",
      "Reset environment\n",
      "Episode reward: 2757.7722\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.21056  10.178151 10.208923  8.91605   9.712703 10.204635]\n",
      "Reset environment\n",
      "Episode reward: 3239.4792\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.212032 10.179615 10.210398  8.917657  9.714007 10.206108]\n",
      "Reset environment\n",
      "Episode reward: 3975.9158\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.213897 10.181474 10.212249  8.919667  9.715649 10.207972]\n",
      "Reset environment\n",
      "Episode reward: 1754.6318\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.214606 10.182203 10.212936  8.920446  9.716275 10.208684]\n",
      "Reset environment\n",
      "Episode reward: 2138.9473\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.215872 10.183472 10.214191  8.92186   9.717377 10.209948]\n",
      "Reset environment\n",
      "Episode reward: 2273.5425\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.217217 10.184813 10.215536  8.923327  9.718564 10.21129 ]\n",
      "Reset environment\n",
      "Episode reward: 1867.2201\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.218048 10.18564  10.21637   8.924247  9.719301 10.212121]\n",
      "Reset environment\n",
      "Episode reward: 2202.4639\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.219374 10.186969 10.21769   8.925688  9.72046  10.213447]\n",
      "Reset environment\n",
      "Episode reward: 1328.8115\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.219892  10.187497  10.218186   8.926259   9.72092   10.2139635]\n",
      "Reset environment\n",
      "Episode reward: 2439.576\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.220894 10.188486 10.219203  8.927375  9.721794 10.214967]\n",
      "Reset environment\n",
      "Episode reward: 2315.7012\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.22174  10.189296 10.220078  8.928338  9.722544 10.215814]\n",
      "Reset environment\n",
      "Episode reward: 2000.5604\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.222931 10.190479 10.221266  8.929647  9.723594 10.217004]\n",
      "Reset environment\n",
      "Episode reward: 2011.6633\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.224125 10.19167  10.222457  8.930976  9.72465  10.218197]\n",
      "Reset environment\n",
      "Episode reward: 2880.4917\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.225375 10.192918 10.22371   8.932357  9.725761 10.219448]\n",
      "Reset environment\n",
      "Episode reward: 2067.3296\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.226617 10.194159 10.22495   8.933718  9.726861 10.22069 ]\n",
      "Reset environment\n",
      "Episode reward: 817.985\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.226921 10.194462 10.22525   8.933991  9.727156 10.220999]\n",
      "Reset environment\n",
      "Episode reward: 1623.1478\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.227569 10.195126 10.225882  8.934716  9.727732 10.221647]\n",
      "Reset environment\n",
      "Episode reward: 2198.1787\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.228872 10.196435 10.227181  8.936139  9.728884 10.222954]\n",
      "Reset environment\n",
      "Episode reward: 3059.6316\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.23027   10.197825  10.228585   8.9376745  9.730132  10.224351 ]\n",
      "Reset environment\n",
      "Episode reward: 3725.026\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.231942 10.199479 10.230277  8.939513  9.731618 10.226025]\n",
      "Reset environment\n",
      "Episode reward: 2098.0474\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.233199 10.200738 10.231533  8.940888  9.732728 10.227283]\n",
      "Reset environment\n",
      "Episode reward: 1140.9415\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.233604 10.201131 10.231944  8.941278  9.733108 10.22769 ]\n",
      "Reset environment\n",
      "Episode reward: 1821.468\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.234723 10.202248 10.233061  8.942505  9.734088 10.228808]\n",
      "Reset environment\n",
      "Episode reward: 2188.2156\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.235635 10.203136 10.233993  8.943509  9.734906 10.229718]\n",
      "Reset environment\n",
      "Episode reward: 2073.7017\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.236473 10.203958 10.234843  8.944442  9.735652 10.230558]\n",
      "Reset environment\n",
      "Episode reward: 1884.8453\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.237264 10.204752 10.235624  8.945318  9.736341 10.231351]\n",
      "Reset environment\n",
      "Episode reward: 4181.059\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.239222 10.206692 10.237593  8.94744   9.738096 10.233307]\n",
      "Reset environment\n",
      "Episode reward: 231.48593\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.238804 10.206197 10.237242  8.947059  9.737716 10.23289 ]\n",
      "Reset environment\n",
      "Episode reward: 2270.7039\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.2401285 10.207518  10.238564   8.94852    9.7388935 10.234212 ]\n",
      "Reset environment\n",
      "Episode reward: 2060.1926\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.241    10.208387 10.239434  8.949488  9.739661 10.235086]\n",
      "Reset environment\n",
      "Episode reward: -282.33124\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.240176 10.207462 10.23871   8.948641  9.738901 10.234263]\n",
      "Reset environment\n",
      "Episode reward: 1378.6505\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.240726 10.208003 10.239271  8.949258  9.739392 10.234814]\n",
      "Reset environment\n",
      "Episode reward: 870.09827\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.240934 10.208196 10.239487  8.949393  9.739587 10.235023]\n",
      "Reset environment\n",
      "Episode reward: 2256.4646\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.241885 10.209157 10.240426  8.950455  9.74042  10.235973]\n",
      "Reset environment\n",
      "Episode reward: 1406.1572\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.242786 10.210057 10.241326  8.951455  9.74121  10.236874]\n",
      "Reset environment\n",
      "Episode reward: 5449.7275\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.245383 10.21265  10.243925  8.954275  9.743534 10.23947 ]\n",
      "Reset environment\n",
      "Episode reward: 1670.2668\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.2459955 10.21323   10.244563   8.954976   9.744085  10.240082 ]\n",
      "Reset environment\n",
      "Episode reward: 2087.3198\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.246853 10.21411  10.245397  8.955921  9.744841 10.240943]\n",
      "Reset environment\n",
      "Episode reward: 2657.2722\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.248017 10.215287 10.246553  8.9572    9.745876 10.242108]\n",
      "Reset environment\n",
      "Episode reward: -266.331\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.247224 10.21456  10.24569   8.956399  9.745167 10.241317]\n",
      "Reset environment\n",
      "Episode reward: 5746.325\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.249984 10.217312 10.248463  8.959385  9.747671 10.244075]\n",
      "Reset environment\n",
      "Episode reward: 2163.9932\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.251264 10.218583 10.249744  8.960798  9.748814 10.245356]\n",
      "Reset environment\n",
      "Episode reward: 2016.4851\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.252133 10.219432 10.250625  8.961761  9.749591 10.246225]\n",
      "Reset environment\n",
      "Episode reward: 1685.0579\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.252823 10.220121 10.251315  8.962524  9.750192 10.246915]\n",
      "Reset environment\n",
      "Episode reward: 5244.769\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.255307 10.222606 10.253803  8.965218  9.752423 10.249404]\n",
      "Reset environment\n",
      "Episode reward: 3580.365\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.256913  10.224197  10.2554245  8.966968   9.75386   10.251009 ]\n",
      "Reset environment\n",
      "Episode reward: 4354.31\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.258961 10.226239 10.257471  8.96918   9.755682 10.253053]\n",
      "Reset environment\n",
      "Episode reward: 2182.8784\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.259904 10.227177 10.258419  8.970211  9.756519 10.253997]\n",
      "Reset environment\n",
      "Episode reward: 2906.5964\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.2612095 10.2284775 10.259731   8.97163    9.757677  10.255302 ]\n",
      "Reset environment\n",
      "Episode reward: 3379.006\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.262712 10.229966 10.261241  8.973273  9.759008 10.256803]\n",
      "Reset environment\n",
      "Episode reward: 4170.856\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.26466  10.231923 10.263173  8.975378  9.760745 10.258748]\n",
      "Reset environment\n",
      "Episode reward: 2043.3806\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.265875 10.233136 10.264387  8.976714  9.761819 10.259963]\n",
      "Reset environment\n",
      "Episode reward: 1407.7246\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.266779 10.234038 10.26529   8.977709  9.762612 10.260867]\n",
      "Reset environment\n",
      "Episode reward: 1775.8208\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.26739  10.234612 10.265937  8.978421  9.76316  10.261479]\n",
      "Reset environment\n",
      "Episode reward: 3272.6248\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.268866 10.236084 10.267413  8.980038  9.764467 10.262957]\n",
      "Reset environment\n",
      "Episode reward: 1675.6295\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.269877  10.237098  10.268423   8.9811735  9.765349  10.263969 ]\n",
      "Reset environment\n",
      "Episode reward: 4641.36\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.272035 10.239248 10.270586  8.983521  9.767282 10.266128]\n",
      "Reset environment\n",
      "Episode reward: 5917.4253\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.274895 10.242105 10.273438  8.986592  9.769829 10.268984]\n",
      "Reset environment\n",
      "Episode reward: 4844.435\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.277197 10.244404 10.275737  8.989061  9.771862 10.271285]\n",
      "Reset environment\n",
      "Episode reward: 5440.288\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.279807 10.247011 10.278337  8.991869  9.774172 10.273893]\n",
      "Reset environment\n",
      "Episode reward: 1123.3462\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.280178  10.24736   10.2787285  8.992303   9.774498  10.274264 ]\n",
      "Reset environment\n",
      "Episode reward: 4576.647\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.282342  10.249529  10.280884   8.9946575  9.776428  10.276428 ]\n",
      "Reset environment\n",
      "Episode reward: 1550.5598\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.282927 10.250134 10.281442  8.995312  9.776945 10.277014]\n",
      "Reset environment\n",
      "Episode reward: 2053.9583\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.284137  10.251345  10.282649   8.996652   9.7780075 10.278227 ]\n",
      "Reset environment\n",
      "Episode reward: 2474.0903\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.285198 10.252423 10.283695  8.997825  9.77896  10.279293]\n",
      "Reset environment\n",
      "Episode reward: 3324.171\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.286662 10.253861 10.285181  8.999426  9.780258 10.280758]\n",
      "Reset environment\n",
      "Episode reward: 224.89331\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.286187  10.2532625 10.28482    8.999085   9.779796  10.280283 ]\n",
      "Reset environment\n",
      "Episode reward: 2412.991\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.2871685 10.254218  10.285819   9.000173   9.780647  10.281261 ]\n",
      "Reset environment\n",
      "Episode reward: 1765.4656\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.2879   10.254946 10.286553  9.000991  9.781291 10.281995]\n",
      "Reset environment\n",
      "Episode reward: 3388.952\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.289456 10.25649  10.288116  9.002684  9.782677 10.283551]\n",
      "Reset environment\n",
      "Episode reward: 2645.3416\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.290545 10.25761  10.289169  9.003891  9.783645 10.284641]\n",
      "Reset environment\n",
      "Episode reward: 199.47794\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.289929 10.256915 10.288632  9.003266  9.783144 10.284031]\n",
      "Reset environment\n",
      "Episode reward: 5234.987\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.292393 10.259378 10.291083  9.005957  9.785335 10.286492]\n",
      "Reset environment\n",
      "Episode reward: 1548.45\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.2929945 10.260001  10.291661   9.006622   9.785868  10.287097 ]\n",
      "Reset environment\n",
      "Episode reward: 2090.2742\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.294241 10.261243 10.292906  9.007985  9.786968 10.288343]\n",
      "Reset environment\n",
      "Episode reward: -672.1878\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.29305  10.259881 10.291877  9.006899  9.785826 10.287157]\n",
      "Reset environment\n",
      "Episode reward: 5391.147\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.295616  10.2624445 10.294449   9.009679   9.78812   10.289723 ]\n",
      "Reset environment\n",
      "Episode reward: 2454.9778\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.296704 10.263536 10.295536  9.010877  9.789081 10.290814]\n",
      "Reset environment\n",
      "Episode reward: 2679.737\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.297866  10.264688  10.2967005  9.012172   9.790113  10.291981 ]\n",
      "Reset environment\n",
      "Episode reward: 2423.846\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.299295 10.266121 10.298119  9.01372   9.791365 10.29341 ]\n",
      "Reset environment\n",
      "Episode reward: 1437.873\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.29987  10.266679 10.298705  9.01435   9.791873 10.293986]\n",
      "Reset environment\n",
      "Episode reward: 2091.5925\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.300713  10.2675295 10.29953    9.015274   9.792607  10.294828 ]\n",
      "Reset environment\n",
      "Episode reward: 6742.0537\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.291871 10.258789 10.29067   9.000887  9.78467  10.285969]\n",
      "Reset environment\n",
      "Episode reward: 4034.7825\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.293754 10.260674 10.292547  9.002935  9.786342 10.287851]\n",
      "Reset environment\n",
      "Episode reward: 3173.0293\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.295171 10.262094 10.293953  9.004487  9.787595 10.289271]\n",
      "Reset environment\n",
      "Episode reward: 3325.9321\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.296678 10.263602 10.295447  9.006113  9.788923 10.290776]\n",
      "Reset environment\n",
      "Episode reward: 2092.8123\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.29793  10.264858 10.296692  9.007482  9.790017 10.292031]\n",
      "Reset environment\n",
      "Episode reward: 1994.8676\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.298743 10.265666 10.297508  9.008387  9.790731 10.292846]\n",
      "Reset environment\n",
      "Episode reward: 3749.0417\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.3003845 10.26731   10.299146   9.010181   9.792204  10.294488 ]\n",
      "Reset environment\n",
      "Episode reward: 1525.5665\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.301337 10.268263 10.300095  9.011235  9.793033 10.295439]\n",
      "Reset environment\n",
      "Episode reward: 2179.195\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.302182 10.269083 10.300966  9.012181  9.793793 10.296287]\n",
      "Reset environment\n",
      "Episode reward: 5698.4355\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.304874 10.271785 10.303643  9.015091  9.796201 10.29898 ]\n",
      "Reset environment\n",
      "Episode reward: 2149.3147\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.305711 10.272646 10.304449  9.016023  9.796934 10.299815]\n",
      "Reset environment\n",
      "Episode reward: 1439.8749\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.306299 10.273243 10.305027  9.016681  9.797463 10.300403]\n",
      "Reset environment\n",
      "Episode reward: 1965.6001\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.307171 10.274121 10.305886  9.017642  9.79824  10.301275]\n",
      "Reset environment\n",
      "Episode reward: 4751.161\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.309391 10.276355 10.308094  9.02004   9.800205 10.303497]\n",
      "Reset environment\n",
      "Episode reward: 2287.9927\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.310103  10.277112  10.308769   9.020785   9.800859  10.3042145]\n",
      "Reset environment\n",
      "Episode reward: 664.29614\n",
      "Total Steps: 24\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.3102665 10.277287  10.308921   9.020997   9.800998  10.304378 ]\n",
      "Reset environment\n",
      "Episode reward: 3104.9492\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.311636 10.278642 10.310306  9.022486  9.802217 10.305749]\n",
      "Reset environment\n",
      "Episode reward: 2146.626\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.312894  10.279897  10.311568   9.0238695  9.803335  10.307008 ]\n",
      "Reset environment\n",
      "Episode reward: 1340.982\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.313408 10.280428 10.312068  9.024454  9.803789 10.307522]\n",
      "Reset environment\n",
      "Episode reward: 3612.8796\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.314981 10.282003 10.31364   9.026183  9.805197 10.309095]\n",
      "Reset environment\n",
      "Episode reward: 1587.5553\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.315599 10.282604 10.314272  9.02687   9.80574  10.309715]\n",
      "Reset environment\n",
      "Episode reward: 3463.5166\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.317173 10.284179 10.315839  9.02858   9.807126 10.31129 ]\n",
      "Reset environment\n",
      "Episode reward: 4044.7712\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.319056 10.286063 10.317715  9.030627  9.808801 10.313173]\n",
      "Reset environment\n",
      "Episode reward: 3858.4297\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.320754 10.287764 10.319409  9.032472  9.810319 10.314873]\n",
      "Reset environment\n",
      "Episode reward: 4382.436\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.322697 10.289695 10.321363  9.034599  9.812048 10.316818]\n",
      "Reset environment\n",
      "Episode reward: 2392.069\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.323765 10.290754 10.322441  9.035762  9.813004 10.317886]\n",
      "Reset environment\n",
      "Episode reward: 2309.1628\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.324788 10.291772 10.323467  9.03688   9.813922 10.31891 ]\n",
      "Reset environment\n",
      "Episode reward: 2283.307\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.325699 10.292703 10.324353  9.037891  9.814729 10.319817]\n",
      "Reset environment\n",
      "Episode reward: 2931.9998\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.326883 10.293852 10.325569  9.039218  9.815792 10.321006]\n",
      "Reset environment\n",
      "Episode reward: 1909.3712\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.32802  10.294993 10.326703  9.040476  9.816799 10.322143]\n",
      "Reset environment\n",
      "Episode reward: 1943.064\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.328821  10.295806  10.3274975  9.041361   9.817506  10.322945 ]\n",
      "Reset environment\n",
      "Episode reward: 4009.1218\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.330641 10.297613 10.329326  9.043343  9.819134 10.324763]\n",
      "Reset environment\n",
      "Episode reward: 2077.3906\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.331871 10.298841 10.330546  9.044688  9.820213 10.325992]\n",
      "Reset environment\n",
      "Episode reward: 1677.2194\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.332907 10.299879 10.331577  9.04582   9.821118 10.327031]\n",
      "Reset environment\n",
      "Episode reward: 1961.9335\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.333638 10.300634 10.332287  9.04665   9.821766 10.327762]\n",
      "Reset environment\n",
      "Episode reward: 2899.3557\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.334734  10.301688  10.3334255  9.047895   9.82276   10.328859 ]\n",
      "Reset environment\n",
      "Episode reward: 2172.1208\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.335632 10.302575 10.334329  9.048885  9.823551 10.329757]\n",
      "Reset environment\n",
      "Episode reward: 2022.6512\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.336484 10.303423 10.335181  9.049831  9.824301 10.330607]\n",
      "Reset environment\n",
      "Episode reward: 4777.1973\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.33859   10.30553   10.337293   9.0521345  9.826189  10.332717 ]\n",
      "Reset environment\n",
      "Episode reward: 1786.263\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.339241 10.306147 10.337971  9.052873  9.826772 10.333369]\n",
      "Reset environment\n",
      "Episode reward: 5984.038\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.342089 10.308984 10.340822  9.055948  9.829312 10.336216]\n",
      "Reset environment\n",
      "Episode reward: 747.63464\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.342054  10.308903  10.340828   9.055877   9.8293085 10.336185 ]\n",
      "Reset environment\n",
      "Episode reward: 5605.4907\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.344737 10.311582 10.343507  9.058747  9.83169  10.338867]\n",
      "Reset environment\n",
      "Episode reward: 1009.5033\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.3449135 10.311788  10.343654   9.058855   9.831851  10.339047 ]\n",
      "Reset environment\n",
      "Episode reward: 3314.6267\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.346361 10.313227 10.345105  9.060445  9.833141 10.340494]\n",
      "Reset environment\n",
      "Episode reward: 2197.2778\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.347633 10.314506 10.346372  9.061841  9.834241 10.341766]\n",
      "Reset environment\n",
      "Episode reward: 1912.8844\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.348418 10.315287 10.347164  9.062712  9.834931 10.342553]\n",
      "Reset environment\n",
      "Episode reward: 1467.237\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.348998 10.315861 10.347745  9.063372  9.835431 10.343133]\n",
      "Reset environment\n",
      "Episode reward: 2282.2822\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.349964 10.316813 10.348725  9.064442  9.836289 10.344101]\n",
      "Reset environment\n",
      "Episode reward: 1382.6737\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.35084   10.317692  10.349601   9.065421   9.8370495 10.344977 ]\n",
      "Reset environment\n",
      "Episode reward: 1436.7794\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.35141  10.318266 10.350169  9.06606   9.837548 10.345551]\n",
      "Reset environment\n",
      "Episode reward: 2049.5156\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.35227   10.319136  10.351025   9.067004   9.838303  10.3464155]\n",
      "Reset environment\n",
      "Episode reward: 1422.2146\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.352643  10.3194685 10.351439   9.067471   9.838631  10.34679  ]\n",
      "Reset environment\n",
      "Episode reward: 1238.396\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.353082 10.319893 10.351892  9.067976  9.839016 10.347229]\n",
      "Reset environment\n",
      "Episode reward: 1554.3005\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.353627 10.320465 10.352416  9.068603  9.839498 10.347777]\n",
      "Reset environment\n",
      "Episode reward: 1678.3491\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.354301  10.321135  10.353095   9.069357   9.84009   10.3484535]\n",
      "Reset environment\n",
      "Episode reward: 2289.1523\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.355163  10.321957  10.3539915  9.07033    9.84085   10.349315 ]\n",
      "Reset environment\n",
      "Episode reward: 1332.0664\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.355678 10.322457 10.354509  9.070821  9.841344 10.34983 ]\n",
      "Reset environment\n",
      "Episode reward: 2020.6025\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.356518 10.323306 10.355341  9.071745  9.84209  10.350671]\n",
      "Reset environment\n",
      "Episode reward: 4050.1934\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.358368  10.325155  10.357193   9.0737505  9.843743  10.352521 ]\n",
      "Reset environment\n",
      "Episode reward: 2589.3022\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.35941  10.326226 10.358207  9.074913  9.844666 10.353563]\n",
      "Reset environment\n",
      "Episode reward: 1762.3173\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.36012  10.326941 10.35891   9.075725  9.845286 10.354273]\n",
      "Reset environment\n",
      "Episode reward: 2235.7832\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.361037  10.327838  10.359845   9.0767355  9.846098  10.35519  ]\n",
      "Reset environment\n",
      "Episode reward: 2056.379\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.361893  10.328693  10.3607025  9.077686   9.846849  10.356049 ]\n",
      "Reset environment\n",
      "Episode reward: 4769.156\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.364115  10.330915  10.362918   9.080088   9.848822  10.3582735]\n",
      "Reset environment\n",
      "Episode reward: 2173.945\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.365016  10.3318205 10.363804   9.081085   9.849605  10.359173 ]\n",
      "Reset environment\n",
      "Episode reward: 1349.6056\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.365334 10.33211  10.364143  9.081351  9.849917 10.359494]\n",
      "Reset environment\n",
      "Episode reward: 5455.4717\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.367897 10.334666 10.366702  9.084117  9.852203 10.362054]\n",
      "Reset environment\n",
      "Episode reward: 2670.4304\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.369063 10.335835 10.367862  9.085407  9.853225 10.36322 ]\n",
      "Reset environment\n",
      "Episode reward: 2438.9956\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.370118 10.336886 10.368922  9.086556  9.854172 10.364275]\n",
      "Reset environment\n",
      "Episode reward: 2384.764\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.37102  10.337758 10.369857  9.087577  9.854984 10.365179]\n",
      "Reset environment\n",
      "Episode reward: 2557.23\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.372107 10.338867 10.370916  9.088779  9.855946 10.366265]\n",
      "Reset environment\n",
      "Episode reward: 4651.27\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.374289 10.341053 10.37309   9.091128  9.857899 10.368447]\n",
      "Reset environment\n",
      "Episode reward: 2357.2375\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.375326 10.342088 10.374125  9.092265  9.858823 10.369486]\n",
      "Reset environment\n",
      "Episode reward: 1945.1538\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.376478 10.343242 10.375273  9.093535  9.859841 10.370636]\n",
      "Reset environment\n",
      "Episode reward: 4032.7544\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.3783   10.345055 10.377103  9.095523  9.861463 10.372457]\n",
      "Reset environment\n",
      "Episode reward: 1414.757\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.378832 10.345601 10.377613  9.096126  9.861934 10.372989]\n",
      "Reset environment\n",
      "Episode reward: 3873.4187\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.380594 10.347352 10.379382  9.098051  9.863511 10.374753]\n",
      "Reset environment\n",
      "Episode reward: 3508.1904\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.382175  10.348928  10.3809595  9.0997715  9.864913  10.376333 ]\n",
      "Reset environment\n",
      "Episode reward: 1970.7893\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.382801 10.349597 10.381531  9.100508  9.865458 10.376959]\n",
      "Reset environment\n",
      "Episode reward: -1.0543518\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.382132 10.349036 10.380756  9.099833  9.864854 10.376296]\n",
      "Reset environment\n",
      "Episode reward: 4299.7456\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.384132 10.351038 10.382753  9.101989  9.866625 10.378301]\n",
      "Reset environment\n",
      "Episode reward: 1704.1252\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.384817 10.351718 10.383444  9.102761  9.867222 10.378987]\n",
      "Reset environment\n",
      "Episode reward: 1954.5518\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.385629 10.352523 10.384255  9.103672  9.86793  10.379797]\n",
      "Reset environment\n",
      "Episode reward: 2346.563\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.386635 10.353524 10.385257  9.104782  9.868816 10.380803]\n",
      "Reset environment\n",
      "Episode reward: 3031.4033\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.387907 10.354825 10.386499  9.106197  9.869955 10.382077]\n",
      "Reset environment\n",
      "Episode reward: 2517.2122\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.388934 10.355841 10.387514  9.10731   9.870893 10.383109]\n",
      "Reset environment\n",
      "Episode reward: 3129.8342\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.390325 10.357229 10.388901  9.108842  9.872122 10.384497]\n",
      "Reset environment\n",
      "Episode reward: 2244.401\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.39123  10.358135 10.389806  9.109848  9.872908 10.385401]\n",
      "Reset environment\n",
      "Episode reward: 3556.7173\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.3928385 10.3597555 10.3913965  9.111589   9.874316  10.3870125]\n",
      "Reset environment\n",
      "Episode reward: 3457.2266\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.394394 10.361305 10.392953  9.113289  9.875703 10.388571]\n",
      "Reset environment\n",
      "Episode reward: 1363.6205\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.394926 10.361836 10.393486  9.113891  9.876174 10.389103]\n",
      "Reset environment\n",
      "Episode reward: 4399.272\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.396936  10.363855  10.395494   9.1160755  9.877969  10.391115 ]\n",
      "Reset environment\n",
      "Episode reward: 1425.3458\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.397395 10.364299 10.395954  9.116525  9.878379 10.391577]\n",
      "Reset environment\n",
      "Episode reward: 3386.778\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.398909  10.365811  10.3974695  9.118173   9.879722  10.393091 ]\n",
      "Reset environment\n",
      "Episode reward: 2704.7415\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.399987 10.366918 10.39852   9.119389  9.880679 10.394172]\n",
      "Reset environment\n",
      "Episode reward: 3619.189\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.401607  10.3685465 10.400122   9.121149   9.882118  10.395791 ]\n",
      "Reset environment\n",
      "Episode reward: 1088.0237\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.401662 10.368558 10.400219  9.121162  9.882237 10.39585 ]\n",
      "Reset environment\n",
      "Episode reward: 3529.0686\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.40324  10.370134 10.401801  9.122885  9.883642 10.397429]\n",
      "Reset environment\n",
      "Episode reward: 2138.505\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.404133 10.371024 10.402696  9.12387   9.884434 10.398322]\n",
      "Reset environment\n",
      "Episode reward: 5646.4307\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.406785  10.373681  10.4053335  9.126748   9.886806  10.400976 ]\n",
      "Reset environment\n",
      "Episode reward: 2576.0364\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.407875  10.374758  10.406428   9.127949   9.8877735 10.402065 ]\n",
      "Reset environment\n",
      "Episode reward: 2710.3933\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.409069 10.375943 10.407633  9.129256  9.888847 10.40326 ]\n",
      "Reset environment\n",
      "Episode reward: 2034.9764\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.409863 10.376758 10.408406  9.130147  9.889555 10.404056]\n",
      "Reset environment\n",
      "Episode reward: 3542.5146\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.411445 10.378344 10.409985  9.131874  9.890977 10.405638]\n",
      "Reset environment\n",
      "Episode reward: 2310.846\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.412775 10.379675 10.41131   9.133323  9.892151 10.406967]\n",
      "Reset environment\n",
      "Episode reward: 214.0\n",
      "Total Steps: 10\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.4127    10.3796015 10.411236   9.13325    9.892087  10.406893 ]\n",
      "Reset environment\n",
      "Episode reward: -588.5913\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.411859 10.378775 10.410379  9.132138  9.891321 10.406052]\n",
      "Reset environment\n",
      "Episode reward: 991.3401\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.411927 10.37889  10.41039   9.132168  9.891388 10.406123]\n",
      "Reset environment\n",
      "Episode reward: 5605.0664\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.414474 10.381442 10.412926  9.134926  9.893672 10.408671]\n",
      "Reset environment\n",
      "Episode reward: 2417.7366\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.415521 10.382483 10.413979  9.136066  9.894608 10.409713]\n",
      "Reset environment\n",
      "Episode reward: 2138.4543\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.416295 10.383289 10.414721  9.136938  9.89528  10.410487]\n",
      "Reset environment\n",
      "Episode reward: 2109.5906\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.417038 10.38407  10.415428  9.137788  9.895926 10.41123 ]\n",
      "Reset environment\n",
      "Episode reward: 643.8962\n",
      "Total Steps: 23\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.417199 10.384219 10.415596  9.137991  9.896059 10.411391]\n",
      "Reset environment\n",
      "Episode reward: 2825.1416\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.418402 10.385407 10.416809  9.139326  9.897126 10.412596]\n",
      "Reset environment\n",
      "Episode reward: 2289.1401\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.419725  10.386732  10.418131   9.140775   9.898288  10.4139185]\n",
      "Reset environment\n",
      "Episode reward: -67.43207\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.419055 10.386147 10.417378  9.140003  9.897697 10.413254]\n",
      "Reset environment\n",
      "Episode reward: 5348.7363\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.421532 10.388638 10.419836  9.142704  9.899912 10.415728]\n",
      "Reset environment\n",
      "Episode reward: 23.861145\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.420819 10.38798  10.419061  9.142136  9.899215 10.415015]\n",
      "Reset environment\n",
      "Episode reward: 154.52066\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.420462 10.387627 10.418692  9.141621  9.898951 10.414659]\n",
      "Reset environment\n",
      "Episode reward: 2362.6157\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.421454 10.388608 10.419698  9.142706  9.899828 10.415654]\n",
      "Reset environment\n",
      "Episode reward: 1815.2367\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.422187 10.389346 10.420422  9.143516  9.900475 10.416392]\n",
      "Reset environment\n",
      "Episode reward: 5211.3047\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.424517 10.391683 10.422749  9.146043  9.902551 10.418724]\n",
      "Reset environment\n",
      "Episode reward: 2439.5215\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.425511 10.392679 10.42374   9.147145  9.903422 10.419722]\n",
      "Reset environment\n",
      "Episode reward: -493.81482\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.4245   10.391571 10.422821  9.146065  9.902498 10.418717]\n",
      "Reset environment\n",
      "Episode reward: 2033.362\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.425692 10.392763 10.424008  9.147371  9.903542 10.419909]\n",
      "Reset environment\n",
      "Episode reward: 2623.4995\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.426819 10.393896 10.425128  9.148617  9.904519 10.421034]\n",
      "Reset environment\n",
      "Episode reward: 4411.2695\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.429032  10.396094  10.427351   9.15101    9.906523  10.4232435]\n",
      "Reset environment\n",
      "Episode reward: 2885.3142\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.43028  10.397335 10.428602  9.152377  9.90762  10.424492]\n",
      "Reset environment\n",
      "Episode reward: 2201.3083\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.431569 10.398625 10.429889  9.153791  9.908742 10.425781]\n",
      "Reset environment\n",
      "Episode reward: 2464.1865\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.432531 10.399561 10.430876  9.154857  9.909595 10.426744]\n",
      "Reset environment\n",
      "Episode reward: 1894.8196\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.433308 10.400344 10.431643  9.155708  9.910275 10.427522]\n",
      "Reset environment\n",
      "Episode reward: 2007.2051\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.4341345 10.40118   10.432458   9.156626   9.910994  10.42835  ]\n",
      "Reset environment\n",
      "Episode reward: 2099.7927\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.435358 10.402396 10.433682  9.157959  9.912076 10.429571]\n",
      "Reset environment\n",
      "Episode reward: 4816.8687\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.437572  10.4046135 10.435884   9.160359   9.914048  10.431784 ]\n",
      "Reset environment\n",
      "Episode reward: 2812.714\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.438733 10.405747 10.437064  9.161628  9.91509  10.432946]\n",
      "Reset environment\n",
      "Episode reward: 1381.4851\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.4396105 10.406626  10.43794    9.16259    9.915853  10.433825 ]\n",
      "Reset environment\n",
      "Episode reward: -315.52277\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.438923 10.405939 10.437251  9.161824  9.915236 10.433141]\n",
      "Reset environment\n",
      "Episode reward: 5134.731\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.441303 10.408319 10.439618  9.164422  9.917343 10.435514]\n",
      "Reset environment\n",
      "Episode reward: 5107.7617\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.44366  10.41067  10.441982  9.166975  9.919445 10.437874]\n",
      "Reset environment\n",
      "Episode reward: 2521.895\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.444709 10.411738 10.44301   9.168134  9.920375 10.438924]\n",
      "Reset environment\n",
      "Episode reward: 2902.0513\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.445993 10.413017 10.444295  9.169536  9.921523 10.440208]\n",
      "Reset environment\n",
      "Episode reward: 1296.7379\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.4464655 10.413506  10.444746   9.170066   9.921939  10.4406805]\n",
      "Reset environment\n",
      "Episode reward: 2656.2324\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.447643 10.414687 10.445917  9.171361  9.922987 10.441861]\n",
      "Reset environment\n",
      "Episode reward: 1582.2054\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.448296  10.415331  10.44657    9.172079   9.923567  10.4425125]\n",
      "Reset environment\n",
      "Episode reward: 1909.2651\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.448968 10.415973 10.447276  9.172856  9.924168 10.443188]\n",
      "Reset environment\n",
      "Episode reward: 2947.8271\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.450236  10.4172535 10.448534   9.174249   9.925293  10.444462 ]\n",
      "Reset environment\n",
      "Episode reward: 1450.9377\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.45075   10.417794  10.4490185  9.174835   9.925744  10.444978 ]\n",
      "Reset environment\n",
      "Episode reward: 2312.8264\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.45165  10.418666 10.449937  9.175831  9.926535 10.445879]\n",
      "Reset environment\n",
      "Episode reward: 2424.167\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.452615 10.419656 10.450874  9.176908  9.927393 10.446851]\n",
      "Reset environment\n",
      "Episode reward: 2890.784\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.453855 10.420881 10.452124  9.178262  9.928493 10.448089]\n",
      "Reset environment\n",
      "Episode reward: 5331.7666\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.456698 10.423715 10.454966  9.181318  9.931042 10.45093 ]\n",
      "Reset environment\n",
      "Episode reward: 2667.111\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.457785 10.424783 10.456073  9.182527  9.931997 10.452017]\n",
      "Reset environment\n",
      "Episode reward: 3329.582\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.45916   10.426136  10.457477   9.1840515  9.93324   10.453394 ]\n",
      "Reset environment\n",
      "Episode reward: 2494.1912\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.460142  10.4270935 10.458481   9.185139   9.934103  10.454379 ]\n",
      "Reset environment\n",
      "Episode reward: 2981.3958\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.461443 10.428384 10.45978   9.186548  9.935257 10.455679]\n",
      "Reset environment\n",
      "Episode reward: 1764.2706\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.462098 10.429067 10.460406  9.187282  9.935828 10.456336]\n",
      "Reset environment\n",
      "Episode reward: 2073.6309\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.462981 10.429947 10.461292  9.188254  9.936611 10.457219]\n",
      "Reset environment\n",
      "Episode reward: 2182.6892\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.464234 10.431197 10.462546  9.189624  9.937717 10.458471]\n",
      "Reset environment\n",
      "Episode reward: 3453.1592\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.465781 10.43275  10.464073  9.191307  9.939089 10.460019]\n",
      "Reset environment\n",
      "Episode reward: 1338.1602\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.466015  10.433026  10.4642725  9.191505   9.939291  10.46026  ]\n",
      "Reset environment\n",
      "Episode reward: 3515.3508\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.467571 10.434588 10.465815  9.193212  9.940674 10.461819]\n",
      "Reset environment\n",
      "Episode reward: 3591.5142\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.469155 10.436155 10.467406  9.194946  9.942084 10.463401]\n",
      "Reset environment\n",
      "Episode reward: 4707.781\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.471316 10.438295 10.469577  9.197288  9.944023 10.465559]\n",
      "Reset environment\n",
      "Episode reward: 2522.6777\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.472403 10.439385 10.47066   9.19849   9.944989 10.466646]\n",
      "Reset environment\n",
      "Episode reward: 2630.6567\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.473461 10.440479 10.47169   9.199678  9.945934 10.467705]\n",
      "Reset environment\n",
      "Episode reward: 1416.2786\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.474347 10.441364 10.472572  9.200648  9.946711 10.468592]\n",
      "Reset environment\n",
      "Episode reward: 2341.4922\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.475278 10.44232  10.473481  9.201683  9.947539 10.469525]\n",
      "Reset environment\n",
      "Episode reward: 5322.9375\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.477732 10.444769 10.47593   9.204348  9.949716 10.471976]\n",
      "Reset environment\n",
      "Episode reward: 1462.6765\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.478305 10.44534  10.476501  9.204992  9.950215 10.472549]\n",
      "Reset environment\n",
      "Episode reward: 1855.0508\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.479399  10.446427  10.477598   9.206201   9.9511795 10.473641 ]\n",
      "Reset environment\n",
      "Episode reward: 2767.2778\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.480603 10.447628 10.478806  9.207517  9.952249 10.474846]\n",
      "Reset environment\n",
      "Episode reward: 2739.8857\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.481722  10.4487705 10.479898   9.208756   9.953243  10.475968 ]\n",
      "Reset environment\n",
      "Episode reward: 1990.2577\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.482571 10.449628 10.480741  9.209695  9.954003 10.476818]\n",
      "Reset environment\n",
      "Episode reward: 2733.3599\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.483765  10.4508295 10.481931   9.211007   9.955069  10.478014 ]\n",
      "Reset environment\n",
      "Episode reward: 2724.8508\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.484946 10.452016 10.483109  9.212309  9.956103 10.479198]\n",
      "Reset environment\n",
      "Episode reward: 2243.7104\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.48587  10.452923 10.484043  9.213329  9.956918 10.480122]\n",
      "Reset environment\n",
      "Episode reward: 4480.9517\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.487922 10.454976 10.486081  9.215553  9.958733 10.482167]\n",
      "Reset environment\n",
      "Episode reward: 2950.455\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.489101 10.456126 10.487287  9.216853  9.959794 10.483349]\n",
      "Reset environment\n",
      "Episode reward: 2974.833\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.490397 10.457434 10.488576  9.218274  9.96094  10.484645]\n",
      "Reset environment\n",
      "Episode reward: 5159.5796\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.492778 10.459816 10.490938  9.220849  9.963055 10.487023]\n",
      "Reset environment\n",
      "Episode reward: 5359.237\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.495223 10.462272 10.493371  9.22353   9.965225 10.489472]\n",
      "Reset environment\n",
      "Episode reward: 1571.0764\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.495815 10.462846 10.49398   9.22419   9.965749 10.490064]\n",
      "Reset environment\n",
      "Episode reward: 525.405\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.495542  10.4625025 10.493755   9.223822   9.965514  10.489789 ]\n",
      "Reset environment\n",
      "Episode reward: 1803.217\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.496615  10.463578  10.4948225  9.225003   9.966447  10.490868 ]\n",
      "Reset environment\n",
      "Episode reward: 2315.358\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.497939 10.464899 10.496147  9.226446  9.967615 10.492191]\n",
      "Reset environment\n",
      "Episode reward: 1970.8286\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.498612 10.465535 10.49685   9.227218  9.968204 10.492864]\n",
      "Reset environment\n",
      "Episode reward: 1145.7169\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.499037 10.465956 10.497275  9.227701  9.968576 10.493289]\n",
      "Reset environment\n",
      "Episode reward: 2530.5686\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.500122 10.467034 10.498365  9.22889   9.969544 10.494373]\n",
      "Reset environment\n",
      "Episode reward: 3521.9292\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.501667 10.468584 10.499906  9.230582  9.970914 10.495918]\n",
      "Reset environment\n",
      "Episode reward: 2534.7256\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.502753  10.469666  10.500995   9.231763   9.971881  10.4970045]\n",
      "Reset environment\n",
      "Episode reward: 1934.6609\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.503578 10.470495 10.501817  9.232673  9.972622 10.49783 ]\n",
      "Reset environment\n",
      "Episode reward: 2121.1748\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.504458 10.471386 10.502691  9.233643  9.973399 10.498711]\n",
      "Reset environment\n",
      "Episode reward: 5826.328\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.507175 10.474097 10.505409  9.236576  9.975833 10.501425]\n",
      "Reset environment\n",
      "Episode reward: 5197.3486\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.509579 10.476499 10.507817  9.239165  9.977983 10.503829]\n",
      "Reset environment\n",
      "Episode reward: -85.02017\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.508964 10.475827 10.507267  9.238438  9.977455 10.503222]\n",
      "Reset environment\n",
      "Episode reward: 5147.5166\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.51126  10.478123 10.509566  9.240924  9.979496 10.50552 ]\n",
      "Reset environment\n",
      "Episode reward: 2741.342\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.512443 10.479303 10.510754  9.242209  9.980555 10.506705]\n",
      "Reset environment\n",
      "Episode reward: 2659.8547\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.513495  10.4803295 10.5118265  9.243367   9.981493  10.507758 ]\n",
      "Reset environment\n",
      "Episode reward: 1708.1182\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.514173 10.481006 10.512511  9.244125  9.982088 10.508437]\n",
      "Reset environment\n",
      "Episode reward: 3418.2507\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.515624 10.482456 10.51396   9.245709  9.983378 10.509891]\n",
      "Reset environment\n",
      "Episode reward: 1348.3535\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.516131  10.482976  10.514453   9.246278   9.9838295 10.510398 ]\n",
      "Reset environment\n",
      "Episode reward: 2948.7139\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.517366 10.484228 10.515669  9.247644  9.984921 10.511635]\n",
      "Reset environment\n",
      "Episode reward: 2332.9807\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.518327 10.485174 10.516635  9.248711  9.985769 10.512591]\n",
      "Reset environment\n",
      "Episode reward: 176.03586\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.518015 10.484869 10.516307  9.248236  9.985513 10.512282]\n",
      "Reset environment\n",
      "Episode reward: 5315.0923\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.520446  10.487308  10.518731   9.2508745  9.9876795 10.514711 ]\n",
      "Reset environment\n",
      "Episode reward: 2619.612\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.521533 10.488404 10.519809  9.252081  9.988643 10.515801]\n",
      "Reset environment\n",
      "Episode reward: 3014.6448\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.522824 10.489691 10.521102  9.253491  9.989791 10.517093]\n",
      "Reset environment\n",
      "Episode reward: 1851.9392\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.523592 10.490463 10.521862  9.254344  9.990475 10.51786 ]\n",
      "Reset environment\n",
      "Episode reward: 2673.233\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5247555 10.491633  10.523016   9.2556095  9.991503  10.519024 ]\n",
      "Reset environment\n",
      "Episode reward: 338.97366\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.524367 10.491171 10.522699  9.255157  9.991167 10.518646]\n",
      "Reset environment\n",
      "Episode reward: 3021.4185\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.525698 10.492491 10.524032  9.25659   9.992333 10.519977]\n",
      "Reset environment\n",
      "Episode reward: 1011.3262\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.526051 10.492835 10.524385  9.256998  9.99264  10.52033 ]\n",
      "Reset environment\n",
      "Episode reward: 2078.3862\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.526876 10.493638 10.525229  9.257916  9.993376 10.521157]\n",
      "Reset environment\n",
      "Episode reward: 1661.6409\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.527498 10.494274 10.525831  9.258613  9.993919 10.521778]\n",
      "Reset environment\n",
      "Episode reward: 3029.6077\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.528818 10.495601 10.527141  9.26005   9.995073 10.523096]\n",
      "Reset environment\n",
      "Episode reward: 2367.163\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.529694 10.49644  10.528043  9.261041  9.995854 10.523972]\n",
      "Reset environment\n",
      "Episode reward: 5097.1313\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.532042 10.498789 10.530376  9.263592  9.99794  10.526318]\n",
      "Reset environment\n",
      "Episode reward: -369.06647\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.531396 10.498149 10.529723  9.262753  9.997374 10.525675]\n",
      "Reset environment\n",
      "Episode reward: 1380.3738\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.531948 10.498698 10.530273  9.263369  9.997869 10.526227]\n",
      "Reset environment\n",
      "Episode reward: 2067.9536\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.533138 10.499893 10.531459  9.264675  9.998905 10.527417]\n",
      "Reset environment\n",
      "Episode reward: 2772.6807\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.534324 10.501072 10.532648  9.26597   9.999954 10.528603]\n",
      "Reset environment\n",
      "Episode reward: 5250.4165\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.536746 10.503483 10.535087  9.268599 10.002142 10.531023]\n",
      "Reset environment\n",
      "Episode reward: 2079.6487\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.537957 10.504692 10.536293  9.269934 10.003201 10.532233]\n",
      "Reset environment\n",
      "Episode reward: 3012.794\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.539284  10.506012  10.5376215  9.27136   10.004372  10.533557 ]\n",
      "Reset environment\n",
      "Episode reward: 2339.652\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.540242 10.50698  10.538563  9.272425 10.00521  10.534514]\n",
      "Reset environment\n",
      "Episode reward: 2142.2\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.541081 10.507817 10.539401  9.273352 10.005939 10.535354]\n",
      "Reset environment\n",
      "Episode reward: 2059.3936\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.542264 10.508999 10.540585  9.274654 10.006982 10.536536]\n",
      "Reset environment\n",
      "Episode reward: 1858.3774\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.543358 10.510091 10.541678  9.275851 10.007949 10.53763 ]\n",
      "Reset environment\n",
      "Episode reward: -330.23322\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5425625 10.509257  10.540926   9.274998  10.007257  10.536837 ]\n",
      "Reset environment\n",
      "Episode reward: 1999.4783\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.543259 10.509916 10.541651  9.275795 10.007877 10.537534]\n",
      "Reset environment\n",
      "Episode reward: 1733.2284\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.543962 10.510632 10.542343  9.276573 10.008511 10.538238]\n",
      "Reset environment\n",
      "Episode reward: 4721.0024\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.546039 10.512706 10.544418  9.278829 10.010363 10.540313]\n",
      "Reset environment\n",
      "Episode reward: 1607.3025\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.546646 10.513322 10.545019  9.279515 10.010894 10.540921]\n",
      "Reset environment\n",
      "Episode reward: 1167.0449\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.547065  10.513751  10.5454235  9.279989  10.011264  10.541339 ]\n",
      "Reset environment\n",
      "Episode reward: 2206.7002\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.547939 10.514646 10.546272  9.280952 10.01204  10.542214]\n",
      "Reset environment\n",
      "Episode reward: 476.59018\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.547619 10.514396 10.54589   9.280549 10.011767 10.541901]\n",
      "Reset environment\n",
      "Episode reward: 2048.5127\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.54852  10.515281 10.546801  9.281527 10.012577 10.5428  ]\n",
      "Reset environment\n",
      "Episode reward: 4894.0635\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5376625 10.504253  10.535705   9.269113  10.00239   10.531881 ]\n",
      "Reset environment\n",
      "Episode reward: 795.9077\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5376425 10.504273  10.535647   9.2690115 10.002363  10.53187  ]\n",
      "Reset environment\n",
      "Episode reward: 1596.0773\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.538273 10.504914 10.536271  9.269712 10.002927 10.532503]\n",
      "Reset environment\n",
      "Episode reward: 3368.5786\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.539718 10.506351 10.537726  9.271308 10.004222 10.533947]\n",
      "Reset environment\n",
      "Episode reward: 1728.0332\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.540401 10.507042 10.538402  9.272068 10.004819 10.534631]\n",
      "Reset environment\n",
      "Episode reward: 4421.276\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.542378 10.509009 10.540389  9.274219 10.006595 10.536608]\n",
      "Reset environment\n",
      "Episode reward: 1376.5682\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.542887 10.509537 10.540877  9.274786 10.007047 10.537118]\n",
      "Reset environment\n",
      "Episode reward: 2941.8464\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.544158 10.510814 10.542141  9.276173 10.008154 10.538389]\n",
      "Reset environment\n",
      "Episode reward: 2039.0676\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.544989 10.51163  10.542984  9.277084 10.008897 10.539221]\n",
      "Reset environment\n",
      "Episode reward: 2150.4116\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.545863  10.512514  10.543848   9.278045  10.0096655 10.540096 ]\n",
      "Reset environment\n",
      "Episode reward: 601.68896\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.545651 10.512383 10.543549  9.277834 10.009483 10.539887]\n",
      "Reset environment\n",
      "Episode reward: 2262.9016\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.546505 10.513266 10.544376  9.278799 10.010248 10.540743]\n",
      "Reset environment\n",
      "Episode reward: 3011.6719\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.54779  10.514563 10.545645  9.280205 10.011385 10.542028]\n",
      "Reset environment\n",
      "Episode reward: 2522.3582\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.548837 10.515618 10.546675  9.281339 10.012314 10.543075]\n",
      "Reset environment\n",
      "Episode reward: 1816.8633\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.549569 10.516356 10.547404  9.282149 10.012964 10.54381 ]\n",
      "Reset environment\n",
      "Episode reward: 1770.9703\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.550253 10.517055 10.548072  9.282904 10.013559 10.544494]\n",
      "Reset environment\n",
      "Episode reward: 904.7295\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.550319 10.517149 10.548103  9.282878 10.013612 10.544565]\n",
      "Reset environment\n",
      "Episode reward: 3933.4941\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.552049 10.518869 10.549845  9.284778 10.015167 10.546297]\n",
      "Reset environment\n",
      "Episode reward: 542.71155\n",
      "Total Steps: 17\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.552158  10.518984  10.5499525  9.284926  10.015258  10.546407 ]\n",
      "Reset environment\n",
      "Episode reward: 2513.4534\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5530815 10.519875  10.550905   9.285968  10.0160885 10.547331 ]\n",
      "Reset environment\n",
      "Episode reward: 1463.5759\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.553655  10.5204525 10.551478   9.286612  10.016596  10.547905 ]\n",
      "Reset environment\n",
      "Episode reward: 1565.4319\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.55461  10.521403 10.552427  9.287653 10.017425 10.548858]\n",
      "Reset environment\n",
      "Episode reward: 2541.4023\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.555666 10.522455 10.553481  9.288816 10.018346 10.549914]\n",
      "Reset environment\n",
      "Episode reward: 1412.7009\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.556215  10.522994  10.554035   9.289431  10.0188265 10.550466 ]\n",
      "Reset environment\n",
      "Episode reward: 1228.9965\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.556485  10.523223  10.554336   9.289694  10.019101  10.5507345]\n",
      "Reset environment\n",
      "Episode reward: 2179.249\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.557732 10.524465 10.555582  9.291052 10.020196 10.551981]\n",
      "Reset environment\n",
      "Episode reward: 1847.4816\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.558423  10.525134  10.5562935  9.291826  10.020812  10.552671 ]\n",
      "Reset environment\n",
      "Episode reward: 1378.5978\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.559278 10.525986 10.55714   9.292768 10.021546 10.553523]\n",
      "Reset environment\n",
      "Episode reward: 2169.469\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.560141 10.526839 10.558019  9.293721 10.022318 10.554388]\n",
      "Reset environment\n",
      "Episode reward: 1633.4866\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.560763 10.527476 10.558622  9.294411 10.022864 10.555012]\n",
      "Reset environment\n",
      "Episode reward: 3377.6917\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.562206 10.52891  10.560069  9.295997 10.024151 10.556455]\n",
      "Reset environment\n",
      "Episode reward: 4386.077\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.564184  10.53089   10.562041   9.298156  10.025918  10.5584345]\n",
      "Reset environment\n",
      "Episode reward: 2724.4878\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.565348 10.532057 10.563202  9.29943  10.026939 10.559598]\n",
      "Reset environment\n",
      "Episode reward: 2498.6277\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.566404 10.533108 10.564261  9.300588 10.027879 10.560658]\n",
      "Reset environment\n",
      "Episode reward: 5416.6855\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.568903 10.535612 10.566753  9.303266 10.030117 10.563159]\n",
      "Reset environment\n",
      "Episode reward: 1371.1785\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.56975  10.536458 10.567599  9.304206 10.030859 10.564006]\n",
      "Reset environment\n",
      "Episode reward: -141.54056\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.569139 10.535793 10.567045  9.303462 10.030318 10.563396]\n",
      "Reset environment\n",
      "Episode reward: 3448.7605\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.570683  10.537333  10.568592   9.305145  10.031688  10.5649395]\n",
      "Reset environment\n",
      "Episode reward: 3409.4858\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.572179 10.538841 10.570078  9.306787 10.033011 10.566437]\n",
      "Reset environment\n",
      "Episode reward: 4769.166\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.57431  10.540985 10.572204  9.309105 10.034918 10.56857 ]\n",
      "Reset environment\n",
      "Episode reward: 1568.7906\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.574976 10.54164  10.572877  9.309796 10.035537 10.569239]\n",
      "Reset environment\n",
      "Episode reward: 1527.9182\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.575593 10.542258 10.573495  9.310487 10.036085 10.569856]\n",
      "Reset environment\n",
      "Episode reward: 2002.4048\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5767565 10.543415  10.5746565  9.31176   10.037101  10.571019 ]\n",
      "Reset environment\n",
      "Episode reward: 2171.5444\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.577604 10.544285 10.57548   9.312701 10.03785  10.571868]\n",
      "Reset environment\n",
      "Episode reward: 2439.4124\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.578616 10.545281 10.576498  9.313825 10.038747 10.572875]\n",
      "Reset environment\n",
      "Episode reward: 2303.7893\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.579507 10.546196 10.577362  9.314818 10.039528 10.573768]\n",
      "Reset environment\n",
      "Episode reward: 1905.1335\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5802355 10.546902  10.578112   9.315631  10.040169  10.5745   ]\n",
      "Reset environment\n",
      "Episode reward: 1402.6136\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.580533  10.547235  10.578367   9.315892  10.040423  10.5748005]\n",
      "Reset environment\n",
      "Episode reward: 2154.1523\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.581425 10.548126 10.579254  9.316883 10.041195 10.575693]\n",
      "Reset environment\n",
      "Episode reward: 5409.2803\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.583913 10.550619 10.581732  9.319569 10.043391 10.578179]\n",
      "Reset environment\n",
      "Episode reward: 174.25104\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.583162 10.549962 10.580882  9.318951 10.042689 10.577428]\n",
      "Reset environment\n",
      "Episode reward: 2413.4045\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.58416   10.550945  10.581892   9.3200445 10.043579  10.578425 ]\n",
      "Reset environment\n",
      "Episode reward: 4807.573\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.586334 10.553127 10.58406   9.322392 10.045499 10.580598]\n",
      "Reset environment\n",
      "Episode reward: 2341.1326\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.587275 10.554084 10.584977  9.323429 10.046336 10.581538]\n",
      "Reset environment\n",
      "Episode reward: 1684.4429\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.5882845 10.555095  10.585987   9.324533  10.047214  10.58255  ]\n",
      "Reset environment\n",
      "Episode reward: 3060.147\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.589555 10.556362 10.587253  9.32591  10.048335 10.58382 ]\n",
      "Reset environment\n",
      "Episode reward: 1716.6876\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.590568 10.557375 10.588266  9.327022 10.049217 10.584831]\n",
      "Reset environment\n",
      "Episode reward: 5212.0327\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.592935 10.559749 10.590618  9.329596 10.05131  10.587197]\n",
      "Reset environment\n",
      "Episode reward: 3017.1643\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.594218 10.561062 10.591872  9.331    10.052462 10.588484]\n",
      "Reset environment\n",
      "Episode reward: 5263.181\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.596628 10.56347  10.594278  9.333603 10.054607 10.590895]\n",
      "Reset environment\n",
      "Episode reward: 1888.5083\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.597375 10.564223 10.595012  9.334425 10.055264 10.59164 ]\n",
      "Reset environment\n",
      "Episode reward: 2924.8962\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.598643  10.565493  10.596277   9.3358135 10.056372  10.592911 ]\n",
      "Reset environment\n",
      "Episode reward: 2093.662\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.59984  10.566687 10.597471  9.337127 10.057425 10.59411 ]\n",
      "Reset environment\n",
      "Episode reward: 2471.732\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.600915  10.567752  10.598554   9.3383    10.0583935 10.595183 ]\n",
      "Reset environment\n",
      "Episode reward: 1686.145\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.601476 10.568361 10.599071  9.338945 10.058897 10.595745]\n",
      "Reset environment\n",
      "Episode reward: 2208.6936\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.602366  10.5692625 10.599952   9.339927  10.059685  10.596636 ]\n",
      "Reset environment\n",
      "Episode reward: 3513.3774\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.603905 10.570799 10.601489  9.341596 10.061047 10.598173]\n",
      "Reset environment\n",
      "Episode reward: 2522.8252\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.60494  10.571849 10.602504  9.342725 10.061961 10.599212]\n",
      "Reset environment\n",
      "Episode reward: 2054.0537\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.605796 10.572709 10.603351  9.343657 10.062724 10.600066]\n",
      "Reset environment\n",
      "Episode reward: 2623.775\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.606879 10.573806 10.604411  9.344847 10.063678 10.601148]\n",
      "Reset environment\n",
      "Episode reward: 1971.2355\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.607675 10.574603 10.605202  9.345736 10.064367 10.601944]\n",
      "Reset environment\n",
      "Episode reward: 5629.6987\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.610292 10.577221 10.607809  9.348561 10.066701 10.604563]\n",
      "Reset environment\n",
      "Episode reward: 2693.7302\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.611447 10.578384 10.608952  9.349839 10.067723 10.605716]\n",
      "Reset environment\n",
      "Episode reward: 1539.3633\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.612049  10.578987  10.609552   9.350524  10.068246  10.6063175]\n",
      "Reset environment\n",
      "Episode reward: 4121.8193\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.613905 10.580838 10.611399  9.35254  10.069869 10.60817 ]\n",
      "Reset environment\n",
      "Episode reward: 2599.553\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.6150055 10.581945  10.6124935  9.353758  10.070844  10.60927  ]\n",
      "Reset environment\n",
      "Episode reward: 2667.1184\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.616094 10.58302  10.613587  9.35497  10.071811 10.610359]\n",
      "Reset environment\n",
      "Episode reward: 4359.4316\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.61808  10.58501  10.615563  9.357114 10.073573 10.612349]\n",
      "Reset environment\n",
      "Episode reward: 2082.6567\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.618827  10.5857315 10.616335   9.357954  10.074233  10.613097 ]\n",
      "Reset environment\n",
      "Episode reward: 2078.1316\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.620003 10.586907 10.617507  9.359259 10.075269 10.614275]\n",
      "Reset environment\n",
      "Episode reward: 3067.748\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.621325  10.588224  10.6188345  9.3607025 10.076439  10.615597 ]\n",
      "Reset environment\n",
      "Episode reward: 2112.6658\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.622165  10.5890665 10.619668   9.361646  10.077157  10.616439 ]\n",
      "Reset environment\n",
      "Episode reward: 4524.505\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.624199 10.59111  10.621695  9.363866 10.078951 10.618474]\n",
      "Reset environment\n",
      "Episode reward: 2589.005\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.625224  10.5921335 10.6227255  9.36498   10.079855  10.619503 ]\n",
      "Reset environment\n",
      "Episode reward: 1831.1208\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.625951 10.592856 10.623453  9.365786 10.080493 10.620227]\n",
      "Reset environment\n",
      "Episode reward: 1799.7844\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.6265955 10.593521  10.624072   9.3665085 10.0810585 10.620872 ]\n",
      "Reset environment\n",
      "Episode reward: 2189.577\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.627422 10.594322 10.62492   9.367426 10.081792 10.621702]\n",
      "Reset environment\n",
      "Episode reward: 5236.073\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.62969   10.5965805 10.627189   9.369884  10.083813  10.62397  ]\n",
      "Reset environment\n",
      "Episode reward: 3733.157\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.631351 10.598248 10.628842  9.371682 10.085273 10.625631]\n",
      "Reset environment\n",
      "Episode reward: 1595.8323\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.63196   10.598874  10.62944    9.3723545 10.085812  10.626242 ]\n",
      "Reset environment\n",
      "Episode reward: 1191.1394\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.632085 10.598946 10.629613  9.372464 10.085953 10.626369]\n",
      "Reset environment\n",
      "Episode reward: 1745.7759\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.632775  10.599647  10.6303005  9.373234  10.08657   10.62706  ]\n",
      "Reset environment\n",
      "Episode reward: 2185.0312\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.633672 10.600544 10.631197  9.374227 10.087348 10.627959]\n",
      "Reset environment\n",
      "Episode reward: 1473.2616\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.634239 10.601112 10.631762  9.37486  10.087845 10.628528]\n",
      "Reset environment\n",
      "Episode reward: 1961.6892\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.635037 10.601912 10.632553  9.375736 10.08853  10.629327]\n",
      "Reset environment\n",
      "Episode reward: 2231.0376\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.635869 10.602713 10.633406  9.376664 10.08926  10.630159]\n",
      "Reset environment\n",
      "Episode reward: 118.554596\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.6355095 10.602378  10.633024   9.376115  10.088961  10.629806 ]\n",
      "Reset environment\n",
      "Episode reward: 2126.0452\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.63639  10.603252 10.63391   9.377085 10.089744 10.630687]\n",
      "Reset environment\n",
      "Episode reward: 4560.7427\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.638362  10.605226  10.6358795  9.37922   10.091511  10.632657 ]\n",
      "Reset environment\n",
      "Episode reward: 1641.8859\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.639009  10.6058855 10.636509   9.379942  10.092092  10.633309 ]\n",
      "Reset environment\n",
      "Episode reward: 1880.2683\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.639717 10.606615 10.637195  9.380735 10.092721 10.63402 ]\n",
      "Reset environment\n",
      "Episode reward: 5408.749\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.642195 10.609087 10.63967   9.383399 10.094915 10.636496]\n",
      "Reset environment\n",
      "Episode reward: 1901.4431\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.643303 10.610193 10.64077   9.384612 10.095873 10.637602]\n",
      "Reset environment\n",
      "Episode reward: 3976.4707\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.645073  10.61197   10.6425295  9.386541  10.09743   10.639372 ]\n",
      "Reset environment\n",
      "Episode reward: 5614.7686\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.6475315 10.614429  10.644984   9.389206  10.09963   10.641832 ]\n",
      "Reset environment\n",
      "Episode reward: 3721.7957\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.649173 10.616075 10.646608  9.390983 10.101066 10.643474]\n",
      "Reset environment\n",
      "Episode reward: 2206.457\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.649978 10.616849 10.64744   9.391893 10.10179  10.644279]\n",
      "Reset environment\n",
      "Episode reward: 1614.3212\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.650516 10.617415 10.647945  9.392509 10.102263 10.644818]\n",
      "Reset environment\n",
      "Episode reward: 1559.8988\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.651068 10.61794  10.648518  9.393132 10.102759 10.645371]\n",
      "Reset environment\n",
      "Episode reward: 1339.4784\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.651258 10.61809  10.648758  9.393321 10.102982 10.645564]\n",
      "Reset environment\n",
      "Episode reward: 4079.2922\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.653063 10.619887 10.650561  9.395282 10.104576 10.647371]\n",
      "Reset environment\n",
      "Episode reward: 1453.1097\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.653622 10.620452 10.651116  9.395909 10.105068 10.647932]\n",
      "Reset environment\n",
      "Episode reward: 1373.865\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.6544695 10.621299  10.65196    9.396839  10.105801  10.648782 ]\n",
      "Reset environment\n",
      "Episode reward: 1398.8771\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.65496  10.621814 10.652428  9.397395 10.106238 10.649274]\n",
      "Reset environment\n",
      "Episode reward: 1426.6539\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.655475 10.622352 10.652921  9.397968 10.1067   10.649789]\n",
      "Reset environment\n",
      "Episode reward: 5026.46\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.657727 10.624595 10.655182  9.400412 10.108709 10.652042]\n",
      "Reset environment\n",
      "Episode reward: 2538.0884\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.658748  10.6256    10.656216   9.401534  10.1096115 10.653064 ]\n",
      "Reset environment\n",
      "Episode reward: 1406.4135\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.659612 10.626457 10.657075  9.402484 10.110357 10.653929]\n",
      "Reset environment\n",
      "Episode reward: 5720.817\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.662188  10.629046  10.659641   9.405283  10.1126585 10.656506 ]\n",
      "Reset environment\n",
      "Episode reward: 2939.9897\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.663433 10.630287 10.660889  9.406643 10.113755 10.657753]\n",
      "Reset environment\n",
      "Episode reward: 1742.1902\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.66446  10.631316 10.661914  9.407763 10.114649 10.658782]\n",
      "Reset environment\n",
      "Episode reward: 1503.0159\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.665048 10.631906 10.662494  9.40842  10.11516  10.659369]\n",
      "Reset environment\n",
      "Episode reward: -438.43997\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.664297 10.631112 10.661784  9.407492 10.114476 10.65862 ]\n",
      "Reset environment\n",
      "Episode reward: 1503.2137\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.664879 10.631711 10.662354  9.408137 10.114997 10.659202]\n",
      "Reset environment\n",
      "Episode reward: 1368.3949\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.665723 10.632555 10.663191  9.40906  10.115724 10.660043]\n",
      "Reset environment\n",
      "Episode reward: 3894.1577\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.667434 10.634272 10.664881  9.41093  10.117223 10.661752]\n",
      "Reset environment\n",
      "Episode reward: 2830.1765\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.668512  10.6353245 10.665988   9.412134  10.118199  10.662832 ]\n",
      "Reset environment\n",
      "Episode reward: 2061.3975\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.669686 10.6365   10.667158  9.413425 10.119227 10.664007]\n",
      "Reset environment\n",
      "Episode reward: 1349.6337\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.670199 10.637006 10.667676  9.414003 10.119681 10.66452 ]\n",
      "Reset environment\n",
      "Episode reward: 2394.021\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.671161 10.637967 10.668631  9.415058 10.120528 10.66548 ]\n",
      "Reset environment\n",
      "Episode reward: 2090.1243\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.672338 10.639144 10.669795  9.416354 10.121544 10.666655]\n",
      "Reset environment\n",
      "Episode reward: 4928.457\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.674476 10.641289 10.671928  9.418676 10.123456 10.668796]\n",
      "Reset environment\n",
      "Episode reward: 649.4911\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.674343 10.641196 10.671749  9.418441 10.123335 10.668665]\n",
      "Reset environment\n",
      "Episode reward: 2060.8313\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.675526 10.642383 10.67293   9.419734 10.124361 10.669848]\n",
      "Reset environment\n",
      "Episode reward: 3386.5342\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.676997 10.643844 10.674405  9.421321 10.125662 10.67132 ]\n",
      "Reset environment\n",
      "Episode reward: 4443.668\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.678959 10.645802 10.676366  9.423458 10.127395 10.673283]\n",
      "Reset environment\n",
      "Episode reward: 3474.7288\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.680465 10.647316 10.67786   9.425088 10.128713 10.67479 ]\n",
      "Reset environment\n",
      "Episode reward: 2021.53\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.681231 10.64805  10.678642  9.425938 10.129397 10.675554]\n",
      "Reset environment\n",
      "Episode reward: 2962.3933\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.682502  10.649324  10.679909   9.4273405 10.130522  10.676827 ]\n",
      "Reset environment\n",
      "Episode reward: 2103.08\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.683342  10.650154  10.6807575  9.4282675 10.131268  10.677669 ]\n",
      "Reset environment\n",
      "Episode reward: 1846.9613\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.684037 10.65087  10.681426  9.429035 10.131875 10.678364]\n",
      "Reset environment\n",
      "Episode reward: 79.98007\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.683561 10.650323 10.681005  9.428449 10.13145  10.677887]\n",
      "Reset environment\n",
      "Episode reward: 2239.0027\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.684285  10.651     10.681763   9.4292145 10.13214   10.678612 ]\n",
      "Reset environment\n",
      "Episode reward: 2049.9507\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.685102 10.651809 10.682583  9.430121 10.132861 10.679427]\n",
      "Reset environment\n",
      "Episode reward: 4200.7847\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.686953  10.6536665 10.684426   9.432123  10.134518  10.68128  ]\n",
      "Reset environment\n",
      "Episode reward: 4843.75\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.689027 10.65574  10.686499  9.434367 10.136368 10.683354]\n",
      "Reset environment\n",
      "Episode reward: 3384.4058\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.690486 10.657205 10.687949  9.435955 10.137639 10.68481 ]\n",
      "Reset environment\n",
      "Episode reward: 1814.5477\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.691541 10.658258 10.689004  9.437113 10.138556 10.685869]\n",
      "Reset environment\n",
      "Episode reward: 1359.0575\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.692043 10.658773 10.689488  9.437678 10.139    10.686371]\n",
      "Reset environment\n",
      "Episode reward: 4861.5835\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.694228 10.660963 10.691666  9.440033 10.140928 10.688556]\n",
      "Reset environment\n",
      "Episode reward: 2789.9192\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.695379 10.662099 10.69283   9.44129  10.14195  10.689707]\n",
      "Reset environment\n",
      "Episode reward: 1906.8466\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.69613  10.662854 10.693571  9.442125 10.142609 10.690459]\n",
      "Reset environment\n",
      "Episode reward: 2209.76\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.697382 10.664108 10.694818  9.44349  10.143699 10.69171 ]\n",
      "Reset environment\n",
      "Episode reward: 1989.1115\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.698103  10.664806  10.69556    9.444294  10.144333  10.6924305]\n",
      "Reset environment\n",
      "Episode reward: 2515.2336\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.699145 10.665845 10.696606  9.44543  10.145257 10.693471]\n",
      "Reset environment\n",
      "Episode reward: 2167.6213\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.7003565 10.667053  10.697819   9.446756  10.146334  10.694684 ]\n",
      "Reset environment\n",
      "Episode reward: 1818.9027\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.701056 10.667764 10.698497  9.447519 10.146951 10.695383]\n",
      "Reset environment\n",
      "Episode reward: 3898.7334\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.702763 10.669472 10.700192  9.449386 10.148461 10.69709 ]\n",
      "Reset environment\n",
      "Episode reward: 3877.3328\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.704448  10.671155  10.7018795  9.451216  10.149959  10.698775 ]\n",
      "Reset environment\n",
      "Episode reward: 2956.4705\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.705711 10.672404 10.703158  9.452587 10.151093 10.700041]\n",
      "Reset environment\n",
      "Episode reward: 2063.446\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.706874 10.673568 10.704319  9.453866 10.152118 10.701203]\n",
      "Reset environment\n",
      "Episode reward: 4807.87\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.709025 10.675728 10.706459  9.456188 10.154019 10.703355]\n",
      "Reset environment\n",
      "Episode reward: 1651.1008\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.709672  10.676381  10.707099   9.4569025 10.154593  10.704003 ]\n",
      "Reset environment\n",
      "Episode reward: 3384.277\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.711078  10.6777725 10.708518   9.458452  10.155851  10.705407 ]\n",
      "Reset environment\n",
      "Episode reward: 3343.015\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.712534 10.67923  10.709967  9.460037 10.157119 10.706863]\n",
      "Reset environment\n",
      "Episode reward: 152.71042\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.711938 10.678721 10.709287  9.459402 10.156594 10.706275]\n",
      "Reset environment\n",
      "Episode reward: 1477.462\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.712475 10.679273 10.709808  9.460003 10.157071 10.706813]\n",
      "Reset environment\n",
      "Episode reward: 1997.2982\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.713614 10.680411 10.710942  9.461245 10.158068 10.707952]\n",
      "Reset environment\n",
      "Episode reward: 2485.4297\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.714645  10.681444  10.711967   9.4623785 10.158971  10.7089815]\n",
      "Reset environment\n",
      "Episode reward: 2667.2979\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.715759 10.682565 10.713065  9.463589 10.159945 10.710097]\n",
      "Reset environment\n",
      "Episode reward: 5209.249\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.718111 10.68492  10.715408  9.466132 10.162024 10.712444]\n",
      "Reset environment\n",
      "Episode reward: 1115.1456\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.718499 10.685303 10.715803  9.466575 10.162366 10.712833]\n",
      "Reset environment\n",
      "Episode reward: 2622.9802\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.719461 10.686231 10.716794  9.46767  10.163231 10.713796]\n",
      "Reset environment\n",
      "Episode reward: 1847.593\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.720516  10.6872835 10.717845   9.46884   10.164152  10.714849 ]\n",
      "Reset environment\n",
      "Episode reward: 1821.9954\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.721207 10.687965 10.718544  9.469619 10.164755 10.715544]\n",
      "Reset environment\n",
      "Episode reward: 2221.6985\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.722002 10.68879  10.719314  9.470508 10.165452 10.71634 ]\n",
      "Reset environment\n",
      "Episode reward: 2178.9753\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.722896 10.689706 10.720188  9.471495 10.166253 10.717235]\n",
      "Reset environment\n",
      "Episode reward: 1832.3324\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.723944  10.690755  10.7212305  9.472652  10.167162  10.718285 ]\n",
      "Reset environment\n",
      "Episode reward: 4697.2007\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.726042 10.692846 10.723336  9.474928 10.169012 10.720382]\n",
      "Reset environment\n",
      "Episode reward: 4301.464\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.727857  10.694665  10.7251425  9.476925  10.170622  10.722196 ]\n",
      "Reset environment\n",
      "Episode reward: 1955.3601\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.728647  10.695464  10.7259245  9.47779   10.171327  10.722986 ]\n",
      "Reset environment\n",
      "Episode reward: 1747.3834\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.729307 10.696133 10.726576  9.478533 10.171898 10.723646]\n",
      "Reset environment\n",
      "Episode reward: 1776.7166\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.729971 10.696786 10.727242  9.479284 10.172472 10.724311]\n",
      "Reset environment\n",
      "Episode reward: 1635.484\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.730483 10.697251 10.72779   9.479879 10.172926 10.724824]\n",
      "Reset environment\n",
      "Episode reward: 2246.7527\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.7314205 10.698175  10.728734   9.480903  10.173756  10.72576  ]\n",
      "Reset environment\n",
      "Episode reward: 1823.562\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.732107 10.698882 10.729397  9.481664 10.174357 10.726446]\n",
      "Reset environment\n",
      "Episode reward: 1741.6603\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.732781 10.699566 10.73006   9.482409 10.174956 10.72712 ]\n",
      "Reset environment\n",
      "Episode reward: -492.85962\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.731982 10.69875  10.729279  9.481383 10.174236 10.726325]\n",
      "Reset environment\n",
      "Episode reward: 2366.6377\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.7329235 10.6996765 10.73023    9.482422  10.175075  10.72727  ]\n",
      "Reset environment\n",
      "Episode reward: 3456.5957\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.734401  10.7011595 10.731692   9.484045  10.176377  10.728745 ]\n",
      "Reset environment\n",
      "Episode reward: 5445.3267\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.736867 10.703624 10.734148  9.486709 10.17856  10.731209]\n",
      "Reset environment\n",
      "Episode reward: 2051.337\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.7375765 10.704308  10.734882   9.487523  10.179193  10.731919 ]\n",
      "Reset environment\n",
      "Episode reward: 5210.8438\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.739906 10.706637 10.737198  9.490036 10.18125  10.734249]\n",
      "Reset environment\n",
      "Episode reward: 52.707703\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.739237 10.706052 10.736449  9.489485 10.180608 10.733586]\n",
      "Reset environment\n",
      "Episode reward: 4969.1665\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.741479  10.708295  10.738684   9.491898  10.182583  10.7358265]\n",
      "Reset environment\n",
      "Episode reward: 4857.7427\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.743637  10.710462  10.7408285  9.494221  10.184499  10.737983 ]\n",
      "Reset environment\n",
      "Episode reward: 1677.7156\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.744318 10.711138 10.741512  9.494975 10.185109 10.738663]\n",
      "Reset environment\n",
      "Episode reward: 558.896\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.744131 10.71099  10.741278  9.494686 10.184932 10.738478]\n",
      "Reset environment\n",
      "Episode reward: 2805.5068\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.745304 10.712137 10.742466  9.495952 10.185976 10.739651]\n",
      "Reset environment\n",
      "Episode reward: 1391.8037\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.746148 10.712978 10.743307  9.49688  10.186704 10.740495]\n",
      "Reset environment\n",
      "Episode reward: 1542.5162\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.746727  10.7135725 10.743868   9.497527  10.187221  10.741073 ]\n",
      "Reset environment\n",
      "Episode reward: 1915.8397\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.747818 10.71466  10.744956  9.498721 10.188174 10.742164]\n",
      "Reset environment\n",
      "Episode reward: 3419.8672\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.749255 10.716089 10.746397  9.500303 10.189451 10.743601]\n",
      "Reset environment\n",
      "Episode reward: 2542.2178\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.750265 10.717095 10.747399  9.501401 10.190331 10.744611]\n",
      "Reset environment\n",
      "Episode reward: -74.25162\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.749793 10.716601 10.746944  9.500753 10.189903 10.74414 ]\n",
      "Reset environment\n",
      "Episode reward: 2495.0278\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.750805  10.7176    10.747964   9.501861  10.190808  10.7451515]\n",
      "Reset environment\n",
      "Episode reward: 1781.3511\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.751495 10.718296 10.748647  9.502622 10.191419 10.745847]\n",
      "Reset environment\n",
      "Episode reward: 1821.6151\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.752207 10.719009 10.749351  9.503413 10.192031 10.746558]\n",
      "Reset environment\n",
      "Episode reward: 4139.232\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.75401  10.720801 10.751164  9.50538  10.193643 10.748365]\n",
      "Reset environment\n",
      "Episode reward: 2743.3792\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.755005 10.721758 10.75219   9.506508 10.194533 10.749359]\n",
      "Reset environment\n",
      "Episode reward: 2405.72\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.75599  10.722752 10.753169  9.507605 10.195403 10.750346]\n",
      "Reset environment\n",
      "Episode reward: 1816.201\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.756338 10.723141 10.753472  9.507955 10.195717 10.750695]\n",
      "Reset environment\n",
      "Episode reward: 2651.6848\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.757409  10.724216  10.7545395  9.509134  10.196657  10.751768 ]\n",
      "Reset environment\n",
      "Episode reward: 3053.3354\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.758678  10.725481  10.755812   9.510534  10.197782  10.7530365]\n",
      "Reset environment\n",
      "Episode reward: 2116.5042\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.759869 10.726676 10.756996  9.511835 10.198815 10.754228]\n",
      "Reset environment\n",
      "Episode reward: 558.2252\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.759742 10.726509 10.756889  9.51162  10.198713 10.754101]\n",
      "Reset environment\n",
      "Episode reward: 3063.3433\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.761021 10.727779 10.75818   9.51301  10.19986  10.755382]\n",
      "Reset environment\n",
      "Episode reward: 2146.7273\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.762214 10.728962 10.759376  9.51433  10.200914 10.756576]\n",
      "Reset environment\n",
      "Episode reward: 2061.3535\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.7630625 10.729818  10.760219   9.515268  10.201661  10.757424 ]\n",
      "Reset environment\n",
      "Episode reward: 2433.8457\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.764035 10.730784 10.761201  9.516344 10.202523 10.7584  ]\n",
      "Reset environment\n",
      "Episode reward: 1576.0128\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.764658  10.73141   10.76182    9.517035  10.2030735 10.759022 ]\n",
      "Reset environment\n",
      "Episode reward: 4032.0493\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.766355 10.733112 10.76351   9.518872 10.204589 10.76072 ]\n",
      "Reset environment\n",
      "Episode reward: 1896.6267\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.766895 10.73369  10.764016  9.519518 10.205056 10.761263]\n",
      "Reset environment\n",
      "Episode reward: 2176.8105\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.767647 10.734413 10.764798  9.520373 10.205729 10.762016]\n",
      "Reset environment\n",
      "Episode reward: 3026.123\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.768914 10.735671 10.766073  9.521761 10.206855 10.763283]\n",
      "Reset environment\n",
      "Episode reward: 3910.144\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.770608  10.737356  10.767775   9.523594  10.208364  10.7649765]\n",
      "Reset environment\n",
      "Episode reward: 2152.2246\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.771483  10.738243  10.768634   9.5245695 10.209143  10.765858 ]\n",
      "Reset environment\n",
      "Episode reward: 3174.7454\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.772843 10.739606 10.769988  9.526061 10.210339 10.767216]\n",
      "Reset environment\n",
      "Episode reward: 5145.587\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.775162 10.741907 10.772309  9.528553 10.212389 10.769531]\n",
      "Reset environment\n",
      "Episode reward: 1515.7838\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.775697 10.742464 10.772824  9.52916  10.212863 10.770069]\n",
      "Reset environment\n",
      "Episode reward: 3819.9526\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.777359 10.744116 10.774483  9.530966 10.214326 10.771731]\n",
      "Reset environment\n",
      "Episode reward: 1456.8835\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.777867 10.744646 10.774965  9.531541 10.214778 10.772239]\n",
      "Reset environment\n",
      "Episode reward: 1391.9246\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.77839  10.745169 10.775483  9.532133 10.215235 10.77276 ]\n",
      "Reset environment\n",
      "Episode reward: 4865.896\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.780561 10.747333 10.777656  9.534473 10.217146 10.77493 ]\n",
      "Reset environment\n",
      "Episode reward: 2960.396\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.781815 10.74858  10.778908  9.535838 10.218246 10.776184]\n",
      "Reset environment\n",
      "Episode reward: 3610.3987\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.7833185 10.750068  10.780427   9.537484  10.219587  10.777692 ]\n",
      "Reset environment\n",
      "Episode reward: 3172.1714\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.784606 10.75134  10.781736  9.538914 10.220736 10.778981]\n",
      "Reset environment\n",
      "Episode reward: 1907.3538\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.785363 10.752098 10.782493  9.539752 10.221385 10.77974 ]\n",
      "Reset environment\n",
      "Episode reward: 1390.7036\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.786204 10.752937 10.783332  9.54068  10.222109 10.780581]\n",
      "Reset environment\n",
      "Episode reward: 2142.2625\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.787031 10.753749 10.784173  9.5416   10.222843 10.781409]\n",
      "Reset environment\n",
      "Episode reward: 3722.433\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.788597 10.755306 10.785749  9.543307 10.224238 10.782975]\n",
      "Reset environment\n",
      "Episode reward: 2152.4001\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.789353 10.756091 10.786479  9.544166 10.224896 10.783735]\n",
      "Reset environment\n",
      "Episode reward: 2000.3097\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.790001 10.756709 10.787156  9.544915 10.225471 10.784384]\n",
      "Reset environment\n",
      "Episode reward: 1822.691\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.790641 10.757325 10.787817  9.545636 10.226029 10.785026]\n",
      "Reset environment\n",
      "Episode reward: 1514.2777\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.791229  10.7579155 10.788405   9.546291  10.226553  10.785616 ]\n",
      "Reset environment\n",
      "Episode reward: 1413.1353\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.792086 10.758769 10.78926   9.547232 10.22729  10.786472]\n",
      "Reset environment\n",
      "Episode reward: 2090.621\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.793254 10.759923 10.790429  9.548512 10.228316 10.787639]\n",
      "Reset environment\n",
      "Episode reward: 2497.0452\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.794135  10.760776  10.791339   9.5494995 10.229104  10.788527 ]\n",
      "Reset environment\n",
      "Episode reward: 1648.7014\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.794787 10.761429 10.791989  9.550224 10.229682 10.789178]\n",
      "Reset environment\n",
      "Episode reward: 4222.35\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.796606  10.763231  10.7938175  9.552216  10.231316  10.7909975]\n",
      "Reset environment\n",
      "Episode reward: 2805.169\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.797782 10.764403 10.794991  9.553506 10.232339 10.792176]\n",
      "Reset environment\n",
      "Episode reward: 4544.715\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.799819 10.766443 10.79702   9.555714 10.234151 10.794216]\n",
      "Reset environment\n",
      "Episode reward: 2441.6138\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.800703 10.767303 10.797932  9.556693 10.234937 10.795101]\n",
      "Reset environment\n",
      "Episode reward: 2482.502\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.801482 10.76813  10.798669  9.557608 10.235613 10.795884]\n",
      "Reset environment\n",
      "Episode reward: 1824.3538\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.802154 10.768819 10.799317  9.558355 10.236198 10.796557]\n",
      "Reset environment\n",
      "Episode reward: 2203.0767\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.803386 10.770055 10.80054   9.559706 10.237268 10.797787]\n",
      "Reset environment\n",
      "Episode reward: 2519.2266\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.804381 10.771058 10.801528  9.560812 10.238125 10.798786]\n",
      "Reset environment\n",
      "Episode reward: 1457.0358\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.804925  10.771611  10.8020525  9.561409  10.238607  10.799329 ]\n",
      "Reset environment\n",
      "Episode reward: 2357.1436\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.805832  10.772506  10.802972   9.5624075 10.239417  10.800238 ]\n",
      "Reset environment\n",
      "Episode reward: 1755.5986\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.806497 10.773167 10.803639  9.563155 10.239999 10.8009  ]\n",
      "Reset environment\n",
      "Episode reward: 2005.8093\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.807632  10.774292  10.80477    9.564393  10.240987  10.8020315]\n",
      "Reset environment\n",
      "Episode reward: 2438.548\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.8085575 10.775233  10.805678   9.56538   10.241836  10.802961 ]\n",
      "Reset environment\n",
      "Episode reward: 1261.039\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.808943 10.7756   10.806076  9.565723 10.242226 10.803348]\n",
      "Reset environment\n",
      "Episode reward: 2217.5002\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.810174 10.776831 10.807305  9.567065 10.243305 10.804578]\n",
      "Reset environment\n",
      "Episode reward: 3029.4941\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.81143  10.778094 10.80855   9.56844  10.244405 10.805837]\n",
      "Reset environment\n",
      "Episode reward: 4603.918\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.813461  10.780113  10.810577   9.5706415 10.246203  10.807864 ]\n",
      "Reset environment\n",
      "Episode reward: 5877.77\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.816112 10.782768 10.813222  9.57351  10.248544 10.810516]\n",
      "Reset environment\n",
      "Episode reward: 1491.6057\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.816669 10.783323 10.813775  9.574136 10.249025 10.811073]\n",
      "Reset environment\n",
      "Episode reward: 3106.3833\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.817997 10.784647 10.815106  9.575574 10.25021  10.812401]\n",
      "Reset environment\n",
      "Episode reward: 2956.3953\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.819215 10.78585  10.81634   9.576903 10.251299 10.813622]\n",
      "Reset environment\n",
      "Episode reward: 942.4263\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.819525 10.786165 10.816646  9.577267 10.251572 10.813932]\n",
      "Reset environment\n",
      "Episode reward: 1617.874\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.820135 10.786776 10.817257  9.577958 10.252106 10.814544]\n",
      "Reset environment\n",
      "Episode reward: 3031.9678\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.821367 10.788014 10.818482  9.579326 10.253185 10.815778]\n",
      "Reset environment\n",
      "Episode reward: 3432.4988\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.822814 10.789452 10.819933  9.580908 10.254464 10.817222]\n",
      "Reset environment\n",
      "Episode reward: 2061.0444\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.823581 10.790237 10.820688  9.58176  10.255141 10.817991]\n",
      "Reset environment\n",
      "Episode reward: 5404.496\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.826002 10.792655 10.823112  9.584366 10.257296 10.820412]\n",
      "Reset environment\n",
      "Episode reward: 5103.3545\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.828272 10.794912 10.825379  9.586814 10.259315 10.822679]\n",
      "Reset environment\n",
      "Episode reward: 4720.7266\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.830274 10.796914 10.827373  9.588977 10.261098 10.824682]\n",
      "Reset environment\n",
      "Episode reward: 3349.183\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.831653 10.798291 10.828762  9.590496 10.262323 10.826063]\n",
      "Reset environment\n",
      "Episode reward: 2101.697\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.832427 10.799046 10.82955   9.591356 10.262998 10.826837]\n",
      "Reset environment\n",
      "Episode reward: 4875.945\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.834598 10.80121  10.83172   9.593698 10.264931 10.829008]\n",
      "Reset environment\n",
      "Episode reward: 568.3605\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.833916 10.800401 10.831158  9.593134 10.264273 10.828331]\n",
      "Reset environment\n",
      "Episode reward: 2155.34\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.83511   10.80159   10.832355   9.5944395 10.265323  10.829524 ]\n",
      "Reset environment\n",
      "Episode reward: 2342.779\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.836384 10.802867 10.833624  9.595839 10.26642  10.830798]\n",
      "Reset environment\n",
      "Episode reward: 179.09702\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.835973 10.802509 10.833158  9.595293 10.266049 10.830391]\n",
      "Reset environment\n",
      "Episode reward: 1081.4163\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.835982 10.802459 10.833228  9.595345 10.266111 10.830407]\n",
      "Reset environment\n",
      "Episode reward: 3419.8916\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.837379 10.803854 10.834624  9.59687  10.267354 10.831805]\n",
      "Reset environment\n",
      "Episode reward: 2219.5325\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.838621  10.8050995 10.835858   9.598221  10.26843   10.833045 ]\n",
      "Reset environment\n",
      "Episode reward: 1569.0238\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.839219  10.8056965 10.836454   9.598884  10.268949  10.833643 ]\n",
      "Reset environment\n",
      "Episode reward: 2080.2935\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.840041 10.806526 10.837269  9.599784 10.269655 10.834464]\n",
      "Reset environment\n",
      "Episode reward: 2707.306\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.841118  10.807587  10.838365   9.600971  10.2706175 10.835543 ]\n",
      "Reset environment\n",
      "Episode reward: 5270.5396\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.843425 10.809903 10.840664  9.603474 10.272694 10.837849]\n",
      "Reset environment\n",
      "Episode reward: 1367.0719\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.843923 10.810388 10.841171  9.60403  10.273139 10.838347]\n",
      "Reset environment\n",
      "Episode reward: 3364.2292\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.845357 10.811823 10.842598  9.605584 10.274403 10.839782]\n",
      "Reset environment\n",
      "Episode reward: 2159.7446\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.846554 10.813023 10.843793  9.60689  10.275453 10.840978]\n",
      "Reset environment\n",
      "Episode reward: 2588.3674\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.847598 10.814082 10.844822  9.608031 10.276381 10.842022]\n",
      "Reset environment\n",
      "Episode reward: 2498.3206\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.848612 10.815093 10.845835  9.60915  10.277275 10.843037]\n",
      "Reset environment\n",
      "Episode reward: 1630.1089\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.8492155 10.815681  10.84645    9.609819  10.277813  10.843641 ]\n",
      "Reset environment\n",
      "Episode reward: 4182.887\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.8510475 10.817518  10.8482685  9.611794  10.279433  10.845472 ]\n",
      "Reset environment\n",
      "Episode reward: 1608.4064\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.851709 10.818169 10.848934  9.612481 10.28003  10.846135]\n",
      "Reset environment\n",
      "Episode reward: 3027.3433\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.852982  10.819447  10.850198   9.613879  10.2811365 10.847407 ]\n",
      "Reset environment\n",
      "Episode reward: 1619.5471\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.853917 10.820383 10.851133  9.614915 10.281948 10.848343]\n",
      "Reset environment\n",
      "Episode reward: 2903.5903\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.855114 10.821574 10.852334  9.616225 10.283003 10.849542]\n",
      "Reset environment\n",
      "Episode reward: 1282.5131\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.855596 10.822057 10.852816  9.616766 10.283429 10.850023]\n",
      "Reset environment\n",
      "Episode reward: 2310.0845\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.8565035 10.822974  10.853709   9.617777  10.284237  10.850931 ]\n",
      "Reset environment\n",
      "Episode reward: 1303.9474\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.857272 10.823739 10.854477  9.618641 10.284891 10.851698]\n",
      "Reset environment\n",
      "Episode reward: 3286.0996\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.858656 10.825109 10.855871  9.620148 10.286121 10.853079]\n",
      "Reset environment\n",
      "Episode reward: 1334.8385\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.859139 10.825602 10.856347  9.620696 10.286552 10.853562]\n",
      "Reset environment\n",
      "Episode reward: 2026.8739\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.859808 10.82624  10.857046  9.621464 10.287147 10.854233]\n",
      "Reset environment\n",
      "Episode reward: 1696.7236\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.860461  10.826896  10.8576975  9.6221895 10.287717  10.854887 ]\n",
      "Reset environment\n",
      "Episode reward: 3793.8652\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.862033  10.828451  10.8592825  9.623918  10.289106  10.856458 ]\n",
      "Reset environment\n",
      "Episode reward: 2168.9062\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.86287   10.829271  10.860136   9.624835  10.2898445 10.857297 ]\n",
      "Reset environment\n",
      "Episode reward: 3526.585\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.864379  10.830785  10.861636   9.6264715 10.291182  10.858808 ]\n",
      "Reset environment\n",
      "Episode reward: 3090.7446\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.865647 10.83205  10.86291   9.627858 10.292308 10.860077]\n",
      "Reset environment\n",
      "Episode reward: 1840.1484\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.866304  10.8326845 10.863585   9.628589  10.292892  10.860733 ]\n",
      "Reset environment\n",
      "Episode reward: 1909.6124\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.867372 10.833754 10.864652  9.62977  10.293829 10.861802]\n",
      "Reset environment\n",
      "Episode reward: 2431.3674\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.868689 10.835072 10.865965  9.631208 10.294985 10.86312 ]\n",
      "Reset environment\n",
      "Episode reward: 3028.6619\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.869925 10.836297 10.86721   9.632565 10.296078 10.864359]\n",
      "Reset environment\n",
      "Episode reward: 6044.7896\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.872628 10.839001 10.869916  9.635489 10.298489 10.867062]\n",
      "Reset environment\n",
      "Episode reward: 2069.116\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.873774 10.84015  10.871055  9.636749 10.299481 10.868207]\n",
      "Reset environment\n",
      "Episode reward: 3032.7292\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.875011 10.841392 10.872284  9.638107 10.300567 10.869446]\n",
      "Reset environment\n",
      "Episode reward: 2759.3838\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.876015 10.842427 10.873263  9.639224 10.301459 10.870453]\n",
      "Reset environment\n",
      "Episode reward: 6809.214\n",
      "Total Steps: 232\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.878971 10.845397 10.876215  9.642443 10.304119 10.87341 ]\n",
      "Reset environment\n",
      "Episode reward: 2889.983\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.880129 10.846546 10.877367  9.643688 10.30513  10.874565]\n",
      "Reset environment\n",
      "Episode reward: 5034.3823\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.882262 10.848679 10.879507  9.646006 10.307036 10.876699]\n",
      "Reset environment\n",
      "Episode reward: 2888.4172\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.883413 10.849833 10.880656  9.647257 10.308046 10.877852]\n",
      "Reset environment\n",
      "Episode reward: 2184.6\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.884624 10.851047 10.88186   9.648576 10.309093 10.879062]\n",
      "Reset environment\n",
      "Episode reward: 3523.0356\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.886134 10.852561 10.883364  9.650217 10.310418 10.880572]\n",
      "Reset environment\n",
      "Episode reward: 1659.9346\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.886759 10.853195 10.883984  9.650918 10.310976 10.881199]\n",
      "Reset environment\n",
      "Episode reward: 565.4536\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.886358 10.852857 10.883518  9.650555 10.310631 10.880807]\n",
      "Reset environment\n",
      "Episode reward: 2240.9216\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.887243 10.853738 10.884405  9.651545 10.311403 10.881693]\n",
      "Reset environment\n",
      "Episode reward: 2244.627\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.888126 10.854623 10.885283  9.652529 10.312158 10.882577]\n",
      "Reset environment\n",
      "Episode reward: 2192.1497\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.889334 10.855827 10.886489  9.65384  10.31321  10.883783]\n",
      "Reset environment\n",
      "Episode reward: 2852.616\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.890507  10.856995  10.887665   9.655115  10.3142395 10.884959 ]\n",
      "Reset environment\n",
      "Episode reward: 2460.4817\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.891421 10.857942 10.888557  9.656134 10.315055 10.885879]\n",
      "Reset environment\n",
      "Episode reward: 3474.7786\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.892883  10.859397  10.890027   9.657734  10.316352  10.8873415]\n",
      "Reset environment\n",
      "Episode reward: 3007.6401\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.894137 10.860641 10.891282  9.65909  10.317454 10.888597]\n",
      "Reset environment\n",
      "Episode reward: 2061.2478\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.894925  10.861444  10.8920555  9.659962  10.318146  10.889386 ]\n",
      "Reset environment\n",
      "Episode reward: 1410.9363\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.895771  10.862289  10.8929     9.6608925 10.318871  10.890232 ]\n",
      "Reset environment\n",
      "Episode reward: 2213.007\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.896996  10.863519  10.894121   9.662231  10.319933  10.8914585]\n",
      "Reset environment\n",
      "Episode reward: 2189.0486\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.897818 10.864363 10.894925  9.663138 10.320666 10.892284]\n",
      "Reset environment\n",
      "Episode reward: 3043.3687\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.899088 10.865624 10.896199  9.664523 10.321776 10.893554]\n",
      "Reset environment\n",
      "Episode reward: 1207.8969\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.899526  10.866057  10.89664    9.665013  10.3221655 10.893992 ]\n",
      "Reset environment\n",
      "Episode reward: 4924.1157\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.90169  10.868225 10.898798  9.667364 10.324083 10.896156]\n",
      "Reset environment\n",
      "Episode reward: 4828.3735\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.9037895 10.870321  10.900897   9.669636  10.325952  10.898257 ]\n",
      "Reset environment\n",
      "Episode reward: 1989.988\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.904573 10.8711   10.901683  9.670515 10.326646 10.899042]\n",
      "Reset environment\n",
      "Episode reward: 3648.4385\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.906151  10.8726845 10.903251   9.6722145 10.3280525 10.90062  ]\n",
      "Reset environment\n",
      "Episode reward: 2213.0364\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.906902 10.873408 10.904032  9.673075 10.328717 10.901373]\n",
      "Reset environment\n",
      "Episode reward: 4685.9585\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.908921 10.875425 10.906054  9.67527  10.33052  10.903392]\n",
      "Reset environment\n",
      "Episode reward: 6173.3486\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.911677 10.87819  10.9088    9.678236 10.332996 10.906149]\n",
      "Reset environment\n",
      "Episode reward: 1275.777\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.912112  10.878641  10.909219   9.678727  10.3333845 10.906583 ]\n",
      "Reset environment\n",
      "Episode reward: 1381.9644\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.912941 10.879471 10.910048  9.679635 10.334098 10.907414]\n",
      "Reset environment\n",
      "Episode reward: 2037.061\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.914068 10.880595 10.911171  9.680875 10.335078 10.908541]\n",
      "Reset environment\n",
      "Episode reward: 4456.703\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.916031 10.882559 10.913125  9.682991 10.336812 10.910507]\n",
      "Reset environment\n",
      "Episode reward: 1722.2202\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.91661  10.88311  10.913725  9.683644 10.337321 10.911088]\n",
      "Reset environment\n",
      "Episode reward: 1800.1976\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.917323 10.883818 10.914443  9.684432 10.337958 10.911802]\n",
      "Reset environment\n",
      "Episode reward: 1802.2614\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.91802  10.884514 10.91514   9.685207 10.338558 10.912501]\n",
      "Reset environment\n",
      "Episode reward: 4303.7524\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.919906 10.886404 10.917018  9.68725  10.340216 10.914386]\n",
      "Reset environment\n",
      "Episode reward: 2684.9219\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.920995 10.88749  10.918113  9.688439 10.341181 10.915478]\n",
      "Reset environment\n",
      "Episode reward: 1779.6763\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.921677 10.888166 10.918799  9.689196 10.341781 10.916161]\n",
      "Reset environment\n",
      "Episode reward: 2708.7297\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.922758  10.889256  10.919866   9.690392  10.3427305 10.91724  ]\n",
      "Reset environment\n",
      "Episode reward: 943.4121\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.923072 10.889569 10.920173  9.690751 10.343002 10.917553]\n",
      "Reset environment\n",
      "Episode reward: 1107.4108\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.923452 10.889944 10.920558  9.69118  10.343337 10.917933]\n",
      "Reset environment\n",
      "Episode reward: 1565.7467\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.924028 10.890539 10.921107  9.691819 10.343854 10.918511]\n",
      "Reset environment\n",
      "Episode reward: 1531.3021\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.924597  10.891119  10.9216585  9.692449  10.344361  10.919079 ]\n",
      "Reset environment\n",
      "Episode reward: 1754.089\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.925151 10.891648 10.922236  9.693089 10.344853 10.919635]\n",
      "Reset environment\n",
      "Episode reward: 3067.0583\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.926393 10.89291  10.923461  9.694449 10.345963 10.920877]\n",
      "Reset environment\n",
      "Episode reward: 1941.8694\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.927106 10.893603 10.924194  9.695246 10.346598 10.921591]\n",
      "Reset environment\n",
      "Episode reward: 2077.7593\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.927947 10.894449 10.925031  9.69618  10.347354 10.922435]\n",
      "Reset environment\n",
      "Episode reward: 5785.982\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.930435  10.896946  10.9275055  9.698867  10.349575  10.924917 ]\n",
      "Reset environment\n",
      "Episode reward: 1293.4878\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.930912 10.897419 10.927983  9.699409 10.349997 10.925394]\n",
      "Reset environment\n",
      "Episode reward: 3242.7666\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.932217 10.898715 10.9293    9.700849 10.351158 10.926702]\n",
      "Reset environment\n",
      "Episode reward: 2744.549\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.933144  10.899677  10.930193   9.7019005 10.35197   10.927629 ]\n",
      "Reset environment\n",
      "Episode reward: 3634.3606\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.934691 10.901229 10.931736  9.70358  10.353329 10.929178]\n",
      "Reset environment\n",
      "Episode reward: 1520.7896\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.935261 10.901804 10.932301  9.70422  10.353838 10.929749]\n",
      "Reset environment\n",
      "Episode reward: 3517.3403\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.936706  10.903238  10.933759   9.705811  10.3551235 10.931195 ]\n",
      "Reset environment\n",
      "Episode reward: 1327.0775\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.937486 10.904015 10.934539  9.706674 10.355783 10.931974]\n",
      "Reset environment\n",
      "Episode reward: 1411.7944\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.938328  10.904857  10.935381   9.707601  10.356507  10.9328165]\n",
      "Reset environment\n",
      "Episode reward: 3523.4834\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.939817 10.90634  10.936868  9.709211 10.357816 10.934305]\n",
      "Reset environment\n",
      "Episode reward: 2151.1348\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.94063  10.907169 10.93766   9.710113 10.358529 10.935118]\n",
      "Reset environment\n",
      "Episode reward: 2302.56\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.941888 10.908431 10.938913  9.711493 10.35962  10.936376]\n",
      "Reset environment\n",
      "Episode reward: 1617.0227\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.942489 10.909046 10.939492  9.712162 10.360152 10.936975]\n",
      "Reset environment\n",
      "Episode reward: 4031.1953\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.94422  10.910789 10.941213  9.714035 10.361663 10.938707]\n",
      "Reset environment\n",
      "Episode reward: 4119.806\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.945978 10.912548 10.942965  9.71595  10.363202 10.940465]\n",
      "Reset environment\n",
      "Episode reward: 2093.8206\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.946772 10.913352 10.943748  9.716838 10.363903 10.941259]\n",
      "Reset environment\n",
      "Episode reward: 2038.7047\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.947893  10.914473  10.944866   9.718066  10.3648815 10.942381 ]\n",
      "Reset environment\n",
      "Episode reward: 1442.1914\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.94842  10.915014 10.945376  9.718651 10.365354 10.942908]\n",
      "Reset environment\n",
      "Episode reward: 2892.4863\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.949538 10.91611  10.946517  9.719874 10.366346 10.944029]\n",
      "Reset environment\n",
      "Episode reward: 2535.3083\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.950541  10.917096  10.9475355  9.720969  10.36724   10.945031 ]\n",
      "Reset environment\n",
      "Episode reward: 3130.5417\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.95181  10.918351 10.948822  9.722366 10.368368 10.946301]\n",
      "Reset environment\n",
      "Episode reward: 2595.3433\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.952826 10.919349 10.949856  9.723487 10.369262 10.947318]\n",
      "Reset environment\n",
      "Episode reward: 1100.9991\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.953211 10.919738 10.950237  9.723926 10.3696   10.947706]\n",
      "Reset environment\n",
      "Episode reward: 2329.595\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.954485 10.921008 10.951509  9.725308 10.370705 10.948978]\n",
      "Reset environment\n",
      "Episode reward: 2004.7065\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.955592 10.922113 10.952616  9.726523 10.371675 10.950086]\n",
      "Reset environment\n",
      "Episode reward: 4765.108\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.957669 10.924186 10.954695  9.728764 10.37353  10.952163]\n",
      "Reset environment\n",
      "Episode reward: 5422.0513\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.960047 10.926562 10.957077  9.731337 10.375652 10.954542]\n",
      "Reset environment\n",
      "Episode reward: 2210.971\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.961263 10.927782 10.958283  9.732671 10.376708 10.955758]\n",
      "Reset environment\n",
      "Episode reward: 2246.499\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.962494 10.929008 10.959517  9.734017 10.377793 10.95699 ]\n",
      "Reset environment\n",
      "Episode reward: -206.67783\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.961891  10.928372  10.9589405  9.733278  10.377256  10.956388 ]\n",
      "Reset environment\n",
      "Episode reward: 5731.814\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.964418 10.930893 10.961474  9.736005 10.379504 10.958915]\n",
      "Reset environment\n",
      "Episode reward: 2419.2817\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.965389 10.931854 10.962448  9.737069 10.38035  10.959887]\n",
      "Reset environment\n",
      "Episode reward: 2068.5266\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.966215 10.93269  10.96326   9.737979 10.381089 10.960713]\n",
      "Reset environment\n",
      "Episode reward: 3176.3625\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.967501 10.933959 10.964556  9.739392 10.382226 10.962   ]\n",
      "Reset environment\n",
      "Episode reward: 2188.8376\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.9686985 10.93515   10.965759   9.740706  10.383285  10.9632   ]\n",
      "Reset environment\n",
      "Episode reward: 2002.855\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.969446  10.935906  10.9665     9.7415495 10.38394   10.963948 ]\n",
      "Reset environment\n",
      "Episode reward: 4521.5854\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.9713955 10.937859  10.968439   9.743667  10.3856535 10.965897 ]\n",
      "Reset environment\n",
      "Episode reward: 2290.4773\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.97221  10.938648 10.969278  9.744577 10.386376 10.966711]\n",
      "Reset environment\n",
      "Episode reward: 2039.4283\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.973327 10.939762 10.970393  9.7458   10.387361 10.967826]\n",
      "Reset environment\n",
      "Episode reward: 1808.0388\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.974337 10.94077  10.971401  9.746906 10.388243 10.968835]\n",
      "Reset environment\n",
      "Episode reward: 1230.2234\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.974782 10.941222 10.971839  9.74741  10.388643 10.969282]\n",
      "Reset environment\n",
      "Episode reward: 62.75461\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.974343  10.940736  10.9714365  9.746886  10.388242  10.968844 ]\n",
      "Reset environment\n",
      "Episode reward: 243.14818\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.973847 10.940235 10.970942  9.746261 10.387836 10.968349]\n",
      "Reset environment\n",
      "Episode reward: 2209.543\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.974694 10.941097 10.971769  9.747193 10.388588 10.969198]\n",
      "Reset environment\n",
      "Episode reward: 395.6163\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.974294 10.940793 10.971282  9.746743 10.388246 10.968806]\n",
      "Reset environment\n",
      "Episode reward: 1390.741\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.975111 10.941611 10.972101  9.747647 10.38895  10.969627]\n",
      "Reset environment\n",
      "Episode reward: 2378.8354\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.976028  10.9425335 10.973016   9.748666  10.389749  10.970546 ]\n",
      "Reset environment\n",
      "Episode reward: 1352.4296\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.97682  10.943322 10.973804  9.74955  10.390429 10.971337]\n",
      "Reset environment\n",
      "Episode reward: 3647.9365\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.978349 10.94484  10.975333  9.751205 10.391768 10.972864]\n",
      "Reset environment\n",
      "Episode reward: 2198.934\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.979546 10.946035 10.97653   9.75251  10.392813 10.974065]\n",
      "Reset environment\n",
      "Episode reward: 2739.2334\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.98065  10.947147 10.97762   9.753725 10.39378  10.975168]\n",
      "Reset environment\n",
      "Episode reward: 2178.4666\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.981431 10.947899 10.978427  9.7546   10.394467 10.975951]\n",
      "Reset environment\n",
      "Episode reward: 2087.2944\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.9825735 10.949048  10.979563   9.75586   10.395458  10.977092 ]\n",
      "Reset environment\n",
      "Episode reward: 2223.1619\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.983419 10.949878 10.980421  9.7568   10.396207 10.97794 ]\n",
      "Reset environment\n",
      "Episode reward: 2431.528\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.984735  10.951183  10.981734   9.7582245 10.397352  10.979254 ]\n",
      "Reset environment\n",
      "Episode reward: 2249.1516\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.985655 10.952091 10.982663  9.759227 10.39817  10.980174]\n",
      "Reset environment\n",
      "Episode reward: 4247.716\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.987458  10.9538765 10.984474   9.761184  10.399786  10.9819765]\n",
      "Reset environment\n",
      "Episode reward: 1607.1672\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.988065 10.954483 10.985077  9.761858 10.400316 10.982584]\n",
      "Reset environment\n",
      "Episode reward: 3412.6\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.989471  10.955915  10.986464   9.763388  10.401577  10.9839945]\n",
      "Reset environment\n",
      "Episode reward: -352.57822\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.988724 10.955214 10.985665  9.762595 10.400889 10.983247]\n",
      "Reset environment\n",
      "Episode reward: 3401.414\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.990169 10.956663 10.987102  9.764153 10.402178 10.98469 ]\n",
      "Reset environment\n",
      "Episode reward: 6291.627\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.992956 10.959445 10.98989   9.767163 10.40468  10.987478]\n",
      "Reset environment\n",
      "Episode reward: 2413.461\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.994244  10.9607315 10.991179   9.768567  10.405803  10.988767 ]\n",
      "Reset environment\n",
      "Episode reward: 3284.981\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.995617 10.9621   10.992553  9.770071 10.407004 10.990142]\n",
      "Reset environment\n",
      "Episode reward: 2296.3564\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.996859 10.963337 10.993798  9.771422 10.40808  10.991384]\n",
      "Reset environment\n",
      "Episode reward: 1409.6019\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.997371 10.963845 10.994311  9.772005 10.408527 10.991897]\n",
      "Reset environment\n",
      "Episode reward: 1745.4847\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.9980135 10.964507  10.99494    9.772709  10.409092  10.992538 ]\n",
      "Reset environment\n",
      "Episode reward: 2582.889\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [10.999045 10.965547 10.995963  9.773848 10.410007 10.993572]\n",
      "Reset environment\n",
      "Episode reward: 5414.8813\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.001432 10.967924 10.998356  9.776409 10.412135 10.995957]\n",
      "Reset environment\n",
      "Episode reward: -348.06464\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.00072  10.96721  10.997652  9.775594 10.411505 10.995248]\n",
      "Reset environment\n",
      "Episode reward: 1902.2106\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.001438 10.967934 10.998362  9.776388 10.412137 10.995968]\n",
      "Reset environment\n",
      "Episode reward: 4875.5674\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.003563 10.970055 11.000487  9.77868  10.414007 10.998093]\n",
      "Reset environment\n",
      "Episode reward: 3836.7144\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.00519  10.971687 11.002103  9.780434 10.41544  10.999721]\n",
      "Reset environment\n",
      "Episode reward: 2587.5696\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.006199  10.972703  11.003093   9.781541  10.4163265 11.00073  ]\n",
      "Reset environment\n",
      "Episode reward: 3612.234\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.007708 10.974206 11.004605  9.783189 10.417658 11.002241]\n",
      "Reset environment\n",
      "Episode reward: 2810.5266\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.008843 10.975349 11.005728  9.78443  10.418646 11.003377]\n",
      "Reset environment\n",
      "Episode reward: 3160.865\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.010163 10.976667 11.007048  9.785874 10.419804 11.004694]\n",
      "Reset environment\n",
      "Episode reward: 1590.7557\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.010734 10.977257 11.007602  9.786513 10.420308 11.005264]\n",
      "Reset environment\n",
      "Episode reward: 2161.8298\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.011549  10.978085  11.0084095  9.787427  10.421026  11.0060835]\n",
      "Reset environment\n",
      "Episode reward: 1306.0402\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.01199  10.978512 11.00887   9.787925 10.421421 11.006525]\n",
      "Reset environment\n",
      "Episode reward: 1367.2587\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.012464 10.979004 11.009327  9.788453 10.421844 11.006999]\n",
      "Reset environment\n",
      "Episode reward: 1609.184\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.013093  10.9796295 11.009957   9.789149  10.422399  11.0076275]\n",
      "Reset environment\n",
      "Episode reward: 5726.373\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.015606 10.982153 11.012463  9.791865 10.424628 11.010142]\n",
      "Reset environment\n",
      "Episode reward: 2770.7808\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.016681  10.983211  11.013554   9.793056  10.4255905 11.011218 ]\n",
      "Reset environment\n",
      "Episode reward: 2006.5981\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.017448 10.983971 11.014327  9.793902 10.426255 11.011986]\n",
      "Reset environment\n",
      "Episode reward: 2218.339\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.01821  10.984707 11.015113  9.794765 10.426945 11.01275 ]\n",
      "Reset environment\n",
      "Episode reward: 5423.4355\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.020575 10.987072 11.017477  9.79732  10.429052 11.015114]\n",
      "Reset environment\n",
      "Episode reward: 4714.689\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.022634 10.989125 11.01954   9.799551 10.430897 11.017172]\n",
      "Reset environment\n",
      "Episode reward: 1965.9957\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.023391 10.989883 11.020294  9.800398 10.431544 11.017929]\n",
      "Reset environment\n",
      "Episode reward: 813.4885\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.023498  10.989992  11.020401   9.800416  10.4316635 11.018042 ]\n",
      "Reset environment\n",
      "Episode reward: 4388.936\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.025373  10.991861  11.022274   9.80244   10.433326  11.0199175]\n",
      "Reset environment\n",
      "Episode reward: 2632.2407\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.026424  10.99292   11.023316   9.803593  10.4342375 11.020971 ]\n",
      "Reset environment\n",
      "Episode reward: 4613.9326\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.02843   10.994928  11.025316   9.8057575 10.435988  11.022978 ]\n",
      "Reset environment\n",
      "Episode reward: 1694.2522\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.029061 10.995565 11.025943  9.806461 10.436544 11.023609]\n",
      "Reset environment\n",
      "Episode reward: 2531.1294\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.030074 10.99659  11.026948  9.807567 10.437427 11.024623]\n",
      "Reset environment\n",
      "Episode reward: 4406.4375\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.031957 10.998475 11.028824  9.80961  10.439078 11.026508]\n",
      "Reset environment\n",
      "Episode reward: 870.93677\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.032216 10.998742 11.029078  9.809921 10.439304 11.026769]\n",
      "Reset environment\n",
      "Episode reward: 1730.6842\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.03283   10.999373  11.0296755  9.810604  10.439842  11.027384 ]\n",
      "Reset environment\n",
      "Episode reward: 4503.8643\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.034805 11.001345 11.031651  9.812729 10.441597 11.029359]\n",
      "Reset environment\n",
      "Episode reward: 2032.3414\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.035603 11.002132 11.032459  9.813609 10.44231  11.030155]\n",
      "Reset environment\n",
      "Episode reward: 2284.3203\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.03645  11.002959 11.033323  9.814543 10.443055 11.031003]\n",
      "Reset environment\n",
      "Episode reward: 1356.6207\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.036945 11.00345  11.033821  9.815094 10.443492 11.031498]\n",
      "Reset environment\n",
      "Episode reward: 1339.9316\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.0377245 11.004228  11.034599   9.815953  10.444156  11.032278 ]\n",
      "Reset environment\n",
      "Episode reward: 5411.6104\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.040067  11.006564  11.03694    9.8184805 10.446247  11.034619 ]\n",
      "Reset environment\n",
      "Episode reward: 2069.1333\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.040882 11.007395 11.037739  9.819385 10.446982 11.035438]\n",
      "Reset environment\n",
      "Episode reward: 4544.2964\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.042744  11.009253  11.039596   9.8214035 10.448639  11.037299 ]\n",
      "Reset environment\n",
      "Episode reward: 4057.2573\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.044443 11.010943 11.041301  9.823251 10.450151 11.039004]\n",
      "Reset environment\n",
      "Episode reward: 2327.7505\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.045697 11.012196 11.042555  9.824619 10.451244 11.040258]\n",
      "Reset environment\n",
      "Episode reward: 4008.7002\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.047336 11.013846 11.044184  9.826418 10.452724 11.041901]\n",
      "Reset environment\n",
      "Episode reward: 2541.664\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.048194 11.014669 11.045074  9.827397 10.453493 11.042762]\n",
      "Reset environment\n",
      "Episode reward: 1272.0737\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.04843   11.014876  11.0453415  9.827623  10.453741  11.043002 ]\n",
      "Reset environment\n",
      "Episode reward: 1866.5144\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.049103 11.015527 11.046032  9.82837  10.454331 11.043674]\n",
      "Reset environment\n",
      "Episode reward: 3716.3694\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.050595 11.017021 11.047525  9.82999  10.455661 11.045169]\n",
      "Reset environment\n",
      "Episode reward: 3726.476\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.052159 11.018583 11.04909   9.831685 10.457037 11.046735]\n",
      "Reset environment\n",
      "Episode reward: 1384.2207\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.052979 11.019403 11.04991   9.832586 10.457742 11.047556]\n",
      "Reset environment\n",
      "Episode reward: 1266.1459\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.053436 11.019857 11.050371  9.833095 10.458146 11.048013]\n",
      "Reset environment\n",
      "Episode reward: 5199.765\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.055687  11.022103  11.052618   9.835537  10.460158  11.0502615]\n",
      "Reset environment\n",
      "Episode reward: 4860.538\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.057804 11.024229 11.054728  9.837814 10.462035 11.052381]\n",
      "Reset environment\n",
      "Episode reward: 3702.242\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.059356  11.025791  11.056267   9.839493  10.4633875 11.053931 ]\n",
      "Reset environment\n",
      "Episode reward: 1652.4801\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.060295 11.026733 11.057205  9.840523 10.4642   11.054872]\n",
      "Reset environment\n",
      "Episode reward: 1805.2181\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.060986 11.027411 11.057905  9.841283 10.464817 11.055563]\n",
      "Reset environment\n",
      "Episode reward: 2243.7498\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.0619   11.028319 11.058824  9.842281 10.465629 11.056478]\n",
      "Reset environment\n",
      "Episode reward: 2823.0088\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.063066  11.02947   11.0599985  9.843557  10.466674  11.057646 ]\n",
      "Reset environment\n",
      "Episode reward: 2175.581\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.063925 11.030327 11.060856  9.844503 10.467411 11.058504]\n",
      "Reset environment\n",
      "Episode reward: 2227.024\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.06481  11.031219 11.061732  9.845475 10.468196 11.05939 ]\n",
      "Reset environment\n",
      "Episode reward: 2208.603\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.06567  11.032088 11.062584  9.846418 10.468944 11.060252]\n",
      "Reset environment\n",
      "Episode reward: 2099.5742\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.066796 11.033213 11.06371   9.847661 10.469924 11.061381]\n",
      "Reset environment\n",
      "Episode reward: 371.88446\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.066393 11.032883 11.063232  9.847148 10.469584 11.060981]\n",
      "Reset environment\n",
      "Episode reward: 3993.5479\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.068074 11.034553 11.064909  9.848958 10.471062 11.06266 ]\n",
      "Reset environment\n",
      "Episode reward: 2589.1233\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.069128  11.035609  11.065956   9.850106  10.4719715 11.063715 ]\n",
      "Reset environment\n",
      "Episode reward: 819.41284\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.068834  11.035379  11.065609   9.8498335 10.471712  11.063436 ]\n",
      "Reset environment\n",
      "Episode reward: 2098.6875\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.06998  11.036528 11.066743  9.851084 10.472709 11.064581]\n",
      "Reset environment\n",
      "Episode reward: 2181.4473\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.070849 11.037399 11.067611  9.852041 10.473466 11.06545 ]\n",
      "Reset environment\n",
      "Episode reward: 1546.0227\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.071422 11.037978 11.068176  9.852677 10.473973 11.066022]\n",
      "Reset environment\n",
      "Episode reward: 1376.4763\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.072235 11.038791 11.068989  9.853575 10.474672 11.066835]\n",
      "Reset environment\n",
      "Episode reward: 879.9158\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.072506 11.039065 11.069255  9.853892 10.474908 11.06711 ]\n",
      "Reset environment\n",
      "Episode reward: 1892.918\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.073239  11.039789  11.069987   9.854703  10.475549  11.0678425]\n",
      "Reset environment\n",
      "Episode reward: -262.61847\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.072671 11.039226 11.06942   9.853955 10.475062 11.067278]\n",
      "Reset environment\n",
      "Episode reward: 2212.4448\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.073866 11.04041  11.070617  9.855255 10.476109 11.068472]\n",
      "Reset environment\n",
      "Episode reward: 2030.7998\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.074659 11.041211 11.071401  9.856128 10.476807 11.069266]\n",
      "Reset environment\n",
      "Episode reward: 2090.0884\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.07579  11.042338 11.072532  9.857368 10.477797 11.070398]\n",
      "Reset environment\n",
      "Episode reward: 2034.0942\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.076894 11.043444 11.073633  9.858583 10.478764 11.071506]\n",
      "Reset environment\n",
      "Episode reward: 2064.007\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.078017 11.044562 11.074755  9.859807 10.479737 11.072628]\n",
      "Reset environment\n",
      "Episode reward: 2555.649\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.0789175 11.045491  11.075626   9.860811  10.48052   11.073528 ]\n",
      "Reset environment\n",
      "Episode reward: 1830.5234\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.079594 11.046173 11.076301  9.861572 10.481094 11.074204]\n",
      "Reset environment\n",
      "Episode reward: 1481.7373\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.080156  11.0467415 11.076853   9.862199  10.481589  11.074767 ]\n",
      "Reset environment\n",
      "Episode reward: 1586.6534\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.080701  11.0472555 11.077416   9.862813  10.482069  11.075311 ]\n",
      "Reset environment\n",
      "Episode reward: -538.72925\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.0796995 11.046166  11.0764885  9.86175   10.481143  11.074309 ]\n",
      "Reset environment\n",
      "Episode reward: 1915.4336\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.080753 11.04722  11.077539  9.862905 10.482062 11.075365]\n",
      "Reset environment\n",
      "Episode reward: 1666.5591\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.081359 11.047819 11.078153  9.86358  10.482603 11.075973]\n",
      "Reset environment\n",
      "Episode reward: 1537.1595\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.081926 11.048393 11.078713  9.864221 10.483106 11.076542]\n",
      "Reset environment\n",
      "Episode reward: 1374.3097\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.082417 11.048897 11.079192  9.864777 10.483548 11.077033]\n",
      "Reset environment\n",
      "Episode reward: 5002.0977\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.084545 11.051035 11.081307  9.867088 10.485448 11.079162]\n",
      "Reset environment\n",
      "Episode reward: 2574.0166\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.085406  11.051866  11.082198   9.8680725 10.486222  11.080026 ]\n",
      "Reset environment\n",
      "Episode reward: 2345.9177\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.086225 11.052658 11.083044  9.868996 10.486964 11.080849]\n",
      "Reset environment\n",
      "Episode reward: 2156.7183\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.087051 11.053476 11.083876  9.869903 10.48768  11.081677]\n",
      "Reset environment\n",
      "Episode reward: 3760.9272\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.088559 11.054982 11.085379  9.871534 10.489015 11.083187]\n",
      "Reset environment\n",
      "Episode reward: 2576.459\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.08957  11.055983 11.0864    9.872653 10.48991  11.084198]\n",
      "Reset environment\n",
      "Episode reward: 4484.94\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.091486 11.057909 11.088307  9.874718 10.491592 11.086118]\n",
      "Reset environment\n",
      "Episode reward: 1650.7919\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.092123  11.058546  11.0889435  9.875423  10.49216   11.086754 ]\n",
      "Reset environment\n",
      "Episode reward: 1823.1167\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.092802 11.059234 11.089616  9.876185 10.492744 11.087436]\n",
      "Reset environment\n",
      "Episode reward: -444.0421\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.091714  11.05829   11.08839    9.8751955 10.491712  11.08636  ]\n",
      "Reset environment\n",
      "Episode reward: 5723.163\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.0942    11.060779  11.0908575  9.877881  10.493915  11.088845 ]\n",
      "Reset environment\n",
      "Episode reward: 4157.234\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.095962 11.062541 11.092612  9.879795 10.495455 11.090606]\n",
      "Reset environment\n",
      "Episode reward: 4815.1953\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.098007 11.064594 11.094644  9.882003 10.497265 11.092651]\n",
      "Reset environment\n",
      "Episode reward: 4647.736\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.099971 11.066551 11.096608  9.884131 10.499002 11.094612]\n",
      "Reset environment\n",
      "Episode reward: 1705.7874\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.100622 11.067214 11.097249  9.884858 10.499589 11.095265]\n",
      "Reset environment\n",
      "Episode reward: 1884.4653\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.101272 11.067884 11.097873  9.885585 10.500158 11.095913]\n",
      "Reset environment\n",
      "Episode reward: 5333.7217\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.103557 11.070173 11.100144  9.888054 10.502184 11.098196]\n",
      "Reset environment\n",
      "Episode reward: 2286.4924\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.104314 11.070894 11.100931  9.888908 10.502853 11.098955]\n",
      "Reset environment\n",
      "Episode reward: 1726.8867\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.105257  11.07184   11.101868   9.8899555 10.503671  11.099897 ]\n",
      "Reset environment\n",
      "Episode reward: 1592.8516\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.106159 11.072742 11.102768  9.890942 10.504455 11.1008  ]\n",
      "Reset environment\n",
      "Episode reward: 2159.6453\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.106768 11.073318 11.103408  9.891663 10.504991 11.10141 ]\n",
      "Reset environment\n",
      "Episode reward: 738.62317\n",
      "Total Steps: 24\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.106961 11.073509 11.1036    9.891903 10.505155 11.101604]\n",
      "Reset environment\n",
      "Episode reward: 3470.9229\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.108408 11.074964 11.105037  9.89348  10.506472 11.103051]\n",
      "Reset environment\n",
      "Episode reward: 5655.382\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.11083   11.07739   11.107449   9.8961115 10.508635  11.105472 ]\n",
      "Reset environment\n",
      "Episode reward: 3459.6147\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.11223  11.078785 11.108856  9.897635 10.509889 11.106873]\n",
      "Reset environment\n",
      "Episode reward: 2186.6711\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.113405 11.079967 11.110026  9.898921 10.510906 11.108048]\n",
      "Reset environment\n",
      "Episode reward: 2132.8708\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.114218  11.08076   11.110851   9.89981   10.5116205 11.10886  ]\n",
      "Reset environment\n",
      "Episode reward: 2343.901\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.1151   11.08164  11.111733  9.900769 10.51238  11.109743]\n",
      "Reset environment\n",
      "Episode reward: 3210.3315\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.116369  11.082908  11.112998   9.9021435 10.513495  11.111013 ]\n",
      "Reset environment\n",
      "Episode reward: 3893.6448\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.118016 11.084552 11.114638  9.903929 10.51493  11.112658]\n",
      "Reset environment\n",
      "Episode reward: 4545.674\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.119867 11.086404 11.116486  9.905936 10.516581 11.114511]\n",
      "Reset environment\n",
      "Episode reward: 1734.3536\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.120133 11.086699 11.116732  9.906156 10.516828 11.114779]\n",
      "Reset environment\n",
      "Episode reward: 1702.5706\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.120687 11.087281 11.117261  9.906785 10.517318 11.115335]\n",
      "Reset environment\n",
      "Episode reward: 3296.4363\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.122062 11.088663 11.118626  9.908282 10.518548 11.11671 ]\n",
      "Reset environment\n",
      "Episode reward: 1532.138\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.122602  11.089202  11.119168   9.9088955 10.519019  11.117251 ]\n",
      "Reset environment\n",
      "Episode reward: 1033.2062\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.122948 11.089544 11.11951   9.909292 10.519327 11.117596]\n",
      "Reset environment\n",
      "Episode reward: 5061.167\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.12513   11.091727  11.121691   9.911654  10.5212755 11.11978  ]\n",
      "Reset environment\n",
      "Episode reward: 5862.536\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.127676 11.094263 11.124237  9.914389 10.523553 11.122323]\n",
      "Reset environment\n",
      "Episode reward: 4304.8945\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.129483  11.0960655 11.12605    9.916341  10.525172  11.124131 ]\n",
      "Reset environment\n",
      "Episode reward: 1043.532\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.129637 11.096204 11.126223  9.916456 10.52534  11.124287]\n",
      "Reset environment\n",
      "Episode reward: 1847.4697\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.130329 11.096905 11.126906  9.917218 10.525947 11.124979]\n",
      "Reset environment\n",
      "Episode reward: 1366.692\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.13112  11.097698 11.127694  9.918097 10.526625 11.12577 ]\n",
      "Reset environment\n",
      "Episode reward: -484.72202\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.130275 11.096791 11.126907  9.917146 10.525846 11.124924]\n",
      "Reset environment\n",
      "Episode reward: 6045.8057\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.132905 11.099414 11.12954   9.919978 10.528198 11.127557]\n",
      "Reset environment\n",
      "Episode reward: 5151.2383\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.135105  11.101612  11.1317425  9.922348  10.530151  11.129758 ]\n",
      "Reset environment\n",
      "Episode reward: 3965.9792\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.136733 11.103244 11.13336   9.924113 10.531593 11.131385]\n",
      "Reset environment\n",
      "Episode reward: 3538.4214\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.138172 11.10468  11.134806  9.925682 10.532871 11.132823]\n",
      "Reset environment\n",
      "Episode reward: 1282.3696\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.13863   11.1051445 11.135254   9.9262    10.533276  11.133283 ]\n",
      "Reset environment\n",
      "Episode reward: 1874.2649\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.139372 11.105878 11.135996  9.927017 10.533934 11.134024]\n",
      "Reset environment\n",
      "Episode reward: 4153.7925\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.141097 11.107612 11.137713  9.928902 10.535468 11.135752]\n",
      "Reset environment\n",
      "Episode reward: 4286.3213\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.142913 11.109429 11.13952   9.930865 10.537055 11.137568]\n",
      "Reset environment\n",
      "Episode reward: -150.3765\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.1421385 11.108599  11.138802   9.930154  10.536376  11.136798 ]\n",
      "Reset environment\n",
      "Episode reward: 2603.8354\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.143203 11.109659 11.139866  9.931322 10.537326 11.137863]\n",
      "Reset environment\n",
      "Episode reward: 1688.1075\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.143757 11.110239 11.140397  9.931949 10.537814 11.13842 ]\n",
      "Reset environment\n",
      "Episode reward: 3201.085\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.145077 11.111563 11.141713  9.93339  10.53896  11.13974 ]\n",
      "Reset environment\n",
      "Episode reward: 1444.4772\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.145621  11.112109  11.142258   9.933995  10.5394535 11.1402855]\n",
      "Reset environment\n",
      "Episode reward: 1748.979\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.14628  11.112774 11.142912  9.934725 10.540035 11.140947]\n",
      "Reset environment\n",
      "Episode reward: 2635.6392\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.147149 11.113673 11.14375   9.935713 10.540796 11.141813]\n",
      "Reset environment\n",
      "Episode reward: 1468.2516\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.147658  11.114163  11.144276   9.936281  10.541247  11.1423235]\n",
      "Reset environment\n",
      "Episode reward: 3530.4902\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.1491   11.115621 11.145707  9.937857 10.54254  11.143768]\n",
      "Reset environment\n",
      "Episode reward: 3443.0413\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.150505 11.117017 11.147125  9.939382 10.5438   11.145175]\n",
      "Reset environment\n",
      "Episode reward: 1382.5693\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.1513   11.117812 11.147919  9.940261 10.544487 11.14597 ]\n",
      "Reset environment\n",
      "Episode reward: 1131.8535\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.151666 11.118163 11.148296  9.940675 10.544811 11.146337]\n",
      "Reset environment\n",
      "Episode reward: 1740.4093\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.152305  11.1188135 11.148927   9.941379  10.545378  11.146977 ]\n",
      "Reset environment\n",
      "Episode reward: 1366.0214\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.152806 11.119322 11.149416  9.941939 10.545819 11.14748 ]\n",
      "Reset environment\n",
      "Episode reward: 2157.7085\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.153972  11.120491  11.1505785  9.943212  10.546826  11.148645 ]\n",
      "Reset environment\n",
      "Episode reward: 5029.304\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.156016 11.122529 11.152622  9.945427 10.548658 11.150689]\n",
      "Reset environment\n",
      "Episode reward: 5085.7085\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.158186 11.124703 11.154787  9.94778  10.550582 11.152858]\n",
      "Reset environment\n",
      "Episode reward: 1724.916\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.159145 11.125665 11.155745  9.948831 10.551408 11.153817]\n",
      "Reset environment\n",
      "Episode reward: 5349.0063\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.161477 11.127996 11.158071  9.951329 10.553469 11.156149]\n",
      "Reset environment\n",
      "Episode reward: 2369.9648\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.162393  11.128898  11.158996   9.952332  10.55429   11.1570635]\n",
      "Reset environment\n",
      "Episode reward: 1231.7977\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.162806 11.129326 11.159397  9.952795 10.554661 11.157478]\n",
      "Reset environment\n",
      "Episode reward: 2258.6816\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.163711 11.130236 11.160293  9.953784 10.55546  11.158384]\n",
      "Reset environment\n",
      "Episode reward: 5848.156\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.166593 11.133107 11.163177  9.956869 10.558029 11.161264]\n",
      "Reset environment\n",
      "Episode reward: 542.08484\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.166213 11.132675 11.162843  9.956417 10.557738 11.160887]\n",
      "Reset environment\n",
      "Episode reward: 2065.1985\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.167001 11.133468 11.163623  9.957289 10.558415 11.161673]\n",
      "Reset environment\n",
      "Episode reward: -549.8809\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.166127 11.132653 11.162691  9.956294 10.557597 11.160809]\n",
      "Reset environment\n",
      "Episode reward: 2146.5178\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.167263 11.133797 11.16382   9.95755  10.55858  11.161945]\n",
      "Reset environment\n",
      "Episode reward: 2087.1511\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.168095 11.134614 11.164661  9.958456 10.559319 11.162778]\n",
      "Reset environment\n",
      "Episode reward: 1184.335\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.1684475 11.134945  11.165033   9.958862  10.559631  11.163131 ]\n",
      "Reset environment\n",
      "Episode reward: 2601.1643\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.169308 11.135848 11.165873  9.959843 10.560388 11.163993]\n",
      "Reset environment\n",
      "Episode reward: 1994.5557\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.170041 11.136564 11.166623  9.960652 10.561031 11.164728]\n",
      "Reset environment\n",
      "Episode reward: 2317.177\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.171266 11.137786 11.167851  9.961992 10.562099 11.165956]\n",
      "Reset environment\n",
      "Episode reward: 495.95322\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.170961  11.137418  11.167606   9.9616375 10.5618305 11.165655 ]\n",
      "Reset environment\n",
      "Episode reward: 1992.3348\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.171687 11.138157 11.168318  9.962441 10.562456 11.166381]\n",
      "Reset environment\n",
      "Episode reward: 1993.553\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.172757 11.13923  11.169385  9.963619 10.563391 11.167453]\n",
      "Reset environment\n",
      "Episode reward: 3480.44\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.174181 11.140646 11.170811  9.965173 10.564658 11.168879]\n",
      "Reset environment\n",
      "Episode reward: 2368.2014\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.175063 11.141514 11.171704  9.966149 10.565448 11.169759]\n",
      "Reset environment\n",
      "Episode reward: 2595.938\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.176099  11.142554  11.172733   9.967292  10.5663595 11.1707945]\n",
      "Reset environment\n",
      "Episode reward: 2306.0415\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.176998 11.143456 11.173633  9.968284 10.567138 11.171696]\n",
      "Reset environment\n",
      "Episode reward: 3756.6328\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.178549 11.145002 11.175187  9.96996  10.568503 11.173247]\n",
      "Reset environment\n",
      "Episode reward: 5779.415\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.181058  11.147507  11.177697   9.97266   10.57072   11.1757555]\n",
      "Reset environment\n",
      "Episode reward: 1696.9282\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.181673 11.148114 11.178323  9.973354 10.571267 11.176372]\n",
      "Reset environment\n",
      "Episode reward: 1658.8577\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.182229 11.148645 11.178894  9.973979 10.571754 11.176928]\n",
      "Reset environment\n",
      "Episode reward: 2148.2715\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.182982 11.14938  11.179668  9.974815 10.572415 11.177682]\n",
      "Reset environment\n",
      "Episode reward: 5207.086\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.18521  11.151609 11.181891  9.977225 10.574376 11.17991 ]\n",
      "Reset environment\n",
      "Episode reward: 2740.1633\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.18631  11.152714 11.182988  9.97843  10.575325 11.18101 ]\n",
      "Reset environment\n",
      "Episode reward: 394.08292\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.18592  11.152254 11.18266   9.977987 10.574983 11.180621]\n",
      "Reset environment\n",
      "Episode reward: 4307.971\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.187685 11.154012 11.184436  9.979924 10.576562 11.182386]\n",
      "Reset environment\n",
      "Episode reward: 3383.7788\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.189069 11.155389 11.185815  9.981431 10.577777 11.183773]\n",
      "Reset environment\n",
      "Episode reward: 2493.075\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.190041 11.156373 11.186779  9.982498 10.578626 11.184744]\n",
      "Reset environment\n",
      "Episode reward: 2796.0642\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.191128 11.157449 11.18788   9.983688 10.5796   11.185835]\n",
      "Reset environment\n",
      "Episode reward: 1752.426\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.191801 11.158112 11.188561  9.984427 10.580198 11.186509]\n",
      "Reset environment\n",
      "Episode reward: 1722.1927\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.192409 11.158713 11.189172  9.985114 10.580725 11.187118]\n",
      "Reset environment\n",
      "Episode reward: 1770.1068\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.19307  11.159374 11.189833  9.98584  10.58129  11.187779]\n",
      "Reset environment\n",
      "Episode reward: 1882.7214\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.1937475 11.16008   11.190482   9.986592  10.581889  11.1884575]\n",
      "Reset environment\n",
      "Episode reward: 514.6752\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.193316 11.15972  11.189981  9.986174 10.581497 11.18803 ]\n",
      "Reset environment\n",
      "Episode reward: 3776.522\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.194818 11.161222 11.191482  9.987806 10.582826 11.189534]\n",
      "Reset environment\n",
      "Episode reward: -378.83453\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.193849 11.16016  11.190603  9.986757 10.581943 11.188564]\n",
      "Reset environment\n",
      "Episode reward: 3038.6047\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.195064 11.161383 11.191808  9.988081 10.582999 11.189779]\n",
      "Reset environment\n",
      "Episode reward: 2639.7554\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.196086 11.162391 11.192844  9.989207 10.583919 11.190803]\n",
      "Reset environment\n",
      "Episode reward: 2943.7961\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.197214 11.16352  11.19397   9.990445 10.584908 11.191932]\n",
      "Reset environment\n",
      "Episode reward: 1067.2676\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.197553 11.163871 11.194293  9.990826 10.585205 11.19227 ]\n",
      "Reset environment\n",
      "Episode reward: 1866.601\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.198258 11.164571 11.195005  9.991609 10.585836 11.192976]\n",
      "Reset environment\n",
      "Episode reward: 1912.8433\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.199295 11.16561  11.196039  9.99275  10.586735 11.194015]\n",
      "Reset environment\n",
      "Episode reward: 3594.8665\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.200765 11.167074 11.197509  9.994343 10.588032 11.19548 ]\n",
      "Reset environment\n",
      "Episode reward: 5311.919\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.203042 11.169357 11.199777  9.996804 10.590026 11.197759]\n",
      "Reset environment\n",
      "Episode reward: 997.6858\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.203365 11.169677 11.200101  9.997179 10.590304 11.198082]\n",
      "Reset environment\n",
      "Episode reward: 1774.8337\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.204345 11.170656 11.201079  9.99825  10.591151 11.199061]\n",
      "Reset environment\n",
      "Episode reward: 5548.741\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.206724 11.173037 11.203459 10.000817 10.59324  11.20144 ]\n",
      "Reset environment\n",
      "Episode reward: 2778.5994\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.207807  11.174111  11.204545  10.0020075 10.594193  11.202524 ]\n",
      "Reset environment\n",
      "Episode reward: 4643.876\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.209787 11.176101 11.206519 10.004141 10.595952 11.204505]\n",
      "Reset environment\n",
      "Episode reward: 3370.8955\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.211172  11.1774845 11.207893  10.005645  10.597168  11.20589  ]\n",
      "Reset environment\n",
      "Episode reward: 5307.3896\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.213749 11.180069 11.210461 10.008435 10.599468 11.208466]\n",
      "Reset environment\n",
      "Episode reward: 4839.915\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.215702 11.182025 11.212404 10.010561 10.601198 11.210417]\n",
      "Reset environment\n",
      "Episode reward: 1856.1707\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.21638   11.182706  11.2130785 10.011317  10.601781  11.211097 ]\n",
      "Reset environment\n",
      "Episode reward: 712.79065\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.21638  11.182685 11.213093 10.01122  10.601793 11.211096]\n",
      "Reset environment\n",
      "Episode reward: 4527.8716\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.218318  11.184616  11.215029  10.013306  10.6035185 11.213037 ]\n",
      "Reset environment\n",
      "Episode reward: 2263.6772\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.219165 11.185451 11.215887 10.014245 10.604273 11.213884]\n",
      "Reset environment\n",
      "Episode reward: 3546.0635\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.220601 11.186896 11.21731  10.015806 10.605545 11.21532 ]\n",
      "Reset environment\n",
      "Episode reward: 1978.2386\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.221658 11.187954 11.218366 10.016964 10.606463 11.216377]\n",
      "Reset environment\n",
      "Episode reward: 5407.5303\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.223973 11.190264 11.220686 10.019452 10.6085   11.218693]\n",
      "Reset environment\n",
      "Episode reward: 600.8255\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.22334  11.189499 11.220162 10.018906 10.607887 11.218059]\n",
      "Reset environment\n",
      "Episode reward: 1828.8164\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.224031  11.190192  11.220852  10.0196705 10.608489  11.21875  ]\n",
      "Reset environment\n",
      "Episode reward: 1773.1307\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.224666 11.190815 11.221499 10.020379 10.609054 11.219385]\n",
      "Reset environment\n",
      "Episode reward: 1413.9609\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.225479 11.191629 11.222313 10.021275 10.609751 11.2202  ]\n",
      "Reset environment\n",
      "Episode reward: 1746.3636\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.226115 11.192273 11.222942 10.021983 10.610317 11.220836]\n",
      "Reset environment\n",
      "Episode reward: 3664.3428\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.22762   11.193784  11.224442  10.023615  10.611637  11.2223425]\n",
      "Reset environment\n",
      "Episode reward: 1910.4576\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.228356  11.1945305 11.225168  10.024426  10.612303  11.223079 ]\n",
      "Reset environment\n",
      "Episode reward: 5309.7056\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.230603 11.196771 11.227417 10.026851 10.6143   11.225327]\n",
      "Reset environment\n",
      "Episode reward: 5833.7705\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.233091 11.19925  11.229901 10.029532 10.616525 11.227809]\n",
      "Reset environment\n",
      "Episode reward: 2018.556\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.233712  11.1999035 11.230493  10.030245  10.617059  11.228431 ]\n",
      "Reset environment\n",
      "Episode reward: 4331.5225\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.235528 11.201722 11.232302 10.032213 10.618672 11.230248]\n",
      "Reset environment\n",
      "Episode reward: 5889.1978\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.238029 11.20423  11.234793 10.034915 10.620913 11.232746]\n",
      "Reset environment\n",
      "Episode reward: 1290.8619\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.238494 11.204696 11.235257 10.035433 10.62133  11.233212]\n",
      "Reset environment\n",
      "Episode reward: 1891.1566\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.239199 11.205399 11.235962 10.036212 10.621931 11.233917]\n",
      "Reset environment\n",
      "Episode reward: 4956.492\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.241283 11.207491 11.238034 10.038476 10.62377  11.236003]\n",
      "Reset environment\n",
      "Episode reward: 1216.16\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.241671  11.207877  11.2384205 10.03892   10.624096  11.236391 ]\n",
      "Reset environment\n",
      "Episode reward: 2069.963\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.242765 11.208972 11.239512 10.040124 10.625058 11.237487]\n",
      "Reset environment\n",
      "Episode reward: 1805.6566\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.24345   11.209669  11.240191  10.040892  10.625672  11.2381735]\n",
      "Reset environment\n",
      "Episode reward: 14.82724\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.242996 11.209233 11.239711 10.040243 10.625278 11.237719]\n",
      "Reset environment\n",
      "Episode reward: 2144.028\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.24411  11.210342 11.240825 10.041467 10.626259 11.238831]\n",
      "Reset environment\n",
      "Episode reward: 5318.6123\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.246349 11.212583 11.243056 10.043895 10.628249 11.241067]\n",
      "Reset environment\n",
      "Episode reward: 2874.2576\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.247459 11.213679 11.244178 10.045107 10.629224 11.242177]\n",
      "Reset environment\n",
      "Episode reward: 2550.3638\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.248389 11.214594 11.245128 10.046147 10.630055 11.24311 ]\n",
      "Reset environment\n",
      "Episode reward: 2502.4204\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.249378 11.215584 11.246112 10.047229 10.630912 11.244099]\n",
      "Reset environment\n",
      "Episode reward: 5220.663\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.251615 11.217824 11.248342 10.049636 10.632879 11.246334]\n",
      "Reset environment\n",
      "Episode reward: 2253.2988\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.252485  11.2186985 11.249208  10.050597  10.633641  11.247206 ]\n",
      "Reset environment\n",
      "Episode reward: 2779.606\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.253553 11.219751 11.250286 10.051762 10.634598 11.248274]\n",
      "Reset environment\n",
      "Episode reward: 5487.6733\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.2559   11.222097 11.252629 10.054278 10.636702 11.250623]\n",
      "Reset environment\n",
      "Episode reward: 2822.0696\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.257027 11.223229 11.253752 10.05551  10.637702 11.251749]\n",
      "Reset environment\n",
      "Episode reward: 1438.3093\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.257551 11.223758 11.254273 10.056097 10.638169 11.252274]\n",
      "Reset environment\n",
      "Episode reward: 1173.9738\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.257947 11.224147 11.254671 10.056545 10.638515 11.252669]\n",
      "Reset environment\n",
      "Episode reward: 1388.9373\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.258735  11.2249365 11.255462  10.057427  10.639195  11.25346  ]\n",
      "Reset environment\n",
      "Episode reward: 1796.1478\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.259394 11.225598 11.256118 10.058163 10.639757 11.254119]\n",
      "Reset environment\n",
      "Episode reward: 2191.733\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.260272 11.226467 11.257006 10.059117 10.640547 11.255   ]\n",
      "Reset environment\n",
      "Episode reward: 1508.1089\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.260774 11.226952 11.257525 10.059685 10.640988 11.255504]\n",
      "Reset environment\n",
      "Episode reward: 2070.0981\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.261884 11.228065 11.25863  10.060896 10.64195  11.256613]\n",
      "Reset environment\n",
      "Episode reward: 4021.71\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.263538 11.229712 11.260294 10.062704 10.643427 11.258268]\n",
      "Reset environment\n",
      "Episode reward: 4403.685\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.265375 11.231555 11.262123 10.064692 10.645044 11.260106]\n",
      "Reset environment\n",
      "Episode reward: 3205.8264\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.266591 11.232767 11.263342 10.06602  10.646123 11.261325]\n",
      "Reset environment\n",
      "Episode reward: 4024.115\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.268144 11.234314 11.264897 10.067717 10.647508 11.262882]\n",
      "Reset environment\n",
      "Episode reward: 5452.8076\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.270444  11.236624  11.267191  10.070204  10.64955   11.2651825]\n",
      "Reset environment\n",
      "Episode reward: 1853.7437\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.271125 11.237311 11.267866 10.07096  10.65015  11.265864]\n",
      "Reset environment\n",
      "Episode reward: 2059.3694\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.272212 11.238394 11.268949 10.072152 10.651084 11.266949]\n",
      "Reset environment\n",
      "Episode reward: 3439.9756\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.273605 11.239794 11.270337 10.073669 10.65231  11.268343]\n",
      "Reset environment\n",
      "Episode reward: 1344.0607\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.274069 11.240259 11.270798 10.074195 10.652719 11.268806]\n",
      "Reset environment\n",
      "Episode reward: 2410.9297\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.275001 11.241186 11.271733 10.075209 10.653533 11.269739]\n",
      "Reset environment\n",
      "Episode reward: 1621.622\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.275536 11.241745 11.272241 10.075809 10.654013 11.270273]\n",
      "Reset environment\n",
      "Episode reward: 2851.3674\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.276724 11.242936 11.273424 10.077096 10.65508  11.271463]\n",
      "Reset environment\n",
      "Episode reward: 4978.1123\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.278818  11.245034  11.275508  10.0793495 10.656933  11.273558 ]\n",
      "Reset environment\n",
      "Episode reward: 3308.5334\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.280119 11.246328 11.276819 10.080767 10.658094 11.274859]\n",
      "Reset environment\n",
      "Episode reward: 2283.053\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.280863 11.247046 11.277588 10.081605 10.658753 11.275603]\n",
      "Reset environment\n",
      "Episode reward: 1514.4646\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.281375  11.247544  11.2781105 10.082178  10.6592045 11.276115 ]\n",
      "Reset environment\n",
      "Episode reward: 3551.365\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.282823 11.248984 11.279558 10.083737 10.660491 11.277561]\n",
      "Reset environment\n",
      "Episode reward: 1364.0867\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.283587 11.249752 11.280321 10.08458  10.661154 11.278326]\n",
      "Reset environment\n",
      "Episode reward: 3018.0813\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.284773 11.250945 11.281496 10.085871 10.662194 11.279511]\n",
      "Reset environment\n",
      "Episode reward: 2581.5269\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.28558  11.251787 11.282279 10.086794 10.662908 11.280321]\n",
      "Reset environment\n",
      "Episode reward: 5269.1787\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.287798 11.254012 11.284492 10.089183 10.66488  11.28254 ]\n",
      "Reset environment\n",
      "Episode reward: 2388.8323\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.288708 11.254911 11.285409 10.090176 10.665691 11.283451]\n",
      "Reset environment\n",
      "Episode reward: 3938.8027\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.290268 11.256463 11.286978 10.091888 10.667077 11.28501 ]\n",
      "Reset environment\n",
      "Episode reward: 1868.4841\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.290952 11.257148 11.287664 10.092645 10.667664 11.285696]\n",
      "Reset environment\n",
      "Episode reward: 2199.026\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.291719 11.257937 11.288409 10.093497 10.668335 11.286465]\n",
      "Reset environment\n",
      "Episode reward: 3359.842\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.2930765 11.25931   11.289755  10.094973  10.669558  11.287823 ]\n",
      "Reset environment\n",
      "Episode reward: 1484.8792\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.293615  11.259847  11.290296  10.0955715 10.670048  11.288362 ]\n",
      "Reset environment\n",
      "Episode reward: 1814.4543\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.294274 11.26051  11.290952 10.096312 10.67061  11.289022]\n",
      "Reset environment\n",
      "Episode reward: 2057.5698\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.29504  11.261284 11.291712 10.097153 10.671272 11.289789]\n",
      "Reset environment\n",
      "Episode reward: 1681.871\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.295642 11.261884 11.292312 10.097829 10.671787 11.290393]\n",
      "Reset environment\n",
      "Episode reward: 1563.4788\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.296192 11.262422 11.292871 10.098447 10.672276 11.290947]\n",
      "Reset environment\n",
      "Episode reward: 2552.441\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.297134 11.263348 11.29383  10.099485 10.6731   11.291889]\n",
      "Reset environment\n",
      "Episode reward: 1905.5862\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.297762 11.263997 11.294431 10.100188 10.673654 11.292517]\n",
      "Reset environment\n",
      "Episode reward: 2136.1934\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.298553 11.264799 11.295213 10.101061 10.674339 11.293308]\n",
      "Reset environment\n",
      "Episode reward: 4546.5117\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.300459 11.26671  11.297111 10.103121 10.676019 11.295215]\n",
      "Reset environment\n",
      "Episode reward: 5018.5713\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.302571 11.268827 11.299215 10.105404 10.677873 11.297328]\n",
      "Reset environment\n",
      "Episode reward: 2477.5137\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.303485 11.269718 11.300145 10.106406 10.67868  11.298243]\n",
      "Reset environment\n",
      "Episode reward: 2796.661\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.304563 11.270781 11.301238 10.107584 10.679642 11.299319]\n",
      "Reset environment\n",
      "Episode reward: 1631.7955\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.305137 11.271354 11.30181  10.108227 10.68014  11.299895]\n",
      "Reset environment\n",
      "Episode reward: 3983.8552\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3067465 11.272959  11.303427  10.109976  10.681573  11.301506 ]\n",
      "Reset environment\n",
      "Episode reward: 1364.594\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.307231 11.273453 11.303904 10.110518 10.682012 11.301991]\n",
      "Reset environment\n",
      "Episode reward: 1948.5895\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.307965 11.27418  11.304645 10.111325 10.682665 11.302727]\n",
      "Reset environment\n",
      "Episode reward: 3563.7666\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.309347 11.275554 11.306029 10.112831 10.683887 11.304111]\n",
      "Reset environment\n",
      "Episode reward: 881.069\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.309332 11.275572 11.30598  10.112719 10.683871 11.304099]\n",
      "Reset environment\n",
      "Episode reward: 1834.2189\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.309989  11.276243  11.306623  10.1134405 10.684457  11.304755 ]\n",
      "Reset environment\n",
      "Episode reward: 2919.3057\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.311015 11.277244 11.307676 10.114585 10.685379 11.305782]\n",
      "Reset environment\n",
      "Episode reward: 2888.9082\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.312095 11.278346 11.308728 10.115774 10.686333 11.306859]\n",
      "Reset environment\n",
      "Episode reward: 2088.142\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.312841 11.279108 11.309459 10.1166   10.686989 11.307608]\n",
      "Reset environment\n",
      "Episode reward: 2201.3633\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.313658  11.279932  11.3102665 10.117501  10.687699  11.308424 ]\n",
      "Reset environment\n",
      "Episode reward: 2732.8298\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.314713 11.280993 11.311311 10.118655 10.688629 11.309482]\n",
      "Reset environment\n",
      "Episode reward: 1755.6526\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.315375 11.281661 11.311972 10.119388 10.68922  11.310145]\n",
      "Reset environment\n",
      "Episode reward: 2101.2842\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.316473  11.282759  11.313069  10.120595  10.6901865 11.311249 ]\n",
      "Reset environment\n",
      "Episode reward: 1882.6997\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.317163 11.283457 11.313752 10.121358 10.690798 11.31194 ]\n",
      "Reset environment\n",
      "Episode reward: 3028.4902\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.318377 11.284672 11.31496  10.122677 10.691858 11.313153]\n",
      "Reset environment\n",
      "Episode reward: 2402.1147\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.319314 11.285611 11.315893 10.123704 10.69267  11.314092]\n",
      "Reset environment\n",
      "Episode reward: 3212.6333\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.320576 11.286865 11.317158 10.1251   10.693789 11.315356]\n",
      "Reset environment\n",
      "Episode reward: 2455.008\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.321513 11.287813 11.318085 10.126124 10.694607 11.316295]\n",
      "Reset environment\n",
      "Episode reward: 2206.726\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.322666 11.288964 11.319245 10.127391 10.695612 11.317448]\n",
      "Reset environment\n",
      "Episode reward: 1493.2114\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.323205 11.289495 11.319788 10.127991 10.696097 11.317985]\n",
      "Reset environment\n",
      "Episode reward: 4392.933\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.325029 11.291325 11.321605 10.129962 10.697711 11.319808]\n",
      "Reset environment\n",
      "Episode reward: 762.0029\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.324948  11.2912035 11.321557  10.129798  10.697651  11.319729 ]\n",
      "Reset environment\n",
      "Episode reward: 3507.9443\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.32635  11.292592 11.322961 10.131326 10.698873 11.321128]\n",
      "Reset environment\n",
      "Episode reward: 2021.6333\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3271   11.293347 11.323708 10.132159 10.699517 11.321879]\n",
      "Reset environment\n",
      "Episode reward: 2588.5671\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.328085 11.29432  11.324703 10.133238 10.700382 11.322863]\n",
      "Reset environment\n",
      "Episode reward: 1908.1378\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.328758 11.294982 11.325388 10.133989 10.700982 11.323536]\n",
      "Reset environment\n",
      "Episode reward: 1582.9055\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.329284 11.295492 11.325927 10.134585 10.701447 11.324062]\n",
      "Reset environment\n",
      "Episode reward: 5311.298\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.331519 11.297729 11.328158 10.137    10.703398 11.326299]\n",
      "Reset environment\n",
      "Episode reward: 4056.8916\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3331785 11.299383  11.329822  10.1388035 10.704856  11.327961 ]\n",
      "Reset environment\n",
      "Episode reward: 1674.6298\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.333771 11.299956 11.330431 10.139462 10.705386 11.328554]\n",
      "Reset environment\n",
      "Episode reward: 1438.9558\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.334585  11.300769  11.3312435 10.140361  10.706099  11.329368 ]\n",
      "Reset environment\n",
      "Episode reward: 1596.869\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.335151 11.301327 11.331808 10.140988 10.706596 11.329935]\n",
      "Reset environment\n",
      "Episode reward: 4152.3135\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.336848 11.303034 11.333488 10.142821 10.708094 11.331634]\n",
      "Reset environment\n",
      "Episode reward: 1962.5206\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.337553 11.303754 11.334181 10.143603 10.708711 11.33234 ]\n",
      "Reset environment\n",
      "Episode reward: 1666.7985\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.338154 11.304362 11.334776 10.14427  10.709247 11.33294 ]\n",
      "Reset environment\n",
      "Episode reward: 3348.705\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3394785 11.305675  11.336106  10.14572   10.710413  11.334267 ]\n",
      "Reset environment\n",
      "Episode reward: 4650.439\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.341401 11.307605 11.338024 10.147801 10.712095 11.336192]\n",
      "Reset environment\n",
      "Episode reward: 1301.2518\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.341853 11.308052 11.338485 10.148307 10.712499 11.336644]\n",
      "Reset environment\n",
      "Episode reward: 1359.4353\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.34231  11.308493 11.338954 10.148814 10.712901 11.337101]\n",
      "Reset environment\n",
      "Episode reward: 2028.0203\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.343023 11.309186 11.339685 10.149611 10.713525 11.337814]\n",
      "Reset environment\n",
      "Episode reward: 2020.3031\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.343768  11.309942  11.340417  10.1504345 10.714186  11.33856  ]\n",
      "Reset environment\n",
      "Episode reward: 2046.9554\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.344843 11.311015 11.34149  10.151618 10.715118 11.339637]\n",
      "Reset environment\n",
      "Episode reward: 1593.1001\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3454    11.311566  11.342053  10.152241  10.7156105 11.340195 ]\n",
      "Reset environment\n",
      "Episode reward: 1413.5769\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.346202  11.312367  11.3428545 10.153123  10.716299  11.340997 ]\n",
      "Reset environment\n",
      "Episode reward: 2006.5217\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.347271 11.31344  11.343918 10.154291 10.717226 11.342064]\n",
      "Reset environment\n",
      "Episode reward: 1333.4885\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.347737 11.313901 11.344389 10.154817 10.71764  11.342531]\n",
      "Reset environment\n",
      "Episode reward: 1585.0073\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3483   11.314479 11.34494  10.155446 10.718146 11.343095]\n",
      "Reset environment\n",
      "Episode reward: 1883.8395\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.349296 11.315475 11.345934 10.156549 10.719002 11.34409 ]\n",
      "Reset environment\n",
      "Episode reward: 3255.198\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.350585 11.31677  11.347208 10.157957 10.720126 11.345377]\n",
      "Reset environment\n",
      "Episode reward: 1689.3763\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.35113   11.317343  11.347723  10.158573  10.720609  11.3459215]\n",
      "Reset environment\n",
      "Episode reward: 4882.324\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.353166 11.319372 11.349767 10.160777 10.722428 11.347959]\n",
      "Reset environment\n",
      "Episode reward: 4751.6733\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.355139 11.321335 11.351737 10.162914 10.724177 11.349928]\n",
      "Reset environment\n",
      "Episode reward: 4766.9946\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.357104  11.323303  11.353691  10.165038  10.725926  11.3518915]\n",
      "Reset environment\n",
      "Episode reward: 3423.919\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.358493  11.324684  11.355085  10.166538  10.7271595 11.353281 ]\n",
      "Reset environment\n",
      "Episode reward: 1568.8914\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.359035 11.32524  11.355613 10.167141 10.727641 11.353822]\n",
      "Reset environment\n",
      "Episode reward: 2512.0464\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.360005 11.326204 11.356585 10.16821  10.728479 11.354793]\n",
      "Reset environment\n",
      "Episode reward: 2953.2869\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.361128 11.327313 11.357711 10.169455 10.729469 11.355917]\n",
      "Reset environment\n",
      "Episode reward: 2209.9385\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.36228  11.32846  11.358864 10.170711 10.730476 11.357068]\n",
      "Reset environment\n",
      "Episode reward: 2373.2976\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.363178 11.329348 11.35977  10.1717   10.731273 11.357967]\n",
      "Reset environment\n",
      "Episode reward: 1674.396\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.363786 11.329962 11.360371 10.172373 10.731816 11.358574]\n",
      "Reset environment\n",
      "Episode reward: 2241.847\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3646555 11.33083   11.361244  10.173329  10.732589  11.359445 ]\n",
      "Reset environment\n",
      "Episode reward: 3278.9297\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.365969  11.332123  11.362559  10.1747465 10.733764  11.360761 ]\n",
      "Reset environment\n",
      "Episode reward: 2312.7085\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.366828 11.332989 11.363407 10.175691 10.734516 11.36162 ]\n",
      "Reset environment\n",
      "Episode reward: 5330.909\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.369071 11.335225 11.365654 10.178109 10.736502 11.363864]\n",
      "Reset environment\n",
      "Episode reward: 4629.598\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.370986 11.337132 11.367571 10.180183 10.738201 11.365779]\n",
      "Reset environment\n",
      "Episode reward: 1940.0247\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.37169   11.337824  11.368282  10.1809635 10.738828  11.366485 ]\n",
      "Reset environment\n",
      "Episode reward: 2566.9421\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.372686  11.338829  11.36927   10.1820545 10.739711  11.36748  ]\n",
      "Reset environment\n",
      "Episode reward: 3284.941\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.374018 11.340166 11.370594 10.183495 10.740895 11.368813]\n",
      "Reset environment\n",
      "Episode reward: 2643.4697\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.374957 11.341133 11.371509 10.18454  10.74173  11.369752]\n",
      "Reset environment\n",
      "Episode reward: 1992.6865\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.37566   11.34182   11.372221  10.1853285 10.742343  11.370454 ]\n",
      "Reset environment\n",
      "Episode reward: 2971.6003\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.376824 11.342989 11.373375 10.186592 10.743365 11.371618]\n",
      "Reset environment\n",
      "Episode reward: 2646.1345\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.377819 11.343995 11.374353 10.18769  10.744241 11.372614]\n",
      "Reset environment\n",
      "Episode reward: 2847.1348\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.378939  11.345119  11.375467  10.1889105 10.745222  11.373733 ]\n",
      "Reset environment\n",
      "Episode reward: 1110.164\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.379308 11.345495 11.375829 10.189328 10.745549 11.374103]\n",
      "Reset environment\n",
      "Episode reward: 153.94724\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.378741 11.344851 11.37533  10.188691 10.745046 11.373536]\n",
      "Reset environment\n",
      "Episode reward: 2027.4318\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.379492 11.345601 11.37608  10.189521 10.74569  11.374287]\n",
      "Reset environment\n",
      "Episode reward: 2325.9634\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.380285 11.34638  11.37689  10.190413 10.746387 11.375081]\n",
      "Reset environment\n",
      "Episode reward: 1746.7502\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.380933  11.34702   11.377544  10.191129  10.7469635 11.375729 ]\n",
      "Reset environment\n",
      "Episode reward: 2156.063\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.381637 11.347704 11.378271 10.191923 10.74759  11.376433]\n",
      "Reset environment\n",
      "Episode reward: 3557.8916\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.383055  11.349105  11.379695  10.193465  10.748844  11.3778515]\n",
      "Reset environment\n",
      "Episode reward: 2452.6243\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.383979 11.350018 11.380624 10.194481 10.749646 11.378776]\n",
      "Reset environment\n",
      "Episode reward: 4623.964\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.385819 11.351861 11.382464 10.19647  10.751294 11.380618]\n",
      "Reset environment\n",
      "Episode reward: 5866.719\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.38831  11.354355 11.384951 10.199143 10.753491 11.38311 ]\n",
      "Reset environment\n",
      "Episode reward: 5929.1587\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.390808 11.356849 11.387448 10.201836 10.755713 11.385606]\n",
      "Reset environment\n",
      "Episode reward: 1985.2465\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.39184  11.357886 11.388476 10.20298  10.7566   11.386639]\n",
      "Reset environment\n",
      "Episode reward: 1621.6947\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.392364 11.35843  11.38898  10.203576 10.757054 11.387162]\n",
      "Reset environment\n",
      "Episode reward: 2336.0667\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.393253 11.359313 11.389873 10.204551 10.757823 11.388053]\n",
      "Reset environment\n",
      "Episode reward: 2222.9766\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.394045  11.3601265 11.390646  10.205422  10.758514  11.388847 ]\n",
      "Reset environment\n",
      "Episode reward: 3652.6829\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.395529 11.361619 11.392118 10.207036 10.759823 11.390333]\n",
      "Reset environment\n",
      "Episode reward: 4395.4883\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.397333  11.363418  11.3939295 10.208982  10.761421  11.392139 ]\n",
      "Reset environment\n",
      "Episode reward: 2188.4043\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.3984785 11.364568  11.395074  10.210229  10.762412  11.393286 ]\n",
      "Reset environment\n",
      "Episode reward: 1599.018\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.399049 11.365145 11.395634 10.210863 10.762926 11.393857]\n",
      "Reset environment\n",
      "Episode reward: 2022.5361\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.399811  11.365894  11.396404  10.2116995 10.763603  11.394617 ]\n",
      "Reset environment\n",
      "Episode reward: 2103.8225\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.400591 11.36667  11.397183 10.212566 10.764288 11.395398]\n",
      "Reset environment\n",
      "Episode reward: 1824.0042\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.401263 11.367347 11.397852 10.213308 10.764873 11.396071]\n",
      "Reset environment\n",
      "Episode reward: 2571.3037\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.402257  11.368347  11.398838  10.2143955 10.7657385 11.397064 ]\n",
      "Reset environment\n",
      "Episode reward: 2309.0786\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.403078 11.369172 11.399658 10.215309 10.766446 11.397887]\n",
      "Reset environment\n",
      "Episode reward: 2975.6204\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.404247  11.370349  11.40082   10.216582  10.7674675 11.399057 ]\n",
      "Reset environment\n",
      "Episode reward: 2158.484\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.405361 11.371466 11.40193  10.21781  10.768432 11.400171]\n",
      "Reset environment\n",
      "Episode reward: 888.67017\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.405374  11.371504  11.401916  10.21772   10.768452  11.4001875]\n",
      "Reset environment\n",
      "Episode reward: 1758.2319\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.405956 11.372063 11.402515 10.218377 10.768958 11.40077 ]\n",
      "Reset environment\n",
      "Episode reward: 2698.7441\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.407007 11.373112 11.403568 10.21953  10.76987  11.401821]\n",
      "Reset environment\n",
      "Episode reward: 1806.3225\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.407636 11.373725 11.404212 10.220228 10.770428 11.402451]\n",
      "Reset environment\n",
      "Episode reward: 3104.685\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.408833 11.374931 11.405397 10.221537 10.771469 11.403648]\n",
      "Reset environment\n",
      "Episode reward: 3028.4287\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.410031 11.376136 11.406589 10.222837 10.772515 11.404847]\n",
      "Reset environment\n",
      "Episode reward: 1548.4647\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.41052  11.3766   11.407095 10.223392 10.772949 11.405337]\n",
      "Reset environment\n",
      "Episode reward: 4192.738\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.412238 11.378306 11.408814 10.225234 10.77446  11.407052]\n",
      "Reset environment\n",
      "Episode reward: 2545.2598\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.413029  11.379063  11.409634  10.226139  10.7751665 11.407846 ]\n",
      "Reset environment\n",
      "Episode reward: 1763.6339\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.413663 11.379707 11.41026  10.226834 10.775729 11.408482]\n",
      "Reset environment\n",
      "Episode reward: 1653.8102\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.414566 11.380606 11.411164 10.22782  10.776506 11.409386]\n",
      "Reset environment\n",
      "Episode reward: 1635.682\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.414879 11.380932 11.411466 10.228107 10.776768 11.409702]\n",
      "Reset environment\n",
      "Episode reward: 1521.6183\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.415418 11.381478 11.411995 10.228713 10.77725  11.410241]\n",
      "Reset environment\n",
      "Episode reward: 1774.1882\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.416373 11.382436 11.412952 10.229757 10.778075 11.411197]\n",
      "Reset environment\n",
      "Episode reward: 3102.9602\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.417582 11.383655 11.414154 10.231071 10.779125 11.412406]\n",
      "Reset environment\n",
      "Episode reward: 1574.4202\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.418114 11.384204 11.414675 10.231672 10.779604 11.412944]\n",
      "Reset environment\n",
      "Episode reward: 2126.1826\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.41921   11.3853035 11.415768  10.232877  10.780551  11.414041 ]\n",
      "Reset environment\n",
      "Episode reward: 2320.3389\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.420053  11.386155  11.4165945 10.233804  10.781285  11.414885 ]\n",
      "Reset environment\n",
      "Episode reward: 2261.267\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.420898  11.386998  11.417443  10.2347355 10.78203   11.415731 ]\n",
      "Reset environment\n",
      "Episode reward: 2224.4614\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.42174   11.387846  11.418268  10.2356615 10.782763  11.41657  ]\n",
      "Reset environment\n",
      "Episode reward: 3068.2236\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.422963  11.389065  11.4194975 10.236983  10.783833  11.417793 ]\n",
      "Reset environment\n",
      "Episode reward: -355.8335\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.422147 11.388319 11.418616 10.236025 10.78308  11.416987]\n",
      "Reset environment\n",
      "Episode reward: 2296.294\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.423013 11.389191 11.419477 10.236977 10.78383  11.417854]\n",
      "Reset environment\n",
      "Episode reward: 2208.7307\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.423732 11.389882 11.420219 10.23778  10.784463 11.418578]\n",
      "Reset environment\n",
      "Episode reward: 4584.6235\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.425625 11.391768 11.422118 10.239828 10.786126 11.420471]\n",
      "Reset environment\n",
      "Episode reward: 1384.0695\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.426404 11.392549 11.422898 10.240687 10.786797 11.421251]\n",
      "Reset environment\n",
      "Episode reward: 1613.4874\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.426901  11.393069  11.423368  10.241249  10.7872305 11.421748 ]\n",
      "Reset environment\n",
      "Episode reward: 1283.9702\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.427036  11.393235  11.423472  10.241298  10.787346  11.4218855]\n",
      "Reset environment\n",
      "Episode reward: 1929.0938\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.4277   11.393878 11.424158 10.242035 10.787935 11.422549]\n",
      "Reset environment\n",
      "Episode reward: 5456.273\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.430291  11.396471  11.426742  10.24484   10.7902355 11.42514  ]\n",
      "Reset environment\n",
      "Episode reward: 4477.715\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.4321165 11.398303  11.428567  10.246825  10.791833  11.4269705]\n",
      "Reset environment\n",
      "Episode reward: 4199.863\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.433833 11.400023 11.430278 10.248687 10.793334 11.428688]\n",
      "Reset environment\n",
      "Episode reward: 1379.1514\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.434609 11.400802 11.431055 10.249544 10.794002 11.429465]\n",
      "Reset environment\n",
      "Episode reward: 1244.094\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.435032 11.401232 11.431469 10.250017 10.794383 11.429889]\n",
      "Reset environment\n",
      "Episode reward: 1765.9775\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.435599 11.401824 11.432011 10.250656 10.794876 11.430455]\n",
      "Reset environment\n",
      "Episode reward: 1672.9873\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.436131  11.4023285 11.432566  10.251258  10.795353  11.430988 ]\n",
      "Reset environment\n",
      "Episode reward: 2812.8105\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.437183 11.403379 11.43362  10.252415 10.796275 11.432043]\n",
      "Reset environment\n",
      "Episode reward: 3434.0593\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.438531 11.404718 11.434976 10.253887 10.797451 11.43339 ]\n",
      "Reset environment\n",
      "Episode reward: -246.53346\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.437789 11.403915 11.434291 10.253073 10.796775 11.43265 ]\n",
      "Reset environment\n",
      "Episode reward: 1826.5186\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.438451 11.404581 11.434952 10.253811 10.797357 11.433312]\n",
      "Reset environment\n",
      "Episode reward: 2853.8325\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.439419  11.40558   11.435891  10.254882  10.798205  11.4342785]\n",
      "Reset environment\n",
      "Episode reward: 2373.632\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.440227 11.406364 11.436719 10.255777 10.79891  11.435086]\n",
      "Reset environment\n",
      "Episode reward: 5022.522\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.442318  11.408461  11.438805  10.258032  10.8007555 11.43718  ]\n",
      "Reset environment\n",
      "Episode reward: 2060.6255\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.443039  11.4091835 11.439527  10.258829  10.801371  11.4379015]\n",
      "Reset environment\n",
      "Episode reward: 1295.1349\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.443475 11.409628 11.43995  10.259316 10.80176  11.438337]\n",
      "Reset environment\n",
      "Episode reward: 4264.8467\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.445183  11.4113245 11.441664  10.261176  10.803267  11.440044 ]\n",
      "Reset environment\n",
      "Episode reward: -822.54565\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.444027 11.410075 11.44059  10.25995  10.80221  11.438892]\n",
      "Reset environment\n",
      "Episode reward: 2083.9722\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.444802  11.4108515 11.441363  10.260807  10.802878  11.439668 ]\n",
      "Reset environment\n",
      "Episode reward: 1444.5825\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.445322 11.411379 11.441875 10.261388 10.803348 11.440187]\n",
      "Reset environment\n",
      "Episode reward: 2996.8213\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.446449 11.412503 11.443003 10.26261  10.80433  11.441316]\n",
      "Reset environment\n",
      "Episode reward: 1165.7994\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.446831 11.412885 11.443386 10.26305  10.80466  11.441697]\n",
      "Reset environment\n",
      "Episode reward: 5581.0527\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.449078 11.415132 11.445627 10.265473 10.806671 11.443941]\n",
      "Reset environment\n",
      "Episode reward: 4948.5376\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.451046  11.417101  11.447596  10.267599  10.808435  11.4459095]\n",
      "Reset environment\n",
      "Episode reward: 2625.1494\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.452076  11.418124  11.44863   10.2687235 10.809357  11.44694  ]\n",
      "Reset environment\n",
      "Episode reward: 1729.1211\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.453003 11.419053 11.449555 10.269744 10.810159 11.447868]\n",
      "Reset environment\n",
      "Episode reward: 5262.878\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.455187 11.421233 11.451736 10.2721   10.812077 11.450051]\n",
      "Reset environment\n",
      "Episode reward: 2412.0266\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.455974 11.421996 11.452549 10.272979 10.812769 11.450842]\n",
      "Reset environment\n",
      "Episode reward: 4386.217\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.457674 11.423699 11.454247 10.274829 10.814287 11.452543]\n",
      "Reset environment\n",
      "Episode reward: 2632.839\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.458687  11.424701  11.455269  10.275936  10.8151865 11.453556 ]\n",
      "Reset environment\n",
      "Episode reward: 1414.1654\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.459474 11.425488 11.456056 10.276804 10.81587  11.454343]\n",
      "Reset environment\n",
      "Episode reward: 3363.4136\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.460801 11.426829 11.457366 10.278242 10.817037 11.455669]\n",
      "Reset environment\n",
      "Episode reward: 1747.9434\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.461449 11.427475 11.458015 10.278961 10.817607 11.456318]\n",
      "Reset environment\n",
      "Episode reward: 1932.0627\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.462471 11.428499 11.459036 10.280083 10.818492 11.457339]\n",
      "Reset environment\n",
      "Episode reward: 4480.9854\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.464313 11.430349 11.460873 10.282071 10.82011  11.459181]\n",
      "Reset environment\n",
      "Episode reward: 2768.5322\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.465335 11.431374 11.461894 10.283182 10.820999 11.460204]\n",
      "Reset environment\n",
      "Episode reward: 1829.6768\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.466018  11.4320545 11.46258   10.283933  10.821603  11.460888 ]\n",
      "Reset environment\n",
      "Episode reward: 1440.6313\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.46648  11.432538 11.463016 10.28445  10.822012 11.46135 ]\n",
      "Reset environment\n",
      "Episode reward: 2784.4646\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.467555 11.433617 11.464087 10.285634 10.822942 11.462425]\n",
      "Reset environment\n",
      "Episode reward: 4208.2026\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.469271 11.435336 11.465798 10.287494 10.824437 11.464141]\n",
      "Reset environment\n",
      "Episode reward: 1964.5037\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.469975 11.436035 11.466511 10.288286 10.825066 11.464848]\n",
      "Reset environment\n",
      "Episode reward: 1847.8418\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.470651 11.43671  11.467187 10.289035 10.825652 11.465523]\n",
      "Reset environment\n",
      "Episode reward: 1393.4639\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.471426 11.437485 11.46796  10.289895 10.826313 11.466298]\n",
      "Reset environment\n",
      "Episode reward: 4523.1836\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.473287 11.439356 11.469821 10.291912 10.827972 11.468164]\n",
      "Reset environment\n",
      "Episode reward: 2659.0872\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.474278 11.440356 11.470787 10.29299  10.828843 11.469151]\n",
      "Reset environment\n",
      "Episode reward: -25.01419\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.473534 11.439708 11.469936 10.292202 10.828189 11.468409]\n",
      "Reset environment\n",
      "Episode reward: 2099.4019\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.474613 11.440796 11.471018 10.293392 10.829136 11.469485]\n",
      "Reset environment\n",
      "Episode reward: 3760.124\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.476112  11.442326  11.472506  10.295041  10.830473  11.4709835]\n",
      "Reset environment\n",
      "Episode reward: 2058.7153\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.476848  11.443071  11.4732275 10.295849  10.831116  11.471725 ]\n",
      "Reset environment\n",
      "Episode reward: 4796.169\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.478785  11.4450445 11.475168  10.297981  10.83285   11.473666 ]\n",
      "Reset environment\n",
      "Episode reward: 3102.2366\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.479952  11.446195  11.476339  10.299243  10.8338585 11.4748335]\n",
      "Reset environment\n",
      "Episode reward: 2072.8948\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.480656  11.4468775 11.477062  10.3000345 10.8344755 11.475541 ]\n",
      "Reset environment\n",
      "Episode reward: 3245.0918\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.481902  11.448148  11.478292  10.30141   10.83559   11.4767885]\n",
      "Reset environment\n",
      "Episode reward: 3916.337\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.483446 11.449728 11.479828 10.303119 10.836972 11.478332]\n",
      "Reset environment\n",
      "Episode reward: 2378.2327\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.484325 11.450621 11.480701 10.304084 10.837737 11.479211]\n",
      "Reset environment\n",
      "Episode reward: 2041.6329\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.485373 11.451678 11.481749 10.305245 10.838651 11.480258]\n",
      "Reset environment\n",
      "Episode reward: 4460.957\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.487146 11.453408 11.483523 10.307117 10.840193 11.482031]\n",
      "Reset environment\n",
      "Episode reward: 4214.641\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.488827 11.455111 11.485198 10.308957 10.841703 11.483711]\n",
      "Reset environment\n",
      "Episode reward: 4897.672\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.490818  11.4571085 11.487199  10.311127  10.8434925 11.485703 ]\n",
      "Reset environment\n",
      "Episode reward: 1759.8086\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.491455 11.45774  11.487835 10.311823 10.844043 11.486339]\n",
      "Reset environment\n",
      "Episode reward: 4120.27\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.49321   11.459495  11.4895935 10.313722  10.845643  11.488095 ]\n",
      "Reset environment\n",
      "Episode reward: 1604.6119\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.493783 11.460071 11.490161 10.314349 10.84615  11.488668]\n",
      "Reset environment\n",
      "Episode reward: 1787.7468\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.494397 11.4607   11.490763 10.315037 10.8467   11.489286]\n",
      "Reset environment\n",
      "Episode reward: 5320.4995\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.496535  11.46281   11.492896  10.317306  10.848554  11.4914255]\n",
      "Reset environment\n",
      "Episode reward: 5539.0527\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.49876  11.46505  11.495119 10.319774 10.850566 11.493651]\n",
      "Reset environment\n",
      "Episode reward: 2345.637\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.4995775 11.465894  11.495904  10.32068   10.85129   11.494472 ]\n",
      "Reset environment\n",
      "Episode reward: 5172.3193\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.501665 11.467993 11.49798  10.322979 10.853168 11.496562]\n",
      "Reset environment\n",
      "Episode reward: 5610.521\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.503986 11.470293 11.500298 10.325503 10.855243 11.49888 ]\n",
      "Reset environment\n",
      "Episode reward: 2790.6887\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.505053 11.471366 11.501337 10.326666 10.856175 11.499942]\n",
      "Reset environment\n",
      "Episode reward: 1510.8032\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.505594 11.471911 11.501873 10.327272 10.856658 11.500484]\n",
      "Reset environment\n",
      "Episode reward: 2919.7256\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.506689 11.47301  11.502965 10.328474 10.857609 11.501579]\n",
      "Reset environment\n",
      "Episode reward: 4346.7617\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.508427 11.474745 11.504701 10.330387 10.85916  11.503317]\n",
      "Reset environment\n",
      "Episode reward: 1524.2424\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.508945  11.475257  11.505225  10.33098   10.8596325 11.50384  ]\n",
      "Reset environment\n",
      "Episode reward: 2237.4277\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.509795 11.476108 11.506075 10.331914 10.860378 11.50469 ]\n",
      "Reset environment\n",
      "Episode reward: 2317.398\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.510598 11.476885 11.506903 10.332802 10.861083 11.505495]\n",
      "Reset environment\n",
      "Episode reward: 1800.8342\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.511263 11.477547 11.50757  10.333538 10.86167  11.50616 ]\n",
      "Reset environment\n",
      "Episode reward: 1679.3125\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.511856 11.47814  11.508168 10.3342   10.862189 11.506753]\n",
      "Reset environment\n",
      "Episode reward: 2275.5723\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.512696  11.478986  11.509001  10.3351145 10.862922  11.507593 ]\n",
      "Reset environment\n",
      "Episode reward: 5140.8687\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.514806 11.481085 11.511116 10.337389 10.864826 11.509704]\n",
      "Reset environment\n",
      "Episode reward: 2242.8792\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.51563   11.4818945 11.511944  10.338285  10.865556  11.5105295]\n",
      "Reset environment\n",
      "Episode reward: 1566.6478\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.516164  11.482446  11.512459  10.338877  10.866033  11.5110655]\n",
      "Reset environment\n",
      "Episode reward: 2627.1177\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.517114 11.483397 11.513409 10.339909 10.866848 11.512015]\n",
      "Reset environment\n",
      "Episode reward: 1744.7969\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.517759  11.484039  11.514049  10.3406105 10.867412  11.512658 ]\n",
      "Reset environment\n",
      "Episode reward: 1201.3793\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.5181055 11.4843855 11.514401  10.340916  10.867745  11.513012 ]\n",
      "Reset environment\n",
      "Episode reward: 2902.4995\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.519192 11.485469 11.515497 10.342121 10.868701 11.514098]\n",
      "Reset environment\n",
      "Episode reward: 2118.4421\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.519994  11.4862795 11.516285  10.343005  10.869438  11.514906 ]\n",
      "Reset environment\n",
      "Episode reward: 2199.761\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.520814 11.487094 11.517111 10.343894 10.870157 11.515727]\n",
      "Reset environment\n",
      "Episode reward: 5743.9517\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.523123 11.489408 11.519416 10.346445 10.872231 11.518032]\n",
      "Reset environment\n",
      "Episode reward: 3253.7402\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.524388 11.490671 11.520682 10.347839 10.873352 11.519298]\n",
      "Reset environment\n",
      "Episode reward: 4869.2583\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.526353 11.492628 11.522653 10.349984 10.875114 11.521263]\n",
      "Reset environment\n",
      "Episode reward: 5118.391\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.528422  11.494698  11.524725  10.352252  10.876967  11.5233345]\n",
      "Reset environment\n",
      "Episode reward: 2724.5764\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.529436 11.4957   11.525752 10.353364 10.87787  11.524349]\n",
      "Reset environment\n",
      "Episode reward: 4888.056\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.531397 11.497669 11.527708 10.355534 10.879637 11.526311]\n",
      "Reset environment\n",
      "Episode reward: 1770.7025\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.532038 11.49831  11.528353 10.356241 10.880198 11.526955]\n",
      "Reset environment\n",
      "Episode reward: 983.9397\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.532298 11.498582 11.528597 10.356547 10.880427 11.527216]\n",
      "Reset environment\n",
      "Episode reward: 2047.6965\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.533022 11.499291 11.529332 10.357342 10.88106  11.52794 ]\n",
      "Reset environment\n",
      "Episode reward: 2509.1948\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.534264 11.500532 11.530564 10.358717 10.882151 11.529182]\n",
      "Reset environment\n",
      "Episode reward: 5901.586\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.536661 11.502938 11.532958 10.361242 10.884248 11.531579]\n",
      "Reset environment\n",
      "Episode reward: 1675.4811\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.537223 11.50352  11.533498 10.361866 10.884748 11.532145]\n",
      "Reset environment\n",
      "Episode reward: 1960.85\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.537834 11.504105 11.534133 10.362561 10.885307 11.532752]\n",
      "Reset environment\n",
      "Episode reward: 5289.436\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.539958 11.506242 11.536249 10.364905 10.887219 11.534878]\n",
      "Reset environment\n",
      "Episode reward: 4972.1865\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.541959 11.508244 11.538247 10.367118 10.889023 11.53688 ]\n",
      "Reset environment\n",
      "Episode reward: -256.5772\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.541264 11.507499 11.537598 10.366338 10.888392 11.536187]\n",
      "Reset environment\n",
      "Episode reward: 5543.4136\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.543493 11.509731 11.539818 10.368776 10.890415 11.53842 ]\n",
      "Reset environment\n",
      "Episode reward: 3730.5422\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.544972  11.511212  11.541299  10.3703985 10.891738  11.539898 ]\n",
      "Reset environment\n",
      "Episode reward: 1900.1866\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.545682 11.511926 11.542003 10.371187 10.892366 11.540609]\n",
      "Reset environment\n",
      "Episode reward: 1386.8096\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.54645  11.512695 11.542769 10.372031 10.893035 11.541377]\n",
      "Reset environment\n",
      "Episode reward: 2621.584\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.547438 11.513694 11.543747 10.373117 10.893907 11.542367]\n",
      "Reset environment\n",
      "Episode reward: 4536.865\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.549256 11.515503 11.545574 10.375101 10.895542 11.544187]\n",
      "Reset environment\n",
      "Episode reward: 1487.0315\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.549531 11.515809 11.545817 10.375314 10.895779 11.544465]\n",
      "Reset environment\n",
      "Episode reward: 1908.0442\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.550519 11.516794 11.546806 10.376407 10.896639 11.545454]\n",
      "Reset environment\n",
      "Episode reward: 1865.1447\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.551178 11.517443 11.547477 10.377146 10.897228 11.546113]\n",
      "Reset environment\n",
      "Episode reward: 2430.1006\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.5520525 11.518334  11.548341  10.378117  10.897989  11.546989 ]\n",
      "Reset environment\n",
      "Episode reward: 2014.8848\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.552811 11.519084 11.549095 10.378934 10.89865  11.547749]\n",
      "Reset environment\n",
      "Episode reward: 768.01465\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.55272  11.518965 11.549028 10.378768 10.8986   11.547659]\n",
      "Reset environment\n",
      "Episode reward: 1388.4639\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.553169 11.519421 11.549468 10.379286 10.898999 11.548109]\n",
      "Reset environment\n",
      "Episode reward: 1641.7598\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.553656 11.519882 11.549975 10.379851 10.899438 11.548596]\n",
      "Reset environment\n",
      "Episode reward: -357.0027\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.552837 11.518979 11.549224 10.378971 10.898687 11.547777]\n",
      "Reset environment\n",
      "Episode reward: 2572.3257\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.553776 11.519929 11.550148 10.380013 10.899502 11.548718]\n",
      "Reset environment\n",
      "Episode reward: 1288.8324\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.554182 11.520352 11.550538 10.380474 10.89987  11.549128]\n",
      "Reset environment\n",
      "Episode reward: 2279.469\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.555312 11.521484 11.551664 10.381729 10.900866 11.550257]\n",
      "Reset environment\n",
      "Episode reward: 4375.7764\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.55705  11.52321  11.553404 10.383624 10.902413 11.551995]\n",
      "Reset environment\n",
      "Episode reward: 2066.1902\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.558105  11.524263  11.554458  10.3847885 10.903337  11.553052 ]\n",
      "Reset environment\n",
      "Episode reward: 4960.3843\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.5601015 11.526254  11.556453  10.386987  10.905123  11.555049 ]\n",
      "Reset environment\n",
      "Episode reward: 3310.1743\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.561363 11.52751  11.557722 10.388388 10.906243 11.556311]\n",
      "Reset environment\n",
      "Episode reward: 4711.5444\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.563258 11.529402 11.559613 10.390459 10.907924 11.558201]\n",
      "Reset environment\n",
      "Episode reward: 2593.9282\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.564241 11.530384 11.560593 10.391543 10.908778 11.559183]\n",
      "Reset environment\n",
      "Episode reward: 1854.908\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.564906 11.531051 11.561257 10.39228  10.909346 11.559848]\n",
      "Reset environment\n",
      "Episode reward: 5015.2314\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.566937  11.5330715 11.563278  10.394485  10.911154  11.561878 ]\n",
      "Reset environment\n",
      "Episode reward: 2663.8423\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.5679    11.534059  11.564218  10.3955345 10.911998  11.562844 ]\n",
      "Reset environment\n",
      "Episode reward: 1496.9946\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.568424 11.534583 11.564733 10.396113 10.91245  11.563369]\n",
      "Reset environment\n",
      "Episode reward: 1381.7758\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.569185 11.535346 11.565495 10.396957 10.913108 11.564132]\n",
      "Reset environment\n",
      "Episode reward: 5416.751\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.5713825 11.537535  11.567695  10.399337  10.915067  11.56633  ]\n",
      "Reset environment\n",
      "Episode reward: 2565.0752\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.57225  11.538379 11.568582 10.400304 10.915832 11.567198]\n",
      "Reset environment\n",
      "Episode reward: 1862.2546\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.572911 11.539045 11.569236 10.401039 10.916395 11.567862]\n",
      "Reset environment\n",
      "Episode reward: 5792.5312\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.575256 11.541399 11.571576 10.403622 10.918506 11.570206]\n",
      "Reset environment\n",
      "Episode reward: 1853.8264\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.575936  11.54208   11.572255  10.4043665 10.91909   11.570886 ]\n",
      "Reset environment\n",
      "Episode reward: 1354.0782\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.576401  11.542541  11.5727215 10.404882  10.919501  11.57135  ]\n",
      "Reset environment\n",
      "Episode reward: 1334.4744\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.576834 11.542966 11.573168 10.405386 10.919894 11.571783]\n",
      "Reset environment\n",
      "Episode reward: 2248.6567\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.577638 11.543765 11.57398  10.406274 10.920592 11.57259 ]\n",
      "Reset environment\n",
      "Episode reward: 2150.7634\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.578302 11.544406 11.574677 10.407046 10.921198 11.573261]\n",
      "Reset environment\n",
      "Episode reward: 4088.8894\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.579925 11.546026 11.576293 10.408828 10.922638 11.574882]\n",
      "Reset environment\n",
      "Episode reward: 2054.2314\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.580974 11.54707  11.577341 10.409972 10.923552 11.575932]\n",
      "Reset environment\n",
      "Episode reward: 2653.3098\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.581928  11.548002  11.578315  10.4110155 10.924395  11.576888 ]\n",
      "Reset environment\n",
      "Episode reward: 3248.8118\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.583175  11.549253  11.579557  10.4123745 10.925495  11.5781355]\n",
      "Reset environment\n",
      "Episode reward: 1382.1497\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.583938 11.550018 11.580318 10.41321  10.926152 11.578899]\n",
      "Reset environment\n",
      "Episode reward: 1979.9537\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.584566 11.550614 11.580964 10.413916 10.926704 11.579528]\n",
      "Reset environment\n",
      "Episode reward: 4790.7124\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.5864725 11.552513  11.582869  10.415925  10.928354  11.581435 ]\n",
      "Reset environment\n",
      "Episode reward: 2333.5327\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.587309 11.553362 11.583692 10.416844 10.929083 11.582273]\n",
      "Reset environment\n",
      "Episode reward: 2323.5457\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.588088 11.554114 11.584488 10.41771  10.929771 11.583056]\n",
      "Reset environment\n",
      "Episode reward: 2381.289\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.588945 11.554963 11.585363 10.41866  10.930524 11.583916]\n",
      "Reset environment\n",
      "Episode reward: 5319.4663\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.591098 11.557097 11.587512 10.420996 10.932447 11.586067]\n",
      "Reset environment\n",
      "Episode reward: 4960.6084\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.593074  11.55907   11.589497  10.4231615 10.934222  11.588039 ]\n",
      "Reset environment\n",
      "Episode reward: 1825.1478\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.59371  11.559716 11.590114 10.423861 10.934778 11.588676]\n",
      "Reset environment\n",
      "Episode reward: 1828.2955\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.594355 11.560365 11.590755 10.424579 10.935335 11.589321]\n",
      "Reset environment\n",
      "Episode reward: 2915.3013\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.595426 11.561437 11.591827 10.425751 10.936273 11.590392]\n",
      "Reset environment\n",
      "Episode reward: 1267.664\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.595564 11.561609 11.591933 10.42582  10.936389 11.590531]\n",
      "Reset environment\n",
      "Episode reward: 3985.4336\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.597124  11.563169  11.593488  10.427541  10.9377775 11.592091 ]\n",
      "Reset environment\n",
      "Episode reward: 2642.5576\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.598125 11.564158 11.594496 10.42863  10.938658 11.593094]\n",
      "Reset environment\n",
      "Episode reward: 2014.1437\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.598763 11.564822 11.595112 10.429365 10.939229 11.59373 ]\n",
      "Reset environment\n",
      "Episode reward: 4269.1084\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6004505 11.5665045 11.596794  10.431143  10.940691  11.595418 ]\n",
      "Reset environment\n",
      "Episode reward: 1073.5546\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.600762 11.566834 11.597093 10.431505 10.94097  11.59573 ]\n",
      "Reset environment\n",
      "Episode reward: 649.4276\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.600689 11.566774 11.597003 10.431343 10.940933 11.595667]\n",
      "Reset environment\n",
      "Episode reward: 4243.534\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.602337 11.568433 11.598645 10.433176 10.942413 11.597315]\n",
      "Reset environment\n",
      "Episode reward: 4678.617\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.604218 11.570309 11.600517 10.435231 10.944089 11.599193]\n",
      "Reset environment\n",
      "Episode reward: 4525.801\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.606016 11.572101 11.602316 10.437186 10.945686 11.600991]\n",
      "Reset environment\n",
      "Episode reward: 1106.0922\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.606374 11.572457 11.602678 10.437593 10.946    11.601356]\n",
      "Reset environment\n",
      "Episode reward: 3035.7253\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.607566 11.573669 11.603837 10.438859 10.947066 11.602551]\n",
      "Reset environment\n",
      "Episode reward: 2744.2668\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.608591  11.574672  11.6048765 10.439959  10.947961  11.603577 ]\n",
      "Reset environment\n",
      "Episode reward: 2412.8208\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.609474  11.575566  11.605755  10.4409275 10.948731  11.60446  ]\n",
      "Reset environment\n",
      "Episode reward: 2185.126\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.610235 11.576329 11.606517 10.441765 10.949388 11.605222]\n",
      "Reset environment\n",
      "Episode reward: 2922.7102\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.611352 11.57743  11.607638 10.442977 10.950379 11.60634 ]\n",
      "Reset environment\n",
      "Episode reward: 1248.0039\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.611762  11.577831  11.608048  10.4434395 10.950749  11.6067505]\n",
      "Reset environment\n",
      "Episode reward: 2022.5747\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.612391 11.578436 11.608702 10.444157 10.951307 11.607382]\n",
      "Reset environment\n",
      "Episode reward: 2146.0596\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.613168 11.579201 11.609483 10.445011 10.951987 11.608158]\n",
      "Reset environment\n",
      "Episode reward: 2136.6611\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6142435 11.580277  11.610558  10.446199  10.952927  11.609233 ]\n",
      "Reset environment\n",
      "Episode reward: 847.2617\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.614244  11.580289  11.610546  10.4461155 10.9529505 11.609241 ]\n",
      "Reset environment\n",
      "Episode reward: 3701.248\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.615656  11.581705  11.611945  10.447684  10.9542055 11.610649 ]\n",
      "Reset environment\n",
      "Episode reward: 3045.7979\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.616803 11.582848 11.613097 10.448952 10.955221 11.611801]\n",
      "Reset environment\n",
      "Episode reward: 1795.4789\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.617347 11.5834   11.613621 10.449513 10.955743 11.612348]\n",
      "Reset environment\n",
      "Episode reward: 2008.9214\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.618381  11.584436  11.614654  10.4506445 10.956644  11.613382 ]\n",
      "Reset environment\n",
      "Episode reward: 1442.8247\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.61882  11.584897 11.615066 10.451145 10.957039 11.61382 ]\n",
      "Reset environment\n",
      "Episode reward: 3663.7695\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.620214 11.586284 11.616449 10.452642 10.958243 11.615215]\n",
      "Reset environment\n",
      "Episode reward: 2866.9736\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.621243 11.587337 11.617456 10.453773 10.959153 11.616245]\n",
      "Reset environment\n",
      "Episode reward: 4801.174\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.623178 11.589271 11.619385 10.455877 10.960877 11.618179]\n",
      "Reset environment\n",
      "Episode reward: 2150.881\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.624255 11.590347 11.620463 10.457068 10.961823 11.619257]\n",
      "Reset environment\n",
      "Episode reward: 3377.444\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.625546 11.591643 11.621736 10.458478 10.962961 11.620547]\n",
      "Reset environment\n",
      "Episode reward: 1980.3894\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.626296 11.592387 11.622476 10.459289 10.963612 11.621293]\n",
      "Reset environment\n",
      "Episode reward: 2294.826\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.626754 11.592876 11.622906 10.459855 10.963987 11.621753]\n",
      "Reset environment\n",
      "Episode reward: 2390.9104\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.627549 11.593698 11.623664 10.460754 10.964702 11.622547]\n",
      "Reset environment\n",
      "Episode reward: 5368.126\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.629706 11.595862 11.625809 10.463111 10.96664  11.624705]\n",
      "Reset environment\n",
      "Episode reward: 2625.519\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.630672 11.596835 11.626764 10.464174 10.967485 11.625673]\n",
      "Reset environment\n",
      "Episode reward: 5499.421\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.632832 11.598989 11.628919 10.466466 10.96938  11.62783 ]\n",
      "Reset environment\n",
      "Episode reward: 3127.3242\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6340275 11.600181  11.630111  10.467771  10.970453  11.629027 ]\n",
      "Reset environment\n",
      "Episode reward: 3435.6333\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.635367 11.601513 11.63145  10.469224 10.971641 11.630364]\n",
      "Reset environment\n",
      "Episode reward: 1448.3722\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.63586  11.602007 11.631942 10.469773 10.97207  11.630859]\n",
      "Reset environment\n",
      "Episode reward: 1830.2229\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.636489 11.602622 11.632582 10.470474 10.972636 11.63149 ]\n",
      "Reset environment\n",
      "Episode reward: 1386.2582\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.637242 11.603376 11.633333 10.471307 10.973281 11.632243]\n",
      "Reset environment\n",
      "Episode reward: 4255.2417\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.638954 11.605091 11.635044 10.473171 10.974807 11.633954]\n",
      "Reset environment\n",
      "Episode reward: 283.9249\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.638536 11.604734 11.63456  10.472665 10.974435 11.633541]\n",
      "Reset environment\n",
      "Episode reward: 2147.191\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.639339 11.605535 11.635364 10.473556 10.975146 11.634347]\n",
      "Reset environment\n",
      "Episode reward: 2472.318\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.640167 11.606337 11.636217 10.474468 10.97587  11.635176]\n",
      "Reset environment\n",
      "Episode reward: 2110.6338\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.640824  11.606972  11.636899  10.475225  10.9764595 11.635833 ]\n",
      "Reset environment\n",
      "Episode reward: 1414.9832\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6413    11.60746   11.6373625 10.47576   10.9768915 11.636312 ]\n",
      "Reset environment\n",
      "Episode reward: 1790.6207\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.641966 11.608115 11.638025 10.476476 10.977473 11.636975]\n",
      "Reset environment\n",
      "Episode reward: 4254.109\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.643611 11.609764 11.639664 10.478309 10.97895  11.638618]\n",
      "Reset environment\n",
      "Episode reward: 2067.4016\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.644317 11.610488 11.640354 10.479095 10.979577 11.639328]\n",
      "Reset environment\n",
      "Episode reward: 4803.0454\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6462145 11.612383  11.642255  10.481169  10.9812765 11.641225 ]\n",
      "Reset environment\n",
      "Episode reward: 3625.2495\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.647594 11.613777 11.643626 10.482701 10.982506 11.642606]\n",
      "Reset environment\n",
      "Episode reward: 4571.676\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.649373  11.615566  11.645394  10.4846735 10.984109  11.644384 ]\n",
      "Reset environment\n",
      "Episode reward: 1620.3457\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.649891 11.616104 11.645887 10.485254 10.98457  11.644901]\n",
      "Reset environment\n",
      "Episode reward: 2048.3445\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.650933 11.617145 11.646925 10.486396 10.985475 11.645942]\n",
      "Reset environment\n",
      "Episode reward: 1688.1852\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.651537  11.61776   11.647512  10.4870615 10.986019  11.646546 ]\n",
      "Reset environment\n",
      "Episode reward: 1918.2505\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.652526 11.618751 11.648502 10.488143 10.986875 11.647535]\n",
      "Reset environment\n",
      "Episode reward: 1506.5372\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.652921 11.619176 11.648862 10.4886   10.987222 11.647928]\n",
      "Reset environment\n",
      "Episode reward: 1393.5157\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.653385 11.61965  11.649316 10.48912  10.987638 11.648394]\n",
      "Reset environment\n",
      "Episode reward: 1351.8789\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.654116 11.62038  11.650046 10.489923 10.988268 11.649124]\n",
      "Reset environment\n",
      "Episode reward: 92.31326\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.653421 11.619784 11.649246 10.48919  10.987669 11.648434]\n",
      "Reset environment\n",
      "Episode reward: 3294.924\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.654657 11.621007 11.65049  10.490551 10.988757 11.64967 ]\n",
      "Reset environment\n",
      "Episode reward: 2521.6946\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6555605 11.621936  11.651368  10.491537  10.989558  11.650576 ]\n",
      "Reset environment\n",
      "Episode reward: 142.86191\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.655159 11.62156  11.650939 10.490987 10.989235 11.650174]\n",
      "Reset environment\n",
      "Episode reward: 5648.6\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.657422 11.623814 11.653204 10.493461 10.991263 11.652435]\n",
      "Reset environment\n",
      "Episode reward: 1644.9506\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.657994 11.624387 11.65378  10.494094 10.991756 11.65301 ]\n",
      "Reset environment\n",
      "Episode reward: 2224.697\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.658789 11.625186 11.654568 10.494968 10.992442 11.653805]\n",
      "Reset environment\n",
      "Episode reward: 2353.0227\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.659432 11.625802 11.655242 10.495718 10.993016 11.65445 ]\n",
      "Reset environment\n",
      "Episode reward: 2213.927\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.66025  11.626626 11.656057 10.496615 10.99373  11.655268]\n",
      "Reset environment\n",
      "Episode reward: 5262.31\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.66232  11.628705 11.658123 10.498912 10.99559  11.657344]\n",
      "Reset environment\n",
      "Episode reward: 2027.4956\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.663336 11.629722 11.659135 10.500041 10.996478 11.658363]\n",
      "Reset environment\n",
      "Episode reward: 1709.65\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.66422  11.630607 11.660017 10.501029 10.997247 11.659246]\n",
      "Reset environment\n",
      "Episode reward: 1402.4761\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.664656 11.631061 11.660425 10.501522 10.997634 11.65968 ]\n",
      "Reset environment\n",
      "Episode reward: 5344.1543\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.666788 11.63319  11.662553 10.503861 10.999544 11.661814]\n",
      "Reset environment\n",
      "Episode reward: 5059.042\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.668775 11.635182 11.664531 10.506055 11.001339 11.663798]\n",
      "Reset environment\n",
      "Episode reward: 1590.383\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.669615  11.636023  11.66537   10.506985  11.002068  11.6646385]\n",
      "Reset environment\n",
      "Episode reward: 2153.8574\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6706915 11.637098  11.666449  10.508173  11.003012  11.665717 ]\n",
      "Reset environment\n",
      "Episode reward: 475.5919\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.670305 11.636675 11.666112 10.507691 11.002724 11.665333]\n",
      "Reset environment\n",
      "Episode reward: 1992.4998\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.671054 11.637424 11.666846 10.508512 11.003392 11.666088]\n",
      "Reset environment\n",
      "Episode reward: 4876.453\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.672982  11.639346  11.6687765 10.510624  11.005115  11.668018 ]\n",
      "Reset environment\n",
      "Episode reward: 2137.2659\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.674032 11.640395 11.669825 10.511795 11.006028 11.66907 ]\n",
      "Reset environment\n",
      "Episode reward: 1861.0474\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.674987 11.641354 11.670777 10.51285  11.006859 11.670027]\n",
      "Reset environment\n",
      "Episode reward: 1336.4838\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.675435 11.641808 11.671216 10.513352 11.00726  11.670475]\n",
      "Reset environment\n",
      "Episode reward: 2791.8906\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.676412 11.642811 11.672161 10.514434 11.00813  11.671454]\n",
      "Reset environment\n",
      "Episode reward: 1386.6111\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.677166 11.643567 11.672915 10.515265 11.008784 11.672209]\n",
      "Reset environment\n",
      "Episode reward: 2451.3318\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6780205 11.644398  11.673783  10.516212  11.009535  11.673063 ]\n",
      "Reset environment\n",
      "Episode reward: 2057.8755\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.678758 11.645129 11.674521 10.517024 11.01019  11.673802]\n",
      "Reset environment\n",
      "Episode reward: 2101.114\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.679814 11.646189 11.675571 10.518186 11.011113 11.674857]\n",
      "Reset environment\n",
      "Episode reward: 3145.9888\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.681001 11.647375 11.67676  10.519502 11.012163 11.676045]\n",
      "Reset environment\n",
      "Episode reward: 5144.065\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.683038 11.649406 11.678805 10.521731 11.013994 11.678081]\n",
      "Reset environment\n",
      "Episode reward: 1694.0978\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.683656 11.650021 11.679425 10.522404 11.014544 11.678698]\n",
      "Reset environment\n",
      "Episode reward: 2448.0322\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6845455 11.650909  11.680316  10.523394  11.015317  11.679588 ]\n",
      "Reset environment\n",
      "Episode reward: 2075.6104\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.685275  11.651622  11.6810465 10.524184  11.015946  11.680313 ]\n",
      "Reset environment\n",
      "Episode reward: 3488.6035\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.686614 11.652962 11.682382 10.525657 11.017128 11.681653]\n",
      "Reset environment\n",
      "Episode reward: 2776.9304\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.687672 11.654026 11.68343  10.5268   11.018066 11.682711]\n",
      "Reset environment\n",
      "Episode reward: 2526.8794\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.688564 11.654946 11.68429  10.527765 11.018848 11.683607]\n",
      "Reset environment\n",
      "Episode reward: -509.16315\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.6874895 11.653724  11.683323  10.526694  11.017875  11.682527 ]\n",
      "Reset environment\n",
      "Episode reward: 2035.1837\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.688496 11.654724 11.684329 10.52781  11.018746 11.683534]\n",
      "Reset environment\n",
      "Episode reward: 2407.6025\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.689381 11.655602 11.68522  10.528779 11.019525 11.684419]\n",
      "Reset environment\n",
      "Episode reward: 3711.223\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.690818 11.657062 11.686647 10.53035  11.020812 11.685857]\n",
      "Reset environment\n",
      "Episode reward: 2644.4185\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.691675 11.657941 11.687485 10.531314 11.021583 11.686713]\n",
      "Reset environment\n",
      "Episode reward: -225.02429\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.691045 11.657377 11.686779 10.530735 11.020904 11.686083]\n",
      "Reset environment\n",
      "Episode reward: 1196.5779\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.69143  11.657774 11.687142 10.531166 11.021251 11.686474]\n",
      "Reset environment\n",
      "Episode reward: 1684.9316\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.69196  11.658287 11.687691 10.531782 11.021729 11.687003]\n",
      "Reset environment\n",
      "Episode reward: 1844.221\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.692609 11.658925 11.688346 10.532509 11.022315 11.687654]\n",
      "Reset environment\n",
      "Episode reward: 1731.4407\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.693487 11.659804 11.689223 10.533487 11.023078 11.688532]\n",
      "Reset environment\n",
      "Episode reward: 2159.0854\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.69457  11.660888 11.690297 10.534672 11.024022 11.689615]\n",
      "Reset environment\n",
      "Episode reward: 2450.8545\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.695484 11.661811 11.69121  10.535679 11.024828 11.690531]\n",
      "Reset environment\n",
      "Episode reward: 1566.209\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.696043  11.662364  11.6917715 10.536298  11.025326  11.691089 ]\n",
      "Reset environment\n",
      "Episode reward: 2144.855\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.697125 11.663449 11.692857 10.537489 11.02628  11.692173]\n",
      "Reset environment\n",
      "Episode reward: 2311.0073\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.697965 11.664285 11.693706 10.53841  11.027009 11.693012]\n",
      "Reset environment\n",
      "Episode reward: 1869.1124\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.698614 11.664936 11.694356 10.539133 11.027568 11.693663]\n",
      "Reset environment\n",
      "Episode reward: 2704.5186\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.699458  11.665748  11.695228  10.540102  11.02834   11.6945095]\n",
      "Reset environment\n",
      "Episode reward: 1860.3049\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.7000065 11.666271  11.695806  10.540743  11.028842  11.695059 ]\n",
      "Reset environment\n",
      "Episode reward: 1863.2994\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.700639 11.666922 11.696429 10.541451 11.029406 11.695695]\n",
      "Reset environment\n",
      "Episode reward: 5265.349\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.702753 11.669035 11.698542 10.543759 11.031314 11.697808]\n",
      "Reset environment\n",
      "Episode reward: 2154.2148\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.703812 11.670097 11.699599 10.54493  11.032236 11.698869]\n",
      "Reset environment\n",
      "Episode reward: 2170.4324\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.704555  11.67086   11.70032   10.5457535 11.032884  11.699609 ]\n",
      "Reset environment\n",
      "Episode reward: 1697.985\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.705114  11.671402  11.7008915 10.546372  11.033371  11.700168 ]\n",
      "Reset environment\n",
      "Episode reward: 4794.686\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.706988 11.673272 11.702771 10.548432 11.035052 11.702041]\n",
      "Reset environment\n",
      "Episode reward: 2052.1448\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.708017 11.674298 11.703795 10.549562 11.035949 11.703071]\n",
      "Reset environment\n",
      "Episode reward: 2102.2412\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.709058 11.675336 11.704834 10.550713 11.036855 11.704111]\n",
      "Reset environment\n",
      "Episode reward: 1305.9639\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.709511 11.675795 11.705267 10.551184 11.037271 11.704566]\n",
      "Reset environment\n",
      "Episode reward: 2265.9521\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.710624 11.676902 11.706379 10.552398 11.038238 11.705677]\n",
      "Reset environment\n",
      "Episode reward: 2073.2053\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.711278 11.677585 11.707011 10.553133 11.038818 11.706336]\n",
      "Reset environment\n",
      "Episode reward: 3037.9895\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.71241  11.678711 11.70814  10.554356 11.039807 11.707467]\n",
      "Reset environment\n",
      "Episode reward: 2846.4902\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.713327  11.679599  11.709084  10.5554085 11.040647  11.708387 ]\n",
      "Reset environment\n",
      "Episode reward: 2343.8115\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.714219 11.6805   11.709958 10.556385 11.041445 11.70928 ]\n",
      "Reset environment\n",
      "Episode reward: 2121.022\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.714955 11.681252 11.710685 10.557194 11.042086 11.710016]\n",
      "Reset environment\n",
      "Episode reward: 1694.84\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.715511 11.681798 11.711247 10.557814 11.042582 11.710574]\n",
      "Reset environment\n",
      "Episode reward: 2562.5698\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.716404 11.682717 11.712108 10.558785 11.043369 11.711467]\n",
      "Reset environment\n",
      "Episode reward: 4159.7407\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.718022 11.684335 11.713721 10.560571 11.044812 11.713081]\n",
      "Reset environment\n",
      "Episode reward: 2007.7688\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.719029  11.68534   11.714726  10.561686  11.0456915 11.7140875]\n",
      "Reset environment\n",
      "Episode reward: 4236.872\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.72069  11.686999 11.71638  10.563501 11.047182 11.715748]\n",
      "Reset environment\n",
      "Episode reward: 1987.1588\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.721395  11.687704  11.717085  10.5642805 11.047787  11.716454 ]\n",
      "Reset environment\n",
      "Episode reward: 2161.1152\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.722138  11.688415  11.717836  10.565095  11.048435  11.7171955]\n",
      "Reset environment\n",
      "Episode reward: 2100.4136\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.722874 11.689148 11.718582 10.565911 11.049075 11.717933]\n",
      "Reset environment\n",
      "Episode reward: 1991.8761\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.723872 11.690149 11.719583 10.567013 11.04995  11.71893 ]\n",
      "Reset environment\n",
      "Episode reward: 2349.1824\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.724698 11.690983 11.720396 10.567929 11.050661 11.719756]\n",
      "Reset environment\n",
      "Episode reward: 2023.048\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.725446  11.6917305 11.72114   10.568742  11.051311  11.720504 ]\n",
      "Reset environment\n",
      "Episode reward: 2169.486\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.72652   11.692806  11.722215  10.569924  11.052246  11.7215805]\n",
      "Reset environment\n",
      "Episode reward: 1785.7343\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.727115 11.693399 11.722817 10.570596 11.052783 11.722181]\n",
      "Reset environment\n",
      "Episode reward: 2797.6814\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.72814   11.694411  11.723852  10.571718  11.053682  11.7232065]\n",
      "Reset environment\n",
      "Episode reward: 2462.395\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.729024 11.695304 11.724725 10.572688 11.054454 11.724091]\n",
      "Reset environment\n",
      "Episode reward: 3172.3948\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.7302    11.6964855 11.725895  10.573968  11.055495  11.725268 ]\n",
      "Reset environment\n",
      "Episode reward: 1279.9034\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.730605 11.696888 11.72631  10.574435 11.055856 11.725674]\n",
      "Reset environment\n",
      "Episode reward: 1108.3326\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.730872  11.697133  11.726596  10.574757  11.0560875 11.725943 ]\n",
      "Reset environment\n",
      "Episode reward: 2634.5405\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.731864  11.698123  11.727588  10.575848  11.056955  11.7269335]\n",
      "Reset environment\n",
      "Episode reward: 1408.7896\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.732299 11.698582 11.728004 10.576346 11.057347 11.727373]\n",
      "Reset environment\n",
      "Episode reward: 4542.403\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.734067 11.700358 11.729757 10.578298 11.058936 11.72914 ]\n",
      "Reset environment\n",
      "Episode reward: 3229.7622\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.735292 11.701591 11.730977 10.579645 11.060028 11.730366]\n",
      "Reset environment\n",
      "Episode reward: -148.71506\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.734821 11.701118 11.730503 10.579006 11.059602 11.729895]\n",
      "Reset environment\n",
      "Episode reward: 1543.335\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.73534  11.701655 11.731007 10.579585 11.060066 11.730416]\n",
      "Reset environment\n",
      "Episode reward: 4625.5747\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.737148 11.703451 11.73282  10.581564 11.061693 11.732224]\n",
      "Reset environment\n",
      "Episode reward: 1208.7404\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.737535  11.703839  11.73321   10.5820055 11.062031  11.732612 ]\n",
      "Reset environment\n",
      "Episode reward: 3765.166\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.738968 11.705273 11.734646 10.583598 11.063309 11.734044]\n",
      "Reset environment\n",
      "Episode reward: 2428.7354\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.739818  11.706125  11.7354965 10.584528  11.064051  11.734895 ]\n",
      "Reset environment\n",
      "Episode reward: 1385.8485\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.740561 11.706868 11.736239 10.585351 11.064692 11.735638]\n",
      "Reset environment\n",
      "Episode reward: 850.89856\n",
      "Total Steps: 26\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.740803 11.707112 11.736475 10.585628 11.064902 11.73588 ]\n",
      "Reset environment\n",
      "Episode reward: 1918.3339\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.741774 11.708084 11.737445 10.586701 11.065748 11.736853]\n",
      "Reset environment\n",
      "Episode reward: 1722.7167\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.742337 11.708628 11.738025 10.587333 11.066251 11.737417]\n",
      "Reset environment\n",
      "Episode reward: 1638.4824\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.742899 11.709202 11.738574 10.58796  11.066769 11.737979]\n",
      "Reset environment\n",
      "Episode reward: 2986.0537\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.743995 11.710288 11.739673 10.589171 11.067726 11.739076]\n",
      "Reset environment\n",
      "Episode reward: 5433.3975\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.746434 11.712736 11.742104 10.591859 11.06993  11.741516]\n",
      "Reset environment\n",
      "Episode reward: 2165.821\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.747221 11.713534 11.742887 10.592717 11.070624 11.742304]\n",
      "Reset environment\n",
      "Episode reward: 1698.7826\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.74809  11.714402 11.743755 10.593681 11.071378 11.743175]\n",
      "Reset environment\n",
      "Episode reward: 1446.6261\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.748584 11.714885 11.744253 10.594219 11.071809 11.743666]\n",
      "Reset environment\n",
      "Episode reward: 2938.4712\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.749663 11.715936 11.745352 10.595379 11.072754 11.744743]\n",
      "Reset environment\n",
      "Episode reward: 1959.565\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.75023   11.716527  11.745893  10.596037  11.0732565 11.745311 ]\n",
      "Reset environment\n",
      "Episode reward: 3538.0107\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.751561 11.717866 11.747208 10.597508 11.074439 11.746646]\n",
      "Reset environment\n",
      "Episode reward: 1869.6743\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.7525015 11.718804  11.748147  10.598548  11.075252  11.747589 ]\n",
      "Reset environment\n",
      "Episode reward: 3485.232\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.753826  11.720123  11.7494755 10.599998  11.076428  11.748915 ]\n",
      "Reset environment\n",
      "Episode reward: 1408.6852\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.754581 11.720878 11.750229 10.600833 11.077077 11.74967 ]\n",
      "Reset environment\n",
      "Episode reward: 1624.8466\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.755058 11.721379 11.750685 10.601387 11.07751  11.750149]\n",
      "Reset environment\n",
      "Episode reward: 2188.2148\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.756144 11.722466 11.751764 10.602573 11.078456 11.751232]\n",
      "Reset environment\n",
      "Episode reward: 3698.2075\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.757533 11.723859 11.753138 10.604109 11.079691 11.752622]\n",
      "Reset environment\n",
      "Episode reward: 1932.4081\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.758191 11.724524 11.753778 10.604831 11.080262 11.753281]\n",
      "Reset environment\n",
      "Episode reward: 1791.7905\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.758829 11.725173 11.754403 10.60553  11.080837 11.753923]\n",
      "Reset environment\n",
      "Episode reward: 1604.3738\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.759386 11.725726 11.754965 10.606135 11.081323 11.75448 ]\n",
      "Reset environment\n",
      "Episode reward: 5664.672\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.761626 11.727953 11.757199 10.608585 11.08333  11.756715]\n",
      "Reset environment\n",
      "Episode reward: 3861.0518\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.76311  11.729435 11.75867  10.61021  11.084653 11.758196]\n",
      "Reset environment\n",
      "Episode reward: 2386.6438\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.763933 11.730281 11.759478 10.611124 11.085373 11.759022]\n",
      "Reset environment\n",
      "Episode reward: 2069.9138\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.764965 11.731314 11.760508 10.61226  11.086277 11.760056]\n",
      "Reset environment\n",
      "Episode reward: 2017.2496\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.7656975 11.732047  11.761226  10.6130495 11.086917  11.760794 ]\n",
      "Reset environment\n",
      "Episode reward: 2495.2295\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.766604 11.732959 11.762123 10.614049 11.087701 11.761701]\n",
      "Reset environment\n",
      "Episode reward: 2380.1943\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.767754 11.734107 11.763273 10.61532  11.088715 11.76285 ]\n",
      "Reset environment\n",
      "Episode reward: 2244.5388\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.768406  11.7347975 11.763891  10.616061  11.08929   11.763502 ]\n",
      "Reset environment\n",
      "Episode reward: 2968.8503\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.769507 11.7359   11.764997 10.617279 11.09026  11.764605]\n",
      "Reset environment\n",
      "Episode reward: 2851.025\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.770572  11.736957  11.766065  10.618438  11.0911875 11.76567  ]\n",
      "Reset environment\n",
      "Episode reward: 2646.9724\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.771528  11.737893  11.7670355 10.619487  11.092036  11.76663  ]\n",
      "Reset environment\n",
      "Episode reward: 1947.5728\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.772199  11.73858   11.767687  10.620224  11.092618  11.7673025]\n",
      "Reset environment\n",
      "Episode reward: 5800.6636\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.774496 11.740885 11.769984 10.62275  11.094699 11.769601]\n",
      "Reset environment\n",
      "Episode reward: 4269.392\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.776153 11.742541 11.771635 10.624563 11.09617  11.771255]\n",
      "Reset environment\n",
      "Episode reward: 1885.0292\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.776669  11.743083  11.772122  10.625154  11.096616  11.7717705]\n",
      "Reset environment\n",
      "Episode reward: 5076.9\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.778641 11.74505  11.774099 10.627243 11.098335 11.773744]\n",
      "Reset environment\n",
      "Episode reward: 1777.4594\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.779282 11.745695 11.774731 10.627943 11.098893 11.774385]\n",
      "Reset environment\n",
      "Episode reward: 2353.7356\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.780414 11.746826 11.775857 10.629196 11.099883 11.775516]\n",
      "Reset environment\n",
      "Episode reward: 1858.1265\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.781046 11.747437 11.776495 10.629891 11.100444 11.776147]\n",
      "Reset environment\n",
      "Episode reward: 2460.0764\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.781938 11.748324 11.777386 10.630875 11.101225 11.777037]\n",
      "Reset environment\n",
      "Episode reward: 1796.5457\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.782826 11.749214 11.778272 10.631876 11.101992 11.777926]\n",
      "Reset environment\n",
      "Episode reward: 2580.0566\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.783748 11.750126 11.779205 10.632889 11.102811 11.778849]\n",
      "Reset environment\n",
      "Episode reward: 1910.0394\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.784301 11.750651 11.779784 10.633535 11.103306 11.779409]\n",
      "Reset environment\n",
      "Episode reward: 4157.446\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.785897 11.752245 11.781377 10.635287 11.104721 11.781008]\n",
      "Reset environment\n",
      "Episode reward: 2464.7646\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.786682  11.7530575 11.782134  10.636184  11.105425  11.7817955]\n",
      "Reset environment\n",
      "Episode reward: 5616.6504\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.789204 11.755568 11.784653 10.638937 11.107709 11.784315]\n",
      "Reset environment\n",
      "Episode reward: 1074.8124\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.789531 11.75589  11.784981 10.63931  11.108004 11.784644]\n",
      "Reset environment\n",
      "Episode reward: 2494.216\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.790456 11.756823 11.7859   10.640326 11.108817 11.785568]\n",
      "Reset environment\n",
      "Episode reward: 5335.2485\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.7925625 11.758904  11.788013  10.642619  11.110705  11.787673 ]\n",
      "Reset environment\n",
      "Episode reward: 4553.7573\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.794345 11.760684 11.789794 10.644567 11.112292 11.789456]\n",
      "Reset environment\n",
      "Episode reward: 2947.6655\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.7954235 11.761754  11.790875  10.645759  11.113242  11.790533 ]\n",
      "Reset environment\n",
      "Episode reward: 2588.1125\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.796315  11.76262   11.791787  10.646729  11.114023  11.7914295]\n",
      "Reset environment\n",
      "Episode reward: 3269.9502\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.797523  11.763822  11.792999  10.6480665 11.115094  11.792637 ]\n",
      "Reset environment\n",
      "Episode reward: 1545.6439\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.798003 11.764331 11.793455 10.648618 11.115531 11.793126]\n",
      "Reset environment\n",
      "Episode reward: 1985.569\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.7986965 11.76501   11.794154  10.649371  11.116141  11.7938175]\n",
      "Reset environment\n",
      "Episode reward: 2031.2543\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.799395 11.765718 11.794837 10.650136 11.116751 11.794516]\n",
      "Reset environment\n",
      "Episode reward: 2019.406\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.800102 11.766429 11.795541 10.650919 11.117361 11.795223]\n",
      "Reset environment\n",
      "Episode reward: 3124.55\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.8012705 11.767599  11.796697  10.652201  11.118386  11.79639  ]\n",
      "Reset environment\n",
      "Episode reward: 2511.3677\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.80217  11.768495 11.797601 10.653197 11.119172 11.797288]\n",
      "Reset environment\n",
      "Episode reward: 1802.3037\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.802827 11.769148 11.798256 10.653918 11.119754 11.797945]\n",
      "Reset environment\n",
      "Episode reward: 3704.2751\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.804229 11.770541 11.799655 10.655454 11.120994 11.799349]\n",
      "Reset environment\n",
      "Episode reward: 1975.3737\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.804921  11.771239  11.8003235 10.65621   11.1216    11.800041 ]\n",
      "Reset environment\n",
      "Episode reward: 2417.1902\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.805821 11.772144 11.801222 10.657201 11.122397 11.800943]\n",
      "Reset environment\n",
      "Episode reward: 3942.306\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.807317  11.773638  11.802721  10.658833  11.1237335 11.802443 ]\n",
      "Reset environment\n",
      "Episode reward: 5276.7075\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.809427 11.77574  11.804826 10.661103 11.125611 11.804554]\n",
      "Reset environment\n",
      "Episode reward: 4107.2583\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.810993 11.777312 11.806378 10.662826 11.127021 11.806122]\n",
      "Reset environment\n",
      "Episode reward: 4454.71\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.81271  11.779022 11.808101 10.664713 11.128569 11.807839]\n",
      "Reset environment\n",
      "Episode reward: 4205.4517\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.814315 11.780628 11.809701 10.666408 11.129965 11.809443]\n",
      "Reset environment\n",
      "Episode reward: 2070.1792\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.815059 11.781374 11.810442 10.667222 11.130615 11.810187]\n",
      "Reset environment\n",
      "Episode reward: 3784.601\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.816477  11.7827835 11.811864  10.668796  11.131883  11.811606 ]\n",
      "Reset environment\n",
      "Episode reward: 3955.6895\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.817953 11.78426  11.81335  10.670438 11.1332   11.813085]\n",
      "Reset environment\n",
      "Episode reward: 2040.9907\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.818956 11.785266 11.81435  10.671553 11.134078 11.814093]\n",
      "Reset environment\n",
      "Episode reward: 4271.5635\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.820609 11.786914 11.816004 10.673361 11.135549 11.815747]\n",
      "Reset environment\n",
      "Episode reward: 919.21936\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.820868 11.78718  11.816255 10.673666 11.135776 11.816007]\n",
      "Reset environment\n",
      "Episode reward: 2298.6858\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.821708  11.788017  11.8171015 10.674576  11.136515  11.816847 ]\n",
      "Reset environment\n",
      "Episode reward: 2448.8943\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.822385 11.788727 11.817752 10.675367 11.137109 11.817528]\n",
      "Reset environment\n",
      "Episode reward: 1562.8992\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.82291   11.7892475 11.818274  10.675951  11.137561  11.818055 ]\n",
      "Reset environment\n",
      "Episode reward: 2031.3778\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.823511 11.789822 11.818894 10.676653 11.138103 11.818656]\n",
      "Reset environment\n",
      "Episode reward: 5546.0923\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.825666 11.791978 11.821043 10.679036 11.140047 11.820809]\n",
      "Reset environment\n",
      "Episode reward: 1512.3585\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.826186 11.792495 11.821562 10.679607 11.140501 11.821329]\n",
      "Reset environment\n",
      "Episode reward: 76.038055\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.825726 11.792059 11.82107  10.678959 11.140118 11.820869]\n",
      "Reset environment\n",
      "Episode reward: 5385.8735\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.827832 11.794161 11.82318  10.681268 11.142005 11.822976]\n",
      "Reset environment\n",
      "Episode reward: 4215.288\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.829446 11.795777 11.824792 10.68305  11.143459 11.824589]\n",
      "Reset environment\n",
      "Episode reward: 2371.6653\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.8303    11.79663   11.8256445 10.683994  11.144198  11.825443 ]\n",
      "Reset environment\n",
      "Episode reward: 4415.1357\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.831995 11.798319 11.82734  10.685865 11.14571  11.827139]\n",
      "Reset environment\n",
      "Episode reward: 5414.176\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.834129 11.800447 11.829468 10.688193 11.147628 11.829274]\n",
      "Reset environment\n",
      "Episode reward: 5623.011\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.836303  11.802638  11.83163   10.690593  11.149583  11.8314495]\n",
      "Reset environment\n",
      "Episode reward: 1953.3273\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.836988 11.803325 11.832311 10.691348 11.150179 11.832134]\n",
      "Reset environment\n",
      "Episode reward: 1680.7042\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.837532 11.803847 11.832872 10.691958 11.150665 11.832679]\n",
      "Reset environment\n",
      "Episode reward: 2023.6687\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.838515 11.804828 11.833856 10.693056 11.151515 11.833666]\n",
      "Reset environment\n",
      "Episode reward: -688.8689\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.837325 11.803472 11.832829 10.691963 11.150393 11.832481]\n",
      "Reset environment\n",
      "Episode reward: 1556.5916\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.837837 11.803974 11.833354 10.692541 11.150851 11.832997]\n",
      "Reset environment\n",
      "Episode reward: 1654.3195\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.838685 11.804824 11.834202 10.693479 11.15159  11.833845]\n",
      "Reset environment\n",
      "Episode reward: 1850.8055\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.839327  11.805464  11.8348465 10.694185  11.152141  11.834487 ]\n",
      "Reset environment\n",
      "Episode reward: 1182.6173\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.839705 11.805813 11.835224 10.694545 11.152487 11.834867]\n",
      "Reset environment\n",
      "Episode reward: 3578.6497\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.841036 11.807137 11.836557 10.696016 11.153674 11.836198]\n",
      "Reset environment\n",
      "Episode reward: 2205.6177\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.841796 11.807908 11.837306 10.696855 11.154336 11.836958]\n",
      "Reset environment\n",
      "Episode reward: 2063.4824\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.842817  11.808932  11.8383255 10.697977  11.1552305 11.83798  ]\n",
      "Reset environment\n",
      "Episode reward: 1412.9265\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.843569  11.809684  11.839079  10.698805  11.1558895 11.838732 ]\n",
      "Reset environment\n",
      "Episode reward: 4280.6655\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.845192 11.811303 11.840701 10.700542 11.157301 11.840355]\n",
      "Reset environment\n",
      "Episode reward: 2118.6692\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.846225 11.812335 11.841731 10.701683 11.1582   11.841389]\n",
      "Reset environment\n",
      "Episode reward: 2198.4204\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.847307  11.813421  11.842808  10.7028675 11.159154  11.842474 ]\n",
      "Reset environment\n",
      "Episode reward: -7.8328247\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.846792 11.812875 11.842333 10.702265 11.158694 11.84196 ]\n",
      "Reset environment\n",
      "Episode reward: 4797.648\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.848659  11.814742  11.8442    10.704316  11.1603775 11.843826 ]\n",
      "Reset environment\n",
      "Episode reward: 2491.7053\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.849533 11.815614 11.845083 10.705286 11.161142 11.8447  ]\n",
      "Reset environment\n",
      "Episode reward: 1909.789\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.850073 11.816128 11.845649 10.705924 11.16163  11.84524 ]\n",
      "Reset environment\n",
      "Episode reward: 1529.0754\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.850586  11.816621  11.8461685 10.706491  11.162068  11.845749 ]\n",
      "Reset environment\n",
      "Episode reward: 4904.272\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.852486 11.818516 11.848061 10.708563 11.163763 11.847647]\n",
      "Reset environment\n",
      "Episode reward: 1647.1238\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.853331 11.819359 11.848903 10.709498 11.164499 11.848492]\n",
      "Reset environment\n",
      "Episode reward: 5024.524\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.855268  11.821303  11.850834  10.711617  11.166243  11.8504305]\n",
      "Reset environment\n",
      "Episode reward: 2049.3103\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.85594  11.822    11.85148  10.712378 11.166855 11.851104]\n",
      "Reset environment\n",
      "Episode reward: 4582.8823\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.85771  11.823779 11.853248 10.714325 11.168456 11.852878]\n",
      "Reset environment\n",
      "Episode reward: 1874.1525\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.858408 11.824479 11.853937 10.715083 11.16909  11.853582]\n",
      "Reset environment\n",
      "Episode reward: 4436.6006\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.860104 11.826176 11.855638 10.71695  11.170616 11.855279]\n",
      "Reset environment\n",
      "Episode reward: 3319.6086\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.861361 11.827436 11.856884 10.718317 11.171765 11.856536]\n",
      "Reset environment\n",
      "Episode reward: 2216.784\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.862445 11.828521 11.857965 10.719507 11.172747 11.857619]\n",
      "Reset environment\n",
      "Episode reward: 1400.8547\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.862916  11.828985  11.858445  10.7200365 11.173158  11.858093 ]\n",
      "Reset environment\n",
      "Episode reward: 1661.6329\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.863467 11.829524 11.859007 10.720655 11.173636 11.858644]\n",
      "Reset environment\n",
      "Episode reward: 5239.1196\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.865509 11.831549 11.861056 10.722881 11.17548  11.860683]\n",
      "Reset environment\n",
      "Episode reward: 1516.0793\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.866009 11.832058 11.861537 10.723432 11.175916 11.861187]\n",
      "Reset environment\n",
      "Episode reward: 1486.5244\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.8664665 11.83253   11.861978  10.723942  11.176312  11.861645 ]\n",
      "Reset environment\n",
      "Episode reward: 2545.962\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.867157  11.833256  11.8626375 10.724741  11.176938  11.862334 ]\n",
      "Reset environment\n",
      "Episode reward: 2378.4766\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.867951  11.834025  11.863444  10.725619  11.177612  11.8631315]\n",
      "Reset environment\n",
      "Episode reward: 1657.1696\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.868536 11.834609 11.864028 10.726249 11.178112 11.863716]\n",
      "Reset environment\n",
      "Episode reward: 2259.8442\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.869332 11.835402 11.864826 10.727131 11.178833 11.864514]\n",
      "Reset environment\n",
      "Episode reward: 5640.5728\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.87154  11.837597 11.867031 10.729539 11.180838 11.866718]\n",
      "Reset environment\n",
      "Episode reward: 4783.235\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.873383  11.839432  11.8688755 10.731558  11.182523  11.868562 ]\n",
      "Reset environment\n",
      "Episode reward: 4416.0215\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.875061 11.841116 11.870549 10.733319 11.183998 11.87024 ]\n",
      "Reset environment\n",
      "Episode reward: 2231.1174\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.87585  11.841913 11.871324 10.734182 11.184705 11.871028]\n",
      "Reset environment\n",
      "Episode reward: 2600.3499\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.876822 11.84289  11.872292 10.735241 11.185585 11.872002]\n",
      "Reset environment\n",
      "Episode reward: 1782.0532\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.87742  11.843476 11.872895 10.7359   11.186096 11.8726  ]\n",
      "Reset environment\n",
      "Episode reward: 1688.469\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.878005 11.844058 11.873485 10.736537 11.186606 11.873184]\n",
      "Reset environment\n",
      "Episode reward: 681.8551\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.877782 11.843894 11.87319  10.736229 11.186413 11.872964]\n",
      "Reset environment\n",
      "Episode reward: 2157.2244\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.878836  11.8449545 11.874242  10.737388  11.187368  11.87402  ]\n",
      "Reset environment\n",
      "Episode reward: 3954.9785\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.880337  11.846457  11.875745  10.73904   11.1887455 11.875522 ]\n",
      "Reset environment\n",
      "Episode reward: 4746.33\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.882162  11.848285  11.877574  10.7410345 11.190399  11.877347 ]\n",
      "Reset environment\n",
      "Episode reward: 4758.685\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.883976 11.850103 11.879376 10.743047 11.192059 11.87916 ]\n",
      "Reset environment\n",
      "Episode reward: -383.89154\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.8832655 11.849369  11.878695  10.742176  11.191406  11.878453 ]\n",
      "Reset environment\n",
      "Episode reward: 1856.38\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.884189 11.850294 11.879618 10.743197 11.192245 11.879375]\n",
      "Reset environment\n",
      "Episode reward: 4422.7705\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.885872  11.8519745 11.881303  10.744981  11.193704  11.88106  ]\n",
      "Reset environment\n",
      "Episode reward: 2498.0017\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.886729 11.85282  11.882175 10.745926 11.194431 11.881919]\n",
      "Reset environment\n",
      "Episode reward: 3956.9507\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.888229 11.854323 11.883661 10.747571 11.195793 11.88342 ]\n",
      "Reset environment\n",
      "Episode reward: 3237.4707\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.889407 11.855496 11.884847 10.748882 11.196858 11.884597]\n",
      "Reset environment\n",
      "Episode reward: 2040.9497\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.890408  11.856496  11.8858385 10.749982  11.197763  11.885595 ]\n",
      "Reset environment\n",
      "Episode reward: 1993.0117\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.891108  11.857201  11.886538  10.7507515 11.19839   11.886295 ]\n",
      "Reset environment\n",
      "Episode reward: 2771.6606\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.892115 11.858203 11.887557 10.751856 11.199307 11.887303]\n",
      "Reset environment\n",
      "Episode reward: 1703.2134\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.892531 11.858648 11.887946 10.752343 11.199684 11.887722]\n",
      "Reset environment\n",
      "Episode reward: 2058.4368\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.893144  11.859228  11.8885765 10.753033  11.200219  11.888331 ]\n",
      "Reset environment\n",
      "Episode reward: 1992.2181\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.893763 11.859872 11.889167 10.75373  11.200763 11.888952]\n",
      "Reset environment\n",
      "Episode reward: 993.7966\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.894038 11.860152 11.889435 10.754055 11.200999 11.889232]\n",
      "Reset environment\n",
      "Episode reward: 2060.8704\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.894709 11.860837 11.890089 10.754791 11.2016   11.8899  ]\n",
      "Reset environment\n",
      "Episode reward: 1627.3977\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.895537 11.86167  11.890913 10.755706 11.202347 11.890731]\n",
      "Reset environment\n",
      "Episode reward: 4774.45\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.897591 11.863724 11.892977 10.757946 11.204228 11.892783]\n",
      "Reset environment\n",
      "Episode reward: 2390.0\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.898439 11.864568 11.893831 10.758886 11.20499  11.893631]\n",
      "Reset environment\n",
      "Episode reward: 2161.431\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.899162 11.865305 11.894538 10.759683 11.205635 11.894355]\n",
      "Reset environment\n",
      "Episode reward: 1381.3591\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.899884 11.866029 11.89526  10.760485 11.206286 11.895077]\n",
      "Reset environment\n",
      "Episode reward: 5124.858\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.901853 11.867997 11.897237 10.762647 11.208076 11.897047]\n",
      "Reset environment\n",
      "Episode reward: 1855.3433\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.902482  11.8686285 11.897866  10.763348  11.208647  11.897676 ]\n",
      "Reset environment\n",
      "Episode reward: 1532.2214\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.903021 11.869171 11.8984   10.763944 11.209119 11.898214]\n",
      "Reset environment\n",
      "Episode reward: 2056.2903\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.904027  11.870177  11.8994    10.76505   11.210019  11.8992195]\n",
      "Reset environment\n",
      "Episode reward: 3949.0562\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.905512 11.871668 11.900874 10.766682 11.211355 11.900703]\n",
      "Reset environment\n",
      "Episode reward: 3369.7266\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.906771 11.872929 11.902124 10.76805  11.212491 11.901963]\n",
      "Reset environment\n",
      "Episode reward: 4541.4775\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.908485 11.87465  11.903834 10.76996  11.214052 11.903679]\n",
      "Reset environment\n",
      "Episode reward: 1558.7844\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.908932 11.875074 11.9043   10.770477 11.214451 11.904126]\n",
      "Reset environment\n",
      "Episode reward: 1379.029\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.909378 11.875531 11.904723 10.770967 11.214844 11.904573]\n",
      "Reset environment\n",
      "Episode reward: 3886.5076\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.910856 11.877011 11.906189 10.772581 11.216184 11.90605 ]\n",
      "Reset environment\n",
      "Episode reward: 5282.656\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.912926 11.879067 11.908262 10.774837 11.218065 11.908116]\n",
      "Reset environment\n",
      "Episode reward: 3276.6921\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.914099  11.880229  11.909444  10.7761345 11.219118  11.909289 ]\n",
      "Reset environment\n",
      "Episode reward: 1441.687\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.914493 11.880649 11.909813 10.776589 11.219474 11.909684]\n",
      "Reset environment\n",
      "Episode reward: 5344.8467\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.916584 11.882741 11.911899 10.778875 11.221374 11.911775]\n",
      "Reset environment\n",
      "Episode reward: 2196.416\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.917261 11.88339  11.912597 10.779645 11.221983 11.912454]\n",
      "Reset environment\n",
      "Episode reward: 1879.7488\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.917831 11.883983 11.913136 10.780283 11.222493 11.913027]\n",
      "Reset environment\n",
      "Episode reward: 2146.024\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.91854  11.884708 11.913823 10.781061 11.223127 11.913735]\n",
      "Reset environment\n",
      "Episode reward: 1946.0841\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.919078 11.885214 11.914388 10.781694 11.223603 11.914273]\n",
      "Reset environment\n",
      "Episode reward: 2053.176\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.919761 11.88591  11.915048 10.782443 11.224208 11.914955]\n",
      "Reset environment\n",
      "Episode reward: 2155.6196\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.920497  11.886654  11.9157715 10.78325   11.224872  11.9156885]\n",
      "Reset environment\n",
      "Episode reward: -421.6784\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.919731 11.88585  11.915038 10.782312 11.224178 11.914925]\n",
      "Reset environment\n",
      "Episode reward: 3708.352\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.921099  11.887217  11.916405  10.7838335 11.225422  11.916292 ]\n",
      "Reset environment\n",
      "Episode reward: 3480.322\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.922384 11.888514 11.917686 10.785257 11.226584 11.917577]\n",
      "Reset environment\n",
      "Episode reward: 2419.4243\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.923157 11.889257 11.918486 10.786105 11.227253 11.91835 ]\n",
      "Reset environment\n",
      "Episode reward: 1398.3481\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.923893  11.889992  11.91922   10.78692   11.227914  11.9190855]\n",
      "Reset environment\n",
      "Episode reward: 1654.644\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.924464  11.890566  11.919781  10.787544  11.228412  11.9196615]\n",
      "Reset environment\n",
      "Episode reward: 2273.0164\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.925267  11.891372  11.920579  10.788433  11.229135  11.9204645]\n",
      "Reset environment\n",
      "Episode reward: 2651.6836\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.926237  11.892344  11.921543  10.7894945 11.230011  11.921434 ]\n",
      "Reset environment\n",
      "Episode reward: 2709.6843\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.9270935 11.8932295 11.922374  10.790444  11.230793  11.922293 ]\n",
      "Reset environment\n",
      "Episode reward: 1772.2224\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.927983 11.894123 11.923262 10.791425 11.2316   11.923182]\n",
      "Reset environment\n",
      "Episode reward: 3391.6313\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.929273 11.895415 11.924548 10.792824 11.232778 11.924471]\n",
      "Reset environment\n",
      "Episode reward: 2484.8145\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.930171  11.89631   11.925438  10.793804  11.2335825 11.925369 ]\n",
      "Reset environment\n",
      "Episode reward: 4463.1626\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.931856 11.898002 11.927111 10.795666 11.235121 11.927054]\n",
      "Reset environment\n",
      "Episode reward: -129.23352\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.931199  11.89747   11.926332  10.795072  11.2344885 11.92641  ]\n",
      "Reset environment\n",
      "Episode reward: 2460.4219\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.932033 11.898323 11.927149 10.795994 11.235247 11.927248]\n",
      "Reset environment\n",
      "Episode reward: 2919.1602\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.932973  11.8992405 11.92812   10.797064  11.236105  11.928193 ]\n",
      "Reset environment\n",
      "Episode reward: 4245.375\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.934555 11.900826 11.929703 10.798763 11.237493 11.929778]\n",
      "Reset environment\n",
      "Episode reward: 5152.1343\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.93655  11.90282  11.931692 10.800943 11.239297 11.931772]\n",
      "Reset environment\n",
      "Episode reward: 5774.0664\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.938795 11.905057 11.933934 10.803391 11.241339 11.934018]\n",
      "Reset environment\n",
      "Episode reward: 2104.9482\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.939823  11.906084  11.934959  10.804519  11.2422695 11.935048 ]\n",
      "Reset environment\n",
      "Episode reward: 2148.25\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.94058  11.906844 11.935713 10.805353 11.242956 11.935805]\n",
      "Reset environment\n",
      "Episode reward: 5330.1685\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.942639 11.9089   11.93777  10.8076   11.244817 11.937864]\n",
      "Reset environment\n",
      "Episode reward: 3331.526\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.943889 11.910157 11.93901  10.80895  11.245965 11.939113]\n",
      "Reset environment\n",
      "Episode reward: 6038.4204\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.94624  11.912513 11.941352 10.811525 11.248113 11.941464]\n",
      "Reset environment\n",
      "Episode reward: 2099.8833\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.946936 11.913221 11.942036 10.812299 11.248728 11.94216 ]\n",
      "Reset environment\n",
      "Episode reward: 1859.3654\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.947844  11.914131  11.942944  10.81331   11.249557  11.9430685]\n",
      "Reset environment\n",
      "Episode reward: 2337.086\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.948679  11.9149685 11.943778  10.81423   11.250315  11.943904 ]\n",
      "Reset environment\n",
      "Episode reward: 3017.0574\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.949734 11.916006 11.94484  10.815409 11.251266 11.944959]\n",
      "Reset environment\n",
      "Episode reward: 2011.9205\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.950359 11.916616 11.945488 10.816116 11.251817 11.945587]\n",
      "Reset environment\n",
      "Episode reward: 202.79599\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.949907 11.916124 11.945071 10.815625 11.251405 11.945139]\n",
      "Reset environment\n",
      "Episode reward: 5127.689\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.951839 11.918069 11.94699  10.817771 11.25317  11.947069]\n",
      "Reset environment\n",
      "Episode reward: 4779.1226\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.953663 11.91989  11.948808 10.819773 11.254813 11.948894]\n",
      "Reset environment\n",
      "Episode reward: -446.94952\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.95278  11.918935 11.947993 10.818878 11.253993 11.94801 ]\n",
      "Reset environment\n",
      "Episode reward: 1826.4811\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.953673 11.919827 11.948884 10.819873 11.254799 11.948902]\n",
      "Reset environment\n",
      "Episode reward: 553.0142\n",
      "Total Steps: 18\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.953763  11.919917  11.948975  10.819999  11.2548685 11.948995 ]\n",
      "Reset environment\n",
      "Episode reward: 5099.335\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.955737 11.921883 11.950955 10.822154 11.256671 11.950969]\n",
      "Reset environment\n",
      "Episode reward: 908.47\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.955987 11.922141 11.951198 10.822445 11.256887 11.95122 ]\n",
      "Reset environment\n",
      "Episode reward: 2329.2463\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.956794 11.92294  11.952019 10.823327 11.257596 11.952029]\n",
      "Reset environment\n",
      "Episode reward: 2212.7925\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.957864 11.924006 11.953082 10.824497 11.258562 11.953095]\n",
      "Reset environment\n",
      "Episode reward: 2757.9395\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.958867 11.925006 11.954078 10.825602 11.25946  11.954102]\n",
      "Reset environment\n",
      "Episode reward: 2478.5198\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.959733  11.925891  11.954919  10.826533  11.260238  11.9549675]\n",
      "Reset environment\n",
      "Episode reward: 4806.1187\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.961578 11.927737 11.956766 10.828555 11.26191  11.956814]\n",
      "Reset environment\n",
      "Episode reward: 1193.779\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.961956 11.928109 11.957151 10.828982 11.262237 11.957191]\n",
      "Reset environment\n",
      "Episode reward: 1816.6946\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.962559  11.928732  11.957739  10.8296585 11.26277   11.957804 ]\n",
      "Reset environment\n",
      "Episode reward: 1364.0637\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.963271 11.929445 11.95845  10.830447 11.263413 11.958515]\n",
      "Reset environment\n",
      "Episode reward: 2228.216\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.964049 11.930227 11.959231 10.831309 11.264114 11.959294]\n",
      "Reset environment\n",
      "Episode reward: 4563.837\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.965795 11.931957 11.960975 10.83321  11.265685 11.961037]\n",
      "Reset environment\n",
      "Episode reward: 1634.2617\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.966322 11.932494 11.961478 10.833794 11.266143 11.961571]\n",
      "Reset environment\n",
      "Episode reward: 2474.7778\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.967007 11.933151 11.962187 10.8346   11.266758 11.96226 ]\n",
      "Reset environment\n",
      "Episode reward: 4669.348\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.968809  11.934951  11.963985  10.836549  11.2683735 11.964066 ]\n",
      "Reset environment\n",
      "Episode reward: 4839.528\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.970625 11.936763 11.965793 10.838497 11.269944 11.965882]\n",
      "Reset environment\n",
      "Episode reward: 1945.4917\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.971308 11.937443 11.966472 10.839246 11.270542 11.966566]\n",
      "Reset environment\n",
      "Episode reward: 4622.2007\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.973043 11.939187 11.968194 10.841172 11.272124 11.968296]\n",
      "Reset environment\n",
      "Episode reward: 1800.3333\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.973689 11.93984  11.968837 10.841878 11.27269  11.96895 ]\n",
      "Reset environment\n",
      "Episode reward: 3034.719\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.9748125 11.9409685 11.969959  10.843106  11.273706  11.970076 ]\n",
      "Reset environment\n",
      "Episode reward: 5838.5625\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.977071 11.943232 11.972208 10.845589 11.275766 11.972329]\n",
      "Reset environment\n",
      "Episode reward: 1382.798\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.977528 11.943682 11.972666 10.846083 11.276151 11.972786]\n",
      "Reset environment\n",
      "Episode reward: 2150.716\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.978065  11.94419   11.973234  10.846716  11.2766285 11.973322 ]\n",
      "Reset environment\n",
      "Episode reward: 1471.294\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.978566  11.944684  11.973737  10.8472595 11.27705   11.973823 ]\n",
      "Reset environment\n",
      "Episode reward: 5463.4014\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.980597 11.946699 11.975769 10.849431 11.278809 11.975845]\n",
      "Reset environment\n",
      "Episode reward: 2620.851\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.981515 11.947607 11.976696 10.850427 11.279618 11.976765]\n",
      "Reset environment\n",
      "Episode reward: 2003.2089\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.982196 11.948282 11.977379 10.851168 11.280219 11.977445]\n",
      "Reset environment\n",
      "Episode reward: 1842.4769\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.982837 11.948933 11.978007 10.851871 11.280782 11.97809 ]\n",
      "Reset environment\n",
      "Episode reward: 2459.192\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.9837   11.949788 11.978882 10.852815 11.281566 11.978952]\n",
      "Reset environment\n",
      "Episode reward: 1962.3649\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.984332 11.950439 11.979494 10.853509 11.282126 11.97959 ]\n",
      "Reset environment\n",
      "Episode reward: 2171.2417\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.985019 11.951147 11.980161 10.854277 11.282741 11.980278]\n",
      "Reset environment\n",
      "Episode reward: 1640.5848\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.985537 11.95165  11.980688 10.854851 11.283192 11.980796]\n",
      "Reset environment\n",
      "Episode reward: 1669.9624\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.986031 11.95216  11.981158 10.85541  11.283624 11.981291]\n",
      "Reset environment\n",
      "Episode reward: 1595.0688\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.986566 11.952697 11.981687 10.855997 11.284096 11.981827]\n",
      "Reset environment\n",
      "Episode reward: 1691.2125\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.987142 11.953277 11.982261 10.856628 11.284604 11.982403]\n",
      "Reset environment\n",
      "Episode reward: 2416.0637\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.987997 11.954137 11.983109 10.857566 11.28537  11.98326 ]\n",
      "Reset environment\n",
      "Episode reward: 2073.57\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.988667 11.954799 11.983792 10.858311 11.285952 11.983929]\n",
      "Reset environment\n",
      "Episode reward: 2258.0156\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.989333 11.95549  11.984431 10.859056 11.286552 11.984595]\n",
      "Reset environment\n",
      "Episode reward: 3293.0493\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.990541 11.956712 11.985631 10.860378 11.28766  11.985804]\n",
      "Reset environment\n",
      "Episode reward: 562.3491\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.990239 11.956476 11.98526  10.85999  11.287393 11.985508]\n",
      "Reset environment\n",
      "Episode reward: 3732.361\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.991643 11.957884 11.986656 10.861522 11.288673 11.986913]\n",
      "Reset environment\n",
      "Episode reward: 5265.3203\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.993676  11.959915  11.9886875 10.863733  11.290517  11.988946 ]\n",
      "Reset environment\n",
      "Episode reward: 5311.0127\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.99601  11.962251 11.991007 10.866289 11.292644 11.991276]\n",
      "Reset environment\n",
      "Episode reward: 3364.7773\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.997244 11.963487 11.992236 10.867637 11.293754 11.992509]\n",
      "Reset environment\n",
      "Episode reward: -309.1952\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.996449  11.962612  11.991534  10.866915  11.293034  11.9917145]\n",
      "Reset environment\n",
      "Episode reward: 1422.8503\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.996916 11.963078 11.992005 10.867424 11.293425 11.992182]\n",
      "Reset environment\n",
      "Episode reward: 2407.647\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.997731  11.963895  11.992821  10.8683195 11.294164  11.992997 ]\n",
      "Reset environment\n",
      "Episode reward: 2193.6008\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.998797 11.964962 11.99388  10.869479 11.295118 11.994064]\n",
      "Reset environment\n",
      "Episode reward: 2246.9595\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [11.999594  11.965764  11.994672  10.8703575 11.295843  11.994862 ]\n",
      "Reset environment\n",
      "Episode reward: 2171.6875\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.000352 11.966519 11.995431 10.871192 11.296531 11.995621]\n",
      "Reset environment\n",
      "Episode reward: 2120.124\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.001065 11.967241 11.996132 10.87198  11.297176 11.996334]\n",
      "Reset environment\n",
      "Episode reward: 2127.3076\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.002077 11.968257 11.997141 10.873102 11.298099 11.997346]\n",
      "Reset environment\n",
      "Episode reward: 3063.6472\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.003171 11.969374 11.998213 10.874295 11.299086 11.998438]\n",
      "Reset environment\n",
      "Episode reward: 1375.2357\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.00388   11.970083  11.9989195 10.875085  11.299725  11.999147 ]\n",
      "Reset environment\n",
      "Episode reward: 3411.757\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.005106 11.971306 12.000152 10.876451 11.300847 12.000374]\n",
      "Reset environment\n",
      "Episode reward: 2179.072\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.005869 11.972062 12.000921 10.877288 11.301522 12.001137]\n",
      "Reset environment\n",
      "Episode reward: 975.6253\n",
      "Total Steps: 30\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.006159 11.972354 12.001213 10.877615 11.301766 12.001432]\n",
      "Reset environment\n",
      "Episode reward: 2532.295\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.007057 11.973242 12.002116 10.878597 11.302581 12.002332]\n",
      "Reset environment\n",
      "Episode reward: 1461.7891\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.00754  11.973725 12.002601 10.879124 11.302988 12.002817]\n",
      "Reset environment\n",
      "Episode reward: 2183.251\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.008221 11.974385 12.0033   10.87989  11.303577 12.003499]\n",
      "Reset environment\n",
      "Episode reward: 5245.627\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0102415 11.976395  12.005314  10.882086  11.305397  12.005514 ]\n",
      "Reset environment\n",
      "Episode reward: 2250.7632\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.010912 11.977086 12.005957 10.882839 11.306001 12.006186]\n",
      "Reset environment\n",
      "Episode reward: 1898.4718\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.011802 11.977975 12.006847 10.88384  11.306803 12.007075]\n",
      "Reset environment\n",
      "Episode reward: 2387.3972\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.012488 11.97864  12.007556 10.884639 11.307428 12.00777 ]\n",
      "Reset environment\n",
      "Episode reward: 3281.0972\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.013705 11.979859 12.008767 10.885966 11.308532 12.008989]\n",
      "Reset environment\n",
      "Episode reward: 2295.3176\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.014406 11.98059  12.009447 10.886758 11.30917  12.009696]\n",
      "Reset environment\n",
      "Episode reward: 1391.7329\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.015124 11.981308 12.010163 10.887555 11.309817 12.010413]\n",
      "Reset environment\n",
      "Episode reward: 2686.115\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0161085 11.982297  12.011139  10.888636  11.310703  12.011398 ]\n",
      "Reset environment\n",
      "Episode reward: 1290.4521\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.016527  11.98271   12.0115595 10.889099  11.311069  12.011817 ]\n",
      "Reset environment\n",
      "Episode reward: 2929.0005\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.017562  11.983731  12.012602  10.89023   11.3119955 12.012851 ]\n",
      "Reset environment\n",
      "Episode reward: 3199.8792\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0187    11.984859  12.013756  10.891495  11.313032  12.0139885]\n",
      "Reset environment\n",
      "Episode reward: 2618.824\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.01962  11.98578  12.014675 10.892515 11.313858 12.014913]\n",
      "Reset environment\n",
      "Episode reward: 1914.5507\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.020557 11.986713 12.015611 10.893547 11.314705 12.015847]\n",
      "Reset environment\n",
      "Episode reward: 2853.0732\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.02157  11.987717 12.016633 10.894649 11.315613 12.016862]\n",
      "Reset environment\n",
      "Episode reward: 2505.0278\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.022452 11.988608 12.017508 10.895612 11.31641  12.017744]\n",
      "Reset environment\n",
      "Episode reward: 2157.9878\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.023171 11.989336 12.018221 10.89641  11.317059 12.018462]\n",
      "Reset environment\n",
      "Episode reward: 1836.3428\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.023769 11.989921 12.018825 10.897071 11.317573 12.019061]\n",
      "Reset environment\n",
      "Episode reward: 3067.6377\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.024865 11.991013 12.019925 10.89828  11.318569 12.020158]\n",
      "Reset environment\n",
      "Episode reward: 5546.627\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.027023 11.99317  12.022072 10.900603 11.320505 12.02232 ]\n",
      "Reset environment\n",
      "Episode reward: 2217.0225\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.028082  11.994226  12.023134  10.901764  11.3214655 12.02338  ]\n",
      "Reset environment\n",
      "Episode reward: 4067.1235\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.029611 11.995753 12.024669 10.903444 11.322874 12.024909]\n",
      "Reset environment\n",
      "Episode reward: 1890.6459\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.030526 11.996669 12.025582 10.904457 11.323706 12.025825]\n",
      "Reset environment\n",
      "Episode reward: 1725.8544\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.031144 11.997284 12.026195 10.905126 11.324235 12.02645 ]\n",
      "Reset environment\n",
      "Episode reward: 4734.3066\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.032925  11.999064  12.0279665 10.907078  11.325836  12.028229 ]\n",
      "Reset environment\n",
      "Episode reward: 1749.7777\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0333805 11.99948   12.028461  10.907608  11.326237  12.028689 ]\n",
      "Reset environment\n",
      "Episode reward: 1825.2445\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.033974  12.000058  12.029068  10.9082575 11.326743  12.029283 ]\n",
      "Reset environment\n",
      "Episode reward: 2040.0779\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.034951 12.001037 12.030041 10.909342 11.327624 12.030262]\n",
      "Reset environment\n",
      "Episode reward: 1611.1274\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.035505 12.001579 12.030598 10.909942 11.328089 12.030816]\n",
      "Reset environment\n",
      "Episode reward: 912.65845\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.035768 12.001841 12.030861 10.910238 11.328311 12.031079]\n",
      "Reset environment\n",
      "Episode reward: 2099.3645\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.03678  12.002853 12.031877 10.911346 11.329226 12.032094]\n",
      "Reset environment\n",
      "Episode reward: 2027.3527\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.037758  12.003832  12.032853  10.912418  11.330095  12.0330715]\n",
      "Reset environment\n",
      "Episode reward: 2861.837\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.038748  12.004824  12.033842  10.913499  11.330981  12.0340605]\n",
      "Reset environment\n",
      "Episode reward: 1912.9939\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.039683 12.005765 12.034775 10.914532 11.331821 12.034993]\n",
      "Reset environment\n",
      "Episode reward: 4946.215\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.041548 12.007626 12.036635 10.91659  11.333514 12.036854]\n",
      "Reset environment\n",
      "Episode reward: 1873.0841\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.042178 12.008263 12.037262 10.917284 11.334083 12.037487]\n",
      "Reset environment\n",
      "Episode reward: 1929.6727\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.042833 12.008919 12.037918 10.918009 11.334673 12.038141]\n",
      "Reset environment\n",
      "Episode reward: 5579.8667\n",
      "Total Steps: 209\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.045288  12.0113735 12.040363  10.920675  11.336915  12.040591 ]\n",
      "Reset environment\n",
      "Episode reward: 1781.8317\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.045879  12.011958  12.04096   10.92132   11.337426  12.0411825]\n",
      "Reset environment\n",
      "Episode reward: 2150.8591\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.046582 12.012645 12.041676 10.922096 11.338029 12.041887]\n",
      "Reset environment\n",
      "Episode reward: 1725.6294\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.047435 12.013498 12.042527 10.923047 11.3388   12.04274 ]\n",
      "Reset environment\n",
      "Episode reward: 837.5642\n",
      "Total Steps: 26\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.047656 12.013711 12.042749 10.923303 11.338986 12.042961]\n",
      "Reset environment\n",
      "Episode reward: 2454.9285\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.048486 12.014555 12.043569 10.924221 11.339738 12.043791]\n",
      "Reset environment\n",
      "Episode reward: 1342.8046\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0491705 12.015242  12.044253  10.924983  11.340355  12.044476 ]\n",
      "Reset environment\n",
      "Episode reward: 1590.3711\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.049581  12.015685  12.044629  10.925461  11.34072   12.0448885]\n",
      "Reset environment\n",
      "Episode reward: 505.9337\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.049442 12.015543 12.044488 10.925212 11.340601 12.044753]\n",
      "Reset environment\n",
      "Episode reward: 2701.0686\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.050392 12.016481 12.045449 10.926249 11.341445 12.045704]\n",
      "Reset environment\n",
      "Episode reward: 1781.7063\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.050994 12.017084 12.04605  10.926912 11.341985 12.046306]\n",
      "Reset environment\n",
      "Episode reward: 2375.816\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.051711 12.017826 12.04674  10.927733 11.342617 12.047026]\n",
      "Reset environment\n",
      "Episode reward: 1390.677\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.052431 12.018546 12.04746  10.92853  11.343266 12.047747]\n",
      "Reset environment\n",
      "Episode reward: 1310.972\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.052825 12.018959 12.047841 10.92897  11.343613 12.048142]\n",
      "Reset environment\n",
      "Episode reward: 2748.8645\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.053815 12.019954 12.048828 10.93005  11.344505 12.049132]\n",
      "Reset environment\n",
      "Episode reward: 2531.167\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.054664 12.020813 12.049669 10.930991 11.345264 12.04998 ]\n",
      "Reset environment\n",
      "Episode reward: 2862.8877\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.055691 12.021838 12.050705 10.932109 11.346194 12.051009]\n",
      "Reset environment\n",
      "Episode reward: 4715.4927\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.057468 12.023622 12.052469 10.934055 11.347798 12.052786]\n",
      "Reset environment\n",
      "Episode reward: 2024.1754\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.05816  12.024317 12.053161 10.934817 11.348425 12.053478]\n",
      "Reset environment\n",
      "Episode reward: 1313.3916\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.058246 12.024421 12.053214 10.934819 11.348516 12.053575]\n",
      "Reset environment\n",
      "Episode reward: 1551.2079\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0590105 12.0251875 12.053984  10.935673  11.349206  12.05434  ]\n",
      "Reset environment\n",
      "Episode reward: 2143.453\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0597315 12.02591   12.054703  10.936479  11.34986   12.055062 ]\n",
      "Reset environment\n",
      "Episode reward: 1596.621\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.060121 12.026328 12.05506  10.936936 11.350206 12.055451]\n",
      "Reset environment\n",
      "Episode reward: 5201.514\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.062119 12.028321 12.057057 10.939087 11.351986 12.057449]\n",
      "Reset environment\n",
      "Episode reward: 1394.2549\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.062837  12.02904   12.057776  10.939879  11.352635  12.0581665]\n",
      "Reset environment\n",
      "Episode reward: 2189.3276\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.063605 12.029811 12.05854  10.940721 11.353332 12.058935]\n",
      "Reset environment\n",
      "Episode reward: 1929.7821\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.064166 12.03035  12.059127 10.941365 11.353835 12.059502]\n",
      "Reset environment\n",
      "Episode reward: 1975.3132\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.064806 12.031006 12.059758 10.94208  11.354408 12.060143]\n",
      "Reset environment\n",
      "Episode reward: 4940.3735\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.066678  12.032871  12.061625  10.944131  11.3561125 12.062014 ]\n",
      "Reset environment\n",
      "Episode reward: 2440.5034\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.067512 12.033718 12.062444 10.945044 11.35687  12.062847]\n",
      "Reset environment\n",
      "Episode reward: 1868.087\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0681   12.03429  12.06304  10.945704 11.357384 12.063436]\n",
      "Reset environment\n",
      "Episode reward: 2160.2583\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.069133  12.035323  12.064071  10.9468355 11.358318  12.06447  ]\n",
      "Reset environment\n",
      "Episode reward: 4521.064\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.070838 12.037021 12.065772 10.948698 11.359867 12.06617 ]\n",
      "Reset environment\n",
      "Episode reward: 1606.8911\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.071373 12.037556 12.066307 10.949286 11.360341 12.066705]\n",
      "Reset environment\n",
      "Episode reward: 5417.4585\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.07345  12.039621 12.068385 10.95154  11.362214 12.068782]\n",
      "Reset environment\n",
      "Episode reward: 1571.6914\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.073967 12.040139 12.068898 10.952113 11.362672 12.069301]\n",
      "Reset environment\n",
      "Episode reward: 4000.6536\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.075418 12.04159  12.07035  10.95367  11.36393  12.070752]\n",
      "Reset environment\n",
      "Episode reward: 2726.0269\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.076379 12.042541 12.071311 10.954726 11.364803 12.071712]\n",
      "Reset environment\n",
      "Episode reward: 1369.0504\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.077081  12.043242  12.07201   10.9555025 11.365434  12.0724125]\n",
      "Reset environment\n",
      "Episode reward: 1989.6558\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.077742 12.043898 12.072674 10.956232 11.36601  12.073074]\n",
      "Reset environment\n",
      "Episode reward: 2097.0386\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.078738  12.0449    12.0736685 10.957332  11.366911  12.074071 ]\n",
      "Reset environment\n",
      "Episode reward: 527.453\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.078318  12.04442   12.0733185 10.956866  11.366561  12.073657 ]\n",
      "Reset environment\n",
      "Episode reward: 3688.1172\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.079688 12.045799 12.074681 10.958349 11.367804 12.075028]\n",
      "Reset environment\n",
      "Episode reward: 1940.8182\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.080331  12.046426  12.0753355 10.9590645 11.368367  12.075672 ]\n",
      "Reset environment\n",
      "Episode reward: 2094.425\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.081002  12.04708   12.076024  10.959815  11.368964  12.0763445]\n",
      "Reset environment\n",
      "Episode reward: 5279.685\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.083032 12.049095 12.078041 10.962005 11.370777 12.078369]\n",
      "Reset environment\n",
      "Episode reward: 3921.033\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.084458 12.050526 12.079467 10.963519 11.372031 12.079796]\n",
      "Reset environment\n",
      "Episode reward: 1808.4609\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.0849085 12.051004  12.079882  10.964044  11.372432  12.080248 ]\n",
      "Reset environment\n",
      "Episode reward: 664.2477\n",
      "Total Steps: 21\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.085047 12.051145 12.080018 10.964219 11.372546 12.080385]\n",
      "Reset environment\n",
      "Episode reward: 5189.8096\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.087324 12.053429 12.082285 10.966689 11.374611 12.08266 ]\n",
      "Reset environment\n",
      "Episode reward: 2549.1506\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.088159 12.054293 12.083088 10.967614 11.375337 12.083496]\n",
      "Reset environment\n",
      "Episode reward: 5364.4575\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.090203 12.056341 12.08512  10.969834 11.377186 12.085543]\n",
      "Reset environment\n",
      "Episode reward: 2261.3232\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.090767 12.056936 12.085652 10.970491 11.377697 12.086108]\n",
      "Reset environment\n",
      "Episode reward: 3257.4006\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.091928 12.05809  12.086821 10.971766 11.37875  12.087269]\n",
      "Reset environment\n",
      "Episode reward: 3396.688\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.093134  12.0592985 12.088028  10.973063  11.3798275 12.088475 ]\n",
      "Reset environment\n",
      "Episode reward: -72.2778\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.092398  12.058635  12.087213  10.9723015 11.379155  12.087744 ]\n",
      "Reset environment\n",
      "Episode reward: 1912.2686\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.093331 12.059571 12.088141 10.973327 11.379994 12.08868 ]\n",
      "Reset environment\n",
      "Episode reward: -286.9864\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.092649 12.058862 12.087476 10.972496 11.379374 12.087999]\n",
      "Reset environment\n",
      "Episode reward: 2249.812\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.093455 12.05967  12.088279 10.973372 11.38009  12.088805]\n",
      "Reset environment\n",
      "Episode reward: 683.3989\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.093171 12.059323 12.088041 10.973035 11.379849 12.08852 ]\n",
      "Reset environment\n",
      "Episode reward: 1973.1367\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.093816  12.059954  12.0886965 10.973744  11.380412  12.089168 ]\n",
      "Reset environment\n",
      "Episode reward: 3339.8726\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.094991 12.061136 12.089866 10.975011 11.38147  12.090343]\n",
      "Reset environment\n",
      "Episode reward: 5000.4956\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.096885 12.063027 12.091762 10.977079 11.383201 12.09224 ]\n",
      "Reset environment\n",
      "Episode reward: 4801.4604\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.098698 12.06483  12.093574 10.979055 11.384827 12.094051]\n",
      "Reset environment\n",
      "Episode reward: 2099.1753\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.099696 12.06583  12.094569 10.980148 11.385732 12.095052]\n",
      "Reset environment\n",
      "Episode reward: 3103.8513\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.100795 12.066934 12.095657 10.981357 11.386728 12.096152]\n",
      "Reset environment\n",
      "Episode reward: 2710.8672\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.101713 12.067834 12.096599 10.982369 11.38753  12.097071]\n",
      "Reset environment\n",
      "Episode reward: 2694.0588\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.102658 12.068778 12.097546 10.983413 11.388391 12.098016]\n",
      "Reset environment\n",
      "Episode reward: 2526.4775\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.103484 12.06958  12.098394 10.984318 11.389093 12.09885 ]\n",
      "Reset environment\n",
      "Episode reward: 1412.4086\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.103929  12.070039  12.0988245 10.984811  11.3894825 12.099297 ]\n",
      "Reset environment\n",
      "Episode reward: 2875.7437\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.104961 12.071076 12.099853 10.985938 11.39042  12.10033 ]\n",
      "Reset environment\n",
      "Episode reward: 2402.6394\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.10581  12.071925 12.100704 10.986871 11.391194 12.101179]\n",
      "Reset environment\n",
      "Episode reward: 1842.5874\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.10648  12.072599 12.101364 10.987616 11.391774 12.101857]\n",
      "Reset environment\n",
      "Episode reward: 1408.7499\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.106951 12.073076 12.10182  10.988146 11.392187 12.102327]\n",
      "Reset environment\n",
      "Episode reward: 2059.372\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.10764  12.073773 12.102498 10.988909 11.392803 12.103017]\n",
      "Reset environment\n",
      "Episode reward: 700.8916\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.107419 12.073611 12.102209 10.988604 11.392597 12.102794]\n",
      "Reset environment\n",
      "Episode reward: 2942.6191\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.108442 12.074637 12.103233 10.989719 11.39352  12.103818]\n",
      "Reset environment\n",
      "Episode reward: 2109.4026\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.109105 12.075314 12.103886 10.990466 11.394116 12.10448 ]\n",
      "Reset environment\n",
      "Episode reward: 1744.4813\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.109957 12.076166 12.104738 10.991408 11.394894 12.105334]\n",
      "Reset environment\n",
      "Episode reward: 4818.335\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.111756 12.077969 12.106518 10.993342 11.39653  12.107132]\n",
      "Reset environment\n",
      "Episode reward: 1651.7986\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.112343  12.078561  12.1071005 10.993994  11.397035  12.107721 ]\n",
      "Reset environment\n",
      "Episode reward: 2504.7522\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.113219  12.07943   12.1079855 10.994952  11.397833  12.108598 ]\n",
      "Reset environment\n",
      "Episode reward: 2253.1516\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.113972 12.080182 12.10874  10.995801 11.398512 12.109354]\n",
      "Reset environment\n",
      "Episode reward: 1746.7476\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.114561 12.080771 12.109329 10.996458 11.399028 12.109946]\n",
      "Reset environment\n",
      "Episode reward: 1375.958\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.115254  12.081469  12.110023  10.997237  11.399659  12.1106415]\n",
      "Reset environment\n",
      "Episode reward: 5406.5254\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.117279 12.083496 12.112046 10.999424 11.401484 12.112666]\n",
      "Reset environment\n",
      "Episode reward: 1473.6282\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.117765 12.083992 12.112522 10.999968 11.401904 12.113153]\n",
      "Reset environment\n",
      "Episode reward: 1510.4355\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.118255  12.084487  12.1129875 11.000501  11.402322  12.113644 ]\n",
      "Reset environment\n",
      "Episode reward: 2018.0564\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.1189375 12.085168  12.113672  11.001253  11.402942  12.1143265]\n",
      "Reset environment\n",
      "Episode reward: 2096.3992\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.11994  12.086169 12.114675 11.002339 11.403847 12.115329]\n",
      "Reset environment\n",
      "Episode reward: 396.48563\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.119529 12.085695 12.114309 11.001875 11.403493 12.114919]\n",
      "Reset environment\n",
      "Episode reward: 1797.2498\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.120124 12.086291 12.114904 11.002539 11.40402  12.115514]\n",
      "Reset environment\n",
      "Episode reward: 2291.3389\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.120932 12.087092 12.115711 11.003423 11.404736 12.116324]\n",
      "Reset environment\n",
      "Episode reward: 2031.3442\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.121611 12.087776 12.116386 11.004174 11.405348 12.117003]\n",
      "Reset environment\n",
      "Episode reward: 1734.2168\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.122187 12.088363 12.116956 11.004819 11.405865 12.11758 ]\n",
      "Reset environment\n",
      "Episode reward: 5482.102\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.124572 12.090739 12.119338 11.007386 11.408044 12.119962]\n",
      "Reset environment\n",
      "Episode reward: 1925.6606\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.125205 12.091372 12.119981 11.008089 11.408591 12.120595]\n",
      "Reset environment\n",
      "Episode reward: 3253.5151\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.126365 12.092547 12.121124 11.009351 11.409637 12.121755]\n",
      "Reset environment\n",
      "Episode reward: 2022.4349\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.126825 12.093041 12.121554 11.009907 11.410044 12.122218]\n",
      "Reset environment\n",
      "Episode reward: 3782.0723\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.128232 12.094454 12.122956 11.01142  11.411309 12.123623]\n",
      "Reset environment\n",
      "Episode reward: 2518.1267\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.129093 12.095325 12.123808 11.012363 11.412072 12.124484]\n",
      "Reset environment\n",
      "Episode reward: 1923.1078\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.130015 12.096251 12.124728 11.013377 11.412912 12.125405]\n",
      "Reset environment\n",
      "Episode reward: 4158.178\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.131542 12.097781 12.12625  11.01503  11.414288 12.126932]\n",
      "Reset environment\n",
      "Episode reward: 2567.6487\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.13228  12.098507 12.12702  11.015889 11.414953 12.127686]\n",
      "Reset environment\n",
      "Episode reward: 1256.8483\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.132687  12.098907  12.12743   11.016337  11.4152975 12.128092 ]\n",
      "Reset environment\n",
      "Episode reward: 4952.8867\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.134531  12.100752  12.1292715 11.018326  11.416899  12.129937 ]\n",
      "Reset environment\n",
      "Episode reward: 1728.1765\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.134961 12.101154 12.129725 11.018818 11.417284 12.130369]\n",
      "Reset environment\n",
      "Episode reward: 5591.476\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.137042 12.103244 12.131792 11.021071 11.419167 12.132446]\n",
      "Reset environment\n",
      "Episode reward: 5205.181\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.138973  12.105161  12.1337185 11.023158  11.420819  12.134376 ]\n",
      "Reset environment\n",
      "Episode reward: 2007.1113\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.139636 12.105804 12.134392 11.023876 11.421376 12.135038]\n",
      "Reset environment\n",
      "Episode reward: 2818.1257\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.140605  12.106766  12.135365  11.0249405 11.422249  12.136009 ]\n",
      "Reset environment\n",
      "Episode reward: 4582.7354\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.142326 12.108476 12.13708  11.026786 11.423791 12.137726]\n",
      "Reset environment\n",
      "Episode reward: 2004.9637\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.143268 12.109418 12.138021 11.027823 11.424637 12.138668]\n",
      "Reset environment\n",
      "Episode reward: 2214.2979\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.144318 12.110472 12.139067 11.028968 11.425582 12.139719]\n",
      "Reset environment\n",
      "Episode reward: 1939.4214\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.144964  12.111124  12.139703  11.02968   11.4261675 12.140366 ]\n",
      "Reset environment\n",
      "Episode reward: 2728.6316\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.145922 12.112075 12.140662 11.030728 11.427025 12.141324]\n",
      "Reset environment\n",
      "Episode reward: 4168.5566\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.147433 12.113578 12.142171 11.032366 11.428377 12.142833]\n",
      "Reset environment\n",
      "Episode reward: 1479.3385\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.147908 12.114064 12.142615 11.032905 11.428787 12.143305]\n",
      "Reset environment\n",
      "Episode reward: 4514.483\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.14955  12.115712 12.144249 11.034696 11.43027  12.144949]\n",
      "Reset environment\n",
      "Episode reward: 4354.051\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.151168 12.117333 12.145856 11.036441 11.431737 12.146565]\n",
      "Reset environment\n",
      "Episode reward: -674.90314\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.150065  12.116315  12.1446705 11.035255  11.430743  12.145474 ]\n",
      "Reset environment\n",
      "Episode reward: 2523.61\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.150973 12.117232 12.145574 11.036252 11.431566 12.146384]\n",
      "Reset environment\n",
      "Episode reward: 3231.6362\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.152133 12.118386 12.146733 11.037505 11.432621 12.147545]\n",
      "Reset environment\n",
      "Episode reward: 2187.5688\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.15317   12.119424  12.147764  11.038627  11.433546  12.1485815]\n",
      "Reset environment\n",
      "Episode reward: 2362.4219\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.153957 12.120226 12.14853  11.03949  11.434251 12.14937 ]\n",
      "Reset environment\n",
      "Episode reward: 2018.7257\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.154623 12.120889 12.149196 11.040233 11.434846 12.150034]\n",
      "Reset environment\n",
      "Episode reward: 2339.484\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.155342 12.121629 12.149893 11.041032 11.435496 12.150753]\n",
      "Reset environment\n",
      "Episode reward: 3917.3289\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.156771 12.123057 12.151321 11.042583 11.436794 12.152184]\n",
      "Reset environment\n",
      "Episode reward: 1858.3955\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.157234  12.1235485 12.151755  11.043118  11.437207  12.152646 ]\n",
      "Reset environment\n",
      "Episode reward: 2742.4656\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.1581545 12.124503  12.15263   11.044147  11.438007  12.153573 ]\n",
      "Reset environment\n",
      "Episode reward: 2460.3018\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.159004 12.125334 12.153487 11.045076 11.438771 12.154422]\n",
      "Reset environment\n",
      "Episode reward: 2972.7944\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.160052 12.12638  12.154538 11.046213 11.439724 12.15547 ]\n",
      "Reset environment\n",
      "Episode reward: 2588.5898\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.160924 12.127267 12.155398 11.047174 11.440519 12.156343]\n",
      "Reset environment\n",
      "Episode reward: 1616.0714\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.161415 12.127746 12.155908 11.047726 11.440948 12.156843]\n",
      "Reset environment\n",
      "Episode reward: 2234.0972\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.162473  12.128799  12.1569605 11.048876  11.441902  12.157901 ]\n",
      "Reset environment\n",
      "Episode reward: 3345.6902\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.163655 12.129969 12.158153 11.050157 11.442981 12.159083]\n",
      "Reset environment\n",
      "Episode reward: 2401.6287\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.164515 12.130831 12.159008 11.051095 11.443762 12.159943]\n",
      "Reset environment\n",
      "Episode reward: 2775.088\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.165479 12.131806 12.159959 11.052136 11.444628 12.160908]\n",
      "Reset environment\n",
      "Episode reward: 1816.0143\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.166054 12.132373 12.160549 11.05278  11.445124 12.161484]\n",
      "Reset environment\n",
      "Episode reward: 2551.1094\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.166872 12.133165 12.16139  11.053678 11.445826 12.162303]\n",
      "Reset environment\n",
      "Episode reward: 5492.3726\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.168912 12.135212 12.163423 11.055874 11.447681 12.164343]\n",
      "Reset environment\n",
      "Episode reward: 5330.7837\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.170889 12.137192 12.165386 11.058011 11.449465 12.166317]\n",
      "Reset environment\n",
      "Episode reward: 3637.9717\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.172191 12.138502 12.166678 11.059431 11.450637 12.167621]\n",
      "Reset environment\n",
      "Episode reward: 1701.8556\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.172591 12.138865 12.167116 11.059909 11.451003 12.168028]\n",
      "Reset environment\n",
      "Episode reward: 5501.583\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.174644 12.140929 12.169161 11.062129 11.452862 12.170084]\n",
      "Reset environment\n",
      "Episode reward: 2189.7996\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.175678 12.141954 12.170193 11.06324  11.453784 12.171116]\n",
      "Reset environment\n",
      "Episode reward: 1781.0776\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.176283 12.142555 12.170801 11.063908 11.454316 12.171721]\n",
      "Reset environment\n",
      "Episode reward: 2759.1602\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.177261 12.143534 12.171777 11.064969 11.455195 12.172699]\n",
      "Reset environment\n",
      "Episode reward: 3527.4185\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.178587  12.144855  12.173108  11.066403  11.45641   12.1740265]\n",
      "Reset environment\n",
      "Episode reward: 1504.2552\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.17907  12.145346 12.173574 11.066924 11.456828 12.17451 ]\n",
      "Reset environment\n",
      "Episode reward: 1579.0042\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.179597 12.14588  12.174091 11.067511 11.457287 12.175037]\n",
      "Reset environment\n",
      "Episode reward: 4473.5234\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.181235 12.147516 12.175731 11.069286 11.458732 12.176678]\n",
      "Reset environment\n",
      "Episode reward: 1629.0157\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.181785 12.148072 12.176269 11.069898 11.459208 12.177227]\n",
      "Reset environment\n",
      "Episode reward: 2100.6687\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.18248  12.148765 12.176967 11.070674 11.459835 12.177923]\n",
      "Reset environment\n",
      "Episode reward: 2985.4072\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.183518 12.149802 12.178004 11.071816 11.460783 12.178962]\n",
      "Reset environment\n",
      "Episode reward: -249.85193\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.182709 12.148918 12.17729  11.071097 11.460047 12.178162]\n",
      "Reset environment\n",
      "Episode reward: 2311.026\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.183491  12.149702  12.178062  11.0719595 11.460752  12.178945 ]\n",
      "Reset environment\n",
      "Episode reward: 2690.2952\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.184407 12.150608 12.17899  11.072972 11.461569 12.179862]\n",
      "Reset environment\n",
      "Episode reward: 2313.001\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.185195 12.151393 12.179786 11.073839 11.462272 12.18065 ]\n",
      "Reset environment\n",
      "Episode reward: 3953.058\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.186677 12.152874 12.181262 11.075442 11.463624 12.182131]\n",
      "Reset environment\n",
      "Episode reward: 3541.0142\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.187962  12.154154  12.182538  11.076824  11.464776  12.1834135]\n",
      "Reset environment\n",
      "Episode reward: 2017.7878\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.188609 12.154816 12.183155 11.077544 11.465344 12.18406 ]\n",
      "Reset environment\n",
      "Episode reward: 2323.2305\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.189413 12.15561  12.183966 11.078425 11.466051 12.184864]\n",
      "Reset environment\n",
      "Episode reward: 4250.0166\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.190966 12.157154 12.185524 11.080102 11.467478 12.186417]\n",
      "Reset environment\n",
      "Episode reward: 2419.384\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.191826 12.158019 12.186377 11.081038 11.46825  12.187276]\n",
      "Reset environment\n",
      "Episode reward: -177.58057\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.190877  12.157132  12.185334  11.08017   11.467314  12.1863365]\n",
      "Reset environment\n",
      "Episode reward: 93.87662\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.190233 12.156586 12.184609 11.079478 11.466745 12.185713]\n",
      "Reset environment\n",
      "Episode reward: 5895.728\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.192467  12.1588125 12.186839  11.081889  11.468763  12.187948 ]\n",
      "Reset environment\n",
      "Episode reward: 5843.0933\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.194993  12.161339  12.189359  11.0845995 11.471055  12.190475 ]\n",
      "Reset environment\n",
      "Episode reward: 2750.3665\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.195966 12.162316 12.190329 11.085656 11.471925 12.191446]\n",
      "Reset environment\n",
      "Episode reward: 2370.488\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.196659 12.163033 12.190996 11.086439 11.47255  12.192138]\n",
      "Reset environment\n",
      "Episode reward: 5782.1665\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.198845 12.165207 12.193182 11.088787 11.474532 12.194319]\n",
      "Reset environment\n",
      "Episode reward: 1627.1123\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.199365  12.1657295 12.1937    11.089377  11.474986  12.1948395]\n",
      "Reset environment\n",
      "Episode reward: 158.97949\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.198744 12.165184 12.192985 11.088681 11.474406 12.194227]\n",
      "Reset environment\n",
      "Episode reward: 4211.1694\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.200283 12.166726 12.194513 11.090335 11.475808 12.195765]\n",
      "Reset environment\n",
      "Episode reward: 2342.8433\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.201076 12.167535 12.195294 11.091205 11.476525 12.196558]\n",
      "Reset environment\n",
      "Episode reward: 2266.3752\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.201788 12.168264 12.19599  11.091994 11.477167 12.19727 ]\n",
      "Reset environment\n",
      "Episode reward: 2193.6174\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.202812 12.169285 12.197013 11.093106 11.47809  12.198294]\n",
      "Reset environment\n",
      "Episode reward: 2381.485\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.203604  12.1700945 12.197765  11.09398   11.478771  12.199085 ]\n",
      "Reset environment\n",
      "Episode reward: 2114.0078\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.204241 12.170707 12.198416 11.09469  11.479332 12.199722]\n",
      "Reset environment\n",
      "Episode reward: 1646.6696\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.204813 12.17129  12.198976 11.095332 11.479824 12.200296]\n",
      "Reset environment\n",
      "Episode reward: 2543.1094\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.205713 12.172189 12.199876 11.096315 11.480648 12.201197]\n",
      "Reset environment\n",
      "Episode reward: 5663.1924\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.207828 12.174301 12.201986 11.098597 11.482518 12.203315]\n",
      "Reset environment\n",
      "Episode reward: 2010.3696\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.208416 12.174866 12.202594 11.09926  11.483046 12.203908]\n",
      "Reset environment\n",
      "Episode reward: 2681.5122\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.209363 12.175814 12.203537 11.10029  11.483894 12.204857]\n",
      "Reset environment\n",
      "Episode reward: 1881.5039\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.210252 12.176704 12.204425 11.10127  11.484698 12.205747]\n",
      "Reset environment\n",
      "Episode reward: 3292.8713\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.211413 12.177864 12.205585 11.102537 11.485757 12.206909]\n",
      "Reset environment\n",
      "Episode reward: 1972.3242\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.212341 12.178795 12.206515 11.103561 11.486602 12.207839]\n",
      "Reset environment\n",
      "Episode reward: 2105.624\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.213048 12.179497 12.207227 11.104344 11.487236 12.208544]\n",
      "Reset environment\n",
      "Episode reward: 2359.2363\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.213853 12.180305 12.208023 11.105236 11.487956 12.209349]\n",
      "Reset environment\n",
      "Episode reward: 2168.0847\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.214857  12.181309  12.209028  11.1063385 11.488858  12.210356 ]\n",
      "Reset environment\n",
      "Episode reward: 1904.4917\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.215476 12.181938 12.209641 11.107021 11.489412 12.210973]\n",
      "Reset environment\n",
      "Episode reward: 4997.876\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.217314 12.183786 12.211476 11.109006 11.491088 12.212811]\n",
      "Reset environment\n",
      "Episode reward: 2026.416\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.218003 12.184473 12.212154 11.109761 11.4917   12.213503]\n",
      "Reset environment\n",
      "Episode reward: 1482.8225\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2184305 12.184884  12.212597  11.110244  11.49208   12.213929 ]\n",
      "Reset environment\n",
      "Episode reward: 1573.4979\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.218931  12.185387  12.2130995 11.1108055 11.49252   12.214431 ]\n",
      "Reset environment\n",
      "Episode reward: 1838.7468\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.219545 12.185984 12.213726 11.111492 11.49305  12.215047]\n",
      "Reset environment\n",
      "Episode reward: 4954.6997\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.221354  12.187791  12.215536  11.113451  11.4946165 12.216856 ]\n",
      "Reset environment\n",
      "Episode reward: 5291.505\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.22331  12.189733 12.217502 11.115565 11.496396 12.218813]\n",
      "Reset environment\n",
      "Episode reward: 1483.7595\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.223643 12.190035 12.217863 11.115964 11.496694 12.219147]\n",
      "Reset environment\n",
      "Episode reward: 2433.565\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.224481 12.190877 12.218695 11.116883 11.497441 12.219984]\n",
      "Reset environment\n",
      "Episode reward: 2321.2195\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2252245 12.191625  12.219439  11.117714  11.498117  12.220728 ]\n",
      "Reset environment\n",
      "Episode reward: 1536.0444\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.225654  12.192081  12.2198515 11.11821   11.498499  12.221162 ]\n",
      "Reset environment\n",
      "Episode reward: 2639.2856\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.226564  12.192983  12.22077   11.119208  11.499325  12.2220745]\n",
      "Reset environment\n",
      "Episode reward: 1982.8237\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.227223  12.193641  12.221433  11.119934  11.499922  12.2227335]\n",
      "Reset environment\n",
      "Episode reward: 1690.1187\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.22769  12.194085 12.221923 11.12046  11.500342 12.223202]\n",
      "Reset environment\n",
      "Episode reward: 3325.4807\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.228856 12.195251 12.223089 11.12174  11.501401 12.22437 ]\n",
      "Reset environment\n",
      "Episode reward: 3281.9927\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.230044 12.196439 12.224266 11.123031 11.502469 12.225557]\n",
      "Reset environment\n",
      "Episode reward: 2078.6567\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.230994 12.19739  12.225216 11.124074 11.503323 12.226507]\n",
      "Reset environment\n",
      "Episode reward: 4494.0864\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.232658 12.199047 12.226877 11.12587  11.504812 12.228168]\n",
      "Reset environment\n",
      "Episode reward: 1403.8287\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.233364 12.199755 12.227581 11.126649 11.50545  12.228874]\n",
      "Reset environment\n",
      "Episode reward: 2078.076\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.234038 12.200417 12.228267 11.127398 11.506043 12.229548]\n",
      "Reset environment\n",
      "Episode reward: 1194.2235\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.234321 12.20072  12.228524 11.127729 11.50629  12.229831]\n",
      "Reset environment\n",
      "Episode reward: 2079.1445\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2349415 12.201364  12.229107  11.128435  11.506825  12.230461 ]\n",
      "Reset environment\n",
      "Episode reward: 2978.6494\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.235985  12.2023945 12.230153  11.129566  11.507763  12.2315   ]\n",
      "Reset environment\n",
      "Episode reward: 2858.1316\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.236985 12.203398 12.231154 11.130665 11.508671 12.2325  ]\n",
      "Reset environment\n",
      "Episode reward: 2237.3816\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.237729 12.20414  12.2319   11.131488 11.509345 12.233245]\n",
      "Reset environment\n",
      "Episode reward: 1963.8407\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.238396 12.204815 12.232544 11.132234 11.509924 12.233914]\n",
      "Reset environment\n",
      "Episode reward: 6300.663\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.240797 12.207213 12.234944 11.134812 11.512086 12.236311]\n",
      "Reset environment\n",
      "Episode reward: 1805.6019\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.241215  12.20766   12.2353325 11.1353035 11.512457  12.236729 ]\n",
      "Reset environment\n",
      "Episode reward: 1561.76\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.241643 12.208107 12.235735 11.135785 11.512832 12.23716 ]\n",
      "Reset environment\n",
      "Episode reward: 1929.9095\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.24226  12.208717 12.236358 11.136474 11.513377 12.23778 ]\n",
      "Reset environment\n",
      "Episode reward: 4004.855\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.243706 12.210173 12.237792 11.138034 11.514687 12.239231]\n",
      "Reset environment\n",
      "Episode reward: 2650.8984\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.24458  12.211068 12.238649 11.139009 11.515451 12.240113]\n",
      "Reset environment\n",
      "Episode reward: 3888.5142\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.246003 12.212492 12.240066 11.140545 11.516741 12.241535]\n",
      "Reset environment\n",
      "Episode reward: 1249.3718\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.246398 12.212894 12.240442 11.140994 11.517074 12.241933]\n",
      "Reset environment\n",
      "Episode reward: 2449.1357\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2472315 12.213723  12.241294  11.1419115 11.517813  12.242767 ]\n",
      "Reset environment\n",
      "Episode reward: 2691.1719\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.248179 12.214675 12.242238 11.142941 11.518667 12.243716]\n",
      "Reset environment\n",
      "Episode reward: 2152.0574\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.248888 12.215395 12.242935 11.143723 11.519293 12.244427]\n",
      "Reset environment\n",
      "Episode reward: 2134.4668\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.249417 12.215899 12.243492 11.144343 11.519766 12.244955]\n",
      "Reset environment\n",
      "Episode reward: 2396.1162\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.250256 12.216725 12.244343 11.145276 11.520496 12.245797]\n",
      "Reset environment\n",
      "Episode reward: 2405.1187\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.251023 12.217465 12.245126 11.146108 11.521151 12.246567]\n",
      "Reset environment\n",
      "Episode reward: 1950.3718\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.251637 12.218094 12.245722 11.146788 11.52169  12.247181]\n",
      "Reset environment\n",
      "Episode reward: 5146.4365\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.253557 12.22001  12.247629 11.148846 11.523414 12.2491  ]\n",
      "Reset environment\n",
      "Episode reward: 2890.9658\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.25456  12.221019 12.248614 11.149941 11.524314 12.250103]\n",
      "Reset environment\n",
      "Episode reward: 5395.3843\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.256563 12.223027 12.250607 11.1521   11.526137 12.252105]\n",
      "Reset environment\n",
      "Episode reward: 2042.9204\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.257519  12.223984  12.2515545 11.15315   11.526997  12.253058 ]\n",
      "Reset environment\n",
      "Episode reward: 3465.3804\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.258745 12.225201 12.252794 11.154483 11.528105 12.254285]\n",
      "Reset environment\n",
      "Episode reward: 2154.355\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.259465 12.22593  12.253511 11.155276 11.528756 12.255006]\n",
      "Reset environment\n",
      "Episode reward: 322.89584\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.258912 12.225477 12.252863 11.154686 11.52827  12.254468]\n",
      "Reset environment\n",
      "Episode reward: 1888.3148\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.259517  12.226081  12.25347   11.15537   11.528814  12.2550745]\n",
      "Reset environment\n",
      "Episode reward: 5447.0376\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.261575 12.228137 12.255524 11.157587 11.530673 12.257132]\n",
      "Reset environment\n",
      "Episode reward: 3395.317\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.262784 12.22935  12.256726 11.158899 11.531761 12.258341]\n",
      "Reset environment\n",
      "Episode reward: 1701.3159\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.263331 12.229881 12.257288 11.159496 11.532244 12.258888]\n",
      "Reset environment\n",
      "Episode reward: 2194.935\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.264059  12.230613  12.258011  11.160299  11.5329075 12.259616 ]\n",
      "Reset environment\n",
      "Episode reward: 1357.5739\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.26473  12.231288 12.258683 11.161045 11.533515 12.260288]\n",
      "Reset environment\n",
      "Episode reward: 1702.9462\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.265303 12.231864 12.25924  11.161669 11.534011 12.260861]\n",
      "Reset environment\n",
      "Episode reward: 2093.5854\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.265927 12.232466 12.259884 11.162361 11.53455  12.261488]\n",
      "Reset environment\n",
      "Episode reward: 3664.9353\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.267237 12.233779 12.261191 11.163784 11.535735 12.262804]\n",
      "Reset environment\n",
      "Episode reward: 1906.1477\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.267859 12.234408 12.261805 11.164472 11.536294 12.263429]\n",
      "Reset environment\n",
      "Episode reward: 5757.591\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.269984  12.236535  12.263913  11.166756  11.5382185 12.265547 ]\n",
      "Reset environment\n",
      "Episode reward: 3510.2656\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.271206 12.237761 12.265134 11.16809  11.539329 12.266768]\n",
      "Reset environment\n",
      "Episode reward: 1310.8784\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.271573  12.2381115 12.265518  11.168507  11.539652  12.267138 ]\n",
      "Reset environment\n",
      "Episode reward: 5516.832\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.273862 12.240387 12.267813 11.170966 11.541686 12.269426]\n",
      "Reset environment\n",
      "Episode reward: 2030.6742\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.27452   12.2410555 12.268452  11.171694  11.542252  12.270088 ]\n",
      "Reset environment\n",
      "Episode reward: 3010.9336\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.275558 12.242092 12.269498 11.172827 11.543198 12.271127]\n",
      "Reset environment\n",
      "Episode reward: -183.56412\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.274952 12.24145  12.268918 11.172058 11.542654 12.270522]\n",
      "Reset environment\n",
      "Episode reward: 1930.5441\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2755785 12.242075  12.269552  11.172752  11.54322   12.27115  ]\n",
      "Reset environment\n",
      "Episode reward: 524.5891\n",
      "Total Steps: 18\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.275646 12.242143 12.269622 11.172856 11.543268 12.271217]\n",
      "Reset environment\n",
      "Episode reward: 2067.4563\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.276599 12.243099 12.270575 11.173895 11.544126 12.272171]\n",
      "Reset environment\n",
      "Episode reward: 2015.1613\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2772665 12.24377   12.271241  11.174641  11.544723  12.27284  ]\n",
      "Reset environment\n",
      "Episode reward: 3792.7876\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.278607 12.245113 12.272583 11.176097 11.545902 12.274181]\n",
      "Reset environment\n",
      "Episode reward: 2460.2148\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.279381  12.2459135 12.273327  11.176955  11.546583  12.274955 ]\n",
      "Reset environment\n",
      "Episode reward: 4418.4424\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2809725 12.247506  12.274914  11.178678  11.548033  12.276546 ]\n",
      "Reset environment\n",
      "Episode reward: 2384.0542\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.281772 12.248321 12.275701 11.179549 11.548745 12.277344]\n",
      "Reset environment\n",
      "Episode reward: 1829.787\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.282311 12.24884  12.276257 11.180164 11.54921  12.277883]\n",
      "Reset environment\n",
      "Episode reward: 1836.7343\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.282906 12.249434 12.276856 11.180825 11.549743 12.278477]\n",
      "Reset environment\n",
      "Episode reward: 3412.635\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.28414   12.250672  12.278082  11.182142  11.550846  12.2797165]\n",
      "Reset environment\n",
      "Episode reward: 3423.2363\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.2853565 12.2518835 12.279295  11.183462  11.55195   12.280931 ]\n",
      "Reset environment\n",
      "Episode reward: 1656.7037\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.285887 12.252426 12.279818 11.184055 11.552428 12.281462]\n",
      "Reset environment\n",
      "Episode reward: 2884.037\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.286866  12.253432  12.280767  11.185131  11.5532875 12.282439 ]\n",
      "Reset environment\n",
      "Episode reward: 1805.9553\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.287719 12.254288 12.281622 11.186066 11.55406  12.283294]\n",
      "Reset environment\n",
      "Episode reward: 1779.8641\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.288253 12.254809 12.282172 11.186665 11.554528 12.283834]\n",
      "Reset environment\n",
      "Episode reward: 1845.0969\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.288892  12.255456  12.2828045 11.187378  11.555076  12.284477 ]\n",
      "Reset environment\n",
      "Episode reward: -263.79214\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.288072 12.254742 12.281881 11.186613 11.554308 12.283667]\n",
      "Reset environment\n",
      "Episode reward: 2314.6948\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.288788 12.255429 12.282616 11.187402 11.554934 12.284386]\n",
      "Reset environment\n",
      "Episode reward: 1712.1611\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.289608  12.2562475 12.283433  11.188304  11.555669  12.285205 ]\n",
      "Reset environment\n",
      "Episode reward: 2104.3672\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.290648 12.257287 12.284471 11.189428 11.556592 12.286245]\n",
      "Reset environment\n",
      "Episode reward: 2195.0205\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.291671 12.258302 12.285489 11.19053  11.557505 12.287268]\n",
      "Reset environment\n",
      "Episode reward: 1110.2443\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.291997 12.258636 12.285806 11.190909 11.557789 12.287596]\n",
      "Reset environment\n",
      "Episode reward: 2820.1794\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.292969 12.259602 12.286783 11.191961 11.55867  12.288567]\n",
      "Reset environment\n",
      "Episode reward: 2754.2468\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.29393  12.260565 12.28773  11.192998 11.559528 12.289527]\n",
      "Reset environment\n",
      "Episode reward: 3555.6963\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.295227 12.261864 12.28902  11.194398 11.560703 12.290825]\n",
      "Reset environment\n",
      "Episode reward: 1974.8376\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.295843 12.262474 12.289644 11.195093 11.56124  12.29144 ]\n",
      "Reset environment\n",
      "Episode reward: 5597.7573\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.297906  12.264542  12.291705  11.197313  11.5630665 12.293502 ]\n",
      "Reset environment\n",
      "Episode reward: 1558.3179\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.298259 12.264927 12.292019 11.197731 11.563378 12.293858]\n",
      "Reset environment\n",
      "Episode reward: 2397.9949\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.299075 12.265748 12.292825 11.19863  11.564122 12.294673]\n",
      "Reset environment\n",
      "Episode reward: 3597.7688\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.300348 12.267018 12.294096 11.200026 11.565279 12.295947]\n",
      "Reset environment\n",
      "Episode reward: -604.3428\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.29948  12.266117 12.293254 11.198961 11.564482 12.295081]\n",
      "Reset environment\n",
      "Episode reward: 1381.1741\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.300163 12.266799 12.293937 11.199724 11.565099 12.295763]\n",
      "Reset environment\n",
      "Episode reward: 2173.9956\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.30086  12.267493 12.29464  11.200499 11.565732 12.296463]\n",
      "Reset environment\n",
      "Episode reward: 2361.0598\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.301656 12.2683   12.295426 11.201368 11.566444 12.297258]\n",
      "Reset environment\n",
      "Episode reward: 4562.6367\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.303316 12.26996  12.297098 11.203166 11.567973 12.29892 ]\n",
      "Reset environment\n",
      "Episode reward: 1956.0464\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.303928 12.27055  12.297729 11.203844 11.568509 12.299536]\n",
      "Reset environment\n",
      "Episode reward: 4772.911\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.305678 12.272305 12.299467 11.205733 11.570105 12.301289]\n",
      "Reset environment\n",
      "Episode reward: 3841.933\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.307046 12.273684 12.300827 11.207225 11.571341 12.30266 ]\n",
      "Reset environment\n",
      "Episode reward: 3744.3535\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.3083725 12.275015  12.302151  11.208669  11.572552  12.303991 ]\n",
      "Reset environment\n",
      "Episode reward: 153.13779\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.308065  12.2747135 12.301816  11.208226  11.572251  12.303685 ]\n",
      "Reset environment\n",
      "Episode reward: 3095.3508\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.309131 12.275777 12.30288  11.209383 11.573201 12.304749]\n",
      "Reset environment\n",
      "Episode reward: 1380.0176\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.309815  12.2764635 12.303566  11.210142  11.573819  12.305433 ]\n",
      "Reset environment\n",
      "Episode reward: 1461.9019\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.310262 12.276926 12.303999 11.210631 11.574205 12.305881]\n",
      "Reset environment\n",
      "Episode reward: 3777.8306\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.3116   12.278263 12.305326 11.212091 11.57541  12.30722 ]\n",
      "Reset environment\n",
      "Episode reward: 5056.888\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.313462 12.280114 12.307174 11.214094 11.577083 12.30908 ]\n",
      "Reset environment\n",
      "Episode reward: 2626.5645\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.314327 12.28097  12.308046 11.215039 11.577858 12.309944]\n",
      "Reset environment\n",
      "Episode reward: 1956.0135\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.315244 12.28189  12.308961 11.216047 11.578681 12.310862]\n",
      "Reset environment\n",
      "Episode reward: 1504.9207\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.315745 12.282385 12.309469 11.216608 11.579115 12.311363]\n",
      "Reset environment\n",
      "Episode reward: 2148.8499\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.316737 12.283375 12.310461 11.217696 11.580009 12.312355]\n",
      "Reset environment\n",
      "Episode reward: 1403.2891\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.317437  12.284077  12.311159  11.2184725 11.580639  12.313055 ]\n",
      "Reset environment\n",
      "Episode reward: 2860.217\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.318423 12.285077 12.312134 11.219546 11.581544 12.314042]\n",
      "Reset environment\n",
      "Episode reward: 5429.1226\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.320407  12.2870655 12.314103  11.221688  11.583352  12.316028 ]\n",
      "Reset environment\n",
      "Episode reward: 6248.0674\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.32272   12.289382  12.316402  11.224193  11.585456  12.3183365]\n",
      "Reset environment\n",
      "Episode reward: 4525.4033\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.324377 12.291038 12.318054 11.225971 11.586945 12.319996]\n",
      "Reset environment\n",
      "Episode reward: 4030.917\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.325822  12.292494  12.3194895 11.227547  11.58826   12.321443 ]\n",
      "Reset environment\n",
      "Episode reward: 2092.4023\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.326792  12.293469  12.3204565 11.22861   11.589137  12.322414 ]\n",
      "Reset environment\n",
      "Episode reward: -23.106628\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.326387 12.293069 12.320051 11.228062 11.588772 12.322012]\n",
      "Reset environment\n",
      "Episode reward: 1777.6671\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.326922 12.293591 12.320596 11.228659 11.58923  12.322547]\n",
      "Reset environment\n",
      "Episode reward: 1989.6345\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.327834 12.294498 12.321504 11.229656 11.590045 12.323461]\n",
      "Reset environment\n",
      "Episode reward: 2595.9233\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.328728 12.295399 12.322386 11.230637 11.590844 12.324355]\n",
      "Reset environment\n",
      "Episode reward: 1366.8705\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.329394 12.296064 12.323053 11.231382 11.591438 12.325022]\n",
      "Reset environment\n",
      "Episode reward: 4916.1313\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.331206 12.297871 12.32487  11.233324 11.593106 12.326832]\n",
      "Reset environment\n",
      "Episode reward: 5867.5347\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.333349 12.30002  12.327003 11.235635 11.595051 12.328976]\n",
      "Reset environment\n",
      "Episode reward: 2180.8418\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.333901 12.300547 12.327583 11.236276 11.59555  12.329529]\n",
      "Reset environment\n",
      "Episode reward: -501.69696\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.332889 12.29948  12.326642 11.2352   11.594629 12.328525]\n",
      "Reset environment\n",
      "Episode reward: 4966.2397\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.334703 12.301286 12.328464 11.237159 11.596288 12.330336]\n",
      "Reset environment\n",
      "Episode reward: 1640.2366\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.335208 12.301803 12.328945 11.237705 11.596711 12.33084 ]\n",
      "Reset environment\n",
      "Episode reward: 1378.3527\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.335887 12.302484 12.329624 11.23846  11.597326 12.331519]\n",
      "Reset environment\n",
      "Episode reward: 2017.2002\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.336796 12.303394 12.330527 11.239478 11.598133 12.332428]\n",
      "Reset environment\n",
      "Episode reward: 2851.2236\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.337781 12.304376 12.331517 11.240547 11.599025 12.333416]\n",
      "Reset environment\n",
      "Episode reward: 1639.017\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.338299 12.30489  12.332042 11.241119 11.599466 12.333933]\n",
      "Reset environment\n",
      "Episode reward: 3424.6763\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.339484  12.306072  12.333227  11.2424135 11.600548  12.335118 ]\n",
      "Reset environment\n",
      "Episode reward: 2148.599\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.3404665 12.307051  12.33421   11.24349   11.6014385 12.3361   ]\n",
      "Reset environment\n",
      "Episode reward: 2113.0461\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.341103  12.307667  12.3348675 11.244189  11.601991  12.336737 ]\n",
      "Reset environment\n",
      "Episode reward: 2017.7346\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.341752 12.30831  12.335522 11.244909 11.602577 12.337386]\n",
      "Reset environment\n",
      "Episode reward: 1942.1311\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.342337 12.30888  12.336126 11.245562 11.603093 12.337973]\n",
      "Reset environment\n",
      "Episode reward: 1655.1918\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.342875  12.30942   12.33666   11.246161  11.603562  12.3385105]\n",
      "Reset environment\n",
      "Episode reward: 1527.7042\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.343324  12.309885  12.3370905 11.2466545 11.603957  12.33896  ]\n",
      "Reset environment\n",
      "Episode reward: 1801.563\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.343921 12.31047  12.337688 11.247308 11.60448  12.339556]\n",
      "Reset environment\n",
      "Episode reward: 1543.7745\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.344425 12.310977 12.338189 11.247868 11.604911 12.340063]\n",
      "Reset environment\n",
      "Episode reward: 2787.3962\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.34532  12.311853 12.339096 11.248856 11.605687 12.340958]\n",
      "Reset environment\n",
      "Episode reward: 2035.3137\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.346267 12.312801 12.340037 11.249877 11.606531 12.341907]\n",
      "Reset environment\n",
      "Episode reward: 3295.1106\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.347407 12.313942 12.341178 11.251121 11.607571 12.343045]\n",
      "Reset environment\n",
      "Episode reward: 2051.6917\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.348073 12.314595 12.341853 11.251849 11.608142 12.343715]\n",
      "Reset environment\n",
      "Episode reward: 5502.2666\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.350116 12.316618 12.343891 11.254059 11.609964 12.345754]\n",
      "Reset environment\n",
      "Episode reward: 1930.8032\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.350623  12.317099  12.344425  11.25464   11.6104145 12.346265 ]\n",
      "Reset environment\n",
      "Episode reward: 1857.454\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.351211 12.317687 12.345012 11.255299 11.610937 12.346853]\n",
      "Reset environment\n",
      "Episode reward: 5308.825\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.353168 12.319653 12.346951 11.257398 11.612702 12.348808]\n",
      "Reset environment\n",
      "Episode reward: 1492.1088\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.353677 12.320155 12.34746  11.257963 11.613128 12.349317]\n",
      "Reset environment\n",
      "Episode reward: 1058.6334\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.353979 12.320463 12.347755 11.258323 11.61338  12.34962 ]\n",
      "Reset environment\n",
      "Episode reward: 1592.782\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.3547535 12.321239  12.348528  11.25917   11.6140785 12.350395 ]\n",
      "Reset environment\n",
      "Episode reward: 2855.3777\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.355567 12.322082 12.349315 11.260089 11.614828 12.351211]\n",
      "Reset environment\n",
      "Episode reward: 4375.5396\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.357157  12.3236685 12.3509035 11.2618065 11.616259  12.352802 ]\n",
      "Reset environment\n",
      "Episode reward: 2455.7307\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.357981 12.324498 12.351718 11.262714 11.617003 12.353626]\n",
      "Reset environment\n",
      "Episode reward: 2093.8003\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.358514 12.325005 12.352274 11.263325 11.617483 12.354162]\n",
      "Reset environment\n",
      "Episode reward: 2356.6128\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.359237 12.32571  12.353016 11.264127 11.618101 12.354886]\n",
      "Reset environment\n",
      "Episode reward: 4271.0503\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.360794 12.327255 12.354563 11.265806 11.619498 12.356443]\n",
      "Reset environment\n",
      "Episode reward: 2365.6077\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.361583  12.328038  12.355357  11.266669  11.6202135 12.357232 ]\n",
      "Reset environment\n",
      "Episode reward: 5224.913\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.36349  12.329948 12.357254 11.268726 11.621942 12.359138]\n",
      "Reset environment\n",
      "Episode reward: 1814.5972\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.363998  12.330437  12.3577795 11.269302  11.6224    12.359647 ]\n",
      "Reset environment\n",
      "Episode reward: 3282.1726\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.365143 12.331589 12.358915 11.270548 11.623429 12.360788]\n",
      "Reset environment\n",
      "Episode reward: 2311.1497\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.36587   12.3322935 12.359662  11.271345  11.624052  12.361515 ]\n",
      "Reset environment\n",
      "Episode reward: 1824.9889\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.36643  12.332833 12.360234 11.271968 11.624533 12.362078]\n",
      "Reset environment\n",
      "Episode reward: 3408.4443\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.367626 12.334036 12.361428 11.273275 11.625609 12.363277]\n",
      "Reset environment\n",
      "Episode reward: 1341.1531\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.368274 12.334683 12.362077 11.273997 11.626186 12.363926]\n",
      "Reset environment\n",
      "Episode reward: 5132.6343\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.370143 12.336558 12.36393  11.276013 11.627886 12.365795]\n",
      "Reset environment\n",
      "Episode reward: 2435.9937\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.370959  12.337374  12.364745  11.276912  11.628615  12.3666115]\n",
      "Reset environment\n",
      "Episode reward: 2370.227\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.371591  12.3379755 12.365401  11.277632  11.629188  12.367247 ]\n",
      "Reset environment\n",
      "Episode reward: 3851.0522\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.372966 12.339354 12.366772 11.279116 11.630428 12.368621]\n",
      "Reset environment\n",
      "Episode reward: 2173.44\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.373675 12.34006  12.367482 11.279906 11.631061 12.369329]\n",
      "Reset environment\n",
      "Episode reward: 1588.8296\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.374206 12.34059  12.368018 11.2805   11.631514 12.36986 ]\n",
      "Reset environment\n",
      "Episode reward: 2907.684\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.375225 12.341603 12.369033 11.281609 11.632431 12.370879]\n",
      "Reset environment\n",
      "Episode reward: 2779.9949\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.376153 12.342543 12.36995  11.282617 11.633261 12.371808]\n",
      "Reset environment\n",
      "Episode reward: 2068.6235\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.377098 12.34349  12.370894 11.28365  11.634106 12.372755]\n",
      "Reset environment\n",
      "Episode reward: 1391.5554\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.377519  12.3439245 12.371299  11.284117  11.634476  12.373176 ]\n",
      "Reset environment\n",
      "Episode reward: 1779.5256\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.3781395 12.344558  12.371916  11.284817  11.635012  12.373802 ]\n",
      "Reset environment\n",
      "Episode reward: 4529.73\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.379774  12.3461895 12.373548  11.286587  11.636484  12.375431 ]\n",
      "Reset environment\n",
      "Episode reward: 5066.9272\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.381611  12.3480215 12.375369  11.28857   11.638142  12.377265 ]\n",
      "Reset environment\n",
      "Episode reward: 2373.561\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.38242   12.348824  12.376177  11.289455  11.6388645 12.378075 ]\n",
      "Reset environment\n",
      "Episode reward: 3144.8499\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.383492 12.34989  12.377252 11.290635 11.639837 12.379149]\n",
      "Reset environment\n",
      "Episode reward: 4506.0547\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.385129 12.351523 12.378894 11.292401 11.641331 12.380788]\n",
      "Reset environment\n",
      "Episode reward: 383.15756\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.384696 12.351153 12.378391 11.291863 11.640943 12.380362]\n",
      "Reset environment\n",
      "Episode reward: 3693.9438\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.385992  12.352446  12.379679  11.293261  11.6421175 12.381659 ]\n",
      "Reset environment\n",
      "Episode reward: 692.39484\n",
      "Total Steps: 21\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.3861475 12.352601  12.379835  11.293452  11.642242  12.381815 ]\n",
      "Reset environment\n",
      "Episode reward: 2539.9395\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.387033 12.353494 12.380718 11.29442  11.643045 12.382701]\n",
      "Reset environment\n",
      "Episode reward: 3064.8115\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.388068 12.354531 12.381754 11.295547 11.643984 12.383738]\n",
      "Reset environment\n",
      "Episode reward: 3449.221\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.389262 12.355711 12.382962 11.296847 11.645069 12.38493 ]\n",
      "Reset environment\n",
      "Episode reward: 2637.7622\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.390154 12.356591 12.383868 11.29782  11.645856 12.385822]\n",
      "Reset environment\n",
      "Episode reward: 1401.3082\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.390843 12.357282 12.384556 11.298584 11.646477 12.386509]\n",
      "Reset environment\n",
      "Episode reward: 1397.7002\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.391531 12.357972 12.385241 11.299343 11.647099 12.387195]\n",
      "Reset environment\n",
      "Episode reward: 1638.6147\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.392046 12.358489 12.385756 11.299921 11.647557 12.38771 ]\n",
      "Reset environment\n",
      "Episode reward: 2770.475\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.393005 12.359442 12.386711 11.30097  11.648419 12.38867 ]\n",
      "Reset environment\n",
      "Episode reward: 2044.2623\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.393941 12.360378 12.387648 11.301992 11.649265 12.389607]\n",
      "Reset environment\n",
      "Episode reward: 3769.8943\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.395267 12.361699 12.388977 11.30343  11.650479 12.390932]\n",
      "Reset environment\n",
      "Episode reward: 1774.3386\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.396107  12.362539  12.389813  11.304338  11.6512375 12.391773 ]\n",
      "Reset environment\n",
      "Episode reward: 2705.4495\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.396993 12.363428 12.390698 11.30531  11.652035 12.39266 ]\n",
      "Reset environment\n",
      "Episode reward: 3036.4258\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.398037 12.364457 12.39175  11.306458 11.65298  12.393705]\n",
      "Reset environment\n",
      "Episode reward: 5702.9316\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.400169 12.366584 12.393872 11.308742 11.654864 12.395838]\n",
      "Reset environment\n",
      "Episode reward: 4812.942\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.401907 12.368323 12.395605 11.310607 11.656446 12.397578]\n",
      "Reset environment\n",
      "Episode reward: 3848.1423\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.40326  12.36967  12.396974 11.312069 11.657692 12.398932]\n",
      "Reset environment\n",
      "Episode reward: 1925.9695\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.403902  12.3703165 12.397614  11.312777  11.658271  12.399575 ]\n",
      "Reset environment\n",
      "Episode reward: 5006.6333\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4057    12.37211   12.399408  11.3147135 11.65989   12.401373 ]\n",
      "Reset environment\n",
      "Episode reward: 3942.127\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.40711   12.373514  12.400822  11.3162365 11.661157  12.402788 ]\n",
      "Reset environment\n",
      "Episode reward: 4526.883\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.40875   12.375152  12.402464  11.318012  11.6626215 12.40443  ]\n",
      "Reset environment\n",
      "Episode reward: 2849.3599\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.409689 12.376081 12.403413 11.319041 11.663462 12.405371]\n",
      "Reset environment\n",
      "Episode reward: 1961.8925\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.410336  12.376739  12.40405   11.319756  11.6640415 12.406022 ]\n",
      "Reset environment\n",
      "Episode reward: 3175.1858\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.411423 12.377825 12.405139 11.320948 11.665023 12.407109]\n",
      "Reset environment\n",
      "Episode reward: 3177.503\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.412543 12.378951 12.406251 11.322163 11.666033 12.408228]\n",
      "Reset environment\n",
      "Episode reward: 1381.9348\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.413224 12.379634 12.406931 11.322914 11.66665  12.408909]\n",
      "Reset environment\n",
      "Episode reward: 1900.3557\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.413766  12.380159  12.4074955 11.323523  11.667129  12.409453 ]\n",
      "Reset environment\n",
      "Episode reward: 2497.4219\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.414604 12.380985 12.40834  11.324436 11.667888 12.410292]\n",
      "Reset environment\n",
      "Episode reward: 2214.1187\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.415619 12.381995 12.409348 11.325529 11.668796 12.411305]\n",
      "Reset environment\n",
      "Episode reward: 3829.923\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.416946 12.383334 12.41066  11.326967 11.67     12.412634]\n",
      "Reset environment\n",
      "Episode reward: 5978.3643\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.419157  12.3855505 12.412869  11.329353  11.671995  12.4148445]\n",
      "Reset environment\n",
      "Episode reward: 1469.2633\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.41964  12.386041 12.413343 11.329893 11.67242  12.415328]\n",
      "Reset environment\n",
      "Episode reward: -42.410553\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.418877  12.3851795 12.412641  11.329052  11.671723  12.414562 ]\n",
      "Reset environment\n",
      "Episode reward: 1773.2029\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.419389 12.385711 12.413116 11.329635 11.672161 12.415077]\n",
      "Reset environment\n",
      "Episode reward: 5513.6343\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.421388 12.38771  12.415117 11.331785 11.673904 12.417077]\n",
      "Reset environment\n",
      "Episode reward: 1806.4575\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4219475 12.388286  12.415665  11.3323965 11.674391  12.417638 ]\n",
      "Reset environment\n",
      "Episode reward: 1683.6216\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.422487 12.388829 12.416202 11.332996 11.674874 12.418178]\n",
      "Reset environment\n",
      "Episode reward: 2150.4856\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.423184 12.389534 12.416897 11.333773 11.675507 12.418876]\n",
      "Reset environment\n",
      "Episode reward: 3396.749\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.424341 12.390686 12.41805  11.335051 11.676558 12.42003 ]\n",
      "Reset environment\n",
      "Episode reward: 1738.9626\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.424895 12.391234 12.41861  11.335664 11.677045 12.420585]\n",
      "Reset environment\n",
      "Episode reward: 4164.705\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.42638  12.392719 12.420082 11.337276 11.678379 12.422065]\n",
      "Reset environment\n",
      "Episode reward: 1935.8544\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.427272 12.393608 12.420972 11.338245 11.679186 12.422958]\n",
      "Reset environment\n",
      "Episode reward: 4294.931\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.428783 12.39511  12.422489 11.339878 11.680551 12.424467]\n",
      "Reset environment\n",
      "Episode reward: 2903.7227\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.429752 12.396097 12.423445 11.340946 11.681422 12.425441]\n",
      "Reset environment\n",
      "Episode reward: 1536.2783\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4302635 12.3966255 12.42395   11.341524  11.681863  12.425953 ]\n",
      "Reset environment\n",
      "Episode reward: 1931.2539\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.430814 12.397153 12.424523 11.342142 11.682351 12.426512]\n",
      "Reset environment\n",
      "Episode reward: 2425.966\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.431658 12.39797  12.425376 11.34307  11.683084 12.427356]\n",
      "Reset environment\n",
      "Episode reward: 4406.1504\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.433249 12.399564 12.426946 11.34478  11.68451  12.428943]\n",
      "Reset environment\n",
      "Episode reward: 857.27625\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.433027  12.399307  12.426752  11.344466  11.684333  12.4287195]\n",
      "Reset environment\n",
      "Episode reward: 2394.89\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.433856  12.4001465 12.427576  11.345383  11.685077  12.42955  ]\n",
      "Reset environment\n",
      "Episode reward: 2047.6713\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.434525  12.400802  12.428266  11.346127  11.685663  12.4302225]\n",
      "Reset environment\n",
      "Episode reward: 1865.9017\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.435134  12.401402  12.4288845 11.346801  11.686204  12.430835 ]\n",
      "Reset environment\n",
      "Episode reward: 2303.1685\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.435877 12.402133 12.429634 11.347615 11.686869 12.431579]\n",
      "Reset environment\n",
      "Episode reward: 2218.9326\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.436578 12.402851 12.430315 11.348379 11.687498 12.432281]\n",
      "Reset environment\n",
      "Episode reward: 6387.8174\n",
      "Total Steps: 216\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.438972 12.405244 12.432711 11.35095  11.689641 12.434675]\n",
      "Reset environment\n",
      "Episode reward: 1282.5099\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.439361 12.405636 12.433098 11.351395 11.689981 12.435066]\n",
      "Reset environment\n",
      "Episode reward: 4110.9604\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.440837 12.407126 12.434568 11.352995 11.69133  12.436543]\n",
      "Reset environment\n",
      "Episode reward: 1720.9253\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.441373 12.407664 12.435105 11.353597 11.69181  12.437079]\n",
      "Reset environment\n",
      "Episode reward: 2467.0806\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.442197 12.408482 12.435934 11.354498 11.692554 12.437903]\n",
      "Reset environment\n",
      "Episode reward: 2606.3843\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.443035 12.409308 12.436785 11.355415 11.693311 12.438744]\n",
      "Reset environment\n",
      "Episode reward: 2191.8306\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.443758 12.410033 12.437504 11.356209 11.693966 12.439466]\n",
      "Reset environment\n",
      "Episode reward: 1953.9315\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.444415 12.410698 12.438153 11.356936 11.694547 12.440125]\n",
      "Reset environment\n",
      "Episode reward: -217.24078\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.44372  12.410053 12.437411 11.356233 11.69389  12.439437]\n",
      "Reset environment\n",
      "Episode reward: 2060.4072\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.444373 12.410713 12.438049 11.35695  11.694479 12.440091]\n",
      "Reset environment\n",
      "Episode reward: 1878.9963\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.444925 12.411286 12.438575 11.35757  11.694944 12.440647]\n",
      "Reset environment\n",
      "Episode reward: 2244.939\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.445673 12.412036 12.43932  11.358389 11.69562  12.441397]\n",
      "Reset environment\n",
      "Episode reward: 4609.3945\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.447347 12.4137   12.441003 11.360185 11.697169 12.443071]\n",
      "Reset environment\n",
      "Episode reward: 1814.1064\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.447916 12.414276 12.441565 11.360831 11.697662 12.443643]\n",
      "Reset environment\n",
      "Episode reward: 4060.306\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.449328 12.415691 12.442976 11.362364 11.698904 12.445055]\n",
      "Reset environment\n",
      "Episode reward: 4492.5957\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.450956 12.417313 12.444605 11.364122 11.700385 12.446683]\n",
      "Reset environment\n",
      "Episode reward: 5898.5737\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.453147  12.419497  12.446799  11.366473  11.702344  12.4488735]\n",
      "Reset environment\n",
      "Episode reward: -703.3967\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.452211 12.418575 12.445851 11.365274 11.70149  12.447944]\n",
      "Reset environment\n",
      "Episode reward: 4043.794\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.453646  12.420006  12.4472885 11.366826  11.702798  12.449378 ]\n",
      "Reset environment\n",
      "Episode reward: 1516.6621\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.454124 12.420482 12.447771 11.367359 11.703212 12.449857]\n",
      "Reset environment\n",
      "Episode reward: 1753.2174\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.454664 12.42101  12.448329 11.367964 11.703683 12.450402]\n",
      "Reset environment\n",
      "Episode reward: 2799.398\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.455615 12.421969 12.449271 11.369007 11.704547 12.451353]\n",
      "Reset environment\n",
      "Episode reward: 1555.6008\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.456083 12.422453 12.449724 11.369522 11.70495  12.451822]\n",
      "Reset environment\n",
      "Episode reward: 2019.787\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.456746 12.423119 12.450382 11.37025  11.705546 12.452485]\n",
      "Reset environment\n",
      "Episode reward: 4633.398\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.458417 12.424784 12.452044 11.372051 11.707058 12.454156]\n",
      "Reset environment\n",
      "Episode reward: 2816.0312\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4593525 12.425712  12.452991  11.373076  11.707897  12.455091 ]\n",
      "Reset environment\n",
      "Episode reward: 3305.1238\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.460507 12.426875 12.454131 11.374329 11.708951 12.456247]\n",
      "Reset environment\n",
      "Episode reward: 4153.2417\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.462021  12.428389  12.4556265 11.375937  11.710311  12.457759 ]\n",
      "Reset environment\n",
      "Episode reward: 4639.7847\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.463693 12.430051 12.457296 11.37774  11.711804 12.459432]\n",
      "Reset environment\n",
      "Episode reward: 1988.9673\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.464293 12.430636 12.457911 11.378397 11.712328 12.460034]\n",
      "Reset environment\n",
      "Episode reward: 1931.1816\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.464913 12.431259 12.458531 11.379085 11.712888 12.460655]\n",
      "Reset environment\n",
      "Episode reward: 3546.0874\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.465935 12.432311 12.45952  11.380226 11.713825 12.461678]\n",
      "Reset environment\n",
      "Episode reward: 2027.5347\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.466589  12.43296   12.460177  11.380946  11.7144165 12.462332 ]\n",
      "Reset environment\n",
      "Episode reward: 1345.484\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.466977 12.433369 12.460554 11.381381 11.714759 12.462724]\n",
      "Reset environment\n",
      "Episode reward: 2196.9517\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4676695 12.434078  12.461221  11.382149  11.715352  12.463418 ]\n",
      "Reset environment\n",
      "Episode reward: 1907.543\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.468279 12.434689 12.461829 11.382823 11.715902 12.464028]\n",
      "Reset environment\n",
      "Episode reward: 3840.4973\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.469649 12.436056 12.463193 11.384293 11.717128 12.465404]\n",
      "Reset environment\n",
      "Episode reward: 1124.8397\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.469965 12.436381 12.463504 11.384661 11.717406 12.46572 ]\n",
      "Reset environment\n",
      "Episode reward: 1600.1534\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.470441 12.436847 12.463993 11.38519  11.717815 12.466199]\n",
      "Reset environment\n",
      "Episode reward: 2585.8733\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.471274  12.437672  12.464835  11.3861065 11.718568  12.4670315]\n",
      "Reset environment\n",
      "Episode reward: 4203.4595\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.472764 12.43917  12.466323 11.387717 11.719913 12.468524]\n",
      "Reset environment\n",
      "Episode reward: 1983.2448\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.47334  12.439763 12.466882 11.388368 11.720407 12.469099]\n",
      "Reset environment\n",
      "Episode reward: 1173.5066\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.473664 12.440073 12.46721  11.388723 11.720688 12.469423]\n",
      "Reset environment\n",
      "Episode reward: 1446.6696\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4741125 12.440512  12.467662  11.389224  11.721069  12.469871 ]\n",
      "Reset environment\n",
      "Episode reward: 1522.3069\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.474587 12.440988 12.468136 11.389753 11.721481 12.470346]\n",
      "Reset environment\n",
      "Episode reward: 1368.7688\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.475256 12.441656 12.468803 11.390493 11.722083 12.471015]\n",
      "Reset environment\n",
      "Episode reward: 2533.2742\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.475917 12.44229  12.469497 11.391253 11.722676 12.471676]\n",
      "Reset environment\n",
      "Episode reward: 175.25528\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.475312  12.441625  12.4689455 11.390571  11.722133  12.471076 ]\n",
      "Reset environment\n",
      "Episode reward: 1384.0447\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4759865 12.442303  12.469621  11.391317  11.722746  12.471752 ]\n",
      "Reset environment\n",
      "Episode reward: 3989.1704\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4774   12.443706 12.471025 11.392839 11.724019 12.473165]\n",
      "Reset environment\n",
      "Episode reward: 2097.1008\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.478359 12.444668 12.471981 11.393887 11.724877 12.474127]\n",
      "Reset environment\n",
      "Episode reward: 3808.9556\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.479703 12.446007 12.473326 11.395345 11.726108 12.47547 ]\n",
      "Reset environment\n",
      "Episode reward: 3565.1875\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4809265 12.447225  12.474559  11.396673  11.727218  12.476694 ]\n",
      "Reset environment\n",
      "Episode reward: 2099.8625\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.481673  12.447963  12.47531   11.3974905 11.727848  12.477444 ]\n",
      "Reset environment\n",
      "Episode reward: 3991.8584\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.483091 12.449369 12.476726 11.399016 11.729139 12.478858]\n",
      "Reset environment\n",
      "Episode reward: 4559.9424\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.484699  12.450963  12.47834   11.4007635 11.730581  12.480462 ]\n",
      "Reset environment\n",
      "Episode reward: 2399.8042\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.485477 12.451755 12.4791   11.401613 11.731238 12.48124 ]\n",
      "Reset environment\n",
      "Episode reward: 2929.5989\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.486451 12.452746 12.480062 11.402675 11.732099 12.482215]\n",
      "Reset environment\n",
      "Episode reward: 3667.1855\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.487724  12.454021  12.4813175 11.4040575 11.733237  12.483489 ]\n",
      "Reset environment\n",
      "Episode reward: 1663.3708\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.488294 12.454593 12.481875 11.404683 11.733713 12.484058]\n",
      "Reset environment\n",
      "Episode reward: 1915.9053\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.488925 12.455217 12.48251  11.405379 11.734263 12.48469 ]\n",
      "Reset environment\n",
      "Episode reward: 3247.7065\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.490014 12.456309 12.4836   11.406567 11.735245 12.48578 ]\n",
      "Reset environment\n",
      "Episode reward: 1591.5596\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.490541  12.4568405 12.484116  11.407147  11.735687  12.486307 ]\n",
      "Reset environment\n",
      "Episode reward: 3124.2515\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.4916115 12.457915  12.485168  11.408314  11.736646  12.487378 ]\n",
      "Reset environment\n",
      "Episode reward: 2421.257\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.492362 12.458669 12.48592  11.40915  11.737318 12.488129]\n",
      "Reset environment\n",
      "Episode reward: 5630.859\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.494391 12.4607   12.48795  11.411343 11.739098 12.490159]\n",
      "Reset environment\n",
      "Episode reward: 1809.815\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.494979  12.461291  12.488534  11.411989  11.739621  12.4907465]\n",
      "Reset environment\n",
      "Episode reward: 2287.4395\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.495544  12.461829  12.489124  11.4126425 11.74013   12.491315 ]\n",
      "Reset environment\n",
      "Episode reward: 4240.321\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.497032 12.463308 12.490617 11.414254 11.741471 12.492803]\n",
      "Reset environment\n",
      "Episode reward: 2161.6074\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.497642 12.463895 12.491243 11.414932 11.742    12.493413]\n",
      "Reset environment\n",
      "Episode reward: 2279.2075\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.498255 12.464482 12.491891 11.415634 11.742549 12.494036]\n",
      "Reset environment\n",
      "Episode reward: 129.65396\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.497793  12.464066  12.491388  11.4150505 11.742125  12.49358  ]\n",
      "Reset environment\n",
      "Episode reward: 2105.1877\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.498317 12.464563 12.491939 11.415652 11.742583 12.494106]\n",
      "Reset environment\n",
      "Episode reward: 1499.0809\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.498812 12.465063 12.492427 11.416201 11.743008 12.494601]\n",
      "Reset environment\n",
      "Episode reward: 2402.5173\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.49961  12.465866 12.493218 11.417073 11.743728 12.4954  ]\n",
      "Reset environment\n",
      "Episode reward: 2543.2344\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.500478 12.466732 12.494088 11.418019 11.744518 12.496268]\n",
      "Reset environment\n",
      "Episode reward: 5079.923\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.502306  12.468551  12.495931  11.4199915 11.746185  12.498096 ]\n",
      "Reset environment\n",
      "Episode reward: 4684.3384\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.503974  12.4702215 12.497582  11.421802  11.747698  12.499765 ]\n",
      "Reset environment\n",
      "Episode reward: 4300.217\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.50549  12.47173  12.499101 11.423447 11.749069 12.501283]\n",
      "Reset environment\n",
      "Episode reward: 4868.601\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.507217 12.47345  12.500829 11.425315 11.750606 12.503011]\n",
      "Reset environment\n",
      "Episode reward: 1774.9769\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.507824  12.474057  12.501433  11.4259815 11.751124  12.503618 ]\n",
      "Reset environment\n",
      "Episode reward: 2536.8289\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.508684  12.4749155 12.502297  11.426923  11.751901  12.504478 ]\n",
      "Reset environment\n",
      "Episode reward: 4840.5596\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.510389 12.476623 12.503988 11.428773 11.75343  12.506181]\n",
      "Reset environment\n",
      "Episode reward: 2295.3362\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.511149 12.477385 12.504745 11.429606 11.754108 12.506941]\n",
      "Reset environment\n",
      "Episode reward: -479.70908\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.510181 12.476323 12.503863 11.428706 11.753211 12.505978]\n",
      "Reset environment\n",
      "Episode reward: 2684.368\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.511057 12.477215 12.504728 11.429667 11.754004 12.506853]\n",
      "Reset environment\n",
      "Episode reward: 1987.4666\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.511685  12.477859  12.5053425 11.430353  11.754545  12.507484 ]\n",
      "Reset environment\n",
      "Episode reward: 2700.196\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.512553 12.478707 12.506225 11.431286 11.755288 12.508351]\n",
      "Reset environment\n",
      "Episode reward: 4394.426\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.514126 12.480286 12.507785 11.432978 11.75671  12.509924]\n",
      "Reset environment\n",
      "Episode reward: 3224.0881\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.515239 12.481411 12.508889 11.434184 11.757729 12.511038]\n",
      "Reset environment\n",
      "Episode reward: 2173.354\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.516214 12.482387 12.509863 11.435252 11.758599 12.512015]\n",
      "Reset environment\n",
      "Episode reward: 2888.8608\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.517166 12.483326 12.510827 11.436289 11.759443 12.512968]\n",
      "Reset environment\n",
      "Episode reward: 1826.2728\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.517744 12.483901 12.511408 11.436927 11.759959 12.513546]\n",
      "Reset environment\n",
      "Episode reward: 2015.0011\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.518316 12.484451 12.511998 11.437562 11.760456 12.514118]\n",
      "Reset environment\n",
      "Episode reward: 3340.9448\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.519433 12.48556  12.513126 11.438784 11.761474 12.515234]\n",
      "Reset environment\n",
      "Episode reward: 4793.2217\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.521156  12.487284  12.514846  11.440647  11.7630205 12.516957 ]\n",
      "Reset environment\n",
      "Episode reward: 1921.3069\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.521749 12.487862 12.515448 11.44131  11.76355  12.517549]\n",
      "Reset environment\n",
      "Episode reward: 1614.638\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.522245 12.488361 12.515945 11.441866 11.763995 12.518046]\n",
      "Reset environment\n",
      "Episode reward: 3283.0212\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.523392 12.489496 12.51708  11.443111 11.765007 12.519193]\n",
      "Reset environment\n",
      "Episode reward: 3616.9639\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.524643 12.490765 12.518313 11.444458 11.766133 12.520443]\n",
      "Reset environment\n",
      "Episode reward: 5024.3276\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.526484  12.4925995 12.520137  11.446425  11.767766  12.522283 ]\n",
      "Reset environment\n",
      "Episode reward: 3579.4724\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.527719 12.493823 12.521377 11.447759 11.768881 12.523517]\n",
      "Reset environment\n",
      "Episode reward: 2398.887\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.528496 12.494591 12.522168 11.448611 11.769588 12.524295]\n",
      "Reset environment\n",
      "Episode reward: 4068.2488\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.529936 12.49603  12.5236   11.450159 11.770875 12.525734]\n",
      "Reset environment\n",
      "Episode reward: 1167.9054\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.5298815 12.496016  12.523508  11.450032  11.770853  12.525689 ]\n",
      "Reset environment\n",
      "Episode reward: 1830.8009\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.530469  12.496601  12.5240965 11.45069   11.771371  12.526277 ]\n",
      "Reset environment\n",
      "Episode reward: 1384.4668\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.531143 12.497277 12.52477  11.451429 11.771981 12.526952]\n",
      "Reset environment\n",
      "Episode reward: 1263.3158\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.530984 12.497139 12.524577 11.451249 11.771832 12.526795]\n",
      "Reset environment\n",
      "Episode reward: 5936.9004\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.533152 12.499306 12.526728 11.453596 11.773793 12.528957]\n",
      "Reset environment\n",
      "Episode reward: 2006.4888\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.534065 12.500218 12.527631 11.454593 11.774616 12.529871]\n",
      "Reset environment\n",
      "Episode reward: 978.3268\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.520582 12.48685  12.514253 11.44032  11.762105 12.516461]\n",
      "Reset environment\n",
      "Episode reward: 2130.3013\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.521094 12.48734  12.514791 11.440913 11.762565 12.516974]\n",
      "Reset environment\n",
      "Episode reward: 4535.402\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.52268  12.48893  12.516377 11.442629 11.763954 12.51856 ]\n",
      "Reset environment\n",
      "Episode reward: 2129.541\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.523632  12.4898815 12.517325  11.443664  11.764812  12.519512 ]\n",
      "Reset environment\n",
      "Episode reward: 5440.3296\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.525562 12.491818 12.519248 11.445755 11.766562 12.521446]\n",
      "Reset environment\n",
      "Episode reward: 2627.2998\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.526393  12.492629  12.520094  11.4466505 11.767267  12.522281 ]\n",
      "Reset environment\n",
      "Episode reward: 2346.261\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.527154 12.493398 12.520852 11.447492 11.767957 12.523042]\n",
      "Reset environment\n",
      "Episode reward: 1794.3508\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.527713 12.493947 12.521419 11.448114 11.76844  12.523601]\n",
      "Reset environment\n",
      "Episode reward: 4703.078\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.529366 12.4956   12.523058 11.449902 11.769936 12.525252]\n",
      "Reset environment\n",
      "Episode reward: 5264.217\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.531233 12.497471 12.524915 11.451919 11.771611 12.52712 ]\n",
      "Reset environment\n",
      "Episode reward: 2090.8923\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.531946 12.498186 12.525625 11.452704 11.772239 12.527834]\n",
      "Reset environment\n",
      "Episode reward: 2280.5867\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.532567 12.498782 12.526269 11.453406 11.772793 12.52846 ]\n",
      "Reset environment\n",
      "Episode reward: 2164.5393\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.533247 12.499453 12.526973 11.454163 11.773398 12.529141]\n",
      "Reset environment\n",
      "Episode reward: 2396.2053\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.533942  12.500177  12.5276375 11.454948  11.774028  12.5298395]\n",
      "Reset environment\n",
      "Episode reward: 2184.7297\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.53463  12.500846 12.528341 11.455702 11.774617 12.530528]\n",
      "Reset environment\n",
      "Episode reward: 1758.6439\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.535434  12.501646  12.529145  11.4565935 11.775338  12.531331 ]\n",
      "Reset environment\n",
      "Episode reward: 3257.976\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.536523 12.502736 12.530233 11.457773 11.776322 12.532421]\n",
      "Reset environment\n",
      "Episode reward: 5063.2197\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.538308 12.504536 12.532013 11.45971  11.777938 12.534212]\n",
      "Reset environment\n",
      "Episode reward: 4685.121\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.539991  12.506209  12.533697  11.4615135 11.779464  12.535894 ]\n",
      "Reset environment\n",
      "Episode reward: 2664.657\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.540901 12.507124 12.534605 11.462506 11.780292 12.536805]\n",
      "Reset environment\n",
      "Episode reward: 4006.6023\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.542304 12.508517 12.536007 11.464018 11.781563 12.538207]\n",
      "Reset environment\n",
      "Episode reward: 1798.7078\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.542878  12.509102  12.5365715 11.464661  11.782077  12.538783 ]\n",
      "Reset environment\n",
      "Episode reward: 1515.1183\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.542974 12.509219 12.536639 11.464676 11.782177 12.53888 ]\n",
      "Reset environment\n",
      "Episode reward: 1988.3113\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.543445  12.509713  12.537084  11.4652195 11.782601  12.53935  ]\n",
      "Reset environment\n",
      "Episode reward: 3833.357\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.544748 12.511019 12.538376 11.466639 11.78378  12.540655]\n",
      "Reset environment\n",
      "Episode reward: 1878.0005\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.545344  12.51161   12.538976  11.4672985 11.784309  12.54125  ]\n",
      "Reset environment\n",
      "Episode reward: 2087.2947\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.545973 12.512239 12.539604 11.467996 11.784881 12.541879]\n",
      "Reset environment\n",
      "Episode reward: 1758.4956\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.546486 12.51274  12.540136 11.468571 11.785337 12.542398]\n",
      "Reset environment\n",
      "Episode reward: 303.98087\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.545937 12.512277 12.539495 11.468005 11.784834 12.541857]\n",
      "Reset environment\n",
      "Episode reward: 2835.798\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.546878 12.513206 12.540455 11.469035 11.785692 12.5428  ]\n",
      "Reset environment\n",
      "Episode reward: 3505.122\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.548092 12.514426 12.541665 11.470355 11.786784 12.544016]\n",
      "Reset environment\n",
      "Episode reward: 2179.4065\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.549069 12.515405 12.542638 11.47142  11.787652 12.544994]\n",
      "Reset environment\n",
      "Episode reward: 3263.0625\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.550202  12.5165415 12.54376   11.472642  11.788668  12.546126 ]\n",
      "Reset environment\n",
      "Episode reward: 5785.8877\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.552268 12.518605 12.545822 11.474857 11.790539 12.548187]\n",
      "Reset environment\n",
      "Episode reward: 2845.5874\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.553212 12.519535 12.546774 11.475884 11.791398 12.549134]\n",
      "Reset environment\n",
      "Episode reward: 2051.1602\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.553794 12.520099 12.547379 11.476544 11.791918 12.549722]\n",
      "Reset environment\n",
      "Episode reward: 2989.4204\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.554792 12.521082 12.548379 11.47763  11.792821 12.550719]\n",
      "Reset environment\n",
      "Episode reward: 1413.353\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.555473 12.521765 12.54906  11.478383 11.793435 12.5514  ]\n",
      "Reset environment\n",
      "Episode reward: 2171.272\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.556437  12.522721  12.550023  11.479431  11.794296  12.5523615]\n",
      "Reset environment\n",
      "Episode reward: 1986.7495\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.556983  12.523243  12.5505905 11.480047  11.794772  12.55291  ]\n",
      "Reset environment\n",
      "Episode reward: 5067.5327\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.558813  12.525071  12.5524235 11.482021  11.796432  12.554739 ]\n",
      "Reset environment\n",
      "Episode reward: 3711.8137\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.560108  12.526361  12.5537195 11.483427  11.797601  12.556035 ]\n",
      "Reset environment\n",
      "Episode reward: 1921.1548\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.560982 12.527236 12.554595 11.484381 11.798389 12.55691 ]\n",
      "Reset environment\n",
      "Episode reward: 1781.3362\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.561792 12.528044 12.555403 11.485276 11.799114 12.55772 ]\n",
      "Reset environment\n",
      "Episode reward: 1807.913\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.562393  12.5286455 12.556004  11.48594   11.799634  12.558322 ]\n",
      "Reset environment\n",
      "Episode reward: 1663.2708\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.562921 12.52917  12.556534 11.486522 11.800098 12.558847]\n",
      "Reset environment\n",
      "Episode reward: 2085.3213\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.563577  12.529837  12.557183  11.4872465 11.800685  12.559504 ]\n",
      "Reset environment\n",
      "Episode reward: -291.27325\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.562706 12.528892 12.556378 11.486456 11.799864 12.558643]\n",
      "Reset environment\n",
      "Episode reward: 1761.3696\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.563232 12.529404 12.556915 11.487044 11.800312 12.559171]\n",
      "Reset environment\n",
      "Episode reward: 5360.901\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.565156  12.531324  12.558825  11.489103  11.8020525 12.56109  ]\n",
      "Reset environment\n",
      "Episode reward: 2151.8914\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.565853  12.5320215 12.559524  11.489869  11.802682  12.5617895]\n",
      "Reset environment\n",
      "Episode reward: 2154.8557\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.566821  12.532986  12.5604925 11.490917  11.803548  12.562758 ]\n",
      "Reset environment\n",
      "Episode reward: 1864.2437\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.567442 12.533604 12.561115 11.491599 11.804084 12.563377]\n",
      "Reset environment\n",
      "Episode reward: 3892.5593\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.568778 12.534937 12.562457 11.493047 11.805299 12.564714]\n",
      "Reset environment\n",
      "Episode reward: 3406.665\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.569914 12.536075 12.563595 11.494281 11.806294 12.56585 ]\n",
      "Reset environment\n",
      "Episode reward: 2613.0527\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.570796 12.536959 12.564473 11.49525  11.807098 12.566732]\n",
      "Reset environment\n",
      "Episode reward: 2824.659\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.571713 12.537861 12.565405 11.496251 11.807917 12.56765 ]\n",
      "Reset environment\n",
      "Episode reward: 1758.1055\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.572516 12.538663 12.566208 11.497131 11.808638 12.568453]\n",
      "Reset environment\n",
      "Episode reward: 2377.6614\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.57329  12.539442 12.566972 11.497982 11.80933  12.569227]\n",
      "Reset environment\n",
      "Episode reward: 2457.6106\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.574081 12.540246 12.567751 11.498844 11.810052 12.570019]\n",
      "Reset environment\n",
      "Episode reward: 1833.9178\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.574921 12.541083 12.568588 11.499756 11.810812 12.570858]\n",
      "Reset environment\n",
      "Episode reward: 1954.7047\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.575537 12.541703 12.569202 11.500438 11.811372 12.571475]\n",
      "Reset environment\n",
      "Episode reward: 2686.071\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.576269 12.542414 12.569962 11.501277 11.812036 12.572208]\n",
      "Reset environment\n",
      "Episode reward: 4274.5146\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.577775 12.543927 12.571462 11.502903 11.813385 12.573717]\n",
      "Reset environment\n",
      "Episode reward: 5707.8\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.579852 12.545994 12.57354  11.505131 11.815261 12.575789]\n",
      "Reset environment\n",
      "Episode reward: 2216.1785\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.580569  12.546712  12.574257  11.5059185 11.815904  12.576506 ]\n",
      "Reset environment\n",
      "Episode reward: 1014.93774\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.580834  12.5469675 12.574527  11.506225  11.816124  12.576772 ]\n",
      "Reset environment\n",
      "Episode reward: 5143.1245\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.582985  12.549103  12.5766735 11.508532  11.818021  12.57892  ]\n",
      "Reset environment\n",
      "Episode reward: 1914.7335\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.58358   12.5497    12.57727   11.509193  11.8185625 12.579516 ]\n",
      "Reset environment\n",
      "Episode reward: 2483.5034\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.584384  12.550514  12.578062  11.510072  11.819287  12.5803175]\n",
      "Reset environment\n",
      "Episode reward: 1371.3511\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.585044  12.551175  12.578719  11.510801  11.8198805 12.5809765]\n",
      "Reset environment\n",
      "Episode reward: 4947.6885\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.586836  12.552958  12.580496  11.512709  11.821466  12.5827675]\n",
      "Reset environment\n",
      "Episode reward: 3143.5664\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.587834 12.553983 12.581465 11.513824 11.822369 12.58377 ]\n",
      "Reset environment\n",
      "Episode reward: 3070.7026\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.588897  12.555049  12.5825205 11.514972  11.8233185 12.584834 ]\n",
      "Reset environment\n",
      "Episode reward: 5145.2124\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.590729 12.556868 12.584342 11.516958 11.824953 12.586665]\n",
      "Reset environment\n",
      "Episode reward: 4672.19\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.592387 12.558526 12.585993 11.518747 11.826433 12.588324]\n",
      "Reset environment\n",
      "Episode reward: 5325.2896\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.594289 12.560437 12.587891 11.52081  11.828165 12.590225]\n",
      "Reset environment\n",
      "Episode reward: 3491.0198\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.595436  12.561586  12.589038  11.522064  11.8292    12.5913725]\n",
      "Reset environment\n",
      "Episode reward: 1792.254\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.595971  12.562118  12.589577  11.522665  11.829677  12.5919075]\n",
      "Reset environment\n",
      "Episode reward: 2221.3977\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.596673 12.562833 12.590273 11.523437 11.830307 12.592609]\n",
      "Reset environment\n",
      "Episode reward: 2098.5732\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.597617 12.563772 12.591213 11.524457 11.831155 12.593557]\n",
      "Reset environment\n",
      "Episode reward: 1683.4531\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.598146 12.564304 12.591736 11.525054 11.831621 12.594088]\n",
      "Reset environment\n",
      "Episode reward: 284.49954\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.597529 12.563778 12.591035 11.524385 11.83108  12.593477]\n",
      "Reset environment\n",
      "Episode reward: 2303.659\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.598081  12.56436   12.591554  11.525026  11.831576  12.5940275]\n",
      "Reset environment\n",
      "Episode reward: 3043.0352\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.599106 12.565394 12.592554 11.52615  11.832491 12.595056]\n",
      "Reset environment\n",
      "Episode reward: 2369.7583\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.599773 12.566039 12.59325  11.526891 11.833071 12.595729]\n",
      "Reset environment\n",
      "Episode reward: 390.2886\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.599334 12.565648 12.59275  11.526338 11.832677 12.595289]\n",
      "Reset environment\n",
      "Episode reward: 2267.6658\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.599912 12.566248 12.593305 11.52699  11.833201 12.595868]\n",
      "Reset environment\n",
      "Episode reward: 1779.9542\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.600503 12.56684  12.593895 11.527643 11.833713 12.59646 ]\n",
      "Reset environment\n",
      "Episode reward: 2375.3862\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.601541 12.567874 12.594922 11.528765 11.83463  12.597499]\n",
      "Reset environment\n",
      "Episode reward: 1393.996\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.60179  12.568094 12.595201 11.529073 11.834858 12.597751]\n",
      "Reset environment\n",
      "Episode reward: -6.313904\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.601144  12.567512  12.594486  11.5283165 11.834291  12.597104 ]\n",
      "Reset environment\n",
      "Episode reward: 2776.781\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.601995 12.568386 12.595298 11.529274 11.835033 12.597959]\n",
      "Reset environment\n",
      "Episode reward: 1911.1296\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.60258   12.568975  12.5958805 11.529931  11.835562  12.598543 ]\n",
      "Reset environment\n",
      "Episode reward: 2436.317\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.603308  12.5696945 12.596617  11.530748  11.836222  12.599271 ]\n",
      "Reset environment\n",
      "Episode reward: 2826.4556\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.604224 12.570612 12.597542 11.531759 11.837058 12.600189]\n",
      "Reset environment\n",
      "Episode reward: 2655.2654\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.605054 12.571424 12.598391 11.532672 11.837787 12.601019]\n",
      "Reset environment\n",
      "Episode reward: 1884.6549\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.605641 12.572033 12.598959 11.533322 11.838294 12.601609]\n",
      "Reset environment\n",
      "Episode reward: 2262.181\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.606379 12.572772 12.599696 11.534132 11.838967 12.602346]\n",
      "Reset environment\n",
      "Episode reward: 2079.0972\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.607305 12.573691 12.600621 11.535138 11.839802 12.603272]\n",
      "Reset environment\n",
      "Episode reward: 2116.9844\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.608017  12.574402  12.601326  11.5359125 11.840428  12.603985 ]\n",
      "Reset environment\n",
      "Episode reward: 3361.5415\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.609175 12.575568 12.602478 11.537155 11.84147  12.605147]\n",
      "Reset environment\n",
      "Episode reward: 1780.3508\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.609725  12.576124  12.6030245 11.537768  11.841963  12.605697 ]\n",
      "Reset environment\n",
      "Episode reward: 2015.5381\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.610621  12.577013  12.60392   11.5387335 11.842765  12.606596 ]\n",
      "Reset environment\n",
      "Episode reward: 1503.8591\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.611071 12.577458 12.604372 11.539242 11.843153 12.607044]\n",
      "Reset environment\n",
      "Episode reward: 1451.7139\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.61154  12.577929 12.60484  11.539761 11.84356  12.607514]\n",
      "Reset environment\n",
      "Episode reward: 2351.038\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.612231  12.578645  12.6055155 11.540528  11.844184  12.608206 ]\n",
      "Reset environment\n",
      "Episode reward: 2090.228\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.612895 12.579315 12.606175 11.541259 11.84479  12.60887 ]\n",
      "Reset environment\n",
      "Episode reward: 5203.47\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.614738 12.581162 12.608006 11.543243 11.846452 12.610714]\n",
      "Reset environment\n",
      "Episode reward: 1386.6914\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.615403 12.58183  12.60867  11.543975 11.847054 12.611378]\n",
      "Reset environment\n",
      "Episode reward: 1707.7415\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.61592  12.582343 12.609198 11.544556 11.847509 12.611898]\n",
      "Reset environment\n",
      "Episode reward: 2096.642\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.616853 12.583271 12.610131 11.545564 11.848353 12.612831]\n",
      "Reset environment\n",
      "Episode reward: 5157.8286\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.618732 12.585146 12.612006 11.547573 11.85005  12.614709]\n",
      "Reset environment\n",
      "Episode reward: 1728.3857\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.619262 12.585691 12.612527 11.548157 11.850502 12.615242]\n",
      "Reset environment\n",
      "Episode reward: 2601.9353\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.6201315 12.586567  12.613386  11.549106  11.851289  12.616112 ]\n",
      "Reset environment\n",
      "Episode reward: 1300.3607\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.620442  12.586854  12.613719  11.54946   11.8515625 12.616425 ]\n",
      "Reset environment\n",
      "Episode reward: 4653.0806\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.622055  12.5884695 12.61533   11.551202  11.853043  12.618037 ]\n",
      "Reset environment\n",
      "Episode reward: 4270.51\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.623549 12.589958 12.61682  11.552814 11.854381 12.619528]\n",
      "Reset environment\n",
      "Episode reward: 1659.8574\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.624057 12.59046  12.617333 11.553378 11.854815 12.620037]\n",
      "Reset environment\n",
      "Episode reward: 2118.5447\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.624735 12.591139 12.618012 11.554123 11.855427 12.620715]\n",
      "Reset environment\n",
      "Episode reward: 2750.81\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.625601  12.5919895 12.6188965 11.555072  11.856186  12.621582 ]\n",
      "Reset environment\n",
      "Episode reward: 1387.0433\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.626028 12.59242  12.619324 11.555552 11.856557 12.622008]\n",
      "Reset environment\n",
      "Episode reward: 2678.8345\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.626901 12.593277 12.620198 11.5565   11.857341 12.622877]\n",
      "Reset environment\n",
      "Episode reward: 3964.5305\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.62824  12.594611 12.621543 11.557956 11.858557 12.62422 ]\n",
      "Reset environment\n",
      "Episode reward: 1923.888\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.628709 12.595052 12.62204  11.558489 11.858969 12.62469 ]\n",
      "Reset environment\n",
      "Episode reward: 2899.5586\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.629641 12.596006 12.622946 11.559521 11.859809 12.625624]\n",
      "Reset environment\n",
      "Episode reward: 1772.3693\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.630451  12.596819  12.6237545 11.560411  11.860541  12.626434 ]\n",
      "Reset environment\n",
      "Episode reward: 2974.873\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.631419 12.597775 12.624735 11.561467 11.861419 12.627402]\n",
      "Reset environment\n",
      "Episode reward: -210.14508\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.63048  12.596958 12.623683 11.5605   11.860586 12.626469]\n",
      "Reset environment\n",
      "Episode reward: 2152.985\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.631122 12.597577 12.624341 11.561204 11.861134 12.627111]\n",
      "Reset environment\n",
      "Episode reward: 1674.2599\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.631647  12.5981045 12.6248665 11.561787  11.861596  12.627637 ]\n",
      "Reset environment\n",
      "Episode reward: 3676.1594\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.632897 12.599351 12.626109 11.563153 11.86273  12.628884]\n",
      "Reset environment\n",
      "Episode reward: 1820.7958\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.633442 12.599886 12.626661 11.563757 11.863212 12.629431]\n",
      "Reset environment\n",
      "Episode reward: 2186.3445\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.634403  12.6008415 12.627624  11.564804  11.864076  12.630399 ]\n",
      "Reset environment\n",
      "Episode reward: 2093.5623\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.635081 12.601521 12.628302 11.565548 11.864693 12.631076]\n",
      "Reset environment\n",
      "Episode reward: 3073.1707\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.636094  12.602545  12.629307  11.5666485 11.865606  12.632093 ]\n",
      "Reset environment\n",
      "Episode reward: 2437.3906\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.636521 12.602988 12.629708 11.567085 11.866032 12.632525]\n",
      "Reset environment\n",
      "Episode reward: 3559.422\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.637743 12.604202 12.630917 11.568409 11.867127 12.633746]\n",
      "Reset environment\n",
      "Episode reward: 3615.7803\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.6390085 12.605469  12.632184  11.56978   11.868282  12.635013 ]\n",
      "Reset environment\n",
      "Episode reward: 4674.2954\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.640623  12.607084  12.6338005 11.571524  11.869703  12.636628 ]\n",
      "Reset environment\n",
      "Episode reward: 3690.6145\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.641892  12.608357  12.635067  11.572897  11.870834  12.6378975]\n",
      "Reset environment\n",
      "Episode reward: 4500.606\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.643448 12.609916 12.636621 11.574583 11.872207 12.639453]\n",
      "Reset environment\n",
      "Episode reward: 1587.9071\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.6439   12.610381 12.63705  11.575096 11.872598 12.639908]\n",
      "Reset environment\n",
      "Episode reward: 5590.278\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.64617  12.612659 12.639308 11.57754  11.874642 12.642179]\n",
      "Reset environment\n",
      "Episode reward: 4909.7783\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.647921 12.614408 12.641052 11.579427 11.876206 12.64393 ]\n",
      "Reset environment\n",
      "Episode reward: 2048.7578\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.648838 12.615323 12.641969 11.580427 11.877031 12.644848]\n",
      "Reset environment\n",
      "Episode reward: 2598.7195\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.649641 12.616143 12.642758 11.581317 11.877741 12.645652]\n",
      "Reset environment\n",
      "Episode reward: 2639.39\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.650443  12.616971  12.643529  11.582215  11.8784485 12.646456 ]\n",
      "Reset environment\n",
      "Episode reward: 552.5707\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.650087 12.616674 12.643103 11.581761 11.87815  12.646101]\n",
      "Reset environment\n",
      "Episode reward: 1467.2386\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.650533 12.617121 12.643548 11.582261 11.878549 12.646546]\n",
      "Reset environment\n",
      "Episode reward: 1307.3217\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.650874 12.617448 12.643908 11.582657 11.878841 12.646888]\n",
      "Reset environment\n",
      "Episode reward: 2721.728\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.651747 12.618311 12.644785 11.583612 11.879629 12.64776 ]\n",
      "Reset environment\n",
      "Episode reward: 2701.7249\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.652597 12.619147 12.645655 11.584541 11.880387 12.648613]\n",
      "Reset environment\n",
      "Episode reward: 1909.2181\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.653196 12.619728 12.646266 11.585205 11.880921 12.649213]\n",
      "Reset environment\n",
      "Episode reward: 1579.9807\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.653688 12.620233 12.646746 11.585748 11.881344 12.649706]\n",
      "Reset environment\n",
      "Episode reward: 4986.2603\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.655439  12.621975  12.6485    11.587643  11.8829365 12.651455 ]\n",
      "Reset environment\n",
      "Episode reward: 1358.564\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.656083 12.622618 12.649145 11.588352 11.88352  12.652099]\n",
      "Reset environment\n",
      "Episode reward: 2524.3682\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.656894  12.623438  12.64995   11.589242  11.8842535 12.652909 ]\n",
      "Reset environment\n",
      "Episode reward: 1929.6353\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.657474  12.6240015 12.650543  11.589881  11.884743  12.653495 ]\n",
      "Reset environment\n",
      "Episode reward: 2639.0344\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.658323  12.6248455 12.651401  11.590812  11.885509  12.654344 ]\n",
      "Reset environment\n",
      "Episode reward: 4260.874\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.659816 12.626333 12.652889 11.592427 11.886825 12.65584 ]\n",
      "Reset environment\n",
      "Episode reward: 2424.0627\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.660601 12.627114 12.653673 11.593289 11.887531 12.656626]\n",
      "Reset environment\n",
      "Episode reward: 3943.9172\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.661949 12.628454 12.655027 11.594744 11.88874  12.657973]\n",
      "Reset environment\n",
      "Episode reward: 2348.0742\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.662671 12.629191 12.655736 11.595539 11.889396 12.658695]\n",
      "Reset environment\n",
      "Episode reward: 2610.5908\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.663526 12.630039 12.656589 11.596462 11.890163 12.65955 ]\n",
      "Reset environment\n",
      "Episode reward: 3803.797\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.664811 12.631321 12.657877 11.59785  11.891334 12.660834]\n",
      "Reset environment\n",
      "Episode reward: 2021.6459\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.665339 12.631871 12.658385 11.598447 11.891814 12.661365]\n",
      "Reset environment\n",
      "Episode reward: 2166.2373\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.666303 12.632833 12.65935  11.599495 11.892683 12.662328]\n",
      "Reset environment\n",
      "Episode reward: 3964.2021\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.667696  12.634232  12.6607275 11.600993  11.893937  12.663718 ]\n",
      "Reset environment\n",
      "Episode reward: 1379.5176\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.668345 12.634882 12.661375 11.601711 11.894525 12.664367]\n",
      "Reset environment\n",
      "Episode reward: 2321.1572\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.668893 12.635455 12.661888 11.602335 11.895018 12.664913]\n",
      "Reset environment\n",
      "Episode reward: 2587.9253\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.669695 12.63624  12.662706 11.603212 11.895721 12.665718]\n",
      "Reset environment\n",
      "Episode reward: 5269.6235\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.671558 12.638097 12.664563 11.605232 11.897394 12.667576]\n",
      "Reset environment\n",
      "Episode reward: 1812.7643\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.672138  12.638679  12.665146  11.605879  11.8979025 12.668158 ]\n",
      "Reset environment\n",
      "Episode reward: 2441.7969\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.672918  12.6394615 12.665917  11.606735  11.8986025 12.66894  ]\n",
      "Reset environment\n",
      "Episode reward: 4056.9934\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.67434  12.640867 12.667328 11.60825  11.899855 12.670359]\n",
      "Reset environment\n",
      "Episode reward: 2038.8994\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.675247 12.641772 12.668229 11.609247 11.900663 12.671265]\n",
      "Reset environment\n",
      "Episode reward: 1394.6421\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.675896 12.642424 12.668879 11.609972 11.901246 12.671913]\n",
      "Reset environment\n",
      "Episode reward: 5640.3877\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.678134 12.64465  12.671112 11.612367 11.903228 12.674148]\n",
      "Reset environment\n",
      "Episode reward: 1561.6632\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.678599  12.645117  12.6715765 11.612886  11.90364   12.674613 ]\n",
      "Reset environment\n",
      "Episode reward: 1540.2906\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.678977 12.645522 12.671924 11.613323 11.903977 12.674991]\n",
      "Reset environment\n",
      "Episode reward: 1333.405\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.6793585 12.645885  12.672311  11.613743  11.904303  12.675372 ]\n",
      "Reset environment\n",
      "Episode reward: 2174.522\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.680021 12.646564 12.672962 11.614476 11.904888 12.676035]\n",
      "Reset environment\n",
      "Episode reward: 1857.5447\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.6806    12.647163  12.6735115 11.615127  11.905399  12.676616 ]\n",
      "Reset environment\n",
      "Episode reward: 2247.8418\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.681602 12.648166 12.674508 11.616215 11.906302 12.677619]\n",
      "Reset environment\n",
      "Episode reward: 4738.8706\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.683309 12.649879 12.676213 11.61805  11.907856 12.679326]\n",
      "Reset environment\n",
      "Episode reward: 1384.4154\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.683966  12.6505375 12.676871  11.618776  11.90845   12.679985 ]\n",
      "Reset environment\n",
      "Episode reward: 5957.885\n",
      "Total Steps: 217\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.68633  12.652893 12.679224 11.621307 11.91055  12.682341]\n",
      "Reset environment\n",
      "Episode reward: 2881.4482\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.687274 12.653829 12.680174 11.622335 11.911396 12.683285]\n",
      "Reset environment\n",
      "Episode reward: 1811.749\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.688094 12.654647 12.680994 11.623236 11.912128 12.684106]\n",
      "Reset environment\n",
      "Episode reward: 3494.6755\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.689285  12.655849  12.682169  11.6245165 11.913186  12.685295 ]\n",
      "Reset environment\n",
      "Episode reward: 5561.606\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.691245  12.6578045 12.684106  11.626637  11.91494   12.68725  ]\n",
      "Reset environment\n",
      "Episode reward: 3731.9875\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.692547 12.659106 12.685403 11.628043 11.91611  12.688552]\n",
      "Reset environment\n",
      "Episode reward: 2031.7534\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.693203 12.659762 12.68606  11.628764 11.91669  12.689209]\n",
      "Reset environment\n",
      "Episode reward: 4680.192\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.694858 12.661408 12.6877   11.630544 11.918162 12.690863]\n",
      "Reset environment\n",
      "Episode reward: 3663.6416\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.696112 12.662667 12.688955 11.631903 11.9193   12.69212 ]\n",
      "Reset environment\n",
      "Episode reward: 2374.8591\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.696661 12.663194 12.689538 11.632554 11.919801 12.692672]\n",
      "Reset environment\n",
      "Episode reward: 5250.2974\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.698482 12.665025 12.691356 11.634528 11.921448 12.694495]\n",
      "Reset environment\n",
      "Episode reward: 1951.6248\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.6990795 12.665622  12.691954  11.635192  11.921987  12.695093 ]\n",
      "Reset environment\n",
      "Episode reward: 4913.2783\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.700829  12.667374  12.693697  11.637069  11.9235735 12.696838 ]\n",
      "Reset environment\n",
      "Episode reward: 1933.9624\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.701416 12.66797  12.694279 11.637722 11.924103 12.697424]\n",
      "Reset environment\n",
      "Episode reward: 5082.927\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.703219 12.669771 12.696072 11.639666 11.9257   12.699222]\n",
      "Reset environment\n",
      "Episode reward: 2213.976\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.704205 12.670754 12.697048 11.640726 11.926575 12.700204]\n",
      "Reset environment\n",
      "Episode reward: 573.98\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.703808 12.670413 12.696599 11.640238 11.926236 12.699813]\n",
      "Reset environment\n",
      "Episode reward: 4462.9375\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.705379 12.671977 12.698161 11.641925 11.927649 12.701383]\n",
      "Reset environment\n",
      "Episode reward: 3708.7063\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.7066345 12.673234  12.69941   11.643305  11.928776  12.7026415]\n",
      "Reset environment\n",
      "Episode reward: 2280.0115\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.707303  12.6738825 12.700094  11.644033  11.929349  12.703311 ]\n",
      "Reset environment\n",
      "Episode reward: 2697.5657\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.708122 12.674686 12.700932 11.644933 11.930048 12.704131]\n",
      "Reset environment\n",
      "Episode reward: 1783.4548\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.708655 12.675211 12.701473 11.645528 11.930507 12.704666]\n",
      "Reset environment\n",
      "Episode reward: 3544.396\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.709862 12.676425 12.702651 11.646844 11.931576 12.705875]\n",
      "Reset environment\n",
      "Episode reward: 2319.3816\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.710873 12.677436 12.70366  11.647934 11.932478 12.706886]\n",
      "Reset environment\n",
      "Episode reward: 5692.0264\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.712892 12.679451 12.705658 11.650123 11.934294 12.708898]\n",
      "Reset environment\n",
      "Episode reward: 5489.5063\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.714866  12.681414  12.707626  11.652243  11.9360285 12.710872 ]\n",
      "Reset environment\n",
      "Episode reward: 4937.28\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.716549 12.683097 12.709314 11.654065 11.937548 12.712555]\n",
      "Reset environment\n",
      "Episode reward: 2347.8323\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.71728  12.683825 12.710048 11.654885 11.938202 12.713289]\n",
      "Reset environment\n",
      "Episode reward: 2636.2026\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.718086 12.684648 12.710831 11.655784 11.938917 12.7141  ]\n",
      "Reset environment\n",
      "Episode reward: 1557.6431\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.718501 12.685045 12.711268 11.656247 11.939292 12.714523]\n",
      "Reset environment\n",
      "Episode reward: 2639.443\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.719336 12.6859   12.71207  11.657164 11.940006 12.715358]\n",
      "Reset environment\n",
      "Episode reward: 1701.3992\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.719734 12.686331 12.712442 11.657623 11.940366 12.715756]\n",
      "Reset environment\n",
      "Episode reward: 1624.9358\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.720474 12.687076 12.713182 11.658441 11.941031 12.716497]\n",
      "Reset environment\n",
      "Episode reward: 5915.138\n",
      "Total Steps: 223\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.722852 12.689444 12.715552 11.661012 11.943188 12.718867]\n",
      "Reset environment\n",
      "Episode reward: -254.71289\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.721933 12.688628 12.714533 11.660038 11.942366 12.717952]\n",
      "Reset environment\n",
      "Episode reward: 4662.5073\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.7235365 12.69023   12.716128  11.661765  11.9438    12.71956  ]\n",
      "Reset environment\n",
      "Episode reward: 2001.7113\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.724181 12.690866 12.716781 11.662477 11.944352 12.720208]\n",
      "Reset environment\n",
      "Episode reward: 2010.9923\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.724764 12.691465 12.717332 11.663128 11.94488  12.72079 ]\n",
      "Reset environment\n",
      "Episode reward: 1206.7681\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.725122  12.691822  12.717697  11.663528  11.945195  12.7211485]\n",
      "Reset environment\n",
      "Episode reward: 1077.502\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.725387 12.692104 12.717949 11.663835 11.945431 12.721415]\n",
      "Reset environment\n",
      "Episode reward: -343.3546\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.724624  12.691342  12.717188  11.663127  11.9447365 12.720654 ]\n",
      "Reset environment\n",
      "Episode reward: 1506.705\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.725079 12.691803 12.71764  11.663634 11.945142 12.721108]\n",
      "Reset environment\n",
      "Episode reward: 2722.115\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.725987 12.692715 12.718548 11.66462  11.94595  12.722017]\n",
      "Reset environment\n",
      "Episode reward: 1850.2327\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.726558 12.693281 12.719122 11.665249 11.94646  12.722588]\n",
      "Reset environment\n",
      "Episode reward: 1827.498\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.727108 12.693817 12.719683 11.665859 11.946937 12.72314 ]\n",
      "Reset environment\n",
      "Episode reward: 1981.3845\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.727788 12.6945   12.720352 11.666597 11.947521 12.72382 ]\n",
      "Reset environment\n",
      "Episode reward: 249.4667\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.727255 12.694048 12.719749 11.666001 11.947036 12.723292]\n",
      "Reset environment\n",
      "Episode reward: 2152.3557\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.727916 12.694697 12.720427 11.666728 11.947615 12.723952]\n",
      "Reset environment\n",
      "Episode reward: 2519.1396\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.728741  12.695528  12.721246  11.667629  11.9483595 12.724779 ]\n",
      "Reset environment\n",
      "Episode reward: 4247.693\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.730181 12.696965 12.722694 11.669187 11.949685 12.726217]\n",
      "Reset environment\n",
      "Episode reward: 1855.9681\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.730721 12.697523 12.723209 11.66979  11.950143 12.726759]\n",
      "Reset environment\n",
      "Episode reward: 1879.1211\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.731322 12.698129 12.723808 11.670455 11.950682 12.727361]\n",
      "Reset environment\n",
      "Episode reward: 1820.2441\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.731876 12.69867  12.724368 11.671073 11.951169 12.727915]\n",
      "Reset environment\n",
      "Episode reward: 3009.577\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.73288   12.699678  12.725366  11.6721735 11.95206   12.728918 ]\n",
      "Reset environment\n",
      "Episode reward: 2476.7363\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.73368  12.700486 12.726163 11.673053 11.952785 12.729719]\n",
      "Reset environment\n",
      "Episode reward: 5477.282\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.735622  12.7024145 12.728088  11.675134  11.954486  12.731667 ]\n",
      "Reset environment\n",
      "Episode reward: 3087.0151\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.736615 12.703401 12.729088 11.676219 11.955386 12.732653]\n",
      "Reset environment\n",
      "Episode reward: 2088.728\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.737242 12.704018 12.729729 11.676916 11.955938 12.73328 ]\n",
      "Reset environment\n",
      "Episode reward: 3137.8928\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.738254 12.705031 12.730739 11.678022 11.956853 12.734292]\n",
      "Reset environment\n",
      "Episode reward: 2173.0117\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.738941  12.705727  12.73142   11.6787815 11.957478  12.734981 ]\n",
      "Reset environment\n",
      "Episode reward: 2087.4292\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.739635 12.706423 12.732112 11.679538 11.9581   12.735674]\n",
      "Reset environment\n",
      "Episode reward: 1831.4163\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.740225 12.707014 12.732699 11.68019  11.958625 12.736264]\n",
      "Reset environment\n",
      "Episode reward: 3473.079\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.741377 12.708178 12.733847 11.681439 11.95965  12.737416]\n",
      "Reset environment\n",
      "Episode reward: 2217.1362\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.742029 12.708816 12.73451  11.682164 11.960214 12.73807 ]\n",
      "Reset environment\n",
      "Episode reward: 5724.598\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.744087 12.710865 12.736564 11.684372 11.962031 12.740119]\n",
      "Reset environment\n",
      "Episode reward: 2647.2605\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.74496   12.7117405 12.737433  11.685326  11.962813  12.740992 ]\n",
      "Reset environment\n",
      "Episode reward: 2156.7932\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.745912  12.712688  12.7383795 11.686354  11.96366   12.741943 ]\n",
      "Reset environment\n",
      "Episode reward: 2139.4116\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.74657  12.713344 12.73904  11.687087 11.964253 12.7426  ]\n",
      "Reset environment\n",
      "Episode reward: 1488.0199\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.747014 12.713789 12.739486 11.687584 11.96465  12.743046]\n",
      "Reset environment\n",
      "Episode reward: 1510.0453\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.747487 12.714264 12.739958 11.688109 11.965066 12.743519]\n",
      "Reset environment\n",
      "Episode reward: 5420.9116\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.749383 12.716169 12.741848 11.690149 11.966776 12.745413]\n",
      "Reset environment\n",
      "Episode reward: 1561.0698\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.749848 12.716625 12.742325 11.690668 11.96717  12.745879]\n",
      "Reset environment\n",
      "Episode reward: 1669.5765\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.750237  12.7169895 12.74274   11.69112   11.967524  12.74627  ]\n",
      "Reset environment\n",
      "Episode reward: 1776.6315\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.750816 12.717567 12.74332  11.691757 11.968025 12.746849]\n",
      "Reset environment\n",
      "Episode reward: 1818.5308\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.751372 12.718132 12.743861 11.692374 11.968505 12.747404]\n",
      "Reset environment\n",
      "Episode reward: 1884.0219\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.751942  12.718704  12.744431  11.693014  11.969019  12.7479725]\n",
      "Reset environment\n",
      "Episode reward: 4361.5938\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.753417 12.720173 12.745912 11.694626 11.970351 12.749449]\n",
      "Reset environment\n",
      "Episode reward: 1789.6449\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.753884 12.720666 12.746353 11.695153 11.970775 12.749916]\n",
      "Reset environment\n",
      "Episode reward: 1988.4384\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.754441 12.721199 12.746926 11.69577  11.971259 12.750473]\n",
      "Reset environment\n",
      "Episode reward: 4430.6787\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.75596  12.722711 12.748447 11.697416 11.972642 12.751992]\n",
      "Reset environment\n",
      "Episode reward: 2049.6228\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.756573 12.723322 12.749062 11.698107 11.973191 12.752606]\n",
      "Reset environment\n",
      "Episode reward: 1745.4728\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.757089 12.723828 12.749589 11.698684 11.973631 12.753125]\n",
      "Reset environment\n",
      "Episode reward: 1386.5396\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.757735 12.724477 12.750235 11.699404 11.974212 12.753772]\n",
      "Reset environment\n",
      "Episode reward: 1206.8055\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.7580595 12.724791  12.750572  11.699764  11.974492  12.754098 ]\n",
      "Reset environment\n",
      "Episode reward: 2171.62\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.758685 12.725398 12.751214 11.700448 11.975028 12.754725]\n",
      "Reset environment\n",
      "Episode reward: 3734.7397\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.759911 12.72662  12.75245  11.701787 11.976152 12.755951]\n",
      "Reset environment\n",
      "Episode reward: 3988.421\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.761262 12.727967 12.75379  11.703249 11.977358 12.757301]\n",
      "Reset environment\n",
      "Episode reward: 5609.952\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.763199  12.729897  12.7557335 11.7053385 11.979019  12.759236 ]\n",
      "Reset environment\n",
      "Episode reward: 84.544586\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.762573  12.729333  12.755026  11.704614  11.978455  12.7586155]\n",
      "Reset environment\n",
      "Episode reward: 2152.4932\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.763517 12.730274 12.755967 11.705632 11.979296 12.759559]\n",
      "Reset environment\n",
      "Episode reward: 2002.5017\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.764405 12.731163 12.756857 11.706594 11.98009  12.760447]\n",
      "Reset environment\n",
      "Episode reward: 1742.4474\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.76519  12.731947 12.757641 11.707457 11.980796 12.761231]\n",
      "Reset environment\n",
      "Episode reward: 5451.8643\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.767114 12.733862 12.759555 11.709529 11.982525 12.763147]\n",
      "Reset environment\n",
      "Episode reward: 1339.5985\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.76773  12.734478 12.760169 11.710221 11.983076 12.763762]\n",
      "Reset environment\n",
      "Episode reward: 3966.7075\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.769096 12.735838 12.761514 11.711689 11.984286 12.765123]\n",
      "Reset environment\n",
      "Episode reward: 3794.4045\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.7703905 12.737136  12.762797  11.713097  11.985434  12.76642  ]\n",
      "Reset environment\n",
      "Episode reward: 1979.4802\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.770881 12.7376   12.763318 11.713653 11.985856 12.766916]\n",
      "Reset environment\n",
      "Episode reward: 1794.7924\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.771432  12.738155  12.763868  11.714267  11.986353  12.7674675]\n",
      "Reset environment\n",
      "Episode reward: 2055.347\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.772336 12.739055 12.76477  11.715248 11.98716  12.768373]\n",
      "Reset environment\n",
      "Episode reward: 3354.4312\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.773442 12.74017  12.765865 11.71646  11.98813  12.769478]\n",
      "Reset environment\n",
      "Episode reward: 2058.221\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.774055 12.740798 12.766458 11.717139 11.988668 12.770091]\n",
      "Reset environment\n",
      "Episode reward: 1785.5077\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.774576  12.7413225 12.76698   11.717731  11.989136  12.770613 ]\n",
      "Reset environment\n",
      "Episode reward: 3219.92\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.775649 12.742394 12.768053 11.7189   11.990094 12.771686]\n",
      "Reset environment\n",
      "Episode reward: 2964.292\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.776626 12.743388 12.769019 11.719959 11.990994 12.772664]\n",
      "Reset environment\n",
      "Episode reward: 5609.5034\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.7785425 12.745293  12.770942  11.722044  11.992708  12.774584 ]\n",
      "Reset environment\n",
      "Episode reward: 2347.362\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.779276 12.746028 12.77168  11.72285  11.993369 12.775317]\n",
      "Reset environment\n",
      "Episode reward: 2454.938\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.780041 12.746797 12.772434 11.723696 11.994053 12.776081]\n",
      "Reset environment\n",
      "Episode reward: 1833.601\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.780597 12.74736  12.772985 11.724312 11.994552 12.776638]\n",
      "Reset environment\n",
      "Episode reward: 4185.802\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.782026 12.748785 12.774416 11.725859 11.995837 12.778065]\n",
      "Reset environment\n",
      "Episode reward: 1859.9674\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.782626 12.749388 12.775015 11.726522 11.996373 12.778663]\n",
      "Reset environment\n",
      "Episode reward: 1575.3315\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.783077 12.749857 12.775444 11.727017 11.996771 12.779115]\n",
      "Reset environment\n",
      "Episode reward: -340.7923\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.782319 12.749097 12.774689 11.726244 11.996098 12.778354]\n",
      "Reset environment\n",
      "Episode reward: 4918.8447\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.784017 12.750791 12.776376 11.728071 11.997608 12.780047]\n",
      "Reset environment\n",
      "Episode reward: 1745.0874\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.784806 12.751577 12.777163 11.728933 11.998317 12.780836]\n",
      "Reset environment\n",
      "Episode reward: 1449.2399\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.785176  12.7519245 12.777554  11.729356  11.998646  12.781213 ]\n",
      "Reset environment\n",
      "Episode reward: 2335.1816\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.785896 12.752657 12.778257 11.73015  11.999299 12.781934]\n",
      "Reset environment\n",
      "Episode reward: 2288.5325\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.786604 12.75336  12.778973 11.73093  11.999942 12.78264 ]\n",
      "Reset environment\n",
      "Episode reward: 1386.8069\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.787252 12.75401  12.779619 11.731645 12.000531 12.783287]\n",
      "Reset environment\n",
      "Episode reward: 4802.0757\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.788934 12.755685 12.781299 11.733452 12.00205  12.784967]\n",
      "Reset environment\n",
      "Episode reward: 1993.358\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.789791 12.756542 12.782148 11.734405 12.002803 12.785823]\n",
      "Reset environment\n",
      "Episode reward: 1911.6821\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.790297 12.757065 12.78263  11.734997 12.00326  12.786331]\n",
      "Reset environment\n",
      "Episode reward: 141.27231\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.7896805 12.756389  12.7820835 11.734432  12.002712  12.785724 ]\n",
      "Reset environment\n",
      "Episode reward: 1861.2302\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.790512 12.757219 12.782914 11.735347 12.003458 12.786556]\n",
      "Reset environment\n",
      "Episode reward: 2003.1981\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.79113  12.757844 12.783523 11.736032 12.004021 12.787175]\n",
      "Reset environment\n",
      "Episode reward: 2086.18\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.791752 12.758448 12.784156 11.736713 12.00457  12.787797]\n",
      "Reset environment\n",
      "Episode reward: 3522.905\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.792945 12.759645 12.78534  11.738002 12.005641 12.788991]\n",
      "Reset environment\n",
      "Episode reward: 2371.3167\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.793669 12.760347 12.786079 11.738796 12.006276 12.789716]\n",
      "Reset environment\n",
      "Episode reward: -83.1145\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.792944  12.759529  12.785437  11.738154  12.005594  12.7890005]\n",
      "Reset environment\n",
      "Episode reward: 5405.711\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.794873 12.761451 12.787355 11.74022  12.007279 12.790932]\n",
      "Reset environment\n",
      "Episode reward: 2416.9846\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.795557 12.762152 12.788006 11.740984 12.007877 12.791616]\n",
      "Reset environment\n",
      "Episode reward: 3132.985\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.796561 12.76314  12.789024 11.742073 12.008795 12.792621]\n",
      "Reset environment\n",
      "Episode reward: 4582.8774\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.798175 12.764749 12.790634 11.743809 12.010243 12.794235]\n",
      "Reset environment\n",
      "Episode reward: 3403.0793\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.799314 12.765885 12.791767 11.745066 12.011263 12.795378]\n",
      "Reset environment\n",
      "Episode reward: 2672.935\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.800127 12.766698 12.792588 11.745965 12.012003 12.796191]\n",
      "Reset environment\n",
      "Episode reward: 1382.0398\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.800768 12.767337 12.793227 11.746674 12.012578 12.796831]\n",
      "Reset environment\n",
      "Episode reward: 2842.8733\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.801636 12.768226 12.794068 11.747631 12.013349 12.797699]\n",
      "Reset environment\n",
      "Episode reward: 2714.3162\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.802514 12.769111 12.794939 11.748598 12.014138 12.798579]\n",
      "Reset environment\n",
      "Episode reward: 1827.3263\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.802979 12.769554 12.795425 11.74912  12.01454  12.799046]\n",
      "Reset environment\n",
      "Episode reward: 1508.5134\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.803442 12.770009 12.795894 11.749634 12.014934 12.799508]\n",
      "Reset environment\n",
      "Episode reward: 1674.7065\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.803943 12.770509 12.796401 11.750197 12.015378 12.800012]\n",
      "Reset environment\n",
      "Episode reward: 3133.1208\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.804974 12.771536 12.797432 11.751316 12.016309 12.801046]\n",
      "Reset environment\n",
      "Episode reward: 2517.782\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.805756 12.772328 12.798207 11.75218  12.017003 12.801827]\n",
      "Reset environment\n",
      "Episode reward: 2213.5\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.806721 12.773289 12.799171 11.753223 12.017861 12.802793]\n",
      "Reset environment\n",
      "Episode reward: 5100.8413\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.808481 12.775045 12.800915 11.755117 12.019442 12.804548]\n",
      "Reset environment\n",
      "Episode reward: 1359.9629\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.809105  12.775667  12.801539  11.7558155 12.020002  12.805172 ]\n",
      "Reset environment\n",
      "Episode reward: 3901.448\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.81041   12.776964  12.8028555 11.75723   12.021189  12.806475 ]\n",
      "Reset environment\n",
      "Episode reward: 3859.1265\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.811714 12.778261 12.804147 11.758642 12.022351 12.807776]\n",
      "Reset environment\n",
      "Episode reward: 2200.8062\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.812669  12.779219  12.8050995 11.759682  12.023203  12.808733 ]\n",
      "Reset environment\n",
      "Episode reward: 2828.1138\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.813572 12.780127 12.805988 11.760683 12.024005 12.809636]\n",
      "Reset environment\n",
      "Episode reward: 4610.6626\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.815186 12.781733 12.807595 11.762415 12.025453 12.811245]\n",
      "Reset environment\n",
      "Episode reward: 1699.8843\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.815705 12.782245 12.808123 11.762999 12.025902 12.811766]\n",
      "Reset environment\n",
      "Episode reward: 2097.5342\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.816338 12.782873 12.808764 11.7637   12.026477 12.812398]\n",
      "Reset environment\n",
      "Episode reward: 2338.6045\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.817077 12.783611 12.809504 11.764515 12.027142 12.813137]\n",
      "Reset environment\n",
      "Episode reward: 1773.3301\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.817631 12.784149 12.810073 11.765129 12.027627 12.813693]\n",
      "Reset environment\n",
      "Episode reward: 1646.3209\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.818121 12.784641 12.810563 11.765675 12.028066 12.814182]\n",
      "Reset environment\n",
      "Episode reward: 2711.1294\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.819007 12.785526 12.811446 11.766638 12.028858 12.815068]\n",
      "Reset environment\n",
      "Episode reward: 923.5991\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.818859  12.785406  12.8112545 11.766438  12.028737  12.81492  ]\n",
      "Reset environment\n",
      "Episode reward: 1653.5792\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.819358 12.785901 12.811755 11.76699  12.029187 12.815419]\n",
      "Reset environment\n",
      "Episode reward: 3925.2893\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.820666 12.78722  12.813045 11.768415 12.030354 12.816723]\n",
      "Reset environment\n",
      "Episode reward: 1940.2365\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.821244 12.787796 12.813627 11.769058 12.030878 12.817302]\n",
      "Reset environment\n",
      "Episode reward: 5373.229\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.823147 12.789691 12.81552  11.771104 12.032545 12.819195]\n",
      "Reset environment\n",
      "Episode reward: 4360.339\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.824651 12.791193 12.817016 11.772726 12.03388  12.8207  ]\n",
      "Reset environment\n",
      "Episode reward: -530.73914\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.823801 12.790349 12.816158 11.771584 12.033113 12.81985 ]\n",
      "Reset environment\n",
      "Episode reward: 1350.838\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.824215 12.79076  12.816573 11.77204  12.033469 12.820264]\n",
      "Reset environment\n",
      "Episode reward: 4415.125\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.825728 12.792273 12.818079 11.773679 12.034812 12.821775]\n",
      "Reset environment\n",
      "Episode reward: 5759.637\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.827771 12.794303 12.820117 11.775868 12.036634 12.823816]\n",
      "Reset environment\n",
      "Episode reward: 2281.9895\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.828336 12.794846 12.820711 11.776512 12.03714  12.824388]\n",
      "Reset environment\n",
      "Episode reward: 1924.0507\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.82895  12.795458 12.821329 11.777187 12.037682 12.825003]\n",
      "Reset environment\n",
      "Episode reward: 1914.1821\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.829517 12.796025 12.8219   11.777824 12.038193 12.825571]\n",
      "Reset environment\n",
      "Episode reward: 2041.6693\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.830114 12.796641 12.82248  11.778492 12.038716 12.826169]\n",
      "Reset environment\n",
      "Episode reward: 1283.8096\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8305   12.797031 12.822858 11.778919 12.039064 12.826554]\n",
      "Reset environment\n",
      "Episode reward: 2145.1448\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.831154  12.797691  12.823508  11.779641  12.039659  12.8272085]\n",
      "Reset environment\n",
      "Episode reward: 4143.0015\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.832559 12.799092 12.824918 11.781164 12.040898 12.828612]\n",
      "Reset environment\n",
      "Episode reward: 2850.1267\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.833504 12.800038 12.825857 11.782188 12.041746 12.829558]\n",
      "Reset environment\n",
      "Episode reward: 4260.8447\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.834975 12.80151  12.827323 11.78376  12.043054 12.831028]\n",
      "Reset environment\n",
      "Episode reward: 215.4\n",
      "Total Steps: 11\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.834901 12.801436 12.82725  11.783689 12.042986 12.830955]\n",
      "Reset environment\n",
      "Episode reward: 1610.2764\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.835382 12.801903 12.82774  11.784217 12.043401 12.831436]\n",
      "Reset environment\n",
      "Episode reward: 2427.584\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.836126 12.802656 12.828472 11.785032 12.044068 12.83218 ]\n",
      "Reset environment\n",
      "Episode reward: 4490.8545\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.837661 12.804196 12.830003 11.786691 12.04544  12.833717]\n",
      "Reset environment\n",
      "Episode reward: 3225.8538\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.838709 12.805259 12.831037 11.787828 12.046388 12.834769]\n",
      "Reset environment\n",
      "Episode reward: 3791.3928\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.839959 12.806504 12.832285 11.789189 12.047515 12.836018]\n",
      "Reset environment\n",
      "Episode reward: 1369.0287\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.840596 12.80714  12.832922 11.78989  12.048088 12.836654]\n",
      "Reset environment\n",
      "Episode reward: 3879.564\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.841888 12.808437 12.834194 11.791286 12.049237 12.837945]\n",
      "Reset environment\n",
      "Episode reward: 5130.1855\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.843685  12.810231  12.835987  11.793221  12.0508375 12.839739 ]\n",
      "Reset environment\n",
      "Episode reward: 2248.9329\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.844308 12.810834 12.836636 11.793908 12.051377 12.840363]\n",
      "Reset environment\n",
      "Episode reward: 4882.4043\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.846007  12.812528  12.838325  11.7957325 12.052891  12.842057 ]\n",
      "Reset environment\n",
      "Episode reward: 4212.254\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8474655 12.813998  12.839756  11.79731   12.054186  12.843514 ]\n",
      "Reset environment\n",
      "Episode reward: 1635.701\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.847957  12.814494  12.840244  11.797861  12.054626  12.8440075]\n",
      "Reset environment\n",
      "Episode reward: 3575.4119\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.849122 12.815652 12.841413 11.799135 12.055693 12.84517 ]\n",
      "Reset environment\n",
      "Episode reward: 3351.2815\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.850232 12.816755 12.84252  11.80034  12.056686 12.84628 ]\n",
      "Reset environment\n",
      "Episode reward: 3182.5835\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.851266 12.817782 12.84356  11.80146  12.057625 12.847313]\n",
      "Reset environment\n",
      "Episode reward: 1688.8171\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.851725 12.818265 12.843997 11.801976 12.058033 12.847774]\n",
      "Reset environment\n",
      "Episode reward: 2069.2422\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.852352 12.818889 12.844629 11.802668 12.058601 12.848402]\n",
      "Reset environment\n",
      "Episode reward: 2165.5332\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.853022  12.819565  12.845295  11.803407  12.059204  12.8490715]\n",
      "Reset environment\n",
      "Episode reward: 527.92224\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.852637 12.819242 12.84484  11.802928 12.058841 12.84869 ]\n",
      "Reset environment\n",
      "Episode reward: 1939.6731\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.853229 12.819844 12.845421 11.80358  12.059353 12.849281]\n",
      "Reset environment\n",
      "Episode reward: 2005.146\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.853848 12.820463 12.846044 11.804261 12.059914 12.849901]\n",
      "Reset environment\n",
      "Episode reward: 1416.0054\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.854504 12.821122 12.846697 11.804984 12.060506 12.850556]\n",
      "Reset environment\n",
      "Episode reward: 2122.7744\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.855422 12.822041 12.847613 11.805976 12.061322 12.851477]\n",
      "Reset environment\n",
      "Episode reward: 4756.957\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.857041 12.823633 12.849241 11.807732 12.062776 12.853093]\n",
      "Reset environment\n",
      "Episode reward: 2627.0466\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.857872  12.824473  12.850058  11.808637  12.0635195 12.853918 ]\n",
      "Reset environment\n",
      "Episode reward: 1533.0986\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.858163  12.8247385 12.850384  11.808989  12.063785  12.854214 ]\n",
      "Reset environment\n",
      "Episode reward: 1432.9984\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.858542 12.825102 12.850781 11.809417 12.064117 12.854596]\n",
      "Reset environment\n",
      "Episode reward: 1672.8348\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.859024 12.825607 12.851243 11.809954 12.064538 12.855077]\n",
      "Reset environment\n",
      "Episode reward: 2204.7097\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.859982 12.826566 12.852198 11.810985 12.065386 12.856033]\n",
      "Reset environment\n",
      "Episode reward: 1558.6002\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.860242 12.826855 12.852427 11.811301 12.065619 12.856295]\n",
      "Reset environment\n",
      "Episode reward: 1377.5394\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8606415 12.827254  12.852826  11.811751  12.065972  12.856694 ]\n",
      "Reset environment\n",
      "Episode reward: 3633.4285\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.861824 12.828417 12.854024 11.813034 12.067037 12.857876]\n",
      "Reset environment\n",
      "Episode reward: 1731.9768\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.862349 12.828929 12.85456  11.813618 12.067483 12.858402]\n",
      "Reset environment\n",
      "Episode reward: 2641.4888\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.863158 12.829726 12.855376 11.814501 12.068213 12.85921 ]\n",
      "Reset environment\n",
      "Episode reward: 3654.1375\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8644   12.830972 12.856607 11.815839 12.069315 12.860451]\n",
      "Reset environment\n",
      "Episode reward: 5366.036\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.866262 12.832826 12.858465 11.817842 12.070996 12.862307]\n",
      "Reset environment\n",
      "Episode reward: 4531.083\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8678055 12.834361  12.860013  11.819517  12.072365  12.863857 ]\n",
      "Reset environment\n",
      "Episode reward: 3497.1646\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.868973 12.835537 12.861161 11.820779 12.073394 12.865022]\n",
      "Reset environment\n",
      "Episode reward: 2915.9255\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.869923  12.836495  12.8621025 11.821814  12.074238  12.86597  ]\n",
      "Reset environment\n",
      "Episode reward: 3369.5063\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.871035 12.837604 12.863209 11.823015 12.075238 12.867082]\n",
      "Reset environment\n",
      "Episode reward: 1555.2783\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.871454 12.838045 12.863606 11.823488 12.075607 12.867503]\n",
      "Reset environment\n",
      "Episode reward: 1758.8278\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.871973 12.838555 12.864139 11.824063 12.076059 12.868023]\n",
      "Reset environment\n",
      "Episode reward: 1803.0006\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8725   12.839081 12.864669 11.824654 12.076533 12.86855 ]\n",
      "Reset environment\n",
      "Episode reward: 810.11865\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.872677 12.839258 12.864845 11.824871 12.076682 12.868728]\n",
      "Reset environment\n",
      "Episode reward: 2066.197\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.873582 12.840159 12.865749 11.825839 12.077483 12.869632]\n",
      "Reset environment\n",
      "Episode reward: 2458.4246\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.874346  12.840917  12.866518  11.8266735 12.078168  12.870395 ]\n",
      "Reset environment\n",
      "Episode reward: 4675.487\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.875881 12.84246  12.868051 11.828341 12.079564 12.87193 ]\n",
      "Reset environment\n",
      "Episode reward: 423.87613\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.875664 12.842239 12.86784  11.828035 12.079356 12.871717]\n",
      "Reset environment\n",
      "Episode reward: 1613.8264\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.87615  12.842729 12.868326 11.828574 12.079794 12.872204]\n",
      "Reset environment\n",
      "Episode reward: 1251.3572\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.876473  12.8430395 12.868659  11.828941  12.08007   12.872528 ]\n",
      "Reset environment\n",
      "Episode reward: 1635.1906\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.876819  12.843411  12.8689785 11.829349  12.080378  12.872874 ]\n",
      "Reset environment\n",
      "Episode reward: 2929.41\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8777685 12.844364  12.869923  11.830384  12.081225  12.873823 ]\n",
      "Reset environment\n",
      "Episode reward: 5367.835\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.879623 12.84622  12.871767 11.832391 12.082889 12.875673]\n",
      "Reset environment\n",
      "Episode reward: 3802.604\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.880916 12.847513 12.873051 11.833787 12.084064 12.876964]\n",
      "Reset environment\n",
      "Episode reward: 2061.5142\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.881811 12.848407 12.873949 11.834758 12.084866 12.87786 ]\n",
      "Reset environment\n",
      "Episode reward: 1413.5061\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8824625 12.849059  12.874601  11.835474  12.085458  12.878512 ]\n",
      "Reset environment\n",
      "Episode reward: 3394.3174\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.883598 12.850196 12.87572  11.8367   12.086453 12.879649]\n",
      "Reset environment\n",
      "Episode reward: -462.55228\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.882579 12.849015 12.874856 11.835757 12.085486 12.878643]\n",
      "Reset environment\n",
      "Episode reward: 1800.1162\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.883101 12.849523 12.87539  11.836338 12.085952 12.879165]\n",
      "Reset environment\n",
      "Episode reward: 1807.7994\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.883639  12.850062  12.875929  11.836939  12.086442  12.8797035]\n",
      "Reset environment\n",
      "Episode reward: 4937.005\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.885346 12.851763 12.877634 11.838769 12.087953 12.881412]\n",
      "Reset environment\n",
      "Episode reward: 1986.9153\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.88594  12.852355 12.878236 11.839429 12.088491 12.882005]\n",
      "Reset environment\n",
      "Episode reward: 4768.9624\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.88757   12.853979  12.8798685 11.841191  12.0899725 12.883636 ]\n",
      "Reset environment\n",
      "Episode reward: 2205.8474\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.888519  12.854924  12.880818  11.8422165 12.090817  12.884585 ]\n",
      "Reset environment\n",
      "Episode reward: 1386.729\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.889157 12.855564 12.881457 11.842921 12.091397 12.885224]\n",
      "Reset environment\n",
      "Episode reward: 3645.5906\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.890384 12.85679  12.882676 11.844241 12.092492 12.886449]\n",
      "Reset environment\n",
      "Episode reward: 2106.5151\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.89099  12.857383 12.883296 11.844918 12.093034 12.887058]\n",
      "Reset environment\n",
      "Episode reward: 4954.6104\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.892728 12.859106 12.885027 11.846769 12.094553 12.888801]\n",
      "Reset environment\n",
      "Episode reward: 1765.2242\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.8932495 12.859634  12.885544  11.847348  12.09502   12.889322 ]\n",
      "Reset environment\n",
      "Episode reward: 2780.1008\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.894138 12.86053  12.886421 11.848318 12.095821 12.890211]\n",
      "Reset environment\n",
      "Episode reward: 2882.9656\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.895077  12.861469  12.887358  11.8493395 12.096659  12.8911495]\n",
      "Reset environment\n",
      "Episode reward: 1883.8608\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.895655 12.86204  12.88794  11.849977 12.097175 12.891727]\n",
      "Reset environment\n",
      "Episode reward: 2115.0798\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.896301  12.8626795 12.888589  11.850685  12.097765  12.892373 ]\n",
      "Reset environment\n",
      "Episode reward: 4328.5513\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.897724 12.864106 12.89001  11.852233 12.099041 12.893796]\n",
      "Reset environment\n",
      "Episode reward: 2298.459\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.898446 12.864833 12.890725 11.853024 12.09969  12.894518]\n",
      "Reset environment\n",
      "Episode reward: 911.5729\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.898681  12.8650675 12.890961  11.853294  12.099892  12.8947525]\n",
      "Reset environment\n",
      "Episode reward: 2264.2617\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.899161 12.865573 12.891405 11.853855 12.100322 12.895233]\n",
      "Reset environment\n",
      "Episode reward: 2378.3296\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.899916  12.866329  12.892157  11.854683  12.100994  12.8959875]\n",
      "Reset environment\n",
      "Episode reward: 1413.4379\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.900338 12.86675  12.89258  11.855153 12.101356 12.89641 ]\n",
      "Reset environment\n",
      "Episode reward: 3542.0688\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.901468 12.867868 12.893714 11.856385 12.102379 12.897538]\n",
      "Reset environment\n",
      "Episode reward: 4382.4546\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.902923  12.869327  12.895169  11.857961  12.10368   12.8989935]\n",
      "Reset environment\n",
      "Episode reward: 3558.369\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.904084 12.870471 12.896334 11.859225 12.104734 12.900153]\n",
      "Reset environment\n",
      "Episode reward: 2305.0667\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.90507  12.871462 12.897314 11.860296 12.105604 12.90114 ]\n",
      "Reset environment\n",
      "Episode reward: 1391.5258\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.905483 12.871889 12.897725 11.860769 12.105974 12.901554]\n",
      "Reset environment\n",
      "Episode reward: 3858.683\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.906794 12.873201 12.899025 11.86219  12.107143 12.902865]\n",
      "Reset environment\n",
      "Episode reward: 1548.9292\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.907212 12.873604 12.899458 11.86266  12.107495 12.903283]\n",
      "Reset environment\n",
      "Episode reward: 1871.9612\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.907773 12.874173 12.900017 11.86328  12.107999 12.903845]\n",
      "Reset environment\n",
      "Episode reward: 4709.5464\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.909367 12.875771 12.901595 11.865001 12.109405 12.905438]\n",
      "Reset environment\n",
      "Episode reward: 3210.618\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.910415 12.876831 12.902635 11.866134 12.110348 12.906487]\n",
      "Reset environment\n",
      "Episode reward: 2343.7852\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.911137 12.877543 12.903368 11.866925 12.111002 12.907209]\n",
      "Reset environment\n",
      "Episode reward: 1920.4784\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.911975 12.878384 12.904202 11.867848 12.111754 12.908048]\n",
      "Reset environment\n",
      "Episode reward: 3157.9666\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.913008 12.879417 12.905221 11.868977 12.112664 12.909081]\n",
      "Reset environment\n",
      "Episode reward: 2206.0344\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.913716 12.880132 12.90592  11.869748 12.113309 12.909791]\n",
      "Reset environment\n",
      "Episode reward: 1555.136\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.914192 12.88061  12.906394 11.870275 12.113733 12.910267]\n",
      "Reset environment\n",
      "Episode reward: 1872.2489\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.914752 12.881169 12.906956 11.870894 12.114241 12.910827]\n",
      "Reset environment\n",
      "Episode reward: 2104.2874\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.915325 12.881724 12.907546 11.871526 12.114729 12.911403]\n",
      "Reset environment\n",
      "Episode reward: 3411.0662\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.916449 12.882849 12.908662 11.872749 12.115726 12.912526]\n",
      "Reset environment\n",
      "Episode reward: 1226.2148\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.916815  12.883215  12.909026  11.8731575 12.116034  12.912892 ]\n",
      "Reset environment\n",
      "Episode reward: 2113.9666\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.917483  12.883873  12.9096985 11.873886  12.116632  12.913562 ]\n",
      "Reset environment\n",
      "Episode reward: 1345.3689\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.91789  12.884284 12.910096 11.87434  12.116986 12.913968]\n",
      "Reset environment\n",
      "Episode reward: 1637.9272\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.918367 12.884762 12.910572 11.874873 12.117415 12.914446]\n",
      "Reset environment\n",
      "Episode reward: 2191.7734\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.919033 12.885426 12.911242 11.875609 12.118017 12.915112]\n",
      "Reset environment\n",
      "Episode reward: 1599.1346\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9195175 12.885917  12.91172   11.876147  12.118446  12.915596 ]\n",
      "Reset environment\n",
      "Episode reward: 1846.8204\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.920066 12.886473 12.912262 11.876754 12.118944 12.916145]\n",
      "Reset environment\n",
      "Episode reward: 2455.1943\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.920835  12.887237  12.9130335 11.877592  12.11963   12.916916 ]\n",
      "Reset environment\n",
      "Episode reward: 1751.5182\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.921337  12.8877325 12.91355   11.878154  12.120065  12.91742  ]\n",
      "Reset environment\n",
      "Episode reward: 2070.4607\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.921899 12.888269 12.914129 11.878764 12.12054  12.917983]\n",
      "Reset environment\n",
      "Episode reward: 2769.7544\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.922748 12.88912  12.914981 11.879694 12.121307 12.918832]\n",
      "Reset environment\n",
      "Episode reward: 2421.3152\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.92347   12.889825  12.915721  11.8804865 12.121946  12.919554 ]\n",
      "Reset environment\n",
      "Episode reward: 2193.7102\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9240265 12.890404  12.91625   11.881113  12.122452  12.920113 ]\n",
      "Reset environment\n",
      "Episode reward: 3028.2656\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9249735 12.891339  12.917216  11.882156  12.123313  12.921059 ]\n",
      "Reset environment\n",
      "Episode reward: 2042.2799\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.925853 12.89222  12.918093 11.883111 12.124098 12.92194 ]\n",
      "Reset environment\n",
      "Episode reward: 1025.1503\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.925846 12.892231 12.918053 11.883016 12.124099 12.92194 ]\n",
      "Reset environment\n",
      "Episode reward: 2340.164\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.926556 12.892929 12.918773 11.883795 12.124724 12.92265 ]\n",
      "Reset environment\n",
      "Episode reward: 1723.2863\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9272995 12.893675  12.919515  11.8846245 12.125386  12.923394 ]\n",
      "Reset environment\n",
      "Episode reward: 3420.8687\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.928445  12.8948145 12.92065   11.885858  12.126396  12.924537 ]\n",
      "Reset environment\n",
      "Episode reward: 1819.2694\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.929009 12.895388 12.921199 11.886481 12.126892 12.925101]\n",
      "Reset environment\n",
      "Episode reward: 1774.2438\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.929535 12.895916 12.921725 11.88707  12.127368 12.925628]\n",
      "Reset environment\n",
      "Episode reward: 2285.0872\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.930221  12.8965845 12.922423  11.887822  12.127951  12.926313 ]\n",
      "Reset environment\n",
      "Episode reward: 2726.4673\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.931049  12.897417  12.923253  11.8887415 12.128708  12.927143 ]\n",
      "Reset environment\n",
      "Episode reward: 1801.9875\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.931596  12.897962  12.9237995 11.889348  12.129202  12.92769  ]\n",
      "Reset environment\n",
      "Episode reward: 4315.1343\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.93306  12.899425 12.925262 11.890931 12.130509 12.929155]\n",
      "Reset environment\n",
      "Episode reward: 2236.9949\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.933632 12.899973 12.925861 11.89159  12.131028 12.929729]\n",
      "Reset environment\n",
      "Episode reward: 1832.793\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.934152 12.900481 12.926395 11.892169 12.131478 12.93025 ]\n",
      "Reset environment\n",
      "Episode reward: 3805.1328\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.935354 12.90169  12.927593 11.893484 12.132565 12.931452]\n",
      "Reset environment\n",
      "Episode reward: 2417.4194\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.936383  12.9027195 12.928616  11.894594  12.133476  12.932481 ]\n",
      "Reset environment\n",
      "Episode reward: 5318.945\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.938219 12.904549 12.930454 11.896579 12.135115 12.934318]\n",
      "Reset environment\n",
      "Episode reward: 5919.9185\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.940256 12.906588 12.93248  11.898783 12.136949 12.936356]\n",
      "Reset environment\n",
      "Episode reward: 2242.9648\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.940944 12.907288 12.93316  11.899545 12.137577 12.937045]\n",
      "Reset environment\n",
      "Episode reward: 1977.6533\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.941479 12.9078   12.933715 11.900133 12.138037 12.937585]\n",
      "Reset environment\n",
      "Episode reward: 4185.9976\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.942894 12.909216 12.935111 11.901653 12.139286 12.938997]\n",
      "Reset environment\n",
      "Episode reward: 2550.2725\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.943567 12.909912 12.935756 11.902391 12.139889 12.939673]\n",
      "Reset environment\n",
      "Episode reward: 1582.1309\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9439745 12.910339  12.936148  11.902853  12.140235  12.940082 ]\n",
      "Reset environment\n",
      "Episode reward: 1129.229\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.94429  12.910659 12.936457 11.903211 12.140517 12.940398]\n",
      "Reset environment\n",
      "Episode reward: 1409.0975\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.944932  12.9113035 12.9370985 11.903922  12.141094  12.94104  ]\n",
      "Reset environment\n",
      "Episode reward: 5446.108\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.946783 12.913149 12.938938 11.905914 12.142752 12.942887]\n",
      "Reset environment\n",
      "Episode reward: 3470.2612\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.947907 12.914263 12.940077 11.907128 12.143772 12.944013]\n",
      "Reset environment\n",
      "Episode reward: 2021.2833\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.948473 12.914812 12.94066  11.90775  12.144258 12.944581]\n",
      "Reset environment\n",
      "Episode reward: 1843.5914\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.949028 12.915352 12.94123  11.908363 12.144749 12.945137]\n",
      "Reset environment\n",
      "Episode reward: 2676.4265\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9499   12.916226 12.942101 11.909315 12.14555  12.946008]\n",
      "Reset environment\n",
      "Episode reward: 2549.4907\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.950709 12.917035 12.942909 11.910206 12.146272 12.946816]\n",
      "Reset environment\n",
      "Episode reward: 1549.21\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.951163 12.917489 12.943362 11.910712 12.146684 12.94727 ]\n",
      "Reset environment\n",
      "Episode reward: 1600.3413\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9516325 12.917962  12.94383   11.911235  12.147109  12.94774  ]\n",
      "Reset environment\n",
      "Episode reward: 3139.6824\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.952672 12.919006 12.944868 11.912363 12.148042 12.948779]\n",
      "Reset environment\n",
      "Episode reward: 2577.6797\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.953433 12.91975  12.945644 11.913203 12.14873  12.949542]\n",
      "Reset environment\n",
      "Episode reward: 1806.8124\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.95396  12.920281 12.946165 11.913797 12.1492   12.950069]\n",
      "Reset environment\n",
      "Episode reward: -389.4655\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.953107  12.9193535 12.945382  11.912922  12.14841   12.949221 ]\n",
      "Reset environment\n",
      "Episode reward: 3473.7192\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.954263 12.920513 12.946532 11.914167 12.149436 12.950383]\n",
      "Reset environment\n",
      "Episode reward: 2774.1714\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.955112 12.921365 12.947366 11.915107 12.150157 12.95124 ]\n",
      "Reset environment\n",
      "Episode reward: 4030.8203\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.956451  12.922697  12.9487095 11.91656   12.151383  12.952578 ]\n",
      "Reset environment\n",
      "Episode reward: 1272.4723\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.95677  12.923029 12.949011 11.916921 12.151652 12.952895]\n",
      "Reset environment\n",
      "Episode reward: 1587.5737\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.957249 12.923493 12.949505 11.917457 12.152071 12.95338 ]\n",
      "Reset environment\n",
      "Episode reward: 4102.7407\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.958625 12.924876 12.950877 11.918952 12.153289 12.954757]\n",
      "Reset environment\n",
      "Episode reward: 2288.6802\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.959315 12.925575 12.951556 11.919709 12.153911 12.955445]\n",
      "Reset environment\n",
      "Episode reward: 2797.3662\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.960195 12.926466 12.952423 11.920662 12.154712 12.956325]\n",
      "Reset environment\n",
      "Episode reward: 5477.4404\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.962039 12.928318 12.954269 11.922645 12.156404 12.95817 ]\n",
      "Reset environment\n",
      "Episode reward: 5781.081\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.964056 12.930337 12.956283 11.924817 12.158226 12.960186]\n",
      "Reset environment\n",
      "Episode reward: 1702.8096\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.964608  12.930892  12.956833  11.9254265 12.158711  12.960739 ]\n",
      "Reset environment\n",
      "Episode reward: 5097.915\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.966358 12.932646 12.958578 11.927312 12.160287 12.96249 ]\n",
      "Reset environment\n",
      "Episode reward: 1381.0354\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.966984 12.933271 12.959205 11.928002 12.160851 12.963115]\n",
      "Reset environment\n",
      "Episode reward: 2285.3113\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.967685 12.933984 12.959898 11.928773 12.16149  12.963816]\n",
      "Reset environment\n",
      "Episode reward: 1353.5225\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.968039 12.934316 12.960266 11.92917  12.161802 12.964171]\n",
      "Reset environment\n",
      "Episode reward: 2263.0625\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.968684 12.934947 12.960925 11.929886 12.162387 12.964817]\n",
      "Reset environment\n",
      "Episode reward: 3051.7415\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.969649 12.935925 12.961875 11.930936 12.163268 12.965782]\n",
      "Reset environment\n",
      "Episode reward: 3546.9504\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.970831 12.937112 12.963054 11.932209 12.164317 12.966964]\n",
      "Reset environment\n",
      "Episode reward: 2172.6218\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.971386 12.937642 12.963635 11.932842 12.164822 12.967525]\n",
      "Reset environment\n",
      "Episode reward: 2116.7432\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.972008 12.938262 12.964268 11.933533 12.165386 12.968147]\n",
      "Reset environment\n",
      "Episode reward: 681.50586\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.971713 12.93792  12.96401  11.933161 12.165169 12.967854]\n",
      "Reset environment\n",
      "Episode reward: 4876.0605\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.973374 12.939578 12.965662 11.934949 12.166642 12.969514]\n",
      "Reset environment\n",
      "Episode reward: 5710.1836\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.97564  12.941836 12.967916 11.937373 12.168691 12.971774]\n",
      "Reset environment\n",
      "Episode reward: 2805.049\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.976482 12.94267  12.968767 11.938305 12.169456 12.972616]\n",
      "Reset environment\n",
      "Episode reward: 4197.064\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.977894 12.944071 12.970175 11.939822 12.17071  12.974029]\n",
      "Reset environment\n",
      "Episode reward: 2518.1147\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.9786825 12.944863  12.970953  11.9406805 12.171414  12.974815 ]\n",
      "Reset environment\n",
      "Episode reward: 2691.6948\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.979489 12.945671 12.971759 11.941565 12.172138 12.975621]\n",
      "Reset environment\n",
      "Episode reward: 5334.2397\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.981273 12.947459 12.973542 11.943489 12.173734 12.977406]\n",
      "Reset environment\n",
      "Episode reward: 1894.0571\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.982088 12.948277 12.974353 11.94439  12.174465 12.978221]\n",
      "Reset environment\n",
      "Episode reward: 3688.582\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.983291 12.949474 12.975534 11.945705 12.17554  12.97942 ]\n",
      "Reset environment\n",
      "Episode reward: 1102.434\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.983594 12.949782 12.975826 11.946048 12.175805 12.979724]\n",
      "Reset environment\n",
      "Episode reward: 2547.4805\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.984221  12.950384  12.9764805 11.94676   12.176365  12.980351 ]\n",
      "Reset environment\n",
      "Episode reward: 2508.0295\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.984853 12.950985 12.977133 11.947478 12.176929 12.980983]\n",
      "Reset environment\n",
      "Episode reward: 4880.363\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.986542 12.952665 12.978812 11.949289 12.178402 12.982673]\n",
      "Reset environment\n",
      "Episode reward: 1852.3381\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.987116 12.953232 12.979386 11.949921 12.178902 12.983245]\n",
      "Reset environment\n",
      "Episode reward: 5937.0664\n",
      "Total Steps: 201\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.989152 12.955267 12.98141  11.952104 12.180736 12.985275]\n",
      "Reset environment\n",
      "Episode reward: 1391.444\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.989782  12.955899  12.9820385 11.952803  12.181299  12.985906 ]\n",
      "Reset environment\n",
      "Episode reward: 4326.814\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.991252 12.95736  12.983494 11.954388 12.182589 12.987371]\n",
      "Reset environment\n",
      "Episode reward: 5667.982\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.993244 12.959335 12.985474 11.956515 12.184321 12.989357]\n",
      "Reset environment\n",
      "Episode reward: 4476.7485\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.994765  12.960848  12.986996  11.9581585 12.185669  12.990878 ]\n",
      "Reset environment\n",
      "Episode reward: 2611.617\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.995592 12.961673 12.987819 11.959061 12.186406 12.991706]\n",
      "Reset environment\n",
      "Episode reward: 1984.4255\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.996436 12.962516 12.988661 11.959975 12.187148 12.99255 ]\n",
      "Reset environment\n",
      "Episode reward: 1678.4624\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.996872  12.9629755 12.98908   11.960482  12.187534  12.992987 ]\n",
      "Reset environment\n",
      "Episode reward: 2311.0269\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.997577  12.963676  12.989788  11.961253  12.1881695 12.993691 ]\n",
      "Reset environment\n",
      "Episode reward: 2313.946\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.99818   12.964304  12.990366  11.961938  12.1887045 12.9943   ]\n",
      "Reset environment\n",
      "Episode reward: 1709.6066\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.998687 12.964811 12.990872 11.962501 12.189167 12.994806]\n",
      "Reset environment\n",
      "Episode reward: 1357.6909\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.999295 12.965423 12.991479 11.963179 12.189711 12.995415]\n",
      "Reset environment\n",
      "Episode reward: 1646.5806\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [12.999777 12.9659   12.991963 11.963712 12.190129 12.995896]\n",
      "Reset environment\n",
      "Episode reward: 1794.1597\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.000363  12.966488  12.9925375 11.964357  12.19064   12.996483 ]\n",
      "Reset environment\n",
      "Episode reward: 3073.835\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.001341 12.967458 12.993521 11.965422 12.191519 12.997459]\n",
      "Reset environment\n",
      "Episode reward: 1472.2552\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.001759 12.967862 12.993953 11.965882 12.191876 12.997878]\n",
      "Reset environment\n",
      "Episode reward: -71.24902\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.001036 12.967205 12.993159 11.965111 12.191212 12.997162]\n",
      "Reset environment\n",
      "Episode reward: 1377.0364\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.00166   12.967832  12.993781  11.965802  12.191775  12.9977865]\n",
      "Reset environment\n",
      "Episode reward: 2569.8643\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.002418 12.968607 12.994517 11.966634 12.192427 12.998545]\n",
      "Reset environment\n",
      "Episode reward: 5048.762\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.004162 12.97034  12.996247 11.968502 12.193952 13.000288]\n",
      "Reset environment\n",
      "Episode reward: 3783.4094\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.005423 12.971583 12.997501 11.969866 12.195071 13.001546]\n",
      "Reset environment\n",
      "Episode reward: 2011.8323\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0062065 12.972366  12.998282  11.970727  12.195775  13.002331 ]\n",
      "Reset environment\n",
      "Episode reward: 1687.4692\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0067005 12.9728775 12.998767  11.971274  12.196199  13.002825 ]\n",
      "Reset environment\n",
      "Episode reward: 4836.72\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0083475 12.974524  13.000414  11.973043  12.197651  13.004477 ]\n",
      "Reset environment\n",
      "Episode reward: 1866.2764\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0088825 12.975067  13.0009365 11.973631  12.198128  13.005012 ]\n",
      "Reset environment\n",
      "Episode reward: 1632.881\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.009394 12.97558  13.001445 11.974196 12.198574 13.005523]\n",
      "Reset environment\n",
      "Episode reward: 1750.0337\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.009903 12.976092 13.001953 11.974763 12.199037 13.006032]\n",
      "Reset environment\n",
      "Episode reward: 3232.2021\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.010962 12.97716  13.003003 11.975916 12.199973 13.007092]\n",
      "Reset environment\n",
      "Episode reward: 2213.941\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.011907  12.978107  13.0039425 11.976942  12.200811  13.008039 ]\n",
      "Reset environment\n",
      "Episode reward: 2148.3906\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.012547 12.978757 13.004573 11.977649 12.201393 13.008679]\n",
      "Reset environment\n",
      "Episode reward: 1920.0372\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.013076 12.979261 13.005119 11.978241 12.201847 13.009211]\n",
      "Reset environment\n",
      "Episode reward: 6139.72\n",
      "Total Steps: 206\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.015216 12.981396 13.007246 11.980532 12.203765 13.011345]\n",
      "Reset environment\n",
      "Episode reward: -514.5841\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.014402  12.980614  13.006404  11.979528  12.2030325 13.010536 ]\n",
      "Reset environment\n",
      "Episode reward: 4505.8896\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.015925 12.982134 13.007914 11.981164 12.204385 13.012059]\n",
      "Reset environment\n",
      "Episode reward: 4744.542\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.01748   12.983692  13.00947   11.982844  12.2057705 13.013615 ]\n",
      "Reset environment\n",
      "Episode reward: 2962.8118\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.018397 12.984591 13.010401 11.983832 12.206577 13.014531]\n",
      "Reset environment\n",
      "Episode reward: 2342.3384\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.019014 12.985179 13.011041 11.984508 12.207114 13.015152]\n",
      "Reset environment\n",
      "Episode reward: 4340.3545\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.020466 12.986628 13.012478 11.986076 12.208403 13.016597]\n",
      "Reset environment\n",
      "Episode reward: 1750.5387\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.020988 12.987164 13.012998 11.986655 12.208881 13.017121]\n",
      "Reset environment\n",
      "Episode reward: 537.87866\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0208025 12.986986  13.0128    11.986344  12.208758  13.016942 ]\n",
      "Reset environment\n",
      "Episode reward: 2758.776\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.021629  12.987798  13.0136385 11.9872465 12.20949   13.017769 ]\n",
      "Reset environment\n",
      "Episode reward: 1796.8953\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.022003 12.988206 13.013983 11.987689 12.209833 13.018144]\n",
      "Reset environment\n",
      "Episode reward: 3718.967\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.023222  12.989412  13.0152025 11.989012  12.210917  13.019364 ]\n",
      "Reset environment\n",
      "Episode reward: 2100.6357\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.023844 12.99002  13.015832 11.9897   12.211478 13.019985]\n",
      "Reset environment\n",
      "Episode reward: 2226.103\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.024539  12.990732  13.0164995 11.990461  12.212074  13.020682 ]\n",
      "Reset environment\n",
      "Episode reward: 3251.1375\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.025504 12.991719 13.017435 11.991527 12.212948 13.021647]\n",
      "Reset environment\n",
      "Episode reward: 5534.5176\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.027413 12.993616 13.019335 11.993585 12.214617 13.023551]\n",
      "Reset environment\n",
      "Episode reward: 1971.0818\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.027989 12.994204 13.019908 11.994219 12.215142 13.024128]\n",
      "Reset environment\n",
      "Episode reward: 1511.7548\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.028375 12.994566 13.020315 11.994663 12.215487 13.024518]\n",
      "Reset environment\n",
      "Episode reward: 1987.4249\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.028964  12.995154  13.0209055 11.995315  12.21602   13.025108 ]\n",
      "Reset environment\n",
      "Episode reward: 3122.999\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.029965  12.9961605 13.021892  11.996411  12.216912  13.026106 ]\n",
      "Reset environment\n",
      "Episode reward: 1679.2483\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.030338 12.996511 13.022281 11.99685  12.217244 13.02648 ]\n",
      "Reset environment\n",
      "Episode reward: 5256.385\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.032077 12.998247 13.02402  11.998723 12.218815 13.028218]\n",
      "Reset environment\n",
      "Episode reward: 4396.068\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0335455 12.999707  13.025493  12.000305  12.220127  13.029685 ]\n",
      "Reset environment\n",
      "Episode reward: 547.03076\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.033205 12.999407 13.025108 11.999867 12.219848 13.029354]\n",
      "Reset environment\n",
      "Episode reward: 3797.7666\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.034469 13.000675 13.026363 12.001234 12.220959 13.030621]\n",
      "Reset environment\n",
      "Episode reward: 4872.8154\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.036135 13.002335 13.02802  12.003027 12.222426 13.032286]\n",
      "Reset environment\n",
      "Episode reward: 1931.788\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.036704 13.002896 13.028596 12.003657 12.222939 13.032857]\n",
      "Reset environment\n",
      "Episode reward: 5243.918\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.038476 13.004665 13.030362 12.005583 12.224505 13.034627]\n",
      "Reset environment\n",
      "Episode reward: 2556.1826\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.039278 13.005455 13.031173 12.006453 12.225226 13.03543 ]\n",
      "Reset environment\n",
      "Episode reward: 4484.8535\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.040781 13.006961 13.032664 12.008085 12.226554 13.03693 ]\n",
      "Reset environment\n",
      "Episode reward: 2345.96\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.04148  13.007652 13.03338  12.008858 12.227194 13.037632]\n",
      "Reset environment\n",
      "Episode reward: 2346.4453\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.04219  13.00835  13.034104 12.009636 12.227817 13.038344]\n",
      "Reset environment\n",
      "Episode reward: 1832.1863\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.042989  13.009151  13.034903  12.010491  12.228528  13.0391445]\n",
      "Reset environment\n",
      "Episode reward: 5040.8105\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.044722 13.010874 13.036632 12.012352 12.230045 13.040877]\n",
      "Reset environment\n",
      "Episode reward: 2421.3438\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.045731 13.011881 13.03764  12.013445 12.230945 13.041887]\n",
      "Reset environment\n",
      "Episode reward: 1465.9928\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.046164 13.012324 13.038063 12.01393  12.231321 13.042321]\n",
      "Reset environment\n",
      "Episode reward: 1676.2263\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.046622 13.012798 13.038511 12.014449 12.231717 13.04278 ]\n",
      "Reset environment\n",
      "Episode reward: 3762.9524\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.047853 13.014033 13.039738 12.015779 12.232805 13.044008]\n",
      "Reset environment\n",
      "Episode reward: 1070.4518\n",
      "Total Steps: 33\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.04815   13.014332  13.0400305 12.016112  12.233057  13.044305 ]\n",
      "Reset environment\n",
      "Episode reward: 4956.6274\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.049774 13.015965 13.041655 12.017874 12.234536 13.04593 ]\n",
      "Reset environment\n",
      "Episode reward: 1361.0464\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0503845 13.016578  13.042266  12.018549  12.235089  13.046541 ]\n",
      "Reset environment\n",
      "Episode reward: 2199.303\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.051318 13.017513 13.043197 12.019562 12.235914 13.047474]\n",
      "Reset environment\n",
      "Episode reward: 1713.8389\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.051705 13.017875 13.043607 12.020006 12.236265 13.047863]\n",
      "Reset environment\n",
      "Episode reward: 3897.771\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.052995 13.019177 13.044885 12.021399 12.237437 13.049153]\n",
      "Reset environment\n",
      "Episode reward: 4315.0635\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.054444 13.020621 13.046321 12.022954 12.238718 13.050599]\n",
      "Reset environment\n",
      "Episode reward: 1389.0651\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.055065 13.021242 13.04694  12.023639 12.239278 13.05122 ]\n",
      "Reset environment\n",
      "Episode reward: 2762.9016\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.055921 13.022087 13.047809 12.024568 12.24005  13.052076]\n",
      "Reset environment\n",
      "Episode reward: 2775.4045\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.056808  13.022977  13.048696  12.0255375 12.24086   13.052965 ]\n",
      "Reset environment\n",
      "Episode reward: 3358.99\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.057916 13.024084 13.049795 12.026728 12.241844 13.054072]\n",
      "Reset environment\n",
      "Episode reward: 1579.2853\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.058385  13.024549  13.05027   12.0272455 12.242265  13.054542 ]\n",
      "Reset environment\n",
      "Episode reward: 2154.942\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.058972 13.02516  13.050832 12.0279   12.242776 13.055135]\n",
      "Reset environment\n",
      "Episode reward: 2197.205\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.059514  13.025677  13.051396  12.028527  12.2432575 13.055682 ]\n",
      "Reset environment\n",
      "Episode reward: 2040.7709\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.060378 13.02654  13.05226  12.029467 12.244026 13.056546]\n",
      "Reset environment\n",
      "Episode reward: 2018.3466\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.060924 13.027109 13.052787 12.030082 12.244509 13.057094]\n",
      "Reset environment\n",
      "Episode reward: 2315.0945\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0616255 13.027807  13.053487  12.030856  12.245137  13.057797 ]\n",
      "Reset environment\n",
      "Episode reward: 2208.0327\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.06228   13.028452  13.0541525 12.031574  12.2457285 13.058453 ]\n",
      "Reset environment\n",
      "Episode reward: 5074.936\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.063936 13.030113 13.055806 12.033375 12.247197 13.06011 ]\n",
      "Reset environment\n",
      "Episode reward: 2172.8406\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0648575 13.031036  13.056726  12.034381  12.24801   13.061032 ]\n",
      "Reset environment\n",
      "Episode reward: 2040.5913\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.065471 13.031647 13.05734  12.035056 12.248568 13.061645]\n",
      "Reset environment\n",
      "Episode reward: 1342.4673\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.066065 13.032243 13.057934 12.035718 12.2491   13.062239]\n",
      "Reset environment\n",
      "Episode reward: 1862.9796\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.066579 13.032747 13.058456 12.036291 12.249554 13.062753]\n",
      "Reset environment\n",
      "Episode reward: 4785.099\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.068168  13.034322  13.060049  12.038003  12.2509985 13.06434  ]\n",
      "Reset environment\n",
      "Episode reward: 1407.8429\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.068795 13.034951 13.060677 12.0387   12.251568 13.064968]\n",
      "Reset environment\n",
      "Episode reward: 1469.1182\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.069214 13.035369 13.061102 12.039176 12.251945 13.065388]\n",
      "Reset environment\n",
      "Episode reward: 1393.9045\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.069837 13.035993 13.061727 12.039864 12.252507 13.06601 ]\n",
      "Reset environment\n",
      "Episode reward: 2775.8787\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.070654 13.03679  13.062562 12.040753 12.253203 13.066827]\n",
      "Reset environment\n",
      "Episode reward: 1335.5479\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.071036  13.037182  13.062937  12.0411825 12.253547  13.067211 ]\n",
      "Reset environment\n",
      "Episode reward: 2664.4707\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.071833  13.037978  13.063733  12.042055  12.254273  13.0680065]\n",
      "Reset environment\n",
      "Episode reward: 2473.7378\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.072553  13.038708  13.06444   12.0428505 12.254913  13.0687275]\n",
      "Reset environment\n",
      "Episode reward: 1666.1265\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.073043 13.0392   13.06493  12.043398 12.255361 13.069218]\n",
      "Reset environment\n",
      "Episode reward: 1172.9014\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.073367 13.03952  13.065254 12.043765 12.255643 13.069541]\n",
      "Reset environment\n",
      "Episode reward: 2098.5417\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.07426  13.040425 13.066134 12.044744 12.256437 13.070434]\n",
      "Reset environment\n",
      "Episode reward: 2035.1881\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.074807 13.040992 13.066664 12.045363 12.256915 13.070989]\n",
      "Reset environment\n",
      "Episode reward: 2108.7786\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.075443 13.041617 13.067311 12.046062 12.257455 13.071625]\n",
      "Reset environment\n",
      "Episode reward: 2146.6758\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.076043 13.042195 13.067925 12.046725 12.25797  13.072227]\n",
      "Reset environment\n",
      "Episode reward: 2171.2046\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0766945 13.042839  13.068584  12.047444  12.258564  13.072879 ]\n",
      "Reset environment\n",
      "Episode reward: 2017.221\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.077109 13.043279 13.068971 12.047929 12.258941 13.073292]\n",
      "Reset environment\n",
      "Episode reward: 5636.178\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.079056 13.04522  13.070917 12.050015 12.260619 13.07524 ]\n",
      "Reset environment\n",
      "Episode reward: 2440.6726\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.079776 13.045926 13.071653 12.050808 12.261253 13.075962]\n",
      "Reset environment\n",
      "Episode reward: 2386.742\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.080455 13.046587 13.072351 12.051547 12.26184  13.076645]\n",
      "Reset environment\n",
      "Episode reward: 4752.9946\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.082052 13.048179 13.073934 12.053275 12.263244 13.078239]\n",
      "Reset environment\n",
      "Episode reward: 5049.885\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0837555 13.049886  13.0756235 12.055114  12.264774  13.0799465]\n",
      "Reset environment\n",
      "Episode reward: 2793.4812\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.084635  13.0507555 13.076504  12.056066  12.265562  13.080825 ]\n",
      "Reset environment\n",
      "Episode reward: 1389.0974\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.084994 13.051129 13.076841 12.056465 12.265877 13.081182]\n",
      "Reset environment\n",
      "Episode reward: 1650.0742\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.085402 13.051517 13.077278 12.056934 12.266239 13.081595]\n",
      "Reset environment\n",
      "Episode reward: 4971.6675\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.087098 13.053209 13.078959 12.058751 12.267769 13.083286]\n",
      "Reset environment\n",
      "Episode reward: 31.616913\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.086418 13.052457 13.078344 12.058017 12.267143 13.082603]\n",
      "Reset environment\n",
      "Episode reward: 3241.6235\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.0874815 13.053527  13.079399  12.059166  12.268091  13.083666 ]\n",
      "Reset environment\n",
      "Episode reward: 4991.7974\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.08919  13.055215 13.081109 12.060994 12.269574 13.085371]\n",
      "Reset environment\n",
      "Episode reward: 1666.1746\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.089663 13.05569  13.081583 12.061526 12.270003 13.085845]\n",
      "Reset environment\n",
      "Episode reward: 4138.2036\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.091033 13.057058 13.082934 12.063014 12.271203 13.087216]\n",
      "Reset environment\n",
      "Episode reward: 1398.3624\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.091443 13.057469 13.083344 12.063471 12.271568 13.087626]\n",
      "Reset environment\n",
      "Episode reward: 2766.73\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.092307  13.058324  13.084204  12.064406  12.272335  13.0884905]\n",
      "Reset environment\n",
      "Episode reward: 1878.9714\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.092864 13.058887 13.084759 12.065021 12.272842 13.089047]\n",
      "Reset environment\n",
      "Episode reward: 93.40604\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.092394 13.058399 13.084308 12.0644   12.272425 13.088582]\n",
      "Reset environment\n",
      "Episode reward: 2502.8237\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.093159 13.059153 13.085084 12.065239 12.273128 13.089347]\n",
      "Reset environment\n",
      "Episode reward: 1726.898\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.093665 13.05966  13.085587 12.065799 12.273586 13.089851]\n",
      "Reset environment\n",
      "Episode reward: 351.60547\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.093199 13.059302 13.085021 12.065425 12.273139 13.089393]\n",
      "Reset environment\n",
      "Episode reward: 600.62646\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.092936 13.059012 13.084782 12.065066 12.272925 13.089133]\n",
      "Reset environment\n",
      "Episode reward: 3715.7847\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.094133 13.060214 13.085967 12.066377 12.273989 13.090331]\n",
      "Reset environment\n",
      "Episode reward: 3985.7322\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.095444 13.061512 13.087284 12.067786 12.275182 13.09164 ]\n",
      "Reset environment\n",
      "Episode reward: 1457.9646\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.095852 13.061929 13.087675 12.06823  12.275541 13.092047]\n",
      "Reset environment\n",
      "Episode reward: 4722.4917\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.097432 13.063502 13.089248 12.069929 12.27694  13.093624]\n",
      "Reset environment\n",
      "Episode reward: 3805.1646\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.098656 13.064716 13.090469 12.071252 12.278035 13.094846]\n",
      "Reset environment\n",
      "Episode reward: 2078.2312\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.099202 13.065244 13.091038 12.071864 12.278515 13.095394]\n",
      "Reset environment\n",
      "Episode reward: 2786.5425\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.100093 13.066133 13.091925 12.072832 12.279306 13.096285]\n",
      "Reset environment\n",
      "Episode reward: 5709.004\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.102072 13.068092 13.093897 12.074947 12.281041 13.098263]\n",
      "Reset environment\n",
      "Episode reward: 3186.4001\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.103086  13.069109  13.094895  12.07605   12.2819395 13.099276 ]\n",
      "Reset environment\n",
      "Episode reward: 1848.2673\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.103619 13.06965  13.095412 12.076637 12.282403 13.099807]\n",
      "Reset environment\n",
      "Episode reward: 2296.3716\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.104581 13.070611 13.09637  12.077684 12.283253 13.10077 ]\n",
      "Reset environment\n",
      "Episode reward: 3513.1611\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.105707 13.071742 13.097483 12.078917 12.284249 13.101899]\n",
      "Reset environment\n",
      "Episode reward: 1788.046\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.1061945 13.072229  13.097971  12.079469  12.284687  13.102386 ]\n",
      "Reset environment\n",
      "Episode reward: 5627.0093\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.108103 13.074139 13.099865 12.081539 12.286396 13.104296]\n",
      "Reset environment\n",
      "Episode reward: 3316.0798\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.109175 13.075209 13.10092  12.082712 12.287327 13.105363]\n",
      "Reset environment\n",
      "Episode reward: 1437.6294\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.109573 13.075623 13.10131  12.08316  12.287672 13.105761]\n",
      "Reset environment\n",
      "Episode reward: 1976.8248\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.110392 13.076439 13.102122 12.084071 12.288386 13.106578]\n",
      "Reset environment\n",
      "Episode reward: 2645.2314\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.111219 13.077273 13.102947 12.084974 12.289124 13.107407]\n",
      "Reset environment\n",
      "Episode reward: 2427.2234\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.111911 13.077984 13.103624 12.085739 12.289754 13.108099]\n",
      "Reset environment\n",
      "Episode reward: 3432.1357\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.113008 13.079071 13.104717 12.086922 12.290734 13.109191]\n",
      "Reset environment\n",
      "Episode reward: 3332.0542\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.1140785 13.08015   13.105784  12.088083  12.291695  13.110262 ]\n",
      "Reset environment\n",
      "Episode reward: 1370.0532\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.114452 13.080537 13.106142 12.088495 12.292027 13.110635]\n",
      "Reset environment\n",
      "Episode reward: 1533.4945\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.114896 13.080983 13.106585 12.088988 12.292425 13.111078]\n",
      "Reset environment\n",
      "Episode reward: 2372.0955\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.11561  13.081703 13.107291 12.089771 12.293067 13.111793]\n",
      "Reset environment\n",
      "Episode reward: 4836.8867\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.117225  13.0833025 13.108905  12.0915165 12.294496  13.113405 ]\n",
      "Reset environment\n",
      "Episode reward: 1918.1019\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.118046 13.084124 13.109723 12.092402 12.295224 13.114226]\n",
      "Reset environment\n",
      "Episode reward: 2510.0747\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.118738  13.084795  13.11044   12.093159  12.2958145 13.114922 ]\n",
      "Reset environment\n",
      "Episode reward: 1971.0602\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.119354 13.085423 13.111053 12.093839 12.296378 13.115539]\n",
      "Reset environment\n",
      "Episode reward: 2012.6472\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.119855 13.085903 13.111579 12.094402 12.296813 13.116044]\n",
      "Reset environment\n",
      "Episode reward: 5313.6743\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.121688 13.087734 13.113409 12.096365 12.298404 13.117878]\n",
      "Reset environment\n",
      "Episode reward: 1566.6301\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.122138  13.088169  13.113872  12.0968685 12.298793  13.11833  ]\n",
      "Reset environment\n",
      "Episode reward: 3245.3408\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.123141  13.0891695 13.114879  12.097964  12.299695  13.119333 ]\n",
      "Reset environment\n",
      "Episode reward: 1572.0608\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.123562 13.089566 13.115319 12.098431 12.300064 13.119756]\n",
      "Reset environment\n",
      "Episode reward: 3597.493\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.124722 13.09073  13.116477 12.09969  12.301085 13.120916]\n",
      "Reset environment\n",
      "Episode reward: 2252.795\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.125344 13.091369 13.11709  12.100387 12.301654 13.12154 ]\n",
      "Reset environment\n",
      "Episode reward: 1927.7069\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.12589  13.091905 13.117645 12.100991 12.302146 13.122086]\n",
      "Reset environment\n",
      "Episode reward: 3703.4504\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.1270895 13.093108  13.11883   12.102294  12.30321   13.123284 ]\n",
      "Reset environment\n",
      "Episode reward: 1645.4297\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.127557 13.093577 13.119297 12.102814 12.303633 13.123753]\n",
      "Reset environment\n",
      "Episode reward: 2572.8918\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.128292 13.094329 13.120004 12.10363  12.304264 13.124491]\n",
      "Reset environment\n",
      "Episode reward: 2834.981\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.129152  13.095175  13.120875  12.1045685 12.305052  13.125352 ]\n",
      "Reset environment\n",
      "Episode reward: 4159.97\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.130528 13.09654  13.122242 12.106049 12.306256 13.126734]\n",
      "Reset environment\n",
      "Episode reward: 1808.0826\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.131302  13.097315  13.1230135 12.106898  12.306945  13.127507 ]\n",
      "Reset environment\n",
      "Episode reward: 2469.4377\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.132053 13.098076 13.123764 12.107723 12.307622 13.12826 ]\n",
      "Reset environment\n",
      "Episode reward: 1415.743\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.132426 13.098431 13.124152 12.108144 12.307952 13.128634]\n",
      "Reset environment\n",
      "Episode reward: 2274.919\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.133077 13.099085 13.124798 12.108855 12.30854  13.129285]\n",
      "Reset environment\n",
      "Episode reward: 1416.1248\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.133507 13.099516 13.125227 12.109331 12.308929 13.129714]\n",
      "Reset environment\n",
      "Episode reward: 3594.024\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.134636 13.100648 13.126356 12.110555 12.309958 13.130844]\n",
      "Reset environment\n",
      "Episode reward: 1897.5435\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.135193 13.101205 13.126915 12.11117  12.310465 13.131401]\n",
      "Reset environment\n",
      "Episode reward: 4352.117\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.1366205 13.102625  13.128346  12.112711  12.311771  13.132829 ]\n",
      "Reset environment\n",
      "Episode reward: 5529.247\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.138505 13.104497 13.130216 12.11472  12.313451 13.134706]\n",
      "Reset environment\n",
      "Episode reward: 2245.1155\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.139187 13.10518  13.130896 12.115477 12.314071 13.135387]\n",
      "Reset environment\n",
      "Episode reward: 1371.4841\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.1397915 13.105783  13.131497  12.116151  12.314612  13.135992 ]\n",
      "Reset environment\n",
      "Episode reward: 2723.2698\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.140576 13.106564 13.132294 12.117019 12.315319 13.136777]\n",
      "Reset environment\n",
      "Episode reward: 2444.5251\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.141598 13.107585 13.133311 12.118125 12.316214 13.137796]\n",
      "Reset environment\n",
      "Episode reward: 1841.047\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.142088 13.108093 13.133769 12.118677 12.316634 13.138288]\n",
      "Reset environment\n",
      "Episode reward: 1544.9338\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.142464 13.108446 13.134171 12.119106 12.316969 13.138667]\n",
      "Reset environment\n",
      "Episode reward: 3301.4944\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.143524  13.109504  13.135229  12.120258  12.317913  13.1397295]\n",
      "Reset environment\n",
      "Episode reward: 2510.5647\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.144271 13.11024  13.135989 12.121081 12.318594 13.140476]\n",
      "Reset environment\n",
      "Episode reward: 5499.689\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.146153 13.11212  13.137864 12.1231   12.320255 13.142363]\n",
      "Reset environment\n",
      "Episode reward: 2641.5474\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.146825 13.112766 13.138561 12.123863 12.320868 13.143038]\n",
      "Reset environment\n",
      "Episode reward: 1907.4012\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.147389  13.113331  13.139128  12.124489  12.3213825 13.143602 ]\n",
      "Reset environment\n",
      "Episode reward: 2252.559\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.14805  13.113999 13.139788 12.125229 12.321978 13.144264]\n",
      "Reset environment\n",
      "Episode reward: 1447.5112\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.14829  13.114205 13.140048 12.125523 12.322195 13.144504]\n",
      "Reset environment\n",
      "Episode reward: 1850.8972\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.148824 13.114757 13.14057  12.12612  12.322662 13.145036]\n",
      "Reset environment\n",
      "Episode reward: 265.23703\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.148429 13.114403 13.140133 12.12559  12.32232  13.144642]\n",
      "Reset environment\n",
      "Episode reward: 3738.329\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.149648 13.115621 13.141338 12.126902 12.323376 13.14586 ]\n",
      "Reset environment\n",
      "Episode reward: 1287.2524\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.149991 13.115974 13.14167  12.127287 12.323681 13.146203]\n",
      "Reset environment\n",
      "Episode reward: 1737.5271\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.15049   13.116465  13.142176  12.127842  12.3241205 13.146703 ]\n",
      "Reset environment\n",
      "Episode reward: 4208.2383\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.15188  13.11785  13.143556 12.129333 12.325348 13.148094]\n",
      "Reset environment\n",
      "Episode reward: 1792.1409\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.152407 13.118379 13.144085 12.129919 12.325824 13.148622]\n",
      "Reset environment\n",
      "Episode reward: 1747.6167\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.152892 13.118885 13.144547 12.130457 12.326245 13.149106]\n",
      "Reset environment\n",
      "Episode reward: 2134.3545\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.153778  13.119775  13.1454315 12.131427  12.327032  13.149992 ]\n",
      "Reset environment\n",
      "Episode reward: 3474.2358\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.154865 13.120853 13.146524 12.132604 12.328013 13.151079]\n",
      "Reset environment\n",
      "Episode reward: 3397.9036\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.155963 13.121954 13.147612 12.133793 12.328984 13.152176]\n",
      "Reset environment\n",
      "Episode reward: 2007.875\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.156544 13.122527 13.148194 12.134434 12.32951  13.152757]\n",
      "Reset environment\n",
      "Episode reward: 1514.546\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.1570015 13.12299   13.148645  12.134941  12.329907  13.153214 ]\n",
      "Reset environment\n",
      "Episode reward: 3621.7825\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.158172  13.124159  13.149811  12.13621   12.330949  13.1543865]\n",
      "Reset environment\n",
      "Episode reward: 2715.496\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.159003 13.124987 13.150645 12.137122 12.331687 13.155221]\n",
      "Reset environment\n",
      "Episode reward: 3323.8882\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.160028 13.12601  13.151665 12.138244 12.332598 13.156248]\n",
      "Reset environment\n",
      "Episode reward: 2171.809\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.160932 13.126915 13.152566 12.13923  12.333391 13.157151]\n",
      "Reset environment\n",
      "Episode reward: 1708.7789\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.161413 13.127409 13.153043 12.139766 12.333828 13.157631]\n",
      "Reset environment\n",
      "Episode reward: 2824.7378\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.162249 13.128231 13.153884 12.140675 12.334576 13.158464]\n",
      "Reset environment\n",
      "Episode reward: 2148.248\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.163148 13.129129 13.154783 12.141652 12.335375 13.159364]\n",
      "Reset environment\n",
      "Episode reward: 1386.5471\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.163759 13.129742 13.155395 12.142325 12.335928 13.159974]\n",
      "Reset environment\n",
      "Episode reward: 1454.237\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.164114 13.130076 13.155769 12.142723 12.336242 13.160332]\n",
      "Reset environment\n",
      "Episode reward: 2061.442\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.164699 13.130686 13.156338 12.143369 12.336752 13.160918]\n",
      "Reset environment\n",
      "Episode reward: 2895.4922\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.165602  13.131586  13.157244  12.1443615 12.337562  13.161827 ]\n",
      "Reset environment\n",
      "Episode reward: 5503.7915\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.167449 13.133422 13.15907  12.146349 12.339187 13.163674]\n",
      "Reset environment\n",
      "Episode reward: 3306.2456\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.168501 13.134465 13.160121 12.147485 12.340126 13.164723]\n",
      "Reset environment\n",
      "Episode reward: 1837.8248\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.169045  13.135011  13.1606655 12.148085  12.340624  13.165268 ]\n",
      "Reset environment\n",
      "Episode reward: 4274.1455\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.170466 13.136424 13.162078 12.149619 12.341869 13.166692]\n",
      "Reset environment\n",
      "Episode reward: 2012.6182\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.171315  13.137279  13.162927  12.150544  12.342624  13.1675415]\n",
      "Reset environment\n",
      "Episode reward: 1646.9115\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.17178  13.137743 13.163395 12.151066 12.343046 13.168007]\n",
      "Reset environment\n",
      "Episode reward: 2127.4116\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.172352 13.138326 13.163956 12.151709 12.343534 13.168586]\n",
      "Reset environment\n",
      "Episode reward: 2133.8528\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.173239 13.139214 13.164843 12.152673 12.344321 13.169474]\n",
      "Reset environment\n",
      "Episode reward: 5427.5625\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.175019 13.141    13.166626 12.154585 12.345945 13.171255]\n",
      "Reset environment\n",
      "Episode reward: 2007.6909\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.175866 13.141849 13.167471 12.155503 12.3467   13.172105]\n",
      "Reset environment\n",
      "Episode reward: 3589.2256\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.177001 13.142974 13.168602 12.156731 12.347721 13.173239]\n",
      "Reset environment\n",
      "Episode reward: 2086.0938\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.177879  13.1438465 13.169478  12.15768   12.348499  13.174114 ]\n",
      "Reset environment\n",
      "Episode reward: 3716.587\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.179087  13.145044  13.1706705 12.158982  12.349566  13.175318 ]\n",
      "Reset environment\n",
      "Episode reward: -156.26459\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.178464 13.144399 13.170082 12.158244 12.349016 13.1747  ]\n",
      "Reset environment\n",
      "Episode reward: 2210.7195\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.179383  13.145321  13.170997  12.1592455 12.349833  13.175616 ]\n",
      "Reset environment\n",
      "Episode reward: 2098.117\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.18027  13.146205 13.171878 12.160212 12.350614 13.176502]\n",
      "Reset environment\n",
      "Episode reward: 1493.1255\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.180706  13.1466465 13.172312  12.160693  12.351011  13.176938 ]\n",
      "Reset environment\n",
      "Episode reward: 2725.2827\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.181406 13.147314 13.173044 12.16149  12.351629 13.17764 ]\n",
      "Reset environment\n",
      "Episode reward: 2035.6871\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.181981 13.147895 13.173609 12.162123 12.352152 13.178216]\n",
      "Reset environment\n",
      "Episode reward: 3645.2207\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.183156 13.149075 13.17478  12.163399 12.353205 13.179391]\n",
      "Reset environment\n",
      "Episode reward: 2503.5288\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.183807 13.149708 13.175453 12.164135 12.353783 13.180047]\n",
      "Reset environment\n",
      "Episode reward: 1955.2949\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.184383 13.150282 13.176032 12.16477  12.354307 13.180623]\n",
      "Reset environment\n",
      "Episode reward: 2341.8337\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.185272 13.151174 13.176916 12.165735 12.355097 13.181514]\n",
      "Reset environment\n",
      "Episode reward: 5397.5264\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.187101 13.152994 13.178745 12.16771  12.356714 13.183342]\n",
      "Reset environment\n",
      "Episode reward: 4828.7466\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.188737  13.154631  13.180377  12.169462  12.35816   13.1849785]\n",
      "Reset environment\n",
      "Episode reward: 637.9424\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.188377 13.154323 13.179943 12.169008 12.357831 13.184618]\n",
      "Reset environment\n",
      "Episode reward: 3881.9502\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.189594 13.155543 13.181162 12.170329 12.358943 13.185836]\n",
      "Reset environment\n",
      "Episode reward: 1515.3713\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.190044 13.155989 13.181621 12.170824 12.35934  13.186286]\n",
      "Reset environment\n",
      "Episode reward: 4262.565\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.191427 13.157362 13.183005 12.172324 12.360599 13.187668]\n",
      "Reset environment\n",
      "Episode reward: 2489.381\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.192197 13.15813  13.183775 12.173164 12.361293 13.188437]\n",
      "Reset environment\n",
      "Episode reward: 797.3301\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.191921 13.157907 13.183446 12.172795 12.361061 13.188172]\n",
      "Reset environment\n",
      "Episode reward: 1967.8602\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.19249  13.158472 13.184022 12.173421 12.361579 13.188742]\n",
      "Reset environment\n",
      "Episode reward: -28.4346\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.191701 13.157777 13.183133 12.172603 12.360871 13.187966]\n",
      "Reset environment\n",
      "Episode reward: -73.24742\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.190507  13.1567335 13.181807  12.171434  12.3597555 13.186793 ]\n",
      "Reset environment\n",
      "Episode reward: 3843.9783\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.191744  13.157986  13.1830225 12.172773  12.360878  13.18803  ]\n",
      "Reset environment\n",
      "Episode reward: 4618.8145\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.193274 13.159511 13.18454  12.174423 12.362229 13.189559]\n",
      "Reset environment\n",
      "Episode reward: 1125.1306\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.193571  13.159805  13.184838  12.1747675 12.362485  13.1898575]\n",
      "Reset environment\n",
      "Episode reward: 1400.802\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.193964 13.160184 13.18524  12.175203 12.362824 13.190251]\n",
      "Reset environment\n",
      "Episode reward: 4186.715\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.195328 13.161535 13.186595 12.176678 12.364048 13.191612]\n",
      "Reset environment\n",
      "Episode reward: 2972.6501\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.196243 13.162441 13.187514 12.177675 12.364879 13.192526]\n",
      "Reset environment\n",
      "Episode reward: 1832.812\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.196767 13.162974 13.188024 12.178254 12.365336 13.19305 ]\n",
      "Reset environment\n",
      "Episode reward: 4755.003\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.19835   13.164564  13.1895895 12.179968  12.36674   13.19463  ]\n",
      "Reset environment\n",
      "Episode reward: 2207.7395\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.199007 13.165223 13.190246 12.180695 12.367338 13.195287]\n",
      "Reset environment\n",
      "Episode reward: 1518.8113\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.199437  13.165653  13.1906805 12.181174  12.367729  13.195718 ]\n",
      "Reset environment\n",
      "Episode reward: 2835.288\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.20028  13.166498 13.191524 12.182095 12.3685   13.196561]\n",
      "Reset environment\n",
      "Episode reward: 5123.3037\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.202004 13.168215 13.193233 12.183951 12.370027 13.198275]\n",
      "Reset environment\n",
      "Episode reward: 1704.4656\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.20249  13.168688 13.193727 12.184485 12.370435 13.19876 ]\n",
      "Reset environment\n",
      "Episode reward: 800.2605\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.202249 13.168513 13.19342  12.184179 12.370229 13.19852 ]\n",
      "Reset environment\n",
      "Episode reward: 982.5893\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.202493  13.168758  13.1936655 12.184464  12.370444  13.198766 ]\n",
      "Reset environment\n",
      "Episode reward: 1814.3724\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.202902 13.169141 13.194098 12.184936 12.370797 13.199177]\n",
      "Reset environment\n",
      "Episode reward: 1678.3474\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.203405 13.169637 13.194615 12.185486 12.371242 13.19968 ]\n",
      "Reset environment\n",
      "Episode reward: 2192.7676\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.204318 13.170553 13.195523 12.186483 12.372045 13.200594]\n",
      "Reset environment\n",
      "Episode reward: 1430.4196\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.204726 13.170971 13.195918 12.186936 12.37241  13.201002]\n",
      "Reset environment\n",
      "Episode reward: 2326.0298\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.205265  13.17153   13.196429  12.187542  12.3728895 13.201542 ]\n",
      "Reset environment\n",
      "Episode reward: 2139.544\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.206151 13.172412 13.197314 12.188508 12.373675 13.20243 ]\n",
      "Reset environment\n",
      "Episode reward: 1831.2635\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.206926 13.173187 13.198091 12.18935  12.37437  13.203209]\n",
      "Reset environment\n",
      "Episode reward: 2558.0598\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.207672 13.173953 13.198817 12.190171 12.375015 13.203955]\n",
      "Reset environment\n",
      "Episode reward: 3294.6292\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.208705  13.17498   13.19985   12.1912775 12.37594   13.204984 ]\n",
      "Reset environment\n",
      "Episode reward: 3262.619\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.209441 13.175741 13.20056  12.192112 12.376608 13.20572 ]\n",
      "Reset environment\n",
      "Episode reward: 659.2888\n",
      "Total Steps: 21\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2095585 13.1758585 13.200676  12.192262  12.376701  13.205837 ]\n",
      "Reset environment\n",
      "Episode reward: 4860.136\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.211189 13.17748  13.202306 12.194013 12.378116 13.207465]\n",
      "Reset environment\n",
      "Episode reward: 2026.0449\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.211767 13.178053 13.202889 12.194653 12.378641 13.208044]\n",
      "Reset environment\n",
      "Episode reward: 1987.7529\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.212593  13.178883  13.203711  12.195564  12.3793745 13.20887  ]\n",
      "Reset environment\n",
      "Episode reward: 4980.5547\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.214259 13.180547 13.205346 12.197354 12.380837 13.210532]\n",
      "Reset environment\n",
      "Episode reward: 4412.3364\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.215674 13.181964 13.206742 12.198893 12.38208  13.21195 ]\n",
      "Reset environment\n",
      "Episode reward: 1387.06\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.216289  13.18258   13.207356  12.199568  12.382637  13.2125635]\n",
      "Reset environment\n",
      "Episode reward: 719.3353\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.215717  13.1819105 13.206888  12.199067  12.382093  13.2120075]\n",
      "Reset environment\n",
      "Episode reward: 2222.9714\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.216367 13.182556 13.207541 12.199781 12.382686 13.212657]\n",
      "Reset environment\n",
      "Episode reward: 3535.1233\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.217513 13.183705 13.208679 12.201021 12.383693 13.213803]\n",
      "Reset environment\n",
      "Episode reward: 2326.1206\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.218207  13.1844015 13.209373  12.201788  12.3843155 13.2144985]\n",
      "Reset environment\n",
      "Episode reward: 2845.2827\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.219074  13.1852865 13.21022   12.202739  12.385097  13.215365 ]\n",
      "Reset environment\n",
      "Episode reward: 3067.182\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.220036 13.186247 13.211183 12.203788 12.385964 13.216328]\n",
      "Reset environment\n",
      "Episode reward: 5767.905\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.221959 13.188172 13.2131   12.205864 12.387673 13.218248]\n",
      "Reset environment\n",
      "Episode reward: 2113.9482\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.222821 13.189033 13.213967 12.206808 12.388446 13.219113]\n",
      "Reset environment\n",
      "Episode reward: 2165.0127\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.223386 13.189619 13.214513 12.207442 12.388941 13.219681]\n",
      "Reset environment\n",
      "Episode reward: 2096.4336\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.224264 13.190497 13.215385 12.208402 12.389716 13.220557]\n",
      "Reset environment\n",
      "Episode reward: 5016.8774\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.225944 13.192176 13.217049 12.2102   12.391188 13.222236]\n",
      "Reset environment\n",
      "Episode reward: 2210.861\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.226497 13.192751 13.217575 12.210822 12.391684 13.222786]\n",
      "Reset environment\n",
      "Episode reward: 3363.8867\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.227551 13.193812 13.218623 12.211971 12.392628 13.223843]\n",
      "Reset environment\n",
      "Episode reward: -406.65332\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.226751  13.193047  13.21779   12.211144  12.3918915 13.223043 ]\n",
      "Reset environment\n",
      "Episode reward: 2406.5881\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.227447 13.19374  13.218491 12.211917 12.392517 13.223741]\n",
      "Reset environment\n",
      "Episode reward: 2382.651\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.228062  13.194328  13.2191305 12.212591  12.393057  13.22436  ]\n",
      "Reset environment\n",
      "Episode reward: 1847.5443\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2284975 13.194739  13.219591  12.213087  12.393452  13.224797 ]\n",
      "Reset environment\n",
      "Episode reward: 2985.3115\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.229388 13.195616 13.220486 12.214073 12.394241 13.225688]\n",
      "Reset environment\n",
      "Episode reward: 1832.7699\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.229907 13.196145 13.220987 12.214655 12.394692 13.226209]\n",
      "Reset environment\n",
      "Episode reward: 3103.3738\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.230888 13.197124 13.221969 12.215713 12.395578 13.227189]\n",
      "Reset environment\n",
      "Episode reward: 2057.8748\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2317505 13.197984  13.22283   12.216653  12.396339  13.228052 ]\n",
      "Reset environment\n",
      "Episode reward: 973.9601\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.231616 13.197876 13.222673 12.216407 12.396231 13.227925]\n",
      "Reset environment\n",
      "Episode reward: 3483.7966\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.232715 13.19896  13.22378  12.217604 12.397232 13.229027]\n",
      "Reset environment\n",
      "Episode reward: 5303.995\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.234514 13.200753 13.225575 12.219525 12.398791 13.230824]\n",
      "Reset environment\n",
      "Episode reward: 1603.4806\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.234972 13.201206 13.226036 12.220032 12.399207 13.231281]\n",
      "Reset environment\n",
      "Episode reward: 1836.1785\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.23549  13.201721 13.226554 12.220611 12.399676 13.231799]\n",
      "Reset environment\n",
      "Episode reward: 5620.412\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.237386 13.203616 13.228443 12.222655 12.401347 13.233696]\n",
      "Reset environment\n",
      "Episode reward: 2249.4958\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.237975 13.204224 13.228999 12.223316 12.401867 13.23429 ]\n",
      "Reset environment\n",
      "Episode reward: 1836.6353\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.238478 13.204705 13.229516 12.22387  12.402289 13.234792]\n",
      "Reset environment\n",
      "Episode reward: 3536.5361\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2396   13.205826 13.230638 12.225082 12.403298 13.235911]\n",
      "Reset environment\n",
      "Episode reward: 2882.9995\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.240489 13.20672  13.231521 12.226052 12.404094 13.2368  ]\n",
      "Reset environment\n",
      "Episode reward: 4861.318\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.242043 13.208277 13.233073 12.22773  12.405526 13.238355]\n",
      "Reset environment\n",
      "Episode reward: -660.74207\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2409725 13.207136  13.232078  12.226611  12.404554  13.237291 ]\n",
      "Reset environment\n",
      "Episode reward: 5934.7\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.242896  13.20905   13.234004  12.228686  12.4062395 13.239215 ]\n",
      "Reset environment\n",
      "Episode reward: 1506.2997\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.243302 13.209458 13.234411 12.22915  12.406606 13.239621]\n",
      "Reset environment\n",
      "Episode reward: 1848.2222\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.243827 13.209969 13.234943 12.229734 12.40707  13.240146]\n",
      "Reset environment\n",
      "Episode reward: 2562.49\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.244546 13.210675 13.235681 12.230524 12.407726 13.240864]\n",
      "Reset environment\n",
      "Episode reward: 1596.4261\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2448225 13.210977  13.235937  12.230864  12.407974  13.241143 ]\n",
      "Reset environment\n",
      "Episode reward: 1386.8044\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.24543  13.211585 13.236546 12.231533 12.408526 13.241751]\n",
      "Reset environment\n",
      "Episode reward: 2058.2583\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2460165 13.212182  13.237122  12.232184  12.40906   13.242338 ]\n",
      "Reset environment\n",
      "Episode reward: 2180.0115\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.246904 13.213063 13.238012 12.233147 12.40985  13.243225]\n",
      "Reset environment\n",
      "Episode reward: 2190.6284\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.247544 13.2137   13.238654 12.233852 12.410424 13.243865]\n",
      "Reset environment\n",
      "Episode reward: 2184.195\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.248233  13.214393  13.239335  12.234607  12.411039  13.2445545]\n",
      "Reset environment\n",
      "Episode reward: 2312.6365\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.248884 13.215032 13.240002 12.235325 12.411615 13.245207]\n",
      "Reset environment\n",
      "Episode reward: 2426.1353\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.249615  13.215766  13.240723  12.236124  12.4122715 13.245937 ]\n",
      "Reset environment\n",
      "Episode reward: 1759.2214\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.249997 13.216177 13.241078 12.236571 12.412618 13.246321]\n",
      "Reset environment\n",
      "Episode reward: 2640.0916\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.250692 13.216897 13.241753 12.237349 12.413232 13.24702 ]\n",
      "Reset environment\n",
      "Episode reward: 3355.1165\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.251753 13.217959 13.242787 12.238496 12.414159 13.248079]\n",
      "Reset environment\n",
      "Episode reward: 2517.9153\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.252414 13.218645 13.243429 12.239251 12.41473  13.248746]\n",
      "Reset environment\n",
      "Episode reward: 1449.2834\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.252832 13.219069 13.243836 12.239711 12.415111 13.249165]\n",
      "Reset environment\n",
      "Episode reward: 1098.8575\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.253132 13.219367 13.244136 12.240047 12.415367 13.249464]\n",
      "Reset environment\n",
      "Episode reward: 5152.4067\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.254814 13.221055 13.245808 12.241873 12.416859 13.251145]\n",
      "Reset environment\n",
      "Episode reward: 2505.332\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.255542 13.2218   13.246509 12.242673 12.41748  13.251873]\n",
      "Reset environment\n",
      "Episode reward: 2215.7437\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.256172 13.222414 13.247149 12.243367 12.418054 13.252505]\n",
      "Reset environment\n",
      "Episode reward: 1690.8472\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.25664   13.222881  13.247621  12.243892  12.418478  13.2529745]\n",
      "Reset environment\n",
      "Episode reward: 1780.809\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.257152 13.223389 13.248137 12.244459 12.418943 13.253487]\n",
      "Reset environment\n",
      "Episode reward: 2790.7837\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.258008 13.224236 13.249006 12.245387 12.419732 13.254343]\n",
      "Reset environment\n",
      "Episode reward: 2034.0204\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.258608 13.224852 13.249597 12.246044 12.420269 13.254944]\n",
      "Reset environment\n",
      "Episode reward: 1472.9388\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.259026 13.225266 13.250018 12.246509 12.42064  13.255362]\n",
      "Reset environment\n",
      "Episode reward: 1799.7328\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2595215 13.225766  13.250514  12.247068  12.421085  13.255857 ]\n",
      "Reset environment\n",
      "Episode reward: -291.73383\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.258676 13.224872 13.249718 12.246292 12.420296 13.255021]\n",
      "Reset environment\n",
      "Episode reward: 3639.803\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.259859 13.226054 13.250889 12.247573 12.421341 13.256206]\n",
      "Reset environment\n",
      "Episode reward: 3537.0435\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.261003  13.2272005 13.252028  12.248808  12.422349  13.257349 ]\n",
      "Reset environment\n",
      "Episode reward: 1337.4163\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.261329 13.227513 13.252368 12.249177 12.422641 13.257676]\n",
      "Reset environment\n",
      "Episode reward: 2000.8127\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.262164  13.22835   13.253203  12.250092  12.423378  13.2585125]\n",
      "Reset environment\n",
      "Episode reward: 2480.195\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.262899 13.22908  13.253943 12.250896 12.424041 13.259249]\n",
      "Reset environment\n",
      "Episode reward: 1014.0326\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.263159 13.229339 13.254201 12.251192 12.424269 13.259507]\n",
      "Reset environment\n",
      "Episode reward: 3106.4377\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.26413  13.230313 13.255165 12.25225  12.425128 13.260478]\n",
      "Reset environment\n",
      "Episode reward: 1778.76\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.264572  13.230731  13.2556305 12.252746  12.425501  13.260925 ]\n",
      "Reset environment\n",
      "Episode reward: 27.705597\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2640505 13.230196  13.255125  12.252064  12.42504   13.260409 ]\n",
      "Reset environment\n",
      "Episode reward: 1957.9397\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.264862 13.231012 13.255938 12.252954 12.425764 13.261223]\n",
      "Reset environment\n",
      "Episode reward: 1554.4254\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.265122 13.231308 13.256165 12.253271 12.426001 13.261487]\n",
      "Reset environment\n",
      "Episode reward: 1771.9633\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.265876 13.232055 13.256916 12.254084 12.42667  13.262239]\n",
      "Reset environment\n",
      "Episode reward: 2401.5442\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.266465  13.232624  13.257534  12.2547455 12.427181  13.262832 ]\n",
      "Reset environment\n",
      "Episode reward: 1843.9838\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.267224 13.233382 13.258293 12.255581 12.427859 13.263591]\n",
      "Reset environment\n",
      "Episode reward: 2197.2349\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.267806 13.233945 13.258888 12.256222 12.428353 13.264176]\n",
      "Reset environment\n",
      "Episode reward: 3616.4175\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.268939 13.235063 13.260017 12.257439 12.429359 13.265306]\n",
      "Reset environment\n",
      "Episode reward: 2098.2527\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.269466 13.235563 13.260568 12.258029 12.429809 13.265837]\n",
      "Reset environment\n",
      "Episode reward: 2972.307\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.270376  13.236461  13.26148   12.259015  12.430618  13.2667465]\n",
      "Reset environment\n",
      "Episode reward: 1699.6119\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.270816 13.236923 13.261898 12.259505 12.430996 13.267186]\n",
      "Reset environment\n",
      "Episode reward: 2761.2551\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.271631 13.237722 13.262721 12.260396 12.431743 13.267998]\n",
      "Reset environment\n",
      "Episode reward: 1967.0305\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.272187 13.238289 13.263265 12.261013 12.432234 13.268554]\n",
      "Reset environment\n",
      "Episode reward: 2329.387\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.272879 13.238982 13.263957 12.261781 12.432867 13.269246]\n",
      "Reset environment\n",
      "Episode reward: 1389.3324\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.273478  13.239582  13.264555  12.2624445 12.43341   13.269846 ]\n",
      "Reset environment\n",
      "Episode reward: 1766.9641\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.273973 13.240078 13.265053 12.262997 12.433857 13.270343]\n",
      "Reset environment\n",
      "Episode reward: 3260.5454\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.274993 13.241088 13.266073 12.2641   12.434766 13.271364]\n",
      "Reset environment\n",
      "Episode reward: 2160.7876\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.275873 13.241974 13.266949 12.26507  12.435538 13.272247]\n",
      "Reset environment\n",
      "Episode reward: 2150.937\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.276482 13.242571 13.267576 12.265743 12.436065 13.272856]\n",
      "Reset environment\n",
      "Episode reward: 2391.0046\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.277148 13.243252 13.268228 12.266478 12.43667  13.273522]\n",
      "Reset environment\n",
      "Episode reward: 1588.5563\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2775755 13.243702  13.268633  12.266953  12.437054  13.273952 ]\n",
      "Reset environment\n",
      "Episode reward: 3463.8484\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.278696 13.244828 13.26975  12.268162 12.438061 13.275072]\n",
      "Reset environment\n",
      "Episode reward: -128.34161\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.277973 13.244168 13.268961 12.267366 12.437418 13.274356]\n",
      "Reset environment\n",
      "Episode reward: 1688.1172\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.278466 13.244666 13.26945  12.26791  12.437869 13.274849]\n",
      "Reset environment\n",
      "Episode reward: 5313.5425\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.280227 13.246417 13.271193 12.269817 12.439417 13.276604]\n",
      "Reset environment\n",
      "Episode reward: 2163.449\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.280853 13.247045 13.271814 12.270514 12.439978 13.27723 ]\n",
      "Reset environment\n",
      "Episode reward: 2062.1406\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.281398 13.247607 13.27234  12.271124 12.440444 13.277775]\n",
      "Reset environment\n",
      "Episode reward: 4178.1387\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.282712 13.248911 13.273666 12.272545 12.44164  13.279087]\n",
      "Reset environment\n",
      "Episode reward: 2411.818\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.283402 13.249596 13.274371 12.273296 12.442263 13.279776]\n",
      "Reset environment\n",
      "Episode reward: 860.28485\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.283599 13.249792 13.274569 12.273529 12.442436 13.279972]\n",
      "Reset environment\n",
      "Episode reward: 2508.0793\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2843485 13.250533  13.275321  12.274347  12.443106  13.280722 ]\n",
      "Reset environment\n",
      "Episode reward: 2175.9294\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.285236 13.251422 13.276204 12.27532  12.443889 13.281606]\n",
      "Reset environment\n",
      "Episode reward: 5579.467\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.28712  13.253298 13.278083 12.277334 12.445555 13.283486]\n",
      "Reset environment\n",
      "Episode reward: 1876.2494\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.287638 13.253813 13.278605 12.277918 12.446024 13.284004]\n",
      "Reset environment\n",
      "Episode reward: 1831.8683\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.288141 13.254319 13.279103 12.278484 12.446475 13.284509]\n",
      "Reset environment\n",
      "Episode reward: 2518.2478\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.288862 13.25504  13.279824 12.279274 12.447132 13.28523 ]\n",
      "Reset environment\n",
      "Episode reward: 1621.8319\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.289341 13.255516 13.280303 12.279799 12.44756  13.285708]\n",
      "Reset environment\n",
      "Episode reward: 2139.781\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.290217  13.256393  13.281179  12.280749  12.4483385 13.286588 ]\n",
      "Reset environment\n",
      "Episode reward: 1651.2412\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.290669 13.256847 13.281631 12.281255 12.448748 13.287041]\n",
      "Reset environment\n",
      "Episode reward: 3488.5386\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.291778 13.257955 13.282725 12.282456 12.449711 13.288148]\n",
      "Reset environment\n",
      "Episode reward: 969.5307\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.292007 13.258179 13.282956 12.282726 12.449912 13.288378]\n",
      "Reset environment\n",
      "Episode reward: 2610.9714\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.292798  13.2589655 13.28375   12.283591  12.450613  13.28917  ]\n",
      "Reset environment\n",
      "Episode reward: 1792.4655\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.293229  13.259367  13.284202  12.284081  12.4509735 13.289603 ]\n",
      "Reset environment\n",
      "Episode reward: 5441.0356\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.295025 13.261155 13.286001 12.28603  12.452574 13.291398]\n",
      "Reset environment\n",
      "Episode reward: 5006.39\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.2966795 13.262818  13.287637  12.287802  12.454036  13.293052 ]\n",
      "Reset environment\n",
      "Episode reward: 2226.7727\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.297597 13.263737 13.288551 12.288799 12.454848 13.293969]\n",
      "Reset environment\n",
      "Episode reward: 2582.833\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.298294  13.264411  13.2892685 12.289553  12.455452  13.29467  ]\n",
      "Reset environment\n",
      "Episode reward: 1635.6538\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.29876  13.264875 13.289738 12.290067 12.455875 13.295136]\n",
      "Reset environment\n",
      "Episode reward: 5168.8457\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.300459 13.266579 13.29143  12.2919   12.457377 13.296837]\n",
      "Reset environment\n",
      "Episode reward: 5383.027\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.30218  13.268304 13.293151 12.293765 12.458963 13.298559]\n",
      "Reset environment\n",
      "Episode reward: 1532.3398\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.302602 13.268725 13.293573 12.294241 12.459348 13.298981]\n",
      "Reset environment\n",
      "Episode reward: 3097.3572\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.303527 13.26967  13.294475 12.29525  12.460188 13.299909]\n",
      "Reset environment\n",
      "Episode reward: 1602.8607\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.30393  13.270092 13.294859 12.295705 12.460542 13.300312]\n",
      "Reset environment\n",
      "Episode reward: 5537.3623\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.306055 13.272198 13.296978 12.297963 12.462455 13.302431]\n",
      "Reset environment\n",
      "Episode reward: 4858.5107\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.307658  13.273781  13.298565  12.299676  12.463866  13.3040285]\n",
      "Reset environment\n",
      "Episode reward: 2122.8938\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.308254  13.27437   13.2991705 12.30034   12.464404  13.304625 ]\n",
      "Reset environment\n",
      "Episode reward: 2507.716\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.309009 13.275116 13.299931 12.301166 12.465079 13.30538 ]\n",
      "Reset environment\n",
      "Episode reward: 2512.3428\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.309766 13.275877 13.300682 12.301992 12.465765 13.306136]\n",
      "Reset environment\n",
      "Episode reward: 1938.5054\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.310566 13.276677 13.301477 12.302865 12.466472 13.306936]\n",
      "Reset environment\n",
      "Episode reward: 1833.586\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.311335 13.277439 13.302243 12.303704 12.467156 13.307704]\n",
      "Reset environment\n",
      "Episode reward: 1984.3608\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.3119    13.278012  13.302804  12.304331  12.4676695 13.308269 ]\n",
      "Reset environment\n",
      "Episode reward: -279.9893\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.311232 13.277319 13.302158 12.303495 12.467069 13.307604]\n",
      "Reset environment\n",
      "Episode reward: 4782.8013\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.312803 13.278891 13.303714 12.305195 12.468437 13.309174]\n",
      "Reset environment\n",
      "Episode reward: 4647.7783\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.314319  13.2803955 13.305221  12.30682   12.469777  13.310677 ]\n",
      "Reset environment\n",
      "Episode reward: 2008.2747\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.314889 13.280972 13.30578  12.307447 12.470297 13.311248]\n",
      "Reset environment\n",
      "Episode reward: 2540.0037\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.31561  13.281709 13.306489 12.308242 12.470935 13.311968]\n",
      "Reset environment\n",
      "Episode reward: 1399.4406\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.316217  13.282318  13.3070965 12.308913  12.471485  13.312576 ]\n",
      "Reset environment\n",
      "Episode reward: 3870.427\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.317468 13.283565 13.308334 12.310264 12.472578 13.313828]\n",
      "Reset environment\n",
      "Episode reward: 1620.5522\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.317788 13.283861 13.308682 12.310644 12.472867 13.314151]\n",
      "Reset environment\n",
      "Episode reward: 2855.9414\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.318629 13.284684 13.309535 12.31156  12.473619 13.31499 ]\n",
      "Reset environment\n",
      "Episode reward: 975.04205\n",
      "Total Steps: 30\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.318876 13.284933 13.309779 12.31184  12.473832 13.315238]\n",
      "Reset environment\n",
      "Episode reward: 2033.5719\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.319456 13.285522 13.310344 12.312473 12.474356 13.315817]\n",
      "Reset environment\n",
      "Episode reward: 2185.3013\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.320043 13.286089 13.310946 12.313126 12.474863 13.316402]\n",
      "Reset environment\n",
      "Episode reward: 1958.7131\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.320842 13.286891 13.31174  12.314009 12.475571 13.317202]\n",
      "Reset environment\n",
      "Episode reward: 2447.9028\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.321581 13.287628 13.312479 12.314811 12.476228 13.317941]\n",
      "Reset environment\n",
      "Episode reward: 1545.3975\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.3219795 13.28801   13.312895  12.315257  12.476579  13.31834  ]\n",
      "Reset environment\n",
      "Episode reward: 5242.141\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.323718 13.289735 13.314629 12.317132 12.478085 13.32008 ]\n",
      "Reset environment\n",
      "Episode reward: 1037.9363\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.323993 13.290009 13.314903 12.317442 12.47833  13.320354]\n",
      "Reset environment\n",
      "Episode reward: 4312.5283\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.325405 13.291413 13.316301 12.318956 12.479546 13.321766]\n",
      "Reset environment\n",
      "Episode reward: 2093.5264\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.325941  13.291927  13.3168545 12.319568  12.480032  13.322304 ]\n",
      "Reset environment\n",
      "Episode reward: 3880.2305\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.327205 13.293184 13.318115 12.320918 12.481128 13.323567]\n",
      "Reset environment\n",
      "Episode reward: 2175.2876\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.327681 13.293685 13.318566 12.321462 12.481556 13.324043]\n",
      "Reset environment\n",
      "Episode reward: 3266.8699\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.328699 13.294689 13.319581 12.322567 12.482461 13.325065]\n",
      "Reset environment\n",
      "Episode reward: 2751.734\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.329548 13.295536 13.320429 12.323491 12.483218 13.325912]\n",
      "Reset environment\n",
      "Episode reward: 1755.4248\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.33003  13.29602  13.320911 12.324032 12.483657 13.326395]\n",
      "Reset environment\n",
      "Episode reward: 4558.1567\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.331528 13.297523 13.3224   12.325649 12.484976 13.327893]\n",
      "Reset environment\n",
      "Episode reward: 2801.5452\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.332337 13.298325 13.32322  12.326535 12.485714 13.328703]\n",
      "Reset environment\n",
      "Episode reward: 2756.076\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.333015  13.298977  13.323918  12.3273115 12.486306  13.329388 ]\n",
      "Reset environment\n",
      "Episode reward: 2139.2583\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.333532 13.299519 13.324412 12.327895 12.486779 13.329906]\n",
      "Reset environment\n",
      "Episode reward: 1712.176\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.333945  13.299909  13.324848  12.328365  12.4871435 13.330324 ]\n",
      "Reset environment\n",
      "Episode reward: 3533.1853\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.335064 13.301026 13.325958 12.329585 12.488124 13.331441]\n",
      "Reset environment\n",
      "Episode reward: 2069.2175\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.335919 13.301883 13.32681  12.33051  12.488881 13.332294]\n",
      "Reset environment\n",
      "Episode reward: 3645.723\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.337094 13.303064 13.327982 12.331781 12.489903 13.33347 ]\n",
      "Reset environment\n",
      "Episode reward: 5773.2007\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.339005 13.304978 13.329874 12.333835 12.491593 13.335381]\n",
      "Reset environment\n",
      "Episode reward: -388.00906\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.338244  13.304252  13.329076  12.333041  12.490878  13.3346195]\n",
      "Reset environment\n",
      "Episode reward: 911.1753\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.33812  13.304097 13.32898  12.332832 12.490785 13.334496]\n",
      "Reset environment\n",
      "Episode reward: 1210.4072\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.338421 13.304409 13.32927  12.333172 12.491055 13.334797]\n",
      "Reset environment\n",
      "Episode reward: 1838.3546\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.33894  13.304929 13.329789 12.333746 12.491527 13.335316]\n",
      "Reset environment\n",
      "Episode reward: 5875.0063\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.340871 13.30685  13.331704 12.335828 12.493248 13.337246]\n",
      "Reset environment\n",
      "Episode reward: 3770.741\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.342055 13.308044 13.33288  12.337111 12.494284 13.338429]\n",
      "Reset environment\n",
      "Episode reward: 1896.4464\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.3428335 13.308826  13.333657  12.337967  12.494977  13.339211 ]\n",
      "Reset environment\n",
      "Episode reward: 6250.584\n",
      "Total Steps: 209\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.344973 13.310938 13.335783 12.340246 12.496861 13.341342]\n",
      "Reset environment\n",
      "Episode reward: 2375.6597\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.345663 13.311635 13.336467 12.341005 12.497482 13.342033]\n",
      "Reset environment\n",
      "Episode reward: 1710.8721\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.346144 13.312115 13.336951 12.341537 12.497922 13.342514]\n",
      "Reset environment\n",
      "Episode reward: 4101.948\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.347469 13.313436 13.33827  12.342969 12.499082 13.343842]\n",
      "Reset environment\n",
      "Episode reward: 3775.504\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.348657 13.314618 13.339442 12.344262 12.500133 13.345027]\n",
      "Reset environment\n",
      "Episode reward: 2124.5713\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.349289 13.315252 13.340073 12.344958 12.500709 13.345658]\n",
      "Reset environment\n",
      "Episode reward: 2914.288\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.350172 13.31614  13.340945 12.345926 12.501482 13.346543]\n",
      "Reset environment\n",
      "Episode reward: 4842.781\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.351767 13.317729 13.342526 12.347639 12.502904 13.348137]\n",
      "Reset environment\n",
      "Episode reward: 2064.3442\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.352613 13.318581 13.343366 12.348567 12.503657 13.348984]\n",
      "Reset environment\n",
      "Episode reward: 4247.114\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.353978 13.319948 13.344715 12.35004  12.504853 13.350347]\n",
      "Reset environment\n",
      "Episode reward: 2280.1963\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.354562 13.32051  13.34532  12.350687 12.505358 13.350934]\n",
      "Reset environment\n",
      "Episode reward: 1759.8038\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.355049 13.320996 13.345813 12.351231 12.505803 13.351422]\n",
      "Reset environment\n",
      "Episode reward: 2607.145\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.355852  13.321803  13.346613  12.352109  12.5065365 13.352229 ]\n",
      "Reset environment\n",
      "Episode reward: 1387.1086\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.356454 13.322406 13.347214 12.352769 12.507083 13.352831]\n",
      "Reset environment\n",
      "Episode reward: 1266.6132\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.356774 13.322739 13.347526 12.353123 12.507367 13.353151]\n",
      "Reset environment\n",
      "Episode reward: 3820.233\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.357989 13.323943 13.348733 12.354437 12.508442 13.354364]\n",
      "Reset environment\n",
      "Episode reward: 1701.6833\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.358469 13.324434 13.349199 12.354966 12.508865 13.354845]\n",
      "Reset environment\n",
      "Episode reward: 5057.827\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.360132  13.326077  13.35086   12.356749  12.510331  13.3565035]\n",
      "Reset environment\n",
      "Episode reward: 2062.6116\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.360685 13.326651 13.351386 12.357362 12.510805 13.357059]\n",
      "Reset environment\n",
      "Episode reward: 1520.7925\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.360947 13.326889 13.351674 12.357682 12.511042 13.357321]\n",
      "Reset environment\n",
      "Episode reward: 5154.474\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.362631 13.328551 13.353361 12.359493 12.512542 13.359   ]\n",
      "Reset environment\n",
      "Episode reward: 1745.1129\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.363031  13.328923  13.3537855 12.35995   12.512889  13.359403 ]\n",
      "Reset environment\n",
      "Episode reward: 2529.765\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.363776 13.329659 13.354534 12.360764 12.51356  13.360147]\n",
      "Reset environment\n",
      "Episode reward: 1842.8185\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.364281 13.330154 13.355049 12.361321 12.513992 13.360653]\n",
      "Reset environment\n",
      "Episode reward: 2384.5984\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.364886  13.330784  13.355634  12.362002  12.514529  13.3612585]\n",
      "Reset environment\n",
      "Episode reward: 2217.074\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.365497 13.331383 13.356254 12.362681 12.515081 13.361866]\n",
      "Reset environment\n",
      "Episode reward: 2707.0828\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.36632  13.33221  13.357071 12.363576 12.51581  13.362689]\n",
      "Reset environment\n",
      "Episode reward: 4198.9653\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.367687 13.333575 13.358431 12.365053 12.51701  13.364055]\n",
      "Reset environment\n",
      "Episode reward: 518.8795\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.367317 13.333165 13.358087 12.364599 12.516704 13.36368 ]\n",
      "Reset environment\n",
      "Episode reward: 2977.5886\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.368244 13.334097 13.359014 12.365609 12.517535 13.364608]\n",
      "Reset environment\n",
      "Episode reward: 2504.7844\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.368977 13.334824 13.35975  12.36641  12.518188 13.365339]\n",
      "Reset environment\n",
      "Episode reward: 1427.51\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.369377 13.335229 13.360149 12.366863 12.518549 13.365741]\n",
      "Reset environment\n",
      "Episode reward: 4728.919\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.370913 13.336758 13.361672 12.368524 12.519889 13.367275]\n",
      "Reset environment\n",
      "Episode reward: 1536.3983\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.371284 13.337112 13.362066 12.368945 12.520217 13.36765 ]\n",
      "Reset environment\n",
      "Episode reward: 3555.0542\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.372358 13.338172 13.363152 12.370112 12.521203 13.368725]\n",
      "Reset environment\n",
      "Episode reward: 2286.8257\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.373052  13.338859  13.363851  12.3708725 12.5218315 13.369419 ]\n",
      "Reset environment\n",
      "Episode reward: 2825.9631\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.373918 13.339728 13.364712 12.371811 12.522597 13.370286]\n",
      "Reset environment\n",
      "Episode reward: 2128.6199\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.374779 13.340593 13.365572 12.372751 12.523359 13.371147]\n",
      "Reset environment\n",
      "Episode reward: 2279.7075\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.375684 13.341496 13.366477 12.373738 12.52416  13.372052]\n",
      "Reset environment\n",
      "Episode reward: 2085.9348\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.376239 13.342059 13.367025 12.374363 12.524661 13.372608]\n",
      "Reset environment\n",
      "Episode reward: 2492.7937\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.377025 13.34284  13.367819 12.375214 12.525375 13.373395]\n",
      "Reset environment\n",
      "Episode reward: 5826.1313\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.378964  13.344778  13.369739  12.377297  12.5270815 13.375334 ]\n",
      "Reset environment\n",
      "Episode reward: 3753.4973\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.380146 13.345967 13.370913 12.378577 12.528116 13.376515]\n",
      "Reset environment\n",
      "Episode reward: 1330.6014\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.380514 13.346329 13.371287 12.378987 12.528442 13.376884]\n",
      "Reset environment\n",
      "Episode reward: 2695.4995\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.381151 13.346991 13.371904 12.379703 12.529024 13.377522]\n",
      "Reset environment\n",
      "Episode reward: 2061.882\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.381994 13.347837 13.372746 12.380628 12.529767 13.378364]\n",
      "Reset environment\n",
      "Episode reward: 2139.8643\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.3828535 13.348697  13.373603  12.381559  12.530519  13.379224 ]\n",
      "Reset environment\n",
      "Episode reward: 1695.549\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.383213 13.349031 13.373989 12.381977 12.530845 13.379585]\n",
      "Reset environment\n",
      "Episode reward: 2587.7563\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.383995 13.349814 13.374769 12.38283  12.531539 13.380368]\n",
      "Reset environment\n",
      "Episode reward: 1754.1532\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.384474 13.350296 13.375244 12.383368 12.531966 13.380847]\n",
      "Reset environment\n",
      "Episode reward: 2874.2415\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.385326  13.351155  13.3760805 12.384302  12.532721  13.3817   ]\n",
      "Reset environment\n",
      "Episode reward: 2206.686\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.3860035 13.351831  13.376759  12.385039  12.533343  13.382379 ]\n",
      "Reset environment\n",
      "Episode reward: 3753.5005\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.387187  13.353015  13.3779335 12.386329  12.534378  13.383563 ]\n",
      "Reset environment\n",
      "Episode reward: 1371.9146\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.387768 13.353598 13.378516 12.386979 12.534903 13.384144]\n",
      "Reset environment\n",
      "Episode reward: 1960.4229\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.388328 13.354166 13.37907  12.387601 12.535412 13.384702]\n",
      "Reset environment\n",
      "Episode reward: -240.62216\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.387507 13.35342  13.37818  12.386773 12.534666 13.383886]\n",
      "Reset environment\n",
      "Episode reward: 2218.366\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.388411  13.354325  13.379081  12.387752  12.535465  13.3847885]\n",
      "Reset environment\n",
      "Episode reward: -53.81427\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.387781 13.353757 13.378391 12.387032 12.53491  13.384167]\n",
      "Reset environment\n",
      "Episode reward: 4063.2954\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.389047 13.355013 13.379661 12.38841  12.536051 13.385431]\n",
      "Reset environment\n",
      "Episode reward: 567.0736\n",
      "Total Steps: 17\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.389133 13.355101 13.379748 12.388523 12.536123 13.385518]\n",
      "Reset environment\n",
      "Episode reward: 1744.8807\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.389865  13.355831  13.380479  12.38932   12.536775  13.3862505]\n",
      "Reset environment\n",
      "Episode reward: 2474.3022\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.390602 13.356571 13.381214 12.39013  12.537433 13.386987]\n",
      "Reset environment\n",
      "Episode reward: 1605.9429\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.391042 13.357001 13.381657 12.390625 12.537828 13.387427]\n",
      "Reset environment\n",
      "Episode reward: 2964.3357\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.391968 13.357931 13.382578 12.391622 12.538665 13.388354]\n",
      "Reset environment\n",
      "Episode reward: 1750.7899\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.392462 13.358424 13.383076 12.392175 12.539108 13.388849]\n",
      "Reset environment\n",
      "Episode reward: 1790.8237\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.392957 13.35892  13.383571 12.392727 12.539556 13.389345]\n",
      "Reset environment\n",
      "Episode reward: 2016.6926\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.3935175 13.359486  13.384125  12.393344  12.540067  13.389906 ]\n",
      "Reset environment\n",
      "Episode reward: 2200.0486\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.394131 13.360098 13.38474  12.394024 12.540627 13.390519]\n",
      "Reset environment\n",
      "Episode reward: 1657.7373\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.394591 13.360559 13.385201 12.394536 12.541047 13.390981]\n",
      "Reset environment\n",
      "Episode reward: 155.67844\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.394133  13.3601265 13.384701  12.393936  12.540648  13.390523 ]\n",
      "Reset environment\n",
      "Episode reward: 2534.5684\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.394881  13.3608675 13.385451  12.394754  12.541312  13.391272 ]\n",
      "Reset environment\n",
      "Episode reward: 2276.583\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.395536 13.361513 13.386116 12.395472 12.541908 13.391927]\n",
      "Reset environment\n",
      "Episode reward: 1878.5441\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.395983 13.361939 13.386581 12.395971 12.54229  13.392379]\n",
      "Reset environment\n",
      "Episode reward: 1919.9684\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.396377 13.362366 13.386945 12.396426 12.542649 13.392775]\n",
      "Reset environment\n",
      "Episode reward: 3468.031\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.39747  13.363463 13.388029 12.397614 12.543629 13.393869]\n",
      "Reset environment\n",
      "Episode reward: 3030.18\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.398407 13.364401 13.388961 12.398635 12.544449 13.394804]\n",
      "Reset environment\n",
      "Episode reward: 733.2556\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.398062  13.364014  13.388671  12.3982115 12.544159  13.394469 ]\n",
      "Reset environment\n",
      "Episode reward: 950.29736\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.39789  13.363801 13.388528 12.397961 12.544021 13.394298]\n",
      "Reset environment\n",
      "Episode reward: 1845.3052\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.398414 13.364328 13.389047 12.398539 12.544498 13.394821]\n",
      "Reset environment\n",
      "Episode reward: 2056.3123\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.399238  13.365154  13.389869  12.3994465 12.545224  13.395644 ]\n",
      "Reset environment\n",
      "Episode reward: 2317.7393\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.400164 13.366074 13.39079  12.400459 12.546042 13.396571]\n",
      "Reset environment\n",
      "Episode reward: 2056.845\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.400772 13.366673 13.391411 12.401125 12.546592 13.39718 ]\n",
      "Reset environment\n",
      "Episode reward: 4002.3413\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.40199  13.367893 13.392628 12.402447 12.547707 13.398397]\n",
      "Reset environment\n",
      "Episode reward: 5520.1533\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.403779 13.369683 13.394408 12.404379 12.549293 13.400188]\n",
      "Reset environment\n",
      "Episode reward: 1404.0337\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.404379 13.370288 13.395009 12.405045 12.549831 13.400789]\n",
      "Reset environment\n",
      "Episode reward: 1674.9336\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.404861 13.370777 13.395488 12.405578 12.550276 13.401272]\n",
      "Reset environment\n",
      "Episode reward: 4195.2363\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.406186 13.372081 13.396807 12.407008 12.551469 13.402592]\n",
      "Reset environment\n",
      "Episode reward: 536.39545\n",
      "Total Steps: 18\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.406245 13.37214  13.396868 12.407103 12.551516 13.402652]\n",
      "Reset environment\n",
      "Episode reward: 1357.3313\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.406624 13.372512 13.397249 12.407521 12.551862 13.403029]\n",
      "Reset environment\n",
      "Episode reward: 1915.3972\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.406902 13.372817 13.397501 12.407867 12.552105 13.403309]\n",
      "Reset environment\n",
      "Episode reward: 1897.9615\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.407458 13.37337  13.398061 12.408478 12.552615 13.403863]\n",
      "Reset environment\n",
      "Episode reward: 4604.26\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.408949 13.374856 13.399553 12.410087 12.553923 13.405358]\n",
      "Reset environment\n",
      "Episode reward: 2916.6106\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.409821 13.37572  13.400427 12.411045 12.554692 13.406231]\n",
      "Reset environment\n",
      "Episode reward: 399.85538\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.409367 13.375211 13.400041 12.410525 12.554296 13.405785]\n",
      "Reset environment\n",
      "Episode reward: 4497.112\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.41083  13.376655 13.401503 12.412095 12.555592 13.407247]\n",
      "Reset environment\n",
      "Episode reward: 5696.461\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.412969  13.378782  13.40363   12.4143715 12.557513  13.409379 ]\n",
      "Reset environment\n",
      "Episode reward: 1897.6445\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.413733 13.379545 13.404393 12.415213 12.558186 13.410143]\n",
      "Reset environment\n",
      "Episode reward: 2797.5657\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.41453  13.380324 13.4052   12.416081 12.558909 13.41094 ]\n",
      "Reset environment\n",
      "Episode reward: 3190.8108\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.415519  13.381323  13.406185  12.4171505 12.5597925 13.411929 ]\n",
      "Reset environment\n",
      "Episode reward: 1338.7955\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.415894 13.381703 13.406554 12.417567 12.560133 13.412304]\n",
      "Reset environment\n",
      "Episode reward: 1851.305\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.416424 13.382238 13.407078 12.418156 12.56061  13.412835]\n",
      "Reset environment\n",
      "Episode reward: 2412.6587\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.417104 13.382932 13.407743 12.418898 12.561229 13.413517]\n",
      "Reset environment\n",
      "Episode reward: 4923.783\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.418717 13.384527 13.409356 12.420632 12.562638 13.415124]\n",
      "Reset environment\n",
      "Episode reward: 2562.8892\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.419474 13.385268 13.410114 12.421454 12.56331  13.415878]\n",
      "Reset environment\n",
      "Episode reward: 2012.515\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.420037 13.385831 13.41068  12.422077 12.563821 13.416442]\n",
      "Reset environment\n",
      "Episode reward: 2693.2551\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.420853 13.386649 13.411494 12.422966 12.564551 13.417257]\n",
      "Reset environment\n",
      "Episode reward: 5108.8726\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.4225445 13.388336  13.413179  12.424772  12.566009  13.418949 ]\n",
      "Reset environment\n",
      "Episode reward: 1513.8662\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.422963  13.388765  13.413586  12.425234  12.5663805 13.419369 ]\n",
      "Reset environment\n",
      "Episode reward: 3564.5293\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.424092 13.389897 13.414714 12.426454 12.56737  13.420498]\n",
      "Reset environment\n",
      "Episode reward: 3233.7793\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.425094 13.390894 13.41572  12.42753  12.568268 13.421498]\n",
      "Reset environment\n",
      "Episode reward: 1486.8536\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.425515 13.391318 13.416135 12.427996 12.568647 13.42192 ]\n",
      "Reset environment\n",
      "Episode reward: 2007.1646\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.426078  13.39189   13.416692  12.428619  12.5691595 13.422483 ]\n",
      "Reset environment\n",
      "Episode reward: 2806.9487\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.426883 13.392695 13.417498 12.429498 12.569895 13.423289]\n",
      "Reset environment\n",
      "Episode reward: 1384.435\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.427477  13.3932905 13.418092  12.430153  12.570433  13.423884 ]\n",
      "Reset environment\n",
      "Episode reward: 1325.7397\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.427841 13.393652 13.418457 12.43056  12.570762 13.42425 ]\n",
      "Reset environment\n",
      "Episode reward: 2015.095\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.428662 13.394475 13.419278 12.431458 12.571493 13.42507 ]\n",
      "Reset environment\n",
      "Episode reward: 3478.731\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.429734 13.395544 13.420348 12.432623 12.572443 13.426146]\n",
      "Reset environment\n",
      "Episode reward: 1495.9653\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.43007  13.395857 13.420709 12.433001 12.572741 13.426487]\n",
      "Reset environment\n",
      "Episode reward: 2967.3728\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.430966 13.396751 13.421606 12.433984 12.573539 13.427384]\n",
      "Reset environment\n",
      "Episode reward: 3350.632\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.431962 13.397749 13.422604 12.435064 12.574451 13.428381]\n",
      "Reset environment\n",
      "Episode reward: 5122.243\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.433637  13.399426  13.424258  12.436876  12.5759115 13.430054 ]\n",
      "Reset environment\n",
      "Episode reward: 4853.1274\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.435205 13.400987 13.425828 12.43856  12.57731  13.431623]\n",
      "Reset environment\n",
      "Episode reward: 1891.3185\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.435672 13.401427 13.426318 12.439085 12.577698 13.432092]\n",
      "Reset environment\n",
      "Episode reward: 1665.1864\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.436136 13.401902 13.42678  12.439597 12.578122 13.432557]\n",
      "Reset environment\n",
      "Episode reward: 5585.3213\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.437944  13.403712  13.428573  12.4415455 12.579697  13.434364 ]\n",
      "Reset environment\n",
      "Episode reward: 2432.453\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.438646 13.404408 13.42928  12.442313 12.580325 13.435066]\n",
      "Reset environment\n",
      "Episode reward: 3460.4783\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.439715 13.405468 13.430351 12.44347  12.581275 13.436132]\n",
      "Reset environment\n",
      "Episode reward: 1888.2819\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.440484 13.406239 13.43112  12.444304 12.581957 13.436901]\n",
      "Reset environment\n",
      "Episode reward: 1757.2587\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.440957 13.4067   13.431611 12.444831 12.582373 13.437376]\n",
      "Reset environment\n",
      "Episode reward: 1734.6146\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.441404 13.407163 13.432047 12.445332 12.582776 13.437823]\n",
      "Reset environment\n",
      "Episode reward: 1779.7292\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.441915  13.407668  13.432562  12.445893  12.5832405 13.4383335]\n",
      "Reset environment\n",
      "Episode reward: 3499.7974\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.443018 13.408767 13.43366  12.447082 12.584201 13.439438]\n",
      "Reset environment\n",
      "Episode reward: 1834.1649\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.443776 13.409524 13.434418 12.447899 12.584876 13.440196]\n",
      "Reset environment\n",
      "Episode reward: 1370.4918\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.444146  13.409897  13.434789  12.4483185 12.585214  13.440568 ]\n",
      "Reset environment\n",
      "Episode reward: 2362.5525\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.444865 13.41062  13.435503 12.449096 12.585863 13.441287]\n",
      "Reset environment\n",
      "Episode reward: 3408.6697\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.445935 13.411689 13.436568 12.450247 12.586806 13.442357]\n",
      "Reset environment\n",
      "Episode reward: 2882.6155\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.446801 13.412562 13.437428 12.451195 12.587568 13.443223]\n",
      "Reset environment\n",
      "Episode reward: 4078.733\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.448083 13.413845 13.438702 12.452584 12.588692 13.444501]\n",
      "Reset environment\n",
      "Episode reward: 1396.8912\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.448674 13.414439 13.439294 12.45324  12.589224 13.445093]\n",
      "Reset environment\n",
      "Episode reward: 2128.445\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.449237 13.415015 13.439842 12.453865 12.589737 13.445655]\n",
      "Reset environment\n",
      "Episode reward: 5426.209\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.451024 13.41679  13.441633 12.455784 12.591325 13.447438]\n",
      "Reset environment\n",
      "Episode reward: 2533.7761\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.451735 13.417489 13.442356 12.456563 12.591974 13.448149]\n",
      "Reset environment\n",
      "Episode reward: 2803.2634\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.452576 13.418338 13.443192 12.457478 12.592719 13.448989]\n",
      "Reset environment\n",
      "Episode reward: 2978.8022\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.453484  13.4192505 13.444095  12.458464  12.593516  13.449897 ]\n",
      "Reset environment\n",
      "Episode reward: 1653.4248\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.453926 13.419676 13.444555 12.458949 12.593895 13.450339]\n",
      "Reset environment\n",
      "Episode reward: 1875.0234\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.454365 13.420143 13.44497  12.459458 12.594273 13.450782]\n",
      "Reset environment\n",
      "Episode reward: 1720.9631\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.455072 13.42085  13.445677 12.460233 12.594905 13.451489]\n",
      "Reset environment\n",
      "Episode reward: 4795.6714\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.456548 13.422327 13.447151 12.461832 12.596242 13.452963]\n",
      "Reset environment\n",
      "Episode reward: 1454.9198\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.4568815 13.422636  13.447506  12.462212  12.5965395 13.453302 ]\n",
      "Reset environment\n",
      "Episode reward: 3872.301\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.4581175 13.423875  13.448737  12.463535  12.597616  13.454538 ]\n",
      "Reset environment\n",
      "Episode reward: 1829.4872\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.458654 13.42441  13.449275 12.464125 12.598109 13.455075]\n",
      "Reset environment\n",
      "Episode reward: 2692.811\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.459466 13.425223 13.450087 12.465011 12.598846 13.455888]\n",
      "Reset environment\n",
      "Episode reward: 5263.1465\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.461205 13.426952 13.451824 12.46687  12.600363 13.457621]\n",
      "Reset environment\n",
      "Episode reward: 5137.483\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.462879 13.428603 13.453501 12.468673 12.601837 13.459296]\n",
      "Reset environment\n",
      "Episode reward: 5068.782\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.464532 13.430256 13.455148 12.470439 12.60331  13.460948]\n",
      "Reset environment\n",
      "Episode reward: 3199.886\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.465464 13.431178 13.456078 12.471464 12.604144 13.461879]\n",
      "Reset environment\n",
      "Episode reward: 5424.7266\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.467226 13.432939 13.457824 12.473352 12.605698 13.463637]\n",
      "Reset environment\n",
      "Episode reward: 3420.3074\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.468272  13.434     13.45886   12.474484  12.606634  13.4646845]\n",
      "Reset environment\n",
      "Episode reward: 1769.6947\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.46873  13.434444 13.459333 12.474994 12.60702  13.465143]\n",
      "Reset environment\n",
      "Episode reward: 5779.9277\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.470601 13.436316 13.4612   12.477016 12.608668 13.467017]\n",
      "Reset environment\n",
      "Episode reward: 1364.9895\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.471174 13.43689  13.461772 12.477658 12.609181 13.46759 ]\n",
      "Reset environment\n",
      "Episode reward: 4329.814\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.472578 13.438295 13.463164 12.479164 12.610404 13.468993]\n",
      "Reset environment\n",
      "Episode reward: 1597.9043\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.472905  13.438644  13.4634695 12.479552  12.6107    13.469319 ]\n",
      "Reset environment\n",
      "Episode reward: 2765.7688\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.473735 13.439478 13.464299 12.480459 12.611429 13.470149]\n",
      "Reset environment\n",
      "Episode reward: 1946.7677\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.474273 13.440014 13.464839 12.481056 12.611918 13.470687]\n",
      "Reset environment\n",
      "Episode reward: 4857.542\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.47586   13.441595  13.46642   12.482755  12.6133175 13.472271 ]\n",
      "Reset environment\n",
      "Episode reward: 5203.366\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.477564 13.443285 13.468117 12.484568 12.614794 13.473976]\n",
      "Reset environment\n",
      "Episode reward: 2134.8198\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.478417  13.444141  13.46897   12.4854965 12.61555   13.47483  ]\n",
      "Reset environment\n",
      "Episode reward: 2090.5913\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.479028 13.444756 13.469579 12.486168 12.616108 13.47544 ]\n",
      "Reset environment\n",
      "Episode reward: 920.6052\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.47924   13.444975  13.4697895 12.48642   12.616296  13.475653 ]\n",
      "Reset environment\n",
      "Episode reward: 4430.2964\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.480669  13.446407  13.471192  12.4879675 12.617529  13.477079 ]\n",
      "Reset environment\n",
      "Episode reward: 1887.2467\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.481183 13.446933 13.471704 12.488537 12.617997 13.477593]\n",
      "Reset environment\n",
      "Episode reward: 5040.7925\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.482821 13.448564 13.473346 12.490301 12.619431 13.479232]\n",
      "Reset environment\n",
      "Episode reward: 1748.5295\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.483323  13.449066  13.4738455 12.490853  12.619889  13.479733 ]\n",
      "Reset environment\n",
      "Episode reward: 1718.9817\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.483794 13.449534 13.474321 12.491379 12.620317 13.480206]\n",
      "Reset environment\n",
      "Episode reward: 2097.5403\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.484642 13.450386 13.475167 12.492301 12.621065 13.481051]\n",
      "Reset environment\n",
      "Episode reward: 2349.1985\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.485229 13.450997 13.475736 12.492953 12.6216   13.48164 ]\n",
      "Reset environment\n",
      "Episode reward: 4476.953\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.486652 13.452402 13.477148 12.494481 12.622872 13.483054]\n",
      "Reset environment\n",
      "Episode reward: 1862.5072\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.487219 13.452975 13.477708 12.495097 12.623396 13.483621]\n",
      "Reset environment\n",
      "Episode reward: 2933.152\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.488107 13.453871 13.478589 12.496063 12.624179 13.484508]\n",
      "Reset environment\n",
      "Episode reward: 2558.5466\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.488846  13.4545965 13.479341  12.496871  12.624835  13.485248 ]\n",
      "Reset environment\n",
      "Episode reward: 1730.9086\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.489319 13.455075 13.479807 12.497396 12.625262 13.485721]\n",
      "Reset environment\n",
      "Episode reward: 2936.937\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.49021  13.455954 13.4807   12.498368 12.626049 13.486611]\n",
      "Reset environment\n",
      "Episode reward: 1869.6447\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.490759  13.456503  13.481251  12.498976  12.6265545 13.487161 ]\n",
      "Reset environment\n",
      "Episode reward: 1720.2478\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.491234 13.456969 13.481733 12.499504 12.626977 13.487636]\n",
      "Reset environment\n",
      "Episode reward: 5446.796\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.492941 13.458678 13.483441 12.501344 12.628516 13.489345]\n",
      "Reset environment\n",
      "Episode reward: 1655.4702\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.4933195 13.459036  13.483845  12.501778  12.628851  13.489725 ]\n",
      "Reset environment\n",
      "Episode reward: 2210.5952\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.494202 13.459918 13.484725 12.502741 12.629633 13.490608]\n",
      "Reset environment\n",
      "Episode reward: 1120.6003\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.494494 13.460212 13.485017 12.503077 12.629898 13.490901]\n",
      "Reset environment\n",
      "Episode reward: 3068.5454\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.495424  13.46115   13.485939  12.504084  12.6307125 13.491829 ]\n",
      "Reset environment\n",
      "Episode reward: 2207.461\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.495951 13.461698 13.486439 12.504676 12.631178 13.492353]\n",
      "Reset environment\n",
      "Episode reward: 917.2212\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.496125 13.461884 13.486599 12.504888 12.631328 13.492527]\n",
      "Reset environment\n",
      "Episode reward: 3113.5166\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.497084 13.462846 13.487554 12.505929 12.632188 13.493483]\n",
      "Reset environment\n",
      "Episode reward: 2114.1113\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.497706  13.463484  13.4881735 12.50661   12.632761  13.494107 ]\n",
      "Reset environment\n",
      "Episode reward: 2396.8997\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.498372 13.464137 13.488847 12.507338 12.63337  13.494772]\n",
      "Reset environment\n",
      "Episode reward: 5208.1797\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.50002   13.4657755 13.490491  12.509132  12.634823  13.496415 ]\n",
      "Reset environment\n",
      "Episode reward: 2775.446\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.500833  13.4666    13.491293  12.5100155 12.63555   13.497228 ]\n",
      "Reset environment\n",
      "Episode reward: 790.4407\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.500498 13.466306 13.490917 12.509595 12.635249 13.496898]\n",
      "Reset environment\n",
      "Episode reward: 1808.6385\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.500953 13.466779 13.491345 12.510102 12.63564  13.497349]\n",
      "Reset environment\n",
      "Episode reward: 2620.4043\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.501732 13.467563 13.492124 12.510951 12.636335 13.498129]\n",
      "Reset environment\n",
      "Episode reward: 2122.9912\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.502317 13.468158 13.492698 12.511594 12.636847 13.498717]\n",
      "Reset environment\n",
      "Episode reward: 2349.5894\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5029545 13.468806  13.49332   12.512291  12.637423  13.4993515]\n",
      "Reset environment\n",
      "Episode reward: 4459.731\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.504385 13.470238 13.494743 12.513845 12.638672 13.500784]\n",
      "Reset environment\n",
      "Episode reward: 3132.6458\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.505296 13.471152 13.495656 12.514837 12.639508 13.501695]\n",
      "Reset environment\n",
      "Episode reward: 3132.8481\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.506232 13.472102 13.496586 12.515849 12.640345 13.502632]\n",
      "Reset environment\n",
      "Episode reward: 2287.3135\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.506863 13.472745 13.497205 12.516539 12.640925 13.503263]\n",
      "Reset environment\n",
      "Episode reward: 2364.8577\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5075035 13.473376  13.497856  12.517243  12.641505  13.503904 ]\n",
      "Reset environment\n",
      "Episode reward: 5748.6006\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.509354  13.475224  13.499687  12.519245  12.643129  13.5057535]\n",
      "Reset environment\n",
      "Episode reward: 5874.8066\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.511249 13.47712  13.501565 12.521282 12.644804 13.507649]\n",
      "Reset environment\n",
      "Episode reward: 3428.1743\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.512319 13.478195 13.502626 12.522435 12.645755 13.508719]\n",
      "Reset environment\n",
      "Episode reward: 832.05786\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.512314 13.4782   13.502614 12.522362 12.6458   13.508719]\n",
      "Reset environment\n",
      "Episode reward: 2202.0928\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.513194 13.479083 13.503494 12.523322 12.646573 13.509599]\n",
      "Reset environment\n",
      "Episode reward: 1411.373\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.51379  13.479682 13.50409  12.52398  12.647111 13.510195]\n",
      "Reset environment\n",
      "Episode reward: 2527.9648\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.514517 13.480414 13.504808 12.52478  12.647766 13.510921]\n",
      "Reset environment\n",
      "Episode reward: 2149.327\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.515082 13.480993 13.50536  12.525411 12.648277 13.511486]\n",
      "Reset environment\n",
      "Episode reward: 4091.718\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.516367 13.482275 13.506635 12.526798 12.649386 13.512771]\n",
      "Reset environment\n",
      "Episode reward: 3124.0903\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.517264  13.483175  13.507532  12.5277815 12.6502075 13.513668 ]\n",
      "Reset environment\n",
      "Episode reward: 1826.765\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.518012 13.483915 13.50828  12.528595 12.650872 13.514416]\n",
      "Reset environment\n",
      "Episode reward: 660.35596\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.517626 13.483609 13.507808 12.528183 12.65054  13.514037]\n",
      "Reset environment\n",
      "Episode reward: 3213.098\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.518616 13.484604 13.50879  12.529255 12.651405 13.51503 ]\n",
      "Reset environment\n",
      "Episode reward: 5024.2876\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.520226 13.486225 13.510382 12.530992 12.652816 13.516642]\n",
      "Reset environment\n",
      "Episode reward: 1697.7261\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.520655  13.486645  13.5108185 12.531478  12.653204  13.517072 ]\n",
      "Reset environment\n",
      "Episode reward: -478.30023\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.519887 13.485861 13.510068 12.53051  12.652502 13.51631 ]\n",
      "Reset environment\n",
      "Episode reward: 4567.3657\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.521338 13.487307 13.511518 12.532081 12.653758 13.517762]\n",
      "Reset environment\n",
      "Episode reward: 1591.7056\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.521763 13.487733 13.511942 12.532555 12.654146 13.518187]\n",
      "Reset environment\n",
      "Episode reward: 2274.2263\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.522373 13.488331 13.51257  12.533228 12.654674 13.518799]\n",
      "Reset environment\n",
      "Episode reward: 3137.2588\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.523332  13.489272  13.513535  12.534263  12.6555195 13.519757 ]\n",
      "Reset environment\n",
      "Episode reward: 1877.8505\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.523843 13.489787 13.51404  12.53483  12.655982 13.520268]\n",
      "Reset environment\n",
      "Episode reward: 2180.4155\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.52471  13.490658 13.514908 12.535778 12.656765 13.521136]\n",
      "Reset environment\n",
      "Episode reward: 3778.794\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.525892 13.491834 13.516079 12.537054 12.657806 13.522318]\n",
      "Reset environment\n",
      "Episode reward: 4968.1895\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.52751  13.493445 13.517694 12.538786 12.659226 13.523933]\n",
      "Reset environment\n",
      "Episode reward: 1522.4253\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.527939  13.493881  13.51812   12.539262  12.659615  13.5243635]\n",
      "Reset environment\n",
      "Episode reward: 1700.9874\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.528385 13.494331 13.518566 12.539767 12.660018 13.524813]\n",
      "Reset environment\n",
      "Episode reward: 2008.1211\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5291815 13.495132  13.519356  12.540642  12.660716  13.525609 ]\n",
      "Reset environment\n",
      "Episode reward: 1891.8069\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.529594 13.495512 13.51979  12.541104 12.661075 13.526024]\n",
      "Reset environment\n",
      "Episode reward: 2159.0845\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.530173 13.496111 13.520352 12.541748 12.661582 13.526603]\n",
      "Reset environment\n",
      "Episode reward: 2240.8765\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.530804 13.496748 13.520977 12.542442 12.66215  13.527233]\n",
      "Reset environment\n",
      "Episode reward: 2501.8662\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5314865 13.49742   13.521675  12.543198  12.662776  13.527916 ]\n",
      "Reset environment\n",
      "Episode reward: 3764.3516\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.532671 13.498601 13.522855 12.544477 12.663813 13.529101]\n",
      "Reset environment\n",
      "Episode reward: 4695.325\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.534184 13.500105 13.524366 12.546105 12.665136 13.530614]\n",
      "Reset environment\n",
      "Episode reward: 2273.2546\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.534656 13.500554 13.524862 12.546646 12.665556 13.531086]\n",
      "Reset environment\n",
      "Episode reward: 1974.2333\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.535167 13.501053 13.525392 12.547217 12.666011 13.531597]\n",
      "Reset environment\n",
      "Episode reward: 5354.7427\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.536911 13.502787 13.527131 12.549081 12.667534 13.533338]\n",
      "Reset environment\n",
      "Episode reward: 2193.188\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.537782 13.503662 13.528    12.550033 12.6683   13.534209]\n",
      "Reset environment\n",
      "Episode reward: 1375.2323\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.538126 13.503999 13.528354 12.550424 12.668612 13.534554]\n",
      "Reset environment\n",
      "Episode reward: 2464.451\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.538804 13.504695 13.529016 12.551165 12.669209 13.535232]\n",
      "Reset environment\n",
      "Episode reward: 1851.9738\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.539131 13.504996 13.52937  12.551559 12.669504 13.535565]\n",
      "Reset environment\n",
      "Episode reward: 3268.085\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.540078 13.505943 13.530317 12.552593 12.670362 13.536513]\n",
      "Reset environment\n",
      "Episode reward: 1616.0724\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.540376 13.506247 13.530613 12.552875 12.670624 13.536812]\n",
      "Reset environment\n",
      "Episode reward: 2404.8591\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.541032  13.506905  13.531271  12.5535965 12.671224  13.537468 ]\n",
      "Reset environment\n",
      "Episode reward: 1844.082\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5414915 13.507344  13.531745  12.554107  12.671599  13.537926 ]\n",
      "Reset environment\n",
      "Episode reward: 2213.9744\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.542074 13.507929 13.53233  12.554757 12.672131 13.538508]\n",
      "Reset environment\n",
      "Episode reward: 1926.3223\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.542603 13.508474 13.53284  12.555338 12.672591 13.539036]\n",
      "Reset environment\n",
      "Episode reward: 1348.532\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.542961 13.508833 13.533198 12.555744 12.672914 13.539394]\n",
      "Reset environment\n",
      "Episode reward: 1790.7787\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.543431 13.509294 13.533681 12.556272 12.673309 13.539865]\n",
      "Reset environment\n",
      "Episode reward: 1068.8876\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.54368  13.509553 13.533922 12.556556 12.673531 13.540114]\n",
      "Reset environment\n",
      "Episode reward: 1855.2788\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.544175 13.510059 13.534408 12.557102 12.673981 13.540608]\n",
      "Reset environment\n",
      "Episode reward: -340.703\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.543417  13.509294  13.53366   12.5563965 12.673349  13.539855 ]\n",
      "Reset environment\n",
      "Episode reward: 2235.9006\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.54405  13.509923 13.534299 12.557096 12.673927 13.540488]\n",
      "Reset environment\n",
      "Episode reward: 4298.1655\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.545413 13.51129  13.535653 12.558567 12.675118 13.541857]\n",
      "Reset environment\n",
      "Episode reward: 3453.671\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.546416 13.512296 13.536657 12.559662 12.676038 13.54286 ]\n",
      "Reset environment\n",
      "Episode reward: 2579.107\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5471325 13.513001  13.537382  12.560444  12.676684  13.543576 ]\n",
      "Reset environment\n",
      "Episode reward: 1600.3577\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.547534 13.513421 13.537763 12.560892 12.677035 13.543979]\n",
      "Reset environment\n",
      "Episode reward: 4190.769\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.548868  13.5147505 13.539088  12.562328  12.678187  13.545313 ]\n",
      "Reset environment\n",
      "Episode reward: 2015.3933\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.549403 13.515308 13.539601 12.562923 12.678667 13.545847]\n",
      "Reset environment\n",
      "Episode reward: 1765.4077\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.54987  13.515777 13.540068 12.563444 12.679091 13.546313]\n",
      "Reset environment\n",
      "Episode reward: -344.35947\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.54915  13.515027 13.539377 12.562573 12.678435 13.545596]\n",
      "Reset environment\n",
      "Episode reward: 4474.1763\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.550572 13.516437 13.540791 12.564089 12.679697 13.547014]\n",
      "Reset environment\n",
      "Episode reward: 2223.5586\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.551167  13.5170145 13.5414    12.564744  12.680205  13.547608 ]\n",
      "Reset environment\n",
      "Episode reward: 1993.3007\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.551722 13.517568 13.541958 12.565352 12.680712 13.548163]\n",
      "Reset environment\n",
      "Episode reward: 1688.8828\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.552006 13.51782  13.542265 12.565695 12.680963 13.548452]\n",
      "Reset environment\n",
      "Episode reward: 2005.2255\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.552815 13.518631 13.543072 12.566577 12.681679 13.549262]\n",
      "Reset environment\n",
      "Episode reward: 3623.2847\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.553926  13.519743  13.54417   12.5677805 12.682646  13.550373 ]\n",
      "Reset environment\n",
      "Episode reward: 4826.5054\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.555468 13.521269 13.545706 12.569429 12.684023 13.55191 ]\n",
      "Reset environment\n",
      "Episode reward: 2312.2092\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.556057  13.521838  13.546314  12.570075  12.6845255 13.552499 ]\n",
      "Reset environment\n",
      "Episode reward: 1908.5952\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.556507 13.522306 13.546737 12.570583 12.684907 13.55295 ]\n",
      "Reset environment\n",
      "Episode reward: 391.64563\n",
      "Total Steps: 13\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.556513 13.522312 13.546742 12.570616 12.684904 13.552956]\n",
      "Reset environment\n",
      "Episode reward: 2351.3481\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.557142 13.522959 13.547361 12.57131  12.685473 13.553585]\n",
      "Reset environment\n",
      "Episode reward: 6186.223\n",
      "Total Steps: 209\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.559159 13.524979 13.549362 12.573469 12.687253 13.555599]\n",
      "Reset environment\n",
      "Episode reward: 3652.5232\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.560292 13.526109 13.55049  12.574696 12.688242 13.55673 ]\n",
      "Reset environment\n",
      "Episode reward: 1750.7087\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.56076  13.52656  13.550966 12.575213 12.688638 13.557197]\n",
      "Reset environment\n",
      "Episode reward: 1729.8386\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.56122  13.527022 13.551427 12.575728 12.689055 13.557657]\n",
      "Reset environment\n",
      "Episode reward: 5350.1304\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.562887 13.528697 13.553089 12.577529 12.69059  13.559324]\n",
      "Reset environment\n",
      "Episode reward: 1332.7231\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.563257 13.529065 13.553463 12.577942 12.69093  13.559695]\n",
      "Reset environment\n",
      "Episode reward: 867.7957\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.563452 13.529258 13.55366  12.57817  12.691099 13.55989 ]\n",
      "Reset environment\n",
      "Episode reward: 1976.1332\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.563977 13.529775 13.554196 12.578752 12.69158  13.560415]\n",
      "Reset environment\n",
      "Episode reward: 1362.7963\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.564341 13.530137 13.554565 12.579161 12.691912 13.56078 ]\n",
      "Reset environment\n",
      "Episode reward: 1854.3921\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.564895 13.530689 13.555122 12.579764 12.692422 13.561334]\n",
      "Reset environment\n",
      "Episode reward: 1764.7137\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.565614 13.531408 13.55584  12.580553 12.693058 13.562052]\n",
      "Reset environment\n",
      "Episode reward: 2011.0892\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.566129 13.53194  13.556336 12.581122 12.693516 13.562568]\n",
      "Reset environment\n",
      "Episode reward: 2069.1199\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.566956 13.532771 13.557162 12.582025 12.694246 13.563395]\n",
      "Reset environment\n",
      "Episode reward: 5286.3047\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.568649  13.53446   13.5588455 12.583864  12.6957245 13.565089 ]\n",
      "Reset environment\n",
      "Episode reward: 1897.4757\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.569165  13.534978  13.5593605 12.584436  12.696191  13.565605 ]\n",
      "Reset environment\n",
      "Episode reward: 1871.669\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.569701 13.535519 13.559896 12.585033 12.696684 13.566141]\n",
      "Reset environment\n",
      "Episode reward: 2003.1317\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.57017  13.536007 13.560345 12.585565 12.697098 13.56661 ]\n",
      "Reset environment\n",
      "Episode reward: 1764.84\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.570889 13.536729 13.561062 12.586354 12.697735 13.567329]\n",
      "Reset environment\n",
      "Episode reward: 1400.3113\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.57122  13.537078 13.561376 12.586727 12.698025 13.56766 ]\n",
      "Reset environment\n",
      "Episode reward: 3508.7522\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.572297 13.538158 13.562448 12.587889 12.69897  13.568738]\n",
      "Reset environment\n",
      "Episode reward: 4907.5317\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.573846 13.539691 13.564    12.589556 12.700355 13.570283]\n",
      "Reset environment\n",
      "Episode reward: 4855.327\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.575329  13.541177  13.565486  12.591156  12.7016945 13.571766 ]\n",
      "Reset environment\n",
      "Episode reward: 2308.1206\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.576232 13.542074 13.566385 12.592137 12.70249  13.572668]\n",
      "Reset environment\n",
      "Episode reward: 1344.3903\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.576578 13.542415 13.566737 12.592523 12.702798 13.573013]\n",
      "Reset environment\n",
      "Episode reward: 3254.5173\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.577528 13.543367 13.567688 12.593555 12.703656 13.573964]\n",
      "Reset environment\n",
      "Episode reward: 1471.9927\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.577926 13.543763 13.568088 12.593997 12.704018 13.57436 ]\n",
      "Reset environment\n",
      "Episode reward: 2907.294\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.578798  13.544642  13.5689535 12.594943  12.704792  13.5752325]\n",
      "Reset environment\n",
      "Episode reward: 5164.3154\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.580451  13.546297  13.5706005 12.596723  12.706236  13.576888 ]\n",
      "Reset environment\n",
      "Episode reward: 980.99963\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.580222 13.546103 13.570351 12.596459 12.706027 13.576668]\n",
      "Reset environment\n",
      "Episode reward: 1349.814\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.580587 13.546468 13.570718 12.596873 12.70636  13.577035]\n",
      "Reset environment\n",
      "Episode reward: 3258.6758\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.581584  13.54747   13.5717125 12.597958  12.707237  13.578033 ]\n",
      "Reset environment\n",
      "Episode reward: 3108.9194\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5823345 13.548243  13.572439  12.598791  12.707918  13.578784 ]\n",
      "Reset environment\n",
      "Episode reward: 3457.283\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.583377  13.549265  13.5734825 12.599914  12.708834  13.579825 ]\n",
      "Reset environment\n",
      "Episode reward: 2302.0352\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.584029 13.549921 13.574135 12.600633 12.709418 13.580478]\n",
      "Reset environment\n",
      "Episode reward: -281.65063\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.583201  13.549148  13.5732565 12.599784  12.708668  13.579654 ]\n",
      "Reset environment\n",
      "Episode reward: 2562.6294\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.583919 13.549858 13.573987 12.600572 12.709316 13.580371]\n",
      "Reset environment\n",
      "Episode reward: 5556.318\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.585695 13.551628 13.575756 12.602485 12.710871 13.582144]\n",
      "Reset environment\n",
      "Episode reward: 1312.4133\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5860405 13.551981  13.576091  12.602875  12.711183  13.582488 ]\n",
      "Reset environment\n",
      "Episode reward: -55.946228\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.5854025 13.551307  13.575498  12.602177  12.710609  13.581854 ]\n",
      "Reset environment\n",
      "Episode reward: 1937.1549\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.585971 13.551885 13.576061 12.602798 12.71113  13.582423]\n",
      "Reset environment\n",
      "Episode reward: 2245.3643\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.586589 13.552489 13.576697 12.603477 12.711667 13.583041]\n",
      "Reset environment\n",
      "Episode reward: 1782.9508\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.587012  13.5529375 13.5771    12.603956  12.71204   13.583465 ]\n",
      "Reset environment\n",
      "Episode reward: 1972.5522\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.587492 13.553397 13.577601 12.604496 12.712448 13.583944]\n",
      "Reset environment\n",
      "Episode reward: 1937.8843\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.588019 13.553926 13.578129 12.60508  12.712928 13.584473]\n",
      "Reset environment\n",
      "Episode reward: 3795.4583\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.589176 13.555068 13.579279 12.606332 12.713948 13.585618]\n",
      "Reset environment\n",
      "Episode reward: 2129.7737\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.589651 13.555525 13.579776 12.60687  12.714357 13.586096]\n",
      "Reset environment\n",
      "Episode reward: 4742.638\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.591156 13.557034 13.581279 12.608488 12.715673 13.587604]\n",
      "Reset environment\n",
      "Episode reward: 3498.856\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.592229 13.558107 13.582342 12.609652 12.716611 13.588676]\n",
      "Reset environment\n",
      "Episode reward: 2426.4548\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.592757  13.5586605 13.582848  12.6102495 12.717094  13.589205 ]\n",
      "Reset environment\n",
      "Episode reward: 2067.8232\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.593336  13.559244  13.583424  12.6108885 12.717622  13.589785 ]\n",
      "Reset environment\n",
      "Episode reward: 2420.7844\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.594053 13.559963 13.584138 12.611666 12.718269 13.590502]\n",
      "Reset environment\n",
      "Episode reward: 1679.042\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.594392 13.560274 13.584496 12.612064 12.718556 13.590847]\n",
      "Reset environment\n",
      "Episode reward: 4776.4805\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.595924 13.561796 13.586021 12.613707 12.719878 13.592378]\n",
      "Reset environment\n",
      "Episode reward: 1819.5388\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.596409 13.562268 13.586527 12.614248 12.720309 13.592864]\n",
      "Reset environment\n",
      "Episode reward: 5255.2285\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.598098 13.563958 13.588204 12.616069 12.721775 13.594553]\n",
      "Reset environment\n",
      "Episode reward: 1625.5555\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.598558 13.56443  13.588656 12.616574 12.722195 13.595014]\n",
      "Reset environment\n",
      "Episode reward: -136.35947\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.59776  13.563719 13.587798 12.615795 12.721471 13.594224]\n",
      "Reset environment\n",
      "Episode reward: 2126.9114\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.598582 13.564542 13.588622 12.616703 12.722191 13.595046]\n",
      "Reset environment\n",
      "Episode reward: 1543.2471\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.598995  13.564953  13.589035  12.6171665 12.722563  13.595459 ]\n",
      "Reset environment\n",
      "Episode reward: 2552.9634\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.599711 13.565664 13.589758 12.617963 12.723216 13.596176]\n",
      "Reset environment\n",
      "Episode reward: 1973.6215\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.600232 13.566191 13.590274 12.618546 12.723686 13.596698]\n",
      "Reset environment\n",
      "Episode reward: 1975.1013\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.600768 13.566731 13.590803 12.619135 12.724175 13.597234]\n",
      "Reset environment\n",
      "Episode reward: 2053.3909\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.601335 13.567315 13.591358 12.619759 12.724681 13.5978  ]\n",
      "Reset environment\n",
      "Episode reward: 1566.7128\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.601748 13.56773  13.591772 12.620221 12.725058 13.598214]\n",
      "Reset environment\n",
      "Episode reward: 1647.9553\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.602236  13.568213  13.592262  12.620757  12.725499  13.5987015]\n",
      "Reset environment\n",
      "Episode reward: 3689.442\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.603377 13.569349 13.593401 12.621988 12.726494 13.599845]\n",
      "Reset environment\n",
      "Episode reward: 2621.6216\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.604068  13.570017  13.594111  12.622751  12.727102  13.6005335]\n",
      "Reset environment\n",
      "Episode reward: 1946.4979\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.60459  13.570531 13.594639 12.623333 12.727574 13.601057]\n",
      "Reset environment\n",
      "Episode reward: 2262.8398\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.605224 13.571163 13.595277 12.624027 12.728147 13.60169 ]\n",
      "Reset environment\n",
      "Episode reward: 2008.9287\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.605745 13.571697 13.595786 12.624614 12.728613 13.602213]\n",
      "Reset environment\n",
      "Episode reward: 873.9339\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.605936 13.571891 13.595967 12.624837 12.728773 13.602405]\n",
      "Reset environment\n",
      "Episode reward: 5174.798\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.607581 13.573535 13.597608 12.626606 12.730222 13.604048]\n",
      "Reset environment\n",
      "Episode reward: 5182.815\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.609255  13.575206  13.5992775 12.628395  12.731684  13.605723 ]\n",
      "Reset environment\n",
      "Episode reward: 3314.12\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.610272 13.576227 13.600292 12.629496 12.732579 13.606741]\n",
      "Reset environment\n",
      "Episode reward: 1196.4811\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.610555 13.576524 13.600561 12.629812 12.732833 13.607022]\n",
      "Reset environment\n",
      "Episode reward: 2465.101\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.611256 13.577228 13.601262 12.630586 12.733457 13.607724]\n",
      "Reset environment\n",
      "Episode reward: 2837.7021\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.612051  13.578012  13.602074  12.63145   12.734187  13.6085205]\n",
      "Reset environment\n",
      "Episode reward: 1280.3365\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.612369 13.578324 13.602398 12.631813 12.734466 13.60884 ]\n",
      "Reset environment\n",
      "Episode reward: 5049.499\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.613985 13.579943 13.604004 12.633547 12.735877 13.610454]\n",
      "Reset environment\n",
      "Episode reward: 3142.1096\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.614925 13.580894 13.604935 12.634568 12.736709 13.611395]\n",
      "Reset environment\n",
      "Episode reward: 1734.3043\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.615296  13.58129   13.605282  12.6349945 12.737046  13.611765 ]\n",
      "Reset environment\n",
      "Episode reward: 1903.2102\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.615804 13.58181  13.605771 12.635552 12.737479 13.612272]\n",
      "Reset environment\n",
      "Episode reward: 5117.071\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.617451 13.583452 13.607413 12.637316 12.738929 13.613918]\n",
      "Reset environment\n",
      "Episode reward: 1660.0188\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.6179    13.583905  13.607859  12.6378145 12.739338  13.6143675]\n",
      "Reset environment\n",
      "Episode reward: 1742.4866\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.618604 13.584611 13.608562 12.638586 12.739966 13.615071]\n",
      "Reset environment\n",
      "Episode reward: 1371.6732\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.619175 13.585185 13.609135 12.639221 12.740482 13.615643]\n",
      "Reset environment\n",
      "Episode reward: 4746.834\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.6206875 13.586699  13.610639  12.640845  12.741823  13.617155 ]\n",
      "Reset environment\n",
      "Episode reward: 2482.5298\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.621383  13.5873995 13.611325  12.641613  12.742447  13.617849 ]\n",
      "Reset environment\n",
      "Episode reward: 2166.9487\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.621975 13.587986 13.611922 12.642265 12.742987 13.618443]\n",
      "Reset environment\n",
      "Episode reward: 1587.9387\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.622385 13.588412 13.612309 12.642715 12.743351 13.618851]\n",
      "Reset environment\n",
      "Episode reward: 1863.8729\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.623135 13.589163 13.613059 12.643532 12.744018 13.619601]\n",
      "Reset environment\n",
      "Episode reward: 1416.084\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.623723 13.589753 13.613648 12.64418  12.74455  13.62019 ]\n",
      "Reset environment\n",
      "Episode reward: 1992.5189\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.624295  13.590328  13.614219  12.644813  12.7450695 13.620762 ]\n",
      "Reset environment\n",
      "Episode reward: 1538.0552\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.624709 13.590734 13.614642 12.645272 12.745441 13.621177]\n",
      "Reset environment\n",
      "Episode reward: 1840.6615\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.625188 13.591211 13.615125 12.64581  12.745874 13.621655]\n",
      "Reset environment\n",
      "Episode reward: 1477.3912\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.625615  13.5916395 13.615552  12.646282  12.746267  13.622083 ]\n",
      "Reset environment\n",
      "Episode reward: 2238.148\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.626244 13.592273 13.616176 12.646974 12.746833 13.62271 ]\n",
      "Reset environment\n",
      "Episode reward: 5211.756\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.627886 13.593914 13.6178   12.648761 12.748262 13.624355]\n",
      "Reset environment\n",
      "Episode reward: 1396.1404\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.628464 13.594492 13.618378 12.649397 12.748785 13.624932]\n",
      "Reset environment\n",
      "Episode reward: 2160.2244\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.629307 13.595334 13.61922  12.650316 12.749526 13.625776]\n",
      "Reset environment\n",
      "Episode reward: 1313.255\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.629647 13.595683 13.619553 12.650701 12.749832 13.626115]\n",
      "Reset environment\n",
      "Episode reward: 3858.5732\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.630848 13.596879 13.62074  12.651993 12.750878 13.627316]\n",
      "Reset environment\n",
      "Episode reward: 3160.468\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.631788 13.597829 13.621677 12.653023 12.751715 13.628258]\n",
      "Reset environment\n",
      "Episode reward: 3406.8232\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.632797 13.598823 13.622696 12.654124 12.752604 13.629266]\n",
      "Reset environment\n",
      "Episode reward: 1722.837\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.633202 13.599208 13.623117 12.654575 12.752938 13.629672]\n",
      "Reset environment\n",
      "Episode reward: 1597.348\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.633628 13.599638 13.623531 12.655048 12.75332  13.630098]\n",
      "Reset environment\n",
      "Episode reward: 1563.8926\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.634028 13.600057 13.623918 12.655493 12.753676 13.630499]\n",
      "Reset environment\n",
      "Episode reward: 2176.5\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.634583 13.600594 13.624491 12.656114 12.754141 13.631055]\n",
      "Reset environment\n",
      "Episode reward: 1379.1768\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.63515  13.601161 13.625058 12.656745 12.754649 13.631621]\n",
      "Reset environment\n",
      "Episode reward: 1979.2408\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.635686 13.601694 13.625594 12.657338 12.755136 13.632156]\n",
      "Reset environment\n",
      "Episode reward: 2618.0286\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.63643  13.602446 13.62633  12.658154 12.755796 13.632901]\n",
      "Reset environment\n",
      "Episode reward: 3008.2444\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.637342 13.603362 13.627237 12.65914  12.756635 13.633812]\n",
      "Reset environment\n",
      "Episode reward: 1646.5757\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.6377125 13.603709  13.62763   12.659563  12.756952  13.634185 ]\n",
      "Reset environment\n",
      "Episode reward: 3208.925\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.638643 13.604632 13.628574 12.660575 12.757793 13.635115]\n",
      "Reset environment\n",
      "Episode reward: 2440.872\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.639302 13.605292 13.629233 12.661297 12.758396 13.635774]\n",
      "Reset environment\n",
      "Episode reward: 2142.689\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.639897 13.605886 13.629828 12.661954 12.758935 13.63637 ]\n",
      "Reset environment\n",
      "Episode reward: 2083.8494\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.640713 13.606707 13.630643 12.662844 12.759648 13.637185]\n",
      "Reset environment\n",
      "Episode reward: 2924.6433\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.641545  13.607524  13.631487  12.6637535 12.760407  13.638019 ]\n",
      "Reset environment\n",
      "Episode reward: 1109.8679\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.641825  13.6078005 13.631767  12.66407   12.76066   13.638299 ]\n",
      "Reset environment\n",
      "Episode reward: 4458.1484\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.643223 13.609191 13.633159 12.665576 12.761911 13.639688]\n",
      "Reset environment\n",
      "Episode reward: 4822.942\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.644755 13.610718 13.634672 12.667223 12.763239 13.641214]\n",
      "Reset environment\n",
      "Episode reward: 3015.4392\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.645501 13.611415 13.635442 12.668045 12.763892 13.64196 ]\n",
      "Reset environment\n",
      "Episode reward: 1863.5989\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.646001 13.611912 13.635947 12.6686   12.764347 13.642461]\n",
      "Reset environment\n",
      "Episode reward: 2680.5547\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.646744 13.61264  13.636701 12.669417 12.765008 13.643198]\n",
      "Reset environment\n",
      "Episode reward: 1381.2219\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.647312 13.61321  13.63727  12.670047 12.76552  13.643766]\n",
      "Reset environment\n",
      "Episode reward: 1093.0253\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.646842 13.612626 13.636923 12.669654 12.765069 13.643305]\n",
      "Reset environment\n",
      "Episode reward: 1526.2245\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.647227 13.613025 13.637294 12.670087 12.765419 13.643689]\n",
      "Reset environment\n",
      "Episode reward: 1936.2709\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.647746 13.61355  13.63781  12.670659 12.765891 13.644208]\n",
      "Reset environment\n",
      "Episode reward: 1386.8152\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.648323 13.614128 13.638387 12.671293 12.766414 13.644785]\n",
      "Reset environment\n",
      "Episode reward: 1774.9563\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.649037 13.614841 13.639101 12.672071 12.76705  13.645499]\n",
      "Reset environment\n",
      "Episode reward: 1886.065\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.649457 13.615283 13.639502 12.672549 12.767435 13.645918]\n",
      "Reset environment\n",
      "Episode reward: 2101.347\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.649985 13.615794 13.640046 12.673134 12.767892 13.646447]\n",
      "Reset environment\n",
      "Episode reward: 2237.2842\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.6508465 13.616658  13.640905  12.67408   12.768645  13.647308 ]\n",
      "Reset environment\n",
      "Episode reward: 4613.425\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.652301 13.61811  13.642358 12.675632 12.769919 13.648762]\n",
      "Reset environment\n",
      "Episode reward: 2754.2253\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.653084  13.6189    13.643131  12.676484  12.7706175 13.649545 ]\n",
      "Reset environment\n",
      "Episode reward: 1668.1958\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.6534605 13.619288  13.643485  12.676913  12.7709465 13.649922 ]\n",
      "Reset environment\n",
      "Episode reward: 1927.9136\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.653961 13.61978  13.643995 12.677467 12.771399 13.650423]\n",
      "Reset environment\n",
      "Episode reward: 3897.178\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.6551485 13.62097   13.645183  12.678754  12.772447  13.651612 ]\n",
      "Reset environment\n",
      "Episode reward: 2479.724\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.655834 13.621665 13.645858 12.679503 12.773076 13.652298]\n",
      "Reset environment\n",
      "Episode reward: 3550.947\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.656921 13.622759 13.646945 12.680677 12.774027 13.653386]\n",
      "Reset environment\n",
      "Episode reward: 5006.978\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.658511 13.624344 13.648518 12.682392 12.775405 13.654973]\n",
      "Reset environment\n",
      "Episode reward: 1554.0972\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.658928 13.624758 13.648939 12.682856 12.775786 13.655392]\n",
      "Reset environment\n",
      "Episode reward: 2548.0503\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.659653 13.625482 13.649666 12.683653 12.77643  13.656116]\n",
      "Reset environment\n",
      "Episode reward: 4680.975\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.661058 13.62689  13.65107  12.685175 12.777702 13.65752 ]\n",
      "Reset environment\n",
      "Episode reward: 3695.531\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.662183 13.627998 13.652194 12.686385 12.778699 13.658643]\n",
      "Reset environment\n",
      "Episode reward: 665.93286\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.661885 13.627736 13.651857 12.685994 12.778455 13.658351]\n",
      "Reset environment\n",
      "Episode reward: 5148.6333\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.663538 13.629379 13.653514 12.687766 12.77989  13.66    ]\n",
      "Reset environment\n",
      "Episode reward: 1991.0409\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.664307  13.63015   13.654282  12.688611  12.78057   13.6607685]\n",
      "Reset environment\n",
      "Episode reward: 664.0596\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.663987 13.62989  13.653907 12.688202 12.780302 13.660454]\n",
      "Reset environment\n",
      "Episode reward: 2707.8872\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.664736  13.630627  13.654665  12.689015  12.780986  13.6612015]\n",
      "Reset environment\n",
      "Episode reward: 4065.223\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.666002 13.631883 13.655927 12.690387 12.782091 13.662468]\n",
      "Reset environment\n",
      "Episode reward: 3231.835\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.666962 13.632836 13.656892 12.691428 12.782943 13.663428]\n",
      "Reset environment\n",
      "Episode reward: 1670.1755\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.667416 13.633291 13.657346 12.691933 12.783358 13.663882]\n",
      "Reset environment\n",
      "Episode reward: 1706.1458\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.667883 13.633751 13.657826 12.692449 12.783778 13.664351]\n",
      "Reset environment\n",
      "Episode reward: 1846.8635\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.668364 13.634249 13.658286 12.692978 12.784212 13.664828]\n",
      "Reset environment\n",
      "Episode reward: 1643.1715\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.668755 13.634624 13.658693 12.693422 12.784542 13.665223]\n",
      "Reset environment\n",
      "Episode reward: 2880.1785\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.669575 13.63544  13.659513 12.694326 12.785256 13.666043]\n",
      "Reset environment\n",
      "Episode reward: 5342.1953\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.671287 13.637144 13.661221 12.696163 12.786746 13.66775 ]\n",
      "Reset environment\n",
      "Episode reward: 1603.9822\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.671715  13.637571  13.661653  12.696638  12.787137  13.6681795]\n",
      "Reset environment\n",
      "Episode reward: 1381.1449\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.67206  13.637903 13.662009 12.697022 12.787435 13.668526]\n",
      "Reset environment\n",
      "Episode reward: 4613.68\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.673514 13.639354 13.663462 12.698584 12.788731 13.669977]\n",
      "Reset environment\n",
      "Episode reward: 1805.8173\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.674035 13.639878 13.663981 12.699156 12.789211 13.670498]\n",
      "Reset environment\n",
      "Episode reward: -427.0326\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.673202  13.6390705 13.663124  12.69829   12.788446  13.669663 ]\n",
      "Reset environment\n",
      "Episode reward: 1682.178\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.673694  13.6395645 13.663611  12.69883   12.788896  13.670156 ]\n",
      "Reset environment\n",
      "Episode reward: 2092.549\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.674244 13.640108 13.664174 12.699439 12.7894   13.670707]\n",
      "Reset environment\n",
      "Episode reward: 3438.2712\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.675287 13.641158 13.665212 12.700565 12.790314 13.67175 ]\n",
      "Reset environment\n",
      "Episode reward: 1783.1394\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.675752  13.641611  13.665689  12.701081  12.790708  13.6722145]\n",
      "Reset environment\n",
      "Episode reward: 1409.3168\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.676333 13.642193 13.66627  12.701723 12.791233 13.672795]\n",
      "Reset environment\n",
      "Episode reward: 4360.2812\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.677683  13.643539  13.667607  12.7031765 12.792405  13.67414  ]\n",
      "Reset environment\n",
      "Episode reward: 1998.2278\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.678198 13.644047 13.668135 12.703748 12.792877 13.674657]\n",
      "Reset environment\n",
      "Episode reward: 2290.0718\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.679077 13.644921 13.66901  12.704713 12.793649 13.675537]\n",
      "Reset environment\n",
      "Episode reward: 1923.4738\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.67958   13.645421  13.669518  12.705273  12.7941065 13.67604  ]\n",
      "Reset environment\n",
      "Episode reward: 3385.6296\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.680562 13.646411 13.670491 12.70635  12.794972 13.677022]\n",
      "Reset environment\n",
      "Episode reward: 1563.5826\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.680939 13.646772 13.670887 12.706774 12.795306 13.677402]\n",
      "Reset environment\n",
      "Episode reward: 1874.6198\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.68143  13.647279 13.671369 12.707321 12.795758 13.677894]\n",
      "Reset environment\n",
      "Episode reward: 4719.534\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.682918 13.648773 13.672844 12.708926 12.797054 13.679379]\n",
      "Reset environment\n",
      "Episode reward: 5146.7407\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.684559 13.650411 13.674473 12.71069  12.798499 13.68102 ]\n",
      "Reset environment\n",
      "Episode reward: 3980.8264\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.685801  13.651654  13.675713  12.712023  12.799573  13.6822605]\n",
      "Reset environment\n",
      "Episode reward: 1775.0857\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.68615   13.651981  13.676084  12.712437  12.799893  13.6826105]\n",
      "Reset environment\n",
      "Episode reward: 4081.9548\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.687343 13.653181 13.677269 12.713748 12.800985 13.683803]\n",
      "Reset environment\n",
      "Episode reward: 1822.054\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.688068 13.653907 13.677994 12.714545 12.80163  13.684528]\n",
      "Reset environment\n",
      "Episode reward: 2486.1492\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.688792  13.6546335 13.678715  12.715347  12.802289  13.685253 ]\n",
      "Reset environment\n",
      "Episode reward: 3046.6135\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.689648 13.65549  13.67957  12.716283 12.80307  13.686108]\n",
      "Reset environment\n",
      "Episode reward: 696.718\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.689729 13.655558 13.679664 12.7164   12.803135 13.68619 ]\n",
      "Reset environment\n",
      "Episode reward: 1662.0289\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.690169 13.655993 13.680114 12.71689  12.803534 13.68663 ]\n",
      "Reset environment\n",
      "Episode reward: 2001.5934\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.690668 13.656471 13.680627 12.717443 12.803948 13.687129]\n",
      "Reset environment\n",
      "Episode reward: 3675.499\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.691775 13.657586 13.681731 12.718641 12.804926 13.688237]\n",
      "Reset environment\n",
      "Episode reward: 1524.4915\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.692087 13.657876 13.682064 12.718999 12.805207 13.688549]\n",
      "Reset environment\n",
      "Episode reward: 1972.0016\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.692509 13.658265 13.682525 12.719492 12.805591 13.688978]\n",
      "Reset environment\n",
      "Episode reward: 5143.4614\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.694142 13.659895 13.684158 12.721233 12.807044 13.690608]\n",
      "Reset environment\n",
      "Episode reward: 1605.3229\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.694573 13.660325 13.684595 12.721713 12.807438 13.691041]\n",
      "Reset environment\n",
      "Episode reward: 2535.8118\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.695166  13.660935  13.6851635 12.722368  12.807963  13.691634 ]\n",
      "Reset environment\n",
      "Episode reward: 1113.2576\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.695444 13.661212 13.685446 12.722686 12.808214 13.691913]\n",
      "Reset environment\n",
      "Episode reward: 6050.6396\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.697391 13.663156 13.687397 12.724769 12.809896 13.69386 ]\n",
      "Reset environment\n",
      "Episode reward: 1848.6093\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.6979265 13.663689  13.687937  12.725351  12.810388  13.694396 ]\n",
      "Reset environment\n",
      "Episode reward: 3566.8127\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.698986  13.664758  13.688991  12.726503  12.811309  13.6954565]\n",
      "Reset environment\n",
      "Episode reward: 3991.5417\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.700199  13.66595   13.6902075 12.727807  12.812388  13.696663 ]\n",
      "Reset environment\n",
      "Episode reward: 2479.0105\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.700828 13.66656  13.690855 12.728505 12.812938 13.697292]\n",
      "Reset environment\n",
      "Episode reward: 4551.551\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.70219  13.667924 13.692219 12.729974 12.814178 13.698655]\n",
      "Reset environment\n",
      "Episode reward: 1595.8102\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.702628 13.668356 13.69266  12.730457 12.814577 13.699093]\n",
      "Reset environment\n",
      "Episode reward: 4545.5757\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.704045 13.669773 13.69407  12.731983 12.8158   13.700511]\n",
      "Reset environment\n",
      "Episode reward: 152.40054\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.703533 13.669304 13.693511 12.731351 12.815341 13.700003]\n",
      "Reset environment\n",
      "Episode reward: 2734.887\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7042885 13.670047  13.694281  12.732172  12.816026  13.700757 ]\n",
      "Reset environment\n",
      "Episode reward: 3341.3918\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.705298  13.671056  13.695289  12.733266  12.8169155 13.701769 ]\n",
      "Reset environment\n",
      "Episode reward: 2383.198\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.705913 13.671655 13.695917 12.733943 12.817476 13.702384]\n",
      "Reset environment\n",
      "Episode reward: 1894.9421\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.70643   13.6721735 13.696436  12.734519  12.817952  13.702903 ]\n",
      "Reset environment\n",
      "Episode reward: 2201.635\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.707286 13.673033 13.697292 12.735456 12.818704 13.703758]\n",
      "Reset environment\n",
      "Episode reward: 2231.2124\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.707865 13.673623 13.697858 12.736106 12.819222 13.704337]\n",
      "Reset environment\n",
      "Episode reward: 3327.1475\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.708874 13.674637 13.698865 12.737195 12.820119 13.705346]\n",
      "Reset environment\n",
      "Episode reward: 3825.8076\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.70999  13.675755 13.699979 12.73841  12.821145 13.706465]\n",
      "Reset environment\n",
      "Episode reward: 2567.6912\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.71072  13.676487 13.700709 12.739212 12.821812 13.707198]\n",
      "Reset environment\n",
      "Episode reward: 1815.3799\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.711194 13.67696  13.701187 12.739742 12.822243 13.707672]\n",
      "Reset environment\n",
      "Episode reward: 1208.4135\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.711456 13.677213 13.70146  12.74005  12.82247  13.707934]\n",
      "Reset environment\n",
      "Episode reward: 2484.7183\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.71217   13.677928  13.70217   12.740825  12.8231125 13.708645 ]\n",
      "Reset environment\n",
      "Episode reward: 3461.4949\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.71322  13.678983 13.703217 12.741964 12.824029 13.709696]\n",
      "Reset environment\n",
      "Episode reward: 2823.9644\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.714049  13.679815  13.704044  12.742865  12.824765  13.7105255]\n",
      "Reset environment\n",
      "Episode reward: 2337.5293\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.714645 13.680397 13.704656 12.743525 12.825305 13.711122]\n",
      "Reset environment\n",
      "Episode reward: 2901.2014\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.715466 13.681226 13.705474 12.74443  12.826027 13.711943]\n",
      "Reset environment\n",
      "Episode reward: 2156.0215\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.716292  13.682051  13.7063    12.745335  12.826755  13.7127695]\n",
      "Reset environment\n",
      "Episode reward: 5471.464\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.717948 13.683709 13.707956 12.747122 12.828282 13.714423]\n",
      "Reset environment\n",
      "Episode reward: 1793.1906\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.718296 13.684026 13.708336 12.747532 12.828595 13.714771]\n",
      "Reset environment\n",
      "Episode reward: 3116.6345\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.719222  13.6849575 13.709263  12.748534  12.829416  13.715697 ]\n",
      "Reset environment\n",
      "Episode reward: 2354.7107\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.719749  13.685452  13.709816  12.749129  12.8298855 13.716229 ]\n",
      "Reset environment\n",
      "Episode reward: 2575.992\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.72042   13.6861105 13.7105    12.749873  12.830493  13.716901 ]\n",
      "Reset environment\n",
      "Episode reward: 3341.819\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7214155 13.687111  13.7114935 12.7509575 12.831365  13.717896 ]\n",
      "Reset environment\n",
      "Episode reward: 2319.0845\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.721945 13.687611 13.712043 12.751568 12.83182  13.718431]\n",
      "Reset environment\n",
      "Episode reward: 2418.1138\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.72259  13.688245 13.7127   12.752275 12.83241  13.719077]\n",
      "Reset environment\n",
      "Episode reward: 2544.3713\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.72327  13.68894  13.713366 12.753024 12.833021 13.719756]\n",
      "Reset environment\n",
      "Episode reward: 4265.961\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7245455 13.690213  13.714642  12.754394  12.834175  13.721031 ]\n",
      "Reset environment\n",
      "Episode reward: 3152.5215\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.725479 13.691142 13.715577 12.75541  12.834996 13.721966]\n",
      "Reset environment\n",
      "Episode reward: 2989.7627\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.726165 13.691852 13.716241 12.75618  12.835624 13.722651]\n",
      "Reset environment\n",
      "Episode reward: 3150.1843\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.727065 13.692754 13.717142 12.757158 12.836439 13.723551]\n",
      "Reset environment\n",
      "Episode reward: 2764.4277\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7278185 13.693525  13.717879  12.757984  12.837104  13.724303 ]\n",
      "Reset environment\n",
      "Episode reward: 3661.9854\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.728933 13.694639 13.718987 12.759186 12.838083 13.725412]\n",
      "Reset environment\n",
      "Episode reward: -713.203\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.727881 13.693507 13.717995 12.758097 12.837092 13.724371]\n",
      "Reset environment\n",
      "Episode reward: 4890.1147\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7293415 13.694973  13.719452  12.759667  12.838439  13.725831 ]\n",
      "Reset environment\n",
      "Episode reward: 2262.0332\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.72993  13.695575 13.720032 12.760315 12.838979 13.726419]\n",
      "Reset environment\n",
      "Episode reward: 2357.7803\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.730517 13.696188 13.720591 12.760976 12.8395   13.727004]\n",
      "Reset environment\n",
      "Episode reward: 1551.5668\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.730929  13.696605  13.721002  12.7614355 12.839878  13.727417 ]\n",
      "Reset environment\n",
      "Episode reward: 2252.0508\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.731515 13.697202 13.721569 12.762083 12.840405 13.728003]\n",
      "Reset environment\n",
      "Episode reward: -181.17322\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.73069  13.696457 13.720681 12.761197 12.839675 13.727193]\n",
      "Reset environment\n",
      "Episode reward: 4122.3857\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.731976  13.697744  13.721961  12.762578  12.840795  13.7284775]\n",
      "Reset environment\n",
      "Episode reward: 1774.5725\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.732681 13.698445 13.722669 12.763346 12.841422 13.729181]\n",
      "Reset environment\n",
      "Episode reward: 1681.0577\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.733021 13.698758 13.723032 12.763741 12.841707 13.729526]\n",
      "Reset environment\n",
      "Episode reward: 3552.1885\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7340975 13.6998415 13.724104  12.764904  12.842648  13.730602 ]\n",
      "Reset environment\n",
      "Episode reward: 2174.2676\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.73494  13.700685 13.724947 12.765823 12.843391 13.731444]\n",
      "Reset environment\n",
      "Episode reward: 1825.7734\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.735384 13.701148 13.725379 12.76632  12.843795 13.731889]\n",
      "Reset environment\n",
      "Episode reward: 2101.2932\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.736192 13.701959 13.726185 12.767202 12.844503 13.732697]\n",
      "Reset environment\n",
      "Episode reward: 5251.5957\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.73786   13.7036295 13.727846  12.768993  12.845984  13.7343645]\n",
      "Reset environment\n",
      "Episode reward: 1693.2336\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.73836  13.70413  13.728347 12.769544 12.846445 13.734864]\n",
      "Reset environment\n",
      "Episode reward: 4075.1387\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.739566  13.705325  13.729558  12.7708435 12.847504  13.7360735]\n",
      "Reset environment\n",
      "Episode reward: 5200.9893\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7411995 13.706954  13.731188  12.772605  12.848928  13.737708 ]\n",
      "Reset environment\n",
      "Episode reward: 2174.1997\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.741743  13.707483  13.7317505 12.773208  12.8494005 13.738252 ]\n",
      "Reset environment\n",
      "Episode reward: 2871.7034\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.742556 13.708309 13.732555 12.77409  12.850132 13.739063]\n",
      "Reset environment\n",
      "Episode reward: 2097.212\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.743097 13.70884  13.733103 12.774689 12.850624 13.739604]\n",
      "Reset environment\n",
      "Episode reward: 2154.3499\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.743933 13.709678 13.733936 12.775599 12.851365 13.74044 ]\n",
      "Reset environment\n",
      "Episode reward: 1556.3906\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.744333  13.71008   13.734337  12.776057  12.8517275 13.740841 ]\n",
      "Reset environment\n",
      "Episode reward: 1671.4714\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.744764 13.710503 13.734773 12.776539 12.85212  13.741273]\n",
      "Reset environment\n",
      "Episode reward: 3577.345\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.745849 13.711593 13.735853 12.777707 12.853064 13.742356]\n",
      "Reset environment\n",
      "Episode reward: 3751.652\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.746993 13.712742 13.736996 12.778945 12.854055 13.743502]\n",
      "Reset environment\n",
      "Episode reward: 1786.331\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.747421  13.713185  13.7374115 12.779427  12.854427  13.74393  ]\n",
      "Reset environment\n",
      "Episode reward: 4125.0513\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.748678 13.71444  13.738669 12.780787 12.85552  13.745186]\n",
      "Reset environment\n",
      "Episode reward: 3105.991\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.749596 13.715359 13.739591 12.781786 12.85634  13.746104]\n",
      "Reset environment\n",
      "Episode reward: 1371.6797\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.750155  13.7159195 13.74015   12.782409  12.856846  13.746664 ]\n",
      "Reset environment\n",
      "Episode reward: 4597.585\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.75161  13.717378 13.741602 12.783969 12.858107 13.748118]\n",
      "Reset environment\n",
      "Episode reward: 282.6072\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.751055 13.716899 13.740981 12.783321 12.85763  13.747572]\n",
      "Reset environment\n",
      "Episode reward: 3674.6555\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.752164 13.718014 13.742082 12.78452  12.858594 13.748681]\n",
      "Reset environment\n",
      "Episode reward: 1487.0575\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.752497 13.718328 13.742433 12.784895 12.858886 13.749016]\n",
      "Reset environment\n",
      "Episode reward: 1381.9141\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.753059 13.718893 13.742997 12.785519 12.859396 13.74958 ]\n",
      "Reset environment\n",
      "Episode reward: 2934.0432\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.753907 13.719738 13.743852 12.786446 12.860143 13.750428]\n",
      "Reset environment\n",
      "Episode reward: 1643.1357\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.754248 13.720053 13.744222 12.786837 12.860449 13.750771]\n",
      "Reset environment\n",
      "Episode reward: 3639.6616\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.755333 13.721123 13.745311 12.788019 12.861393 13.751859]\n",
      "Reset environment\n",
      "Episode reward: 3072.134\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.756187 13.721979 13.746166 12.788957 12.862173 13.752714]\n",
      "Reset environment\n",
      "Episode reward: 2152.2742\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.757022 13.722817 13.747002 12.789871 12.862935 13.753549]\n",
      "Reset environment\n",
      "Episode reward: 2511.48\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.757723 13.723518 13.747707 12.790641 12.863559 13.754251]\n",
      "Reset environment\n",
      "Episode reward: 1980.697\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.758111  13.723886  13.748121  12.791106  12.86391   13.7546425]\n",
      "Reset environment\n",
      "Episode reward: 1699.2632\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.758292 13.724091 13.748273 12.791349 12.864064 13.754826]\n",
      "Reset environment\n",
      "Episode reward: 1778.7493\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.75876  13.724563 13.748739 12.791872 12.864488 13.755294]\n",
      "Reset environment\n",
      "Episode reward: 1339.4036\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.759124  13.724923  13.749107  12.7922735 12.864819  13.755658 ]\n",
      "Reset environment\n",
      "Episode reward: 2849.571\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7601185 13.725924  13.750099  12.793358  12.865685  13.756654 ]\n",
      "Reset environment\n",
      "Episode reward: 1262.3972\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.760431  13.726236  13.750414  12.793715  12.865971  13.7569685]\n",
      "Reset environment\n",
      "Episode reward: 1750.0712\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7608795 13.726675  13.7508745 12.79421   12.86636   13.757418 ]\n",
      "Reset environment\n",
      "Episode reward: 3836.7427\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.762027 13.727808 13.752018 12.795451 12.86737  13.758568]\n",
      "Reset environment\n",
      "Episode reward: 3812.6294\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.763191 13.728969 13.753173 12.796707 12.868387 13.759736]\n",
      "Reset environment\n",
      "Episode reward: 296.10306\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.762669 13.72839  13.752687 12.796128 12.86792  13.759223]\n",
      "Reset environment\n",
      "Episode reward: 2135.2542\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.763231 13.728946 13.75326  12.796748 12.868429 13.759786]\n",
      "Reset environment\n",
      "Episode reward: 594.99634\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.762947 13.728697 13.752936 12.796352 12.868204 13.759506]\n",
      "Reset environment\n",
      "Episode reward: 5647.302\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.764731  13.730482  13.754704  12.798265  12.8697815 13.761286 ]\n",
      "Reset environment\n",
      "Episode reward: 4415.8335\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.766084 13.731836 13.756056 12.799733 12.870961 13.76264 ]\n",
      "Reset environment\n",
      "Episode reward: 1952.712\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.766593  13.732349  13.756563  12.8003025 12.871423  13.763149 ]\n",
      "Reset environment\n",
      "Episode reward: 2463.2485\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.767241 13.732997 13.757211 12.801015 12.872007 13.763797]\n",
      "Reset environment\n",
      "Episode reward: 2222.8804\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7677965 13.733536  13.757786  12.80163   12.872483  13.764352 ]\n",
      "Reset environment\n",
      "Episode reward: 3279.5464\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.768759 13.734503 13.758746 12.802678 12.873322 13.765314]\n",
      "Reset environment\n",
      "Episode reward: 1477.315\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.769159 13.7349   13.759149 12.803125 12.873687 13.765715]\n",
      "Reset environment\n",
      "Episode reward: 4149.914\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.770437  13.736187  13.760421  12.8045025 12.874796  13.7669935]\n",
      "Reset environment\n",
      "Episode reward: 25.623688\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7698555 13.735648  13.759786  12.803841  12.874259  13.766414 ]\n",
      "Reset environment\n",
      "Episode reward: 2170.2063\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.770282 13.736097 13.76019  12.80433  12.874646 13.76684 ]\n",
      "Reset environment\n",
      "Episode reward: 2156.5728\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.771103 13.736921 13.761011 12.805227 12.875367 13.767661]\n",
      "Reset environment\n",
      "Episode reward: 4817.763\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7725935 13.738411  13.762484  12.8068285 12.876663  13.769148 ]\n",
      "Reset environment\n",
      "Episode reward: 3676.073\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.773677 13.739487 13.763569 12.807997 12.877626 13.77023 ]\n",
      "Reset environment\n",
      "Episode reward: 2554.9321\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.774397 13.74021  13.764285 12.808787 12.878263 13.77095 ]\n",
      "Reset environment\n",
      "Episode reward: 3953.8926\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.775606  13.741423  13.7654915 12.810097  12.879317  13.7721615]\n",
      "Reset environment\n",
      "Episode reward: 3249.099\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.776568  13.742378  13.7664585 12.811136  12.880166  13.773125 ]\n",
      "Reset environment\n",
      "Episode reward: 2480.0479\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.777494 13.743307 13.767384 12.812148 12.880974 13.774052]\n",
      "Reset environment\n",
      "Episode reward: 1631.3217\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.777947 13.74375  13.767842 12.81264  12.881382 13.774505]\n",
      "Reset environment\n",
      "Episode reward: 2894.6353\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.778763 13.744583 13.768639 12.813526 12.88211  13.775318]\n",
      "Reset environment\n",
      "Episode reward: 1616.7561\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7791605 13.744981  13.769037  12.813978  12.882467  13.775716 ]\n",
      "Reset environment\n",
      "Episode reward: 4387.88\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.780523 13.746349 13.770393 12.815446 12.883659 13.777079]\n",
      "Reset environment\n",
      "Episode reward: 5046.6987\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.782111 13.747933 13.771976 12.817147 12.885037 13.778667]\n",
      "Reset environment\n",
      "Episode reward: 2409.668\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.782753 13.748586 13.772607 12.81785  12.885624 13.779309]\n",
      "Reset environment\n",
      "Episode reward: 2202.047\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.783596  13.749426  13.773451  12.8187685 12.886372  13.780151 ]\n",
      "Reset environment\n",
      "Episode reward: 2149.643\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.784188  13.7500105 13.774049  12.819423  12.886914  13.780745 ]\n",
      "Reset environment\n",
      "Episode reward: 1803.0938\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.784661 13.750472 13.774529 12.819945 12.887342 13.781218]\n",
      "Reset environment\n",
      "Episode reward: 2186.266\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.785256 13.751072 13.775122 12.820599 12.887883 13.781814]\n",
      "Reset environment\n",
      "Episode reward: 4170.4883\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.786523 13.752344 13.77638  12.821968 12.889007 13.783082]\n",
      "Reset environment\n",
      "Episode reward: 2260.524\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.787381  13.7532015 13.777242  12.822904  12.889762  13.783942 ]\n",
      "Reset environment\n",
      "Episode reward: 1574.2307\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.78781  13.753635 13.777668 12.823386 12.89015  13.784371]\n",
      "Reset environment\n",
      "Episode reward: 2110.245\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.788373 13.754186 13.778237 12.824004 12.890657 13.784935]\n",
      "Reset environment\n",
      "Episode reward: 1413.5562\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.788944 13.754758 13.778808 12.824635 12.891175 13.785506]\n",
      "Reset environment\n",
      "Episode reward: 2275.6946\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.789488 13.755285 13.779371 12.825233 12.891645 13.786049]\n",
      "Reset environment\n",
      "Episode reward: 1759.5168\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.789951  13.7557335 13.779845  12.825743  12.892053  13.786513 ]\n",
      "Reset environment\n",
      "Episode reward: 1900.8989\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.790384 13.756137 13.780302 12.826237 12.892444 13.786953]\n",
      "Reset environment\n",
      "Episode reward: 1894.4805\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.790873 13.75662  13.780794 12.826782 12.892889 13.787441]\n",
      "Reset environment\n",
      "Episode reward: 2419.9194\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.7913475 13.757118  13.781245  12.82733   12.893315  13.787916 ]\n",
      "Reset environment\n",
      "Episode reward: 3987.6802\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.792569 13.758332 13.782467 12.828641 12.894381 13.789142]\n",
      "Reset environment\n",
      "Episode reward: 1028.0635\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.792777 13.758541 13.782674 12.828897 12.894562 13.78935 ]\n",
      "Reset environment\n",
      "Episode reward: 6080.3\n",
      "Total Steps: 203\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.794721  13.760488  13.784608  12.8309765 12.896278  13.791293 ]\n",
      "Reset environment\n",
      "Episode reward: 2208.62\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.79507  13.760865 13.784932 12.831401 12.896587 13.791642]\n",
      "Reset environment\n",
      "Episode reward: 2443.0884\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.795755 13.761553 13.785618 12.832152 12.8972   13.792329]\n",
      "Reset environment\n",
      "Episode reward: 1714.8763\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.796427 13.762227 13.786289 12.83289  12.897798 13.793   ]\n",
      "Reset environment\n",
      "Episode reward: 4789.726\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.797921 13.76372  13.787784 12.834507 12.899087 13.794495]\n",
      "Reset environment\n",
      "Episode reward: 2877.4485\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.798706  13.7645235 13.788551  12.835365  12.899807  13.7952795]\n",
      "Reset environment\n",
      "Episode reward: 1533.728\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.799112 13.764931 13.788958 12.83582  12.900179 13.795686]\n",
      "Reset environment\n",
      "Episode reward: 2669.264\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.799699 13.765492 13.789571 12.836493 12.900697 13.796274]\n",
      "Reset environment\n",
      "Episode reward: 1207.0234\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.799566  13.765383  13.7894125 12.836275  12.900598  13.7961445]\n",
      "Reset environment\n",
      "Episode reward: 2409.2976\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.800226 13.766036 13.790082 12.837002 12.901186 13.796804]\n",
      "Reset environment\n",
      "Episode reward: 2335.8743\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.801122 13.766934 13.790975 12.837972 12.901971 13.7977  ]\n",
      "Reset environment\n",
      "Episode reward: 2329.8137\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.801734 13.767562 13.791572 12.838648 12.902521 13.798312]\n",
      "Reset environment\n",
      "Episode reward: 1812.1157\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.802188 13.768027 13.792015 12.839153 12.902938 13.798767]\n",
      "Reset environment\n",
      "Episode reward: 5642.4434\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.803877 13.769712 13.793701 12.840966 12.904458 13.80045 ]\n",
      "Reset environment\n",
      "Episode reward: 5648.616\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.8056   13.77144  13.795427 12.842822 12.906025 13.802176]\n",
      "Reset environment\n",
      "Episode reward: 3003.3047\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.806481 13.772324 13.796305 12.843772 12.906824 13.80306 ]\n",
      "Reset environment\n",
      "Episode reward: 2454.0315\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.80716  13.772999 13.79699  12.844518 12.907431 13.80374 ]\n",
      "Reset environment\n",
      "Episode reward: 1468.6653\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.807517  13.773338  13.797358  12.844915  12.9077425 13.804095 ]\n",
      "Reset environment\n",
      "Episode reward: 3843.644\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.808676  13.774491  13.7985115 12.846171  12.90874   13.805253 ]\n",
      "Reset environment\n",
      "Episode reward: 4183.7275\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.809953 13.775762 13.799789 12.847549 12.909855 13.80653 ]\n",
      "Reset environment\n",
      "Episode reward: 2419.2832\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.810598  13.776418  13.800428  12.848255  12.9104395 13.807174 ]\n",
      "Reset environment\n",
      "Episode reward: 2305.913\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.811473 13.777296 13.801302 12.849209 12.911207 13.808047]\n",
      "Reset environment\n",
      "Episode reward: 1598.5679\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.811889 13.777703 13.801733 12.849672 12.911577 13.808464]\n",
      "Reset environment\n",
      "Episode reward: 3609.155\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.812952 13.778773 13.802787 12.850827 12.912506 13.809528]\n",
      "Reset environment\n",
      "Episode reward: 4404.5083\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.814317 13.780146 13.804142 12.852293 12.913684 13.810892]\n",
      "Reset environment\n",
      "Episode reward: -228.00342\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.813694 13.779544 13.803506 12.851497 12.913136 13.810275]\n",
      "Reset environment\n",
      "Episode reward: 467.59933\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.813595  13.779444  13.803407  12.851321  12.913066  13.8101845]\n",
      "Reset environment\n",
      "Episode reward: -148.37878\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.813036  13.778893  13.802845  12.850595  12.912577  13.8096285]\n",
      "Reset environment\n",
      "Episode reward: 1386.882\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.813599 13.779455 13.803408 12.851214 12.913088 13.810191]\n",
      "Reset environment\n",
      "Episode reward: 2104.2178\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.814164 13.780019 13.803975 12.851838 12.913603 13.810758]\n",
      "Reset environment\n",
      "Episode reward: 2107.8936\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.814717 13.780575 13.804527 12.852452 12.914103 13.811312]\n",
      "Reset environment\n",
      "Episode reward: 1724.0868\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.815153 13.781013 13.804962 12.852941 12.914496 13.811748]\n",
      "Reset environment\n",
      "Episode reward: 2227.6138\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.815408 13.781293 13.805193 12.853271 12.914715 13.812002]\n",
      "Reset environment\n",
      "Episode reward: 3057.7559\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.816238 13.782111 13.806039 12.854181 12.915481 13.812834]\n",
      "Reset environment\n",
      "Episode reward: 2455.6724\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.816912 13.782793 13.806704 12.85493  12.916084 13.813506]\n",
      "Reset environment\n",
      "Episode reward: 1711.8092\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.81741  13.783294 13.8072   12.855476 12.916545 13.814005]\n",
      "Reset environment\n",
      "Episode reward: 1814.1063\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.817885 13.783774 13.807666 12.856001 12.916978 13.81448 ]\n",
      "Reset environment\n",
      "Episode reward: 1879.4003\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.818383 13.784281 13.808152 12.85655  12.917431 13.814977]\n",
      "Reset environment\n",
      "Episode reward: 2389.3303\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.819003 13.784912 13.808761 12.857236 12.917994 13.815598]\n",
      "Reset environment\n",
      "Episode reward: 1627.5978\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.81964  13.785551 13.809399 12.857932 12.918567 13.816236]\n",
      "Reset environment\n",
      "Episode reward: 2263.3154\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.820074  13.786013  13.809811  12.858437  12.918958  13.8166685]\n",
      "Reset environment\n",
      "Episode reward: 1598.436\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.820345 13.78631  13.810058 12.858759 12.919209 13.816941]\n",
      "Reset environment\n",
      "Episode reward: 1980.1174\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.821103 13.787069 13.810816 12.859594 12.919879 13.817699]\n",
      "Reset environment\n",
      "Episode reward: 4317.9565\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.822418 13.788379 13.812139 12.861004 12.921046 13.819014]\n",
      "Reset environment\n",
      "Episode reward: 481.56308\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.821997 13.78792  13.811772 12.860522 12.920693 13.8186  ]\n",
      "Reset environment\n",
      "Episode reward: 2192.8928\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.822557 13.78847  13.812341 12.86114  12.921203 13.819161]\n",
      "Reset environment\n",
      "Episode reward: 5097.23\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.824148 13.790059 13.813909 12.862846 12.922592 13.82075 ]\n",
      "Reset environment\n",
      "Episode reward: 3673.9885\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.825245  13.7911625 13.815002  12.864041  12.923553  13.821848 ]\n",
      "Reset environment\n",
      "Episode reward: 1726.1089\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.825587 13.791479 13.81537  12.86444  12.923838 13.82219 ]\n",
      "Reset environment\n",
      "Episode reward: 1858.311\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.826041 13.791952 13.815812 12.864953 12.924238 13.822644]\n",
      "Reset environment\n",
      "Episode reward: 5486.373\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.827739 13.793651 13.817498 12.866774 12.925726 13.824343]\n",
      "Reset environment\n",
      "Episode reward: 4651.8877\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.829174 13.795084 13.818926 12.868323 12.926973 13.825774]\n",
      "Reset environment\n",
      "Episode reward: 1488.7595\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.829538  13.795449  13.819287  12.86874   12.927297  13.8261385]\n",
      "Reset environment\n",
      "Episode reward: 2266.0142\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.830148 13.796063 13.819894 12.869412 12.927852 13.826747]\n",
      "Reset environment\n",
      "Episode reward: 2847.3325\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.830955 13.796878 13.820689 12.87029  12.928571 13.827554]\n",
      "Reset environment\n",
      "Episode reward: 2787.8599\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.831714 13.797631 13.821453 12.871122 12.929234 13.828313]\n",
      "Reset environment\n",
      "Episode reward: 1557.5549\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.8320465 13.797944  13.821807  12.871496  12.929525  13.82865  ]\n",
      "Reset environment\n",
      "Episode reward: 1322.4539\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.832397  13.798295  13.822157  12.871888  12.929846  13.8289995]\n",
      "Reset environment\n",
      "Episode reward: 3438.7485\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.833406  13.7992935 13.823161  12.872982  12.930724  13.830008 ]\n",
      "Reset environment\n",
      "Episode reward: 1715.8077\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.83384  13.799736 13.823586 12.873465 12.931123 13.83044 ]\n",
      "Reset environment\n",
      "Episode reward: 1600.7372\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.834251 13.800144 13.823999 12.873925 12.931496 13.830851]\n",
      "Reset environment\n",
      "Episode reward: 1864.1436\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.834726 13.800623 13.824465 12.874456 12.931929 13.831325]\n",
      "Reset environment\n",
      "Episode reward: 2388.2773\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.8353615 13.80127   13.825092  12.875151  12.932506  13.831959 ]\n",
      "Reset environment\n",
      "Episode reward: 221.1124\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.834858 13.800823 13.824532 12.874541 12.932091 13.831452]\n",
      "Reset environment\n",
      "Episode reward: 2137.4622\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.835348  13.801331  13.825     12.8750925 12.932523  13.831941 ]\n",
      "Reset environment\n",
      "Episode reward: 2123.153\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.835908 13.801893 13.825559 12.875718 12.933026 13.832501]\n",
      "Reset environment\n",
      "Episode reward: 1877.2524\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.836649 13.802636 13.826297 12.876525 12.933696 13.833242]\n",
      "Reset environment\n",
      "Episode reward: 2017.444\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.837167 13.803143 13.826824 12.877099 12.934167 13.833761]\n",
      "Reset environment\n",
      "Episode reward: 2089.2612\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.83796  13.803939 13.827619 12.877966 12.934863 13.834556]\n",
      "Reset environment\n",
      "Episode reward: 2146.521\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.838526 13.804516 13.828173 12.878588 12.935382 13.83512 ]\n",
      "Reset environment\n",
      "Episode reward: 1359.3406\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.838869  13.804864  13.828514  12.878977  12.935692  13.8354645]\n",
      "Reset environment\n",
      "Episode reward: 36.97473\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.838429 13.80443  13.828071 12.878392 12.935312 13.835028]\n",
      "Reset environment\n",
      "Episode reward: 1196.9963\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.838691 13.804674 13.828345 12.878692 12.935541 13.835288]\n",
      "Reset environment\n",
      "Episode reward: 2091.9675\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.839213 13.805213 13.828855 12.87927  12.936013 13.835812]\n",
      "Reset environment\n",
      "Episode reward: 1523.239\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.839605 13.805618 13.829233 12.879705 12.936367 13.836204]\n",
      "Reset environment\n",
      "Episode reward: 2461.7058\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.840284 13.8063   13.829911 12.880452 12.936974 13.836883]\n",
      "Reset environment\n",
      "Episode reward: 2077.5884\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.841078  13.807095  13.830704  12.88132   12.9376745 13.837676 ]\n",
      "Reset environment\n",
      "Episode reward: 2836.3252\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.841866 13.807888 13.831489 12.882187 12.93836  13.838463]\n",
      "Reset environment\n",
      "Episode reward: 2618.5425\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.842582 13.80861  13.832199 12.882973 12.939003 13.839181]\n",
      "Reset environment\n",
      "Episode reward: 2805.7532\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.84334   13.809361  13.8329735 12.883806  12.939694  13.83994  ]\n",
      "Reset environment\n",
      "Episode reward: 1386.8494\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.843899 13.809921 13.833532 12.884422 12.940201 13.840499]\n",
      "Reset environment\n",
      "Episode reward: 4437.985\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.845253 13.811259 13.834874 12.885869 12.941384 13.841849]\n",
      "Reset environment\n",
      "Episode reward: 1717.1233\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.845656 13.811638 13.835295 12.886319 12.94172  13.842254]\n",
      "Reset environment\n",
      "Episode reward: 1657.1882\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.846088 13.812067 13.835731 12.886798 12.942114 13.842686]\n",
      "Reset environment\n",
      "Episode reward: 4334.163\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.847422 13.813388 13.837062 12.88823  12.943286 13.84402 ]\n",
      "Reset environment\n",
      "Episode reward: 4439.4116\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.848792 13.814759 13.838428 12.889704 12.944465 13.845391]\n",
      "Reset environment\n",
      "Episode reward: 1566.4584\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.849211 13.815178 13.838847 12.89017  12.944848 13.84581 ]\n",
      "Reset environment\n",
      "Episode reward: 2178.19\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.849788 13.815753 13.83943  12.890807 12.945371 13.846387]\n",
      "Reset environment\n",
      "Episode reward: 1179.1874\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.850088 13.816051 13.839733 12.891144 12.945642 13.846687]\n",
      "Reset environment\n",
      "Episode reward: 4537.428\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.851431 13.817394 13.841077 12.892588 12.946861 13.848032]\n",
      "Reset environment\n",
      "Episode reward: 2566.455\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.852155 13.818121 13.841801 12.893377 12.947502 13.848757]\n",
      "Reset environment\n",
      "Episode reward: 1753.486\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.852601 13.818557 13.84226  12.893874 12.947912 13.849204]\n",
      "Reset environment\n",
      "Episode reward: 4837.5093\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.854101 13.820049 13.843745 12.895483 12.949227 13.850698]\n",
      "Reset environment\n",
      "Episode reward: 3045.0957\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.854983  13.8209305 13.844629  12.8964405 12.950001  13.851583 ]\n",
      "Reset environment\n",
      "Episode reward: 2160.5342\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.855557  13.8215065 13.845202  12.89708   12.950522  13.852158 ]\n",
      "Reset environment\n",
      "Episode reward: 3448.2385\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.856547 13.822494 13.846188 12.898165 12.951388 13.853146]\n",
      "Reset environment\n",
      "Episode reward: 1659.8734\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.856971 13.82292  13.846609 12.898638 12.951774 13.853571]\n",
      "Reset environment\n",
      "Episode reward: 1679.4646\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.857395  13.823345  13.847033  12.8991165 12.95216   13.853995 ]\n",
      "Reset environment\n",
      "Episode reward: 5255.588\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.859025 13.824972 13.84866  12.900876 12.953594 13.855624]\n",
      "Reset environment\n",
      "Episode reward: 2330.995\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.859586 13.825514 13.849241 12.901501 12.954077 13.856186]\n",
      "Reset environment\n",
      "Episode reward: 3428.1877\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.860584 13.826519 13.85023  12.902586 12.954945 13.857183]\n",
      "Reset environment\n",
      "Episode reward: 1782.539\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.860953 13.826868 13.850624 12.90301  12.955251 13.857556]\n",
      "Reset environment\n",
      "Episode reward: 2094.5122\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.861754  13.827669  13.851421  12.903886  12.955957  13.8583555]\n",
      "Reset environment\n",
      "Episode reward: 2498.6023\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.862437 13.828358 13.852099 12.904633 12.956569 13.859038]\n",
      "Reset environment\n",
      "Episode reward: 1902.7985\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.862827 13.828718 13.85252  12.905085 12.956925 13.85943 ]\n",
      "Reset environment\n",
      "Episode reward: 2255.554\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.863346 13.829257 13.853012 12.905661 12.957371 13.859946]\n",
      "Reset environment\n",
      "Episode reward: 1760.8623\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.863805 13.829717 13.853472 12.906174 12.957788 13.860405]\n",
      "Reset environment\n",
      "Episode reward: 1920.4622\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.864307 13.830216 13.853978 12.906733 12.958247 13.860908]\n",
      "Reset environment\n",
      "Episode reward: -277.87653\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.863432 13.829262 13.853171 12.905812 12.957452 13.860034]\n",
      "Reset environment\n",
      "Episode reward: 4103.1274\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.864632 13.830463 13.854374 12.907102 12.958541 13.861233]\n",
      "Reset environment\n",
      "Episode reward: -473.52017\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.863802 13.829675 13.853491 12.906195 12.957778 13.860407]\n",
      "Reset environment\n",
      "Episode reward: 3750.1733\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.864871 13.830752 13.854559 12.907354 12.958754 13.861477]\n",
      "Reset environment\n",
      "Episode reward: 2388.7993\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.865459 13.831321 13.855169 12.907999 12.959259 13.862066]\n",
      "Reset environment\n",
      "Episode reward: 1622.6838\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.865888 13.83175  13.855596 12.908471 12.95965  13.862494]\n",
      "Reset environment\n",
      "Episode reward: 5047.11\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.86737   13.833235  13.8570795 12.910067  12.961021  13.8639765]\n",
      "Reset environment\n",
      "Episode reward: 5375.7275\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.869056 13.834913 13.858765 12.911878 12.962479 13.865663]\n",
      "Reset environment\n",
      "Episode reward: 2043.6328\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.869833  13.8356905 13.859543  12.912726  12.963165  13.86644  ]\n",
      "Reset environment\n",
      "Episode reward: 3586.992\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.870898 13.836748 13.860602 12.913876 12.964099 13.867501]\n",
      "Reset environment\n",
      "Episode reward: 2356.2734\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.871379 13.837197 13.861108 12.914441 12.964529 13.867985]\n",
      "Reset environment\n",
      "Episode reward: -821.7426\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.870128 13.836108 13.85973  12.913201 12.963387 13.866756]\n",
      "Reset environment\n",
      "Episode reward: 5089.522\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.871718 13.837701 13.861312 12.914897 12.964752 13.868345]\n",
      "Reset environment\n",
      "Episode reward: 6116.2456\n",
      "Total Steps: 209\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.873624 13.839599 13.863207 12.916945 12.966415 13.870242]\n",
      "Reset environment\n",
      "Episode reward: 4781.949\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.875059 13.841022 13.864642 12.918506 12.967659 13.871675]\n",
      "Reset environment\n",
      "Episode reward: 2098.4456\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.875863 13.841827 13.865443 12.919377 12.968367 13.872477]\n",
      "Reset environment\n",
      "Episode reward: 2680.6853\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.87661  13.84257  13.866193 12.920196 12.969028 13.873223]\n",
      "Reset environment\n",
      "Episode reward: 2580.469\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.877307 13.843279 13.866881 12.920959 12.969657 13.87392 ]\n",
      "Reset environment\n",
      "Episode reward: 3411.8135\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.878297 13.844263 13.867872 12.922028 12.970526 13.87491 ]\n",
      "Reset environment\n",
      "Episode reward: 2142.8047\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.878911  13.844889  13.868482  12.9227    12.97109   13.8755245]\n",
      "Reset environment\n",
      "Episode reward: 1715.5537\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.879346  13.845343  13.8688965 12.923175  12.971482  13.875958 ]\n",
      "Reset environment\n",
      "Episode reward: 3265.7856\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.880304  13.846299  13.869856  12.9242115 12.972321  13.876917 ]\n",
      "Reset environment\n",
      "Episode reward: 2143.8896\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.880859  13.8468485 13.870418  12.924825  12.972825  13.877473 ]\n",
      "Reset environment\n",
      "Episode reward: 1429.1361\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.881236 13.847225 13.870796 12.925249 12.973171 13.877851]\n",
      "Reset environment\n",
      "Episode reward: 2097.7686\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.882037 13.848026 13.871598 12.92612  12.973883 13.878652]\n",
      "Reset environment\n",
      "Episode reward: 2119.1504\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.88259   13.8485775 13.872156  12.926733  12.974384  13.879205 ]\n",
      "Reset environment\n",
      "Episode reward: 1788.6838\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.88301  13.848978 13.872591 12.927201 12.974737 13.879624]\n",
      "Reset environment\n",
      "Episode reward: 2678.9148\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.883726 13.849711 13.873287 12.92798  12.975386 13.880341]\n",
      "Reset environment\n",
      "Episode reward: 3428.3533\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.884743 13.850734 13.874301 12.929077 12.976281 13.881357]\n",
      "Reset environment\n",
      "Episode reward: 5387.8755\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.886414 13.852402 13.875964 12.930876 12.977735 13.883031]\n",
      "Reset environment\n",
      "Episode reward: 3797.249\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.887519 13.853496 13.877082 12.932079 12.978733 13.884135]\n",
      "Reset environment\n",
      "Episode reward: 2021.3317\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.88805   13.854029  13.877612  12.932668  12.9792185 13.884667 ]\n",
      "Reset environment\n",
      "Episode reward: 2021.5182\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.888527 13.854528 13.878065 12.933201 12.97963  13.885144]\n",
      "Reset environment\n",
      "Episode reward: 2045.9622\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.889306 13.855308 13.878845 12.934055 12.980318 13.885923]\n",
      "Reset environment\n",
      "Episode reward: 1335.6311\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.889657 13.855666 13.879189 12.934442 12.980636 13.886274]\n",
      "Reset environment\n",
      "Episode reward: 1986.1665\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.890106  13.85613   13.87962   12.934949  12.9810295 13.8867235]\n",
      "Reset environment\n",
      "Episode reward: 2105.9111\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.8905115 13.856521  13.880039  12.935443  12.9813795 13.8871355]\n",
      "Reset environment\n",
      "Episode reward: 4173.2812\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.891783  13.857796  13.881307  12.9368105 12.982484  13.888408 ]\n",
      "Reset environment\n",
      "Episode reward: 2132.6348\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.892589 13.858603 13.882112 12.937691 12.983194 13.889214]\n",
      "Reset environment\n",
      "Episode reward: 5656.495\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.894369  13.8603735 13.883886  12.939589  12.984759  13.89099  ]\n",
      "Reset environment\n",
      "Episode reward: 2502.6921\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.895065  13.861073  13.884583  12.9403515 12.985381  13.891688 ]\n",
      "Reset environment\n",
      "Episode reward: 1826.1769\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.895574 13.861588 13.885082 12.94091  12.985848 13.892198]\n",
      "Reset environment\n",
      "Episode reward: 5504.5107\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.897305 13.863317 13.886817 12.94276  12.987364 13.893929]\n",
      "Reset environment\n",
      "Episode reward: 1560.6061\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.897697 13.863711 13.88721  12.943199 12.987721 13.894321]\n",
      "Reset environment\n",
      "Episode reward: 5312.7695\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.89934  13.865357 13.888851 12.944959 12.989129 13.895964]\n",
      "Reset environment\n",
      "Episode reward: 3249.428\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.900273 13.866303 13.889771 12.945964 12.989967 13.896897]\n",
      "Reset environment\n",
      "Episode reward: 3246.1836\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.901211 13.867249 13.8907   12.946976 12.990791 13.897836]\n",
      "Reset environment\n",
      "Episode reward: 1959.0839\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.901712  13.867764  13.8911915 12.947535  12.991252  13.898338 ]\n",
      "Reset environment\n",
      "Episode reward: 2710.085\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.902506 13.868564 13.891982 12.948384 12.991964 13.899132]\n",
      "Reset environment\n",
      "Episode reward: 5183.558\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.904124  13.870178  13.8935995 12.9501095 12.993372  13.90075  ]\n",
      "Reset environment\n",
      "Episode reward: 2157.142\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.904943 13.871    13.89442  12.950999 12.994094 13.901569]\n",
      "Reset environment\n",
      "Episode reward: 1660.9078\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.905324 13.871364 13.894816 12.951425 12.994412 13.901951]\n",
      "Reset environment\n",
      "Episode reward: 1871.5446\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.905613  13.8716755 13.895079  12.951769  12.994669  13.902238 ]\n",
      "Reset environment\n",
      "Episode reward: 1882.2867\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.90614  13.872206 13.895603 12.952347 12.995152 13.902766]\n",
      "Reset environment\n",
      "Episode reward: 2750.1152\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.906903 13.872968 13.896367 12.95318  12.995823 13.90353 ]\n",
      "Reset environment\n",
      "Episode reward: 2447.9453\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.907353 13.873443 13.896791 12.953702 12.996227 13.90398 ]\n",
      "Reset environment\n",
      "Episode reward: 1665.5336\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.9077635 13.873869  13.897182  12.954155  12.996598  13.904387 ]\n",
      "Reset environment\n",
      "Episode reward: 1915.9069\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.908258 13.874369 13.897674 12.954701 12.997047 13.904882]\n",
      "Reset environment\n",
      "Episode reward: 1969.106\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.90878  13.874892 13.898195 12.955283 12.997523 13.905404]\n",
      "Reset environment\n",
      "Episode reward: 1463.6467\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.909358 13.875473 13.898773 12.955919 12.998045 13.905983]\n",
      "Reset environment\n",
      "Episode reward: 2233.5298\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.909993 13.876096 13.89942  12.956612 12.998628 13.906619]\n",
      "Reset environment\n",
      "Episode reward: 1879.1932\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.9103985 13.876483  13.89985   12.957076  12.998973  13.907026 ]\n",
      "Reset environment\n",
      "Episode reward: 4901.6416\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.911833 13.877919 13.901285 12.95862  13.000289 13.908463]\n",
      "Reset environment\n",
      "Episode reward: 3474.9258\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.912799 13.878886 13.902251 12.95967  13.001172 13.909429]\n",
      "Reset environment\n",
      "Episode reward: 2305.7544\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.913422 13.879507 13.902875 12.960353 13.001728 13.910051]\n",
      "Reset environment\n",
      "Episode reward: 3281.224\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.914339 13.880412 13.903803 12.961342 13.002573 13.91097 ]\n",
      "Reset environment\n",
      "Episode reward: 1924.7415\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.915062 13.881137 13.904525 12.96214  13.003214 13.911693]\n",
      "Reset environment\n",
      "Episode reward: 4926.7993\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.916571 13.882642 13.906031 12.963762 13.004549 13.913195]\n",
      "Reset environment\n",
      "Episode reward: 1693.0413\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.917204 13.883277 13.906663 12.96447  13.005105 13.913828]\n",
      "Reset environment\n",
      "Episode reward: 3718.4153\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.918296 13.884383 13.907752 12.965652 13.006055 13.91492 ]\n",
      "Reset environment\n",
      "Episode reward: 1523.9084\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.918544 13.884657 13.90797  12.965945 13.006282 13.915168]\n",
      "Reset environment\n",
      "Episode reward: 4457.604\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.919905 13.886022 13.909327 12.967412 13.007458 13.916528]\n",
      "Reset environment\n",
      "Episode reward: 1705.866\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.920363 13.886482 13.909783 12.967922 13.007875 13.916987]\n",
      "Reset environment\n",
      "Episode reward: 1450.5232\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.920727 13.886831 13.910155 12.96833  13.008195 13.917352]\n",
      "Reset environment\n",
      "Episode reward: 1309.5886\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.921004 13.887095 13.910448 12.968652 13.008438 13.917629]\n",
      "Reset environment\n",
      "Episode reward: 3422.603\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.922    13.888099 13.911442 12.969732 13.009308 13.918625]\n",
      "Reset environment\n",
      "Episode reward: 1954.3644\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.922436 13.888515 13.911899 12.970224 13.009673 13.919061]\n",
      "Reset environment\n",
      "Episode reward: 2480.923\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.923134 13.889216 13.912598 12.970996 13.010309 13.919759]\n",
      "Reset environment\n",
      "Episode reward: 3581.7334\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.924192 13.89028  13.913657 12.972142 13.011229 13.920817]\n",
      "Reset environment\n",
      "Episode reward: 1856.335\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.9246645 13.89075   13.91413   12.972668  13.011656  13.921289 ]\n",
      "Reset environment\n",
      "Episode reward: 5370.014\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.926336  13.89242   13.9157915 12.974448  13.013088  13.922961 ]\n",
      "Reset environment\n",
      "Episode reward: 1700.4425\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.926766 13.892845 13.916226 12.974924 13.01348  13.923391]\n",
      "Reset environment\n",
      "Episode reward: 1924.3695\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.927152 13.893253 13.916588 12.975365 13.013827 13.923776]\n",
      "Reset environment\n",
      "Episode reward: 28.852325\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.926566 13.892609 13.916054 12.97473  13.013302 13.923194]\n",
      "Reset environment\n",
      "Episode reward: 924.2999\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.926359  13.89235   13.9158945 12.974496  13.0131235 13.922994 ]\n",
      "Reset environment\n",
      "Episode reward: 2920.4531\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.927154 13.893158 13.916679 12.975366 13.013819 13.923789]\n",
      "Reset environment\n",
      "Episode reward: 1861.992\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.927635 13.893638 13.917171 12.975897 13.014259 13.924271]\n",
      "Reset environment\n",
      "Episode reward: 3148.6309\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.928531 13.894543 13.918059 12.976866 13.015049 13.925168]\n",
      "Reset environment\n",
      "Episode reward: 1943.005\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.929249 13.895264 13.918778 12.977662 13.015679 13.925887]\n",
      "Reset environment\n",
      "Episode reward: 2499.3203\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.929861 13.895861 13.919412 12.978334 13.016214 13.926499]\n",
      "Reset environment\n",
      "Episode reward: 1917.6145\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.930596  13.896596  13.920145  12.9791355 13.016867  13.927235 ]\n",
      "Reset environment\n",
      "Episode reward: 1593.3536\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.930968 13.896988 13.920501 12.979554 13.017201 13.927607]\n",
      "Reset environment\n",
      "Episode reward: 602.88086\n",
      "Total Steps: 20\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.931047 13.897067 13.92058  12.979663 13.017265 13.927686]\n",
      "Reset environment\n",
      "Episode reward: 1852.5378\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.931458 13.897456 13.921009 12.980125 13.017623 13.928102]\n",
      "Reset environment\n",
      "Episode reward: 597.2715\n",
      "Total Steps: 18\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.931548 13.897545 13.921099 12.98024  13.017698 13.928191]\n",
      "Reset environment\n",
      "Episode reward: 2469.197\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.932174 13.898204 13.921699 12.980935 13.018274 13.928817]\n",
      "Reset environment\n",
      "Episode reward: 4643.7456\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.933599 13.899623 13.923115 12.982454 13.019533 13.930241]\n",
      "Reset environment\n",
      "Episode reward: 3704.5278\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.934697 13.900722 13.924215 12.983644 13.02049  13.931338]\n",
      "Reset environment\n",
      "Episode reward: 2185.9893\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.93552  13.901547 13.92504  12.984539 13.021215 13.932162]\n",
      "Reset environment\n",
      "Episode reward: 3172.6174\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.936423 13.902442 13.925946 12.985522 13.02201  13.933065]\n",
      "Reset environment\n",
      "Episode reward: 1556.2378\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.936822 13.902844 13.926342 12.985967 13.022372 13.933464]\n",
      "Reset environment\n",
      "Episode reward: 1925.7671\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.937346 13.903368 13.926868 12.986547 13.022854 13.93399 ]\n",
      "Reset environment\n",
      "Episode reward: 1471.9542\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.937725 13.903745 13.927254 12.986971 13.023201 13.934369]\n",
      "Reset environment\n",
      "Episode reward: 5001.52\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.939263 13.905276 13.928795 12.988612 13.024548 13.935906]\n",
      "Reset environment\n",
      "Episode reward: 3838.5762\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.940386  13.906405  13.9299135 12.989823  13.02552   13.937029 ]\n",
      "Reset environment\n",
      "Episode reward: 5361.0415\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.942046 13.908067 13.931572 12.9916   13.026939 13.938689]\n",
      "Reset environment\n",
      "Episode reward: 2003.406\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.942533 13.90857  13.932042 12.992139 13.027366 13.939178]\n",
      "Reset environment\n",
      "Episode reward: 3809.6328\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.943661  13.90969   13.933171  12.9933605 13.028354  13.940303 ]\n",
      "Reset environment\n",
      "Episode reward: 3674.162\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.94474  13.910777 13.934244 12.994522 13.029292 13.941383]\n",
      "Reset environment\n",
      "Episode reward: 4262.4443\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.946022  13.9120655 13.935514  12.995903  13.030427  13.942665 ]\n",
      "Reset environment\n",
      "Episode reward: 2233.776\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.946439  13.91251   13.935911  12.9963875 13.030812  13.943083 ]\n",
      "Reset environment\n",
      "Episode reward: 3711.0137\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.947541 13.913602 13.937016 12.997576 13.03177  13.944185]\n",
      "Reset environment\n",
      "Episode reward: 2620.4287\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.948227  13.9142885 13.9377    12.99833   13.032394  13.94487  ]\n",
      "Reset environment\n",
      "Episode reward: 2205.112\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.949052 13.915118 13.938524 12.999234 13.033124 13.945697]\n",
      "Reset environment\n",
      "Episode reward: 2093.4685\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.949615 13.915687 13.939087 12.999852 13.033642 13.94626 ]\n",
      "Reset environment\n",
      "Episode reward: 1983.2113\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.950082 13.916132 13.939571 13.00037  13.03403  13.946727]\n",
      "Reset environment\n",
      "Episode reward: 5204.398\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.951687 13.917734 13.941173 13.002092 13.035404 13.948331]\n",
      "Reset environment\n",
      "Episode reward: 1592.7197\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.952072  13.91814   13.941538  13.0025215 13.035756  13.948715 ]\n",
      "Reset environment\n",
      "Episode reward: 1701.4722\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.952354  13.918446  13.941799  13.002857  13.036014  13.9489975]\n",
      "Reset environment\n",
      "Episode reward: 1804.3928\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.953032 13.919126 13.942473 13.003605 13.036605 13.949674]\n",
      "Reset environment\n",
      "Episode reward: 2042.8523\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.953801 13.919896 13.943243 13.00445  13.037284 13.950443]\n",
      "Reset environment\n",
      "Episode reward: 4657.169\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.955233 13.92132  13.944672 13.005978 13.038539 13.951875]\n",
      "Reset environment\n",
      "Episode reward: 1386.628\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.955774  13.9218645 13.945215  13.006581  13.039031  13.952419 ]\n",
      "Reset environment\n",
      "Episode reward: 2360.1018\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.956374 13.922463 13.945817 13.007246 13.039578 13.953018]\n",
      "Reset environment\n",
      "Episode reward: 5855.4863\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.958182 13.924266 13.947612 13.009193 13.041157 13.954821]\n",
      "Reset environment\n",
      "Episode reward: 2158.8853\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.958996 13.925079 13.948426 13.010078 13.041878 13.955635]\n",
      "Reset environment\n",
      "Episode reward: 1383.5051\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.959334 13.925407 13.948775 13.010458 13.042178 13.955975]\n",
      "Reset environment\n",
      "Episode reward: 1850.4519\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.959799  13.925886  13.9492235 13.010968  13.042579  13.956438 ]\n",
      "Reset environment\n",
      "Episode reward: 1376.8218\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.959668 13.925779 13.949061 13.010761 13.042482 13.956309]\n",
      "Reset environment\n",
      "Episode reward: 4744.534\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.961111  13.9272175 13.950503  13.012311  13.043754  13.95775  ]\n",
      "Reset environment\n",
      "Episode reward: 1184.7534\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.961399 13.927501 13.950792 13.012637 13.044012 13.958037]\n",
      "Reset environment\n",
      "Episode reward: 394.981\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.961071 13.927139 13.950484 13.012199 13.043728 13.957713]\n",
      "Reset environment\n",
      "Episode reward: 1440.9167\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.961443 13.927512 13.950854 13.012621 13.044062 13.958085]\n",
      "Reset environment\n",
      "Episode reward: 1085.9044\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.961695 13.927756 13.951112 13.012906 13.044288 13.958338]\n",
      "Reset environment\n",
      "Episode reward: 2703.357\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.962405 13.928454 13.951836 13.013675 13.044931 13.959048]\n",
      "Reset environment\n",
      "Episode reward: 2733.3347\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.963173 13.929223 13.952601 13.01451  13.045611 13.959816]\n",
      "Reset environment\n",
      "Episode reward: 1869.5336\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.963585 13.929658 13.952994 13.014978 13.045984 13.960229]\n",
      "Reset environment\n",
      "Episode reward: 6028.8335\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.965468 13.931539 13.954877 13.016991 13.047642 13.962113]\n",
      "Reset environment\n",
      "Episode reward: 2725.9424\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.966152 13.932206 13.95558  13.017746 13.048266 13.962797]\n",
      "Reset environment\n",
      "Episode reward: 2047.9456\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.966694 13.932751 13.956122 13.018348 13.048762 13.96334 ]\n",
      "Reset environment\n",
      "Episode reward: 1413.8124\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.967251  13.9333105 13.956679  13.018961  13.049266  13.963897 ]\n",
      "Reset environment\n",
      "Episode reward: 2798.619\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.968013 13.934086 13.95743  13.019796 13.049951 13.96466 ]\n",
      "Reset environment\n",
      "Episode reward: 2270.8276\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.968593 13.934675 13.958001 13.020433 13.05048  13.965239]\n",
      "Reset environment\n",
      "Episode reward: 2106.8245\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.96916  13.935255 13.958557 13.021055 13.050999 13.965805]\n",
      "Reset environment\n",
      "Episode reward: 1796.226\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.969513  13.935579  13.958933  13.0214615 13.051319  13.966163 ]\n",
      "Reset environment\n",
      "Episode reward: 1636.9751\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.96996   13.9360285 13.95938   13.0219555 13.05173   13.966611 ]\n",
      "Reset environment\n",
      "Episode reward: 3578.9744\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.971007 13.93708  13.960413 13.023082 13.052678 13.967656]\n",
      "Reset environment\n",
      "Episode reward: 2608.8901\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.97173  13.937802 13.961138 13.023869 13.053322 13.968379]\n",
      "Reset environment\n",
      "Episode reward: 1839.5331\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.9721775 13.9382305 13.961596  13.0243635 13.053697  13.968826 ]\n",
      "Reset environment\n",
      "Episode reward: 151.23837\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.971783 13.937836 13.961181 13.02382  13.053361 13.968427]\n",
      "Reset environment\n",
      "Episode reward: 2856.7783\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.9724455 13.938515  13.9618225 13.024549  13.053967  13.96909  ]\n",
      "Reset environment\n",
      "Episode reward: 3265.055\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.973404 13.939477 13.962778 13.025574 13.054835 13.970051]\n",
      "Reset environment\n",
      "Episode reward: 1998.6948\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.973662 13.939761 13.96301  13.025899 13.055062 13.970306]\n",
      "Reset environment\n",
      "Episode reward: 4149.181\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.974913 13.941013 13.964255 13.027239 13.056159 13.971556]\n",
      "Reset environment\n",
      "Episode reward: 1457.8619\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.975497 13.941598 13.964841 13.027882 13.056695 13.972141]\n",
      "Reset environment\n",
      "Episode reward: 1558.7468\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.975857 13.941973 13.96518  13.028281 13.057011 13.972502]\n",
      "Reset environment\n",
      "Episode reward: -350.422\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.975111 13.941226 13.964457 13.027523 13.056399 13.971761]\n",
      "Reset environment\n",
      "Episode reward: 3688.3394\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.976196 13.942304 13.965543 13.028702 13.057342 13.97285 ]\n",
      "Reset environment\n",
      "Episode reward: 2277.423\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.976852 13.942971 13.96619  13.029413 13.057949 13.973506]\n",
      "Reset environment\n",
      "Episode reward: 1938.1428\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.9774065 13.943525  13.966745  13.030024  13.058459  13.974061 ]\n",
      "Reset environment\n",
      "Episode reward: 1552.3412\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.97779   13.9439125 13.967126  13.030457  13.058809  13.974444 ]\n",
      "Reset environment\n",
      "Episode reward: 1940.2548\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.978287 13.94441  13.967625 13.031008 13.059264 13.974941]\n",
      "Reset environment\n",
      "Episode reward: 1418.9928\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.978668 13.944793 13.968004 13.031436 13.059609 13.975323]\n",
      "Reset environment\n",
      "Episode reward: 2138.3337\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.979121 13.945271 13.968435 13.031945 13.060019 13.975775]\n",
      "Reset environment\n",
      "Episode reward: 5423.316\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.980786  13.946924  13.9700985 13.033731  13.061474  13.977439 ]\n",
      "Reset environment\n",
      "Episode reward: 2163.7646\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.981585 13.947726 13.970897 13.034606 13.062174 13.978237]\n",
      "Reset environment\n",
      "Episode reward: 1710.1614\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.981993  13.948148  13.9712925 13.035065  13.062547  13.978646 ]\n",
      "Reset environment\n",
      "Episode reward: 2199.917\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.98247  13.948597 13.971791 13.035624 13.062969 13.979132]\n",
      "Reset environment\n",
      "Episode reward: 2203.8066\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.98329  13.94942  13.972615 13.036522 13.063695 13.979954]\n",
      "Reset environment\n",
      "Episode reward: 5585.5947\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.985014  13.951139  13.9743185 13.038368  13.0651865 13.981678 ]\n",
      "Reset environment\n",
      "Episode reward: 2734.6558\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.985741 13.951851 13.975055 13.03917  13.065834 13.982406]\n",
      "Reset environment\n",
      "Episode reward: 1949.9824\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.986479 13.952592 13.975793 13.039976 13.06649  13.983145]\n",
      "Reset environment\n",
      "Episode reward: 2460.0957\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.987149  13.953265  13.976462  13.0407095 13.067092  13.983815 ]\n",
      "Reset environment\n",
      "Episode reward: 4218.529\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.988364 13.954485 13.977677 13.042011 13.068194 13.98503 ]\n",
      "Reset environment\n",
      "Episode reward: 1416.2396\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.988922 13.955045 13.978236 13.042625 13.0687   13.985589]\n",
      "Reset environment\n",
      "Episode reward: 2092.4346\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.989373 13.955523 13.978663 13.043139 13.069106 13.98604 ]\n",
      "Reset environment\n",
      "Episode reward: 2215.9744\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.989922  13.9560585 13.979223  13.043744  13.069585  13.9865885]\n",
      "Reset environment\n",
      "Episode reward: 4455.5205\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.991255 13.957389 13.980559 13.045178 13.070749 13.987924]\n",
      "Reset environment\n",
      "Episode reward: 4056.0728\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.992457 13.958574 13.981767 13.046468 13.071811 13.989125]\n",
      "Reset environment\n",
      "Episode reward: 4211.1587\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.993727  13.9598465 13.983033  13.047829  13.07293   13.990396 ]\n",
      "Reset environment\n",
      "Episode reward: 4002.016\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.994844 13.960971 13.984148 13.049043 13.073947 13.991514]\n",
      "Reset environment\n",
      "Episode reward: 1401.1377\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.995398 13.961526 13.9847   13.049654 13.074446 13.992066]\n",
      "Reset environment\n",
      "Episode reward: 593.2949\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.99513   13.961268  13.984416  13.049286  13.0742035 13.991801 ]\n",
      "Reset environment\n",
      "Episode reward: 1892.0309\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.995546  13.9616585 13.984853  13.04976   13.074552  13.992218 ]\n",
      "Reset environment\n",
      "Episode reward: -453.33142\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.994806  13.960898  13.984134  13.0488615 13.073875  13.991481 ]\n",
      "Reset environment\n",
      "Episode reward: 2775.0383\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.99554  13.961636 13.984858 13.049671 13.074528 13.992214]\n",
      "Reset environment\n",
      "Episode reward: 2113.5994\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.996075 13.96217  13.985398 13.050273 13.075009 13.992749]\n",
      "Reset environment\n",
      "Episode reward: 5679.6006\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.997805 13.963907 13.987119 13.052142 13.076512 13.994478]\n",
      "Reset environment\n",
      "Episode reward: 2097.5857\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.998593  13.964697  13.987907  13.0529995 13.077211  13.995267 ]\n",
      "Reset environment\n",
      "Episode reward: 1893.7598\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [13.999304 13.965406 13.988621 13.053774 13.077844 13.995977]\n",
      "Reset environment\n",
      "Episode reward: 5054.2305\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.000858 13.966953 13.990177 13.055434 13.079221 13.997533]\n",
      "Reset environment\n",
      "Episode reward: 2923.2202\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.001662 13.967747 13.990992 13.056308 13.079963 13.998342]\n",
      "Reset environment\n",
      "Episode reward: 2924.9482\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.002316 13.968423 13.991627 13.057033 13.080565 13.998996]\n",
      "Reset environment\n",
      "Episode reward: 3592.6238\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.003315 13.969422 13.992626 13.058117 13.081478 13.999994]\n",
      "Reset environment\n",
      "Episode reward: 5059.0645\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.00487   13.9709635 13.994184  13.059782  13.082841  14.001547 ]\n",
      "Reset environment\n",
      "Episode reward: 2884.1726\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.005681 13.971775 13.994997 13.060664 13.083561 14.002358]\n",
      "Reset environment\n",
      "Episode reward: 3756.8774\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.00679  13.97288  13.996099 13.061854 13.084525 14.003467]\n",
      "Reset environment\n",
      "Episode reward: 1268.3376\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.007127 13.973216 13.996436 13.062229 13.084834 14.003803]\n",
      "Reset environment\n",
      "Episode reward: 1579.7162\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.007522 13.97361  13.996836 13.062673 13.085192 14.004199]\n",
      "Reset environment\n",
      "Episode reward: 1809.2269\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.008005  13.974094  13.99732   13.063205  13.085638  14.0046835]\n",
      "Reset environment\n",
      "Episode reward: 3976.282\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.009178  13.975271  13.9984865 13.064472  13.086649  14.005857 ]\n",
      "Reset environment\n",
      "Episode reward: 724.23425\n",
      "Total Steps: 22\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.009311 13.975405 13.99862  13.064634 13.086767 14.005991]\n",
      "Reset environment\n",
      "Episode reward: 3038.252\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.010155 13.976261 13.999456 13.065551 13.08752  14.006836]\n",
      "Reset environment\n",
      "Episode reward: 2227.741\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.010546 13.976623 13.999878 13.066028 13.087861 14.007231]\n",
      "Reset environment\n",
      "Episode reward: 5439.4844\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.012233 13.978309 14.001564 13.067823 13.089311 14.008918]\n",
      "Reset environment\n",
      "Episode reward: 1718.153\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.012653 13.978721 14.001992 13.068291 13.089684 14.009339]\n",
      "Reset environment\n",
      "Episode reward: 2304.7642\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.013503 13.979571 14.002844 13.069216 13.090428 14.010189]\n",
      "Reset environment\n",
      "Episode reward: 1284.1003\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.013805 13.979875 14.003146 13.069561 13.090701 14.010492]\n",
      "Reset environment\n",
      "Episode reward: 1831.7096\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.014273  13.980335  14.003617  13.070083  13.0911255 14.01096  ]\n",
      "Reset environment\n",
      "Episode reward: 2905.3325\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.0150175 13.981065  14.00438   13.070896  13.091803  14.011704 ]\n",
      "Reset environment\n",
      "Episode reward: 468.26596\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.014597 13.980606 14.004004 13.070391 13.091446 14.011293]\n",
      "Reset environment\n",
      "Episode reward: 2165.8691\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.015198 13.981211 14.004596 13.071047 13.092    14.011893]\n",
      "Reset environment\n",
      "Episode reward: 1941.0321\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.015725  13.981732  14.005133  13.071625  13.0924835 14.012423 ]\n",
      "Reset environment\n",
      "Episode reward: 2083.545\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.016505 13.982513 14.00591  13.072474 13.093168 14.013203]\n",
      "Reset environment\n",
      "Episode reward: 2281.4675\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.017123 13.983131 14.006525 13.073149 13.093726 14.013821]\n",
      "Reset environment\n",
      "Episode reward: 3738.8442\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.018218 13.984226 14.00762  13.074331 13.094683 14.014916]\n",
      "Reset environment\n",
      "Episode reward: 2804.663\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.019006 13.985017 14.008406 13.075188 13.095384 14.015704]\n",
      "Reset environment\n",
      "Episode reward: 513.34534\n",
      "Total Steps: 19\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.019041 13.985053 14.008442 13.075255 13.095407 14.015739]\n",
      "Reset environment\n",
      "Episode reward: 3372.07\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.020014  13.9860325 14.00941   13.076305  13.096263  14.016712 ]\n",
      "Reset environment\n",
      "Episode reward: 5645.5083\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.021776 13.987789 14.011163 13.078191 13.097814 14.018473]\n",
      "Reset environment\n",
      "Episode reward: 2527.063\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.022427 13.98844  14.011813 13.078903 13.098409 14.019123]\n",
      "Reset environment\n",
      "Episode reward: 2093.6794\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.02302  13.989037 14.0124   13.079553 13.098956 14.019716]\n",
      "Reset environment\n",
      "Episode reward: 2321.4634\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.023876  13.989896  14.013257  13.080483  13.0997095 14.020573 ]\n",
      "Reset environment\n",
      "Episode reward: 4744.9985\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.025304 13.991332 14.014678 13.082023 13.100938 14.021998]\n",
      "Reset environment\n",
      "Episode reward: 4007.9985\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.02648  13.992508 14.015852 13.083294 13.101957 14.023173]\n",
      "Reset environment\n",
      "Episode reward: 3930.1013\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.02759  13.993622 14.01696  13.084499 13.102962 14.024283]\n",
      "Reset environment\n",
      "Episode reward: 4135.875\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.028822 13.99486  14.01819  13.085825 13.104046 14.025516]\n",
      "Reset environment\n",
      "Episode reward: 1953.618\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.029282 13.995302 14.018664 13.086333 13.10444  14.025975]\n",
      "Reset environment\n",
      "Episode reward: 2733.2976\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.029959 13.995957 14.019361 13.08708  13.105029 14.026652]\n",
      "Reset environment\n",
      "Episode reward: 1375.401\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.030307  13.9963045 14.019709  13.087469  13.105346  14.027001 ]\n",
      "Reset environment\n",
      "Episode reward: 1307.0237\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.03063  13.996641 14.020027 13.08783  13.105642 14.027325]\n",
      "Reset environment\n",
      "Episode reward: 2077.4365\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.031022 13.997012 14.020451 13.08831  13.105997 14.027725]\n",
      "Reset environment\n",
      "Episode reward: 1491.8624\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.031379 13.997372 14.020806 13.088716 13.106319 14.028082]\n",
      "Reset environment\n",
      "Episode reward: 2393.1995\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.032046 13.99804  14.021473 13.089445 13.10692  14.028749]\n",
      "Reset environment\n",
      "Episode reward: 1726.2296\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.032306 13.998268 14.021762 13.089769 13.107144 14.029019]\n",
      "Reset environment\n",
      "Episode reward: 5562.8887\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.034001  13.999968  14.023448  13.091588  13.1086235 14.030715 ]\n",
      "Reset environment\n",
      "Episode reward: 1535.397\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.034589  14.000557  14.024035  13.0922365 13.109149  14.0313015]\n",
      "Reset environment\n",
      "Episode reward: 2590.9375\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.035308  14.0012865 14.024744  13.0930195 13.109808  14.032021 ]\n",
      "Reset environment\n",
      "Episode reward: 1524.4058\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.035726 14.001704 14.025164 13.093482 13.110193 14.032438]\n",
      "Reset environment\n",
      "Episode reward: 4345.951\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.037026  14.003001  14.0264635 13.09488   13.111323  14.033739 ]\n",
      "Reset environment\n",
      "Episode reward: 3041.5789\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.037858 14.003853 14.027281 13.095783 13.112095 14.034574]\n",
      "Reset environment\n",
      "Episode reward: 2901.6309\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.038607  14.004588  14.028046  13.0966015 13.112773  14.035322 ]\n",
      "Reset environment\n",
      "Episode reward: 1975.3143\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.039014 14.005017 14.028428 13.097068 13.113139 14.035728]\n",
      "Reset environment\n",
      "Episode reward: 2191.2083\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.03957   14.0055895 14.0289755 13.097686  13.113655  14.036285 ]\n",
      "Reset environment\n",
      "Episode reward: 1369.2122\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.040094 14.006115 14.029501 13.098269 13.11413  14.036811]\n",
      "Reset environment\n",
      "Episode reward: 2105.414\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.040867  14.00689   14.0302725 13.099118  13.114808  14.037584 ]\n",
      "Reset environment\n",
      "Episode reward: 5286.1875\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.042467  14.008495  14.031862  13.1008415 13.116192  14.039187 ]\n",
      "Reset environment\n",
      "Episode reward: 4394.567\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.043706 14.009738 14.033102 13.102179 13.117335 14.040426]\n",
      "Reset environment\n",
      "Episode reward: 3724.9795\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.044802 14.010838 14.034198 13.103361 13.118305 14.041523]\n",
      "Reset environment\n",
      "Episode reward: 5187.8022\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.04638   14.012415  14.0357685 13.105048  13.119664  14.0431   ]\n",
      "Reset environment\n",
      "Episode reward: 1904.2666\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.046743 14.012754 14.036162 13.10548  13.119969 14.043469]\n",
      "Reset environment\n",
      "Episode reward: 1357.2877\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.047263 14.013276 14.036681 13.10606  13.12044  14.043989]\n",
      "Reset environment\n",
      "Episode reward: 4992.2246\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.048783 14.0148   14.038199 13.107688 13.121763 14.045511]\n",
      "Reset environment\n",
      "Episode reward: 2523.3828\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.049429 14.015447 14.038845 13.108396 13.122354 14.046157]\n",
      "Reset environment\n",
      "Episode reward: 2966.0894\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.050265 14.016283 14.039686 13.109301 13.123089 14.046993]\n",
      "Reset environment\n",
      "Episode reward: 2279.4155\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.050666 14.016708 14.040062 13.109765 13.123449 14.047392]\n",
      "Reset environment\n",
      "Episode reward: 1889.0487\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.05107  14.017089 14.040495 13.110231 13.123814 14.047801]\n",
      "Reset environment\n",
      "Episode reward: 2746.3262\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.051823  14.017836  14.041252  13.1110525 13.12448   14.048553 ]\n",
      "Reset environment\n",
      "Episode reward: 1924.4304\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.052285 14.018311 14.041705 13.111565 13.124906 14.049015]\n",
      "Reset environment\n",
      "Episode reward: 1768.2855\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.052612 14.018618 14.042055 13.111949 13.125202 14.049343]\n",
      "Reset environment\n",
      "Episode reward: 1989.5247\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.053118  14.019121  14.042568  13.11251   13.125664  14.0498495]\n",
      "Reset environment\n",
      "Episode reward: 1698.7684\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.053468  14.019453  14.042942  13.112911  13.125963  14.0501995]\n",
      "Reset environment\n",
      "Episode reward: 2160.0432\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.05427   14.020258  14.043745  13.113784  13.126672  14.0510025]\n",
      "Reset environment\n",
      "Episode reward: 1776.0995\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.054733 14.020722 14.044208 13.114299 13.127095 14.051466]\n",
      "Reset environment\n",
      "Episode reward: 1868.0665\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.05524  14.021237 14.044707 13.114857 13.127561 14.051973]\n",
      "Reset environment\n",
      "Episode reward: 2514.4722\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.055906 14.021902 14.045382 13.115586 13.128158 14.052639]\n",
      "Reset environment\n",
      "Episode reward: 1412.8599\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.056269  14.022262  14.045748  13.1159935 13.128488  14.053001 ]\n",
      "Reset environment\n",
      "Episode reward: 1857.7885\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.056663 14.022624 14.046172 13.116447 13.128838 14.053409]\n",
      "Reset environment\n",
      "Episode reward: 2193.4482\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.057239 14.0232   14.046745 13.117081 13.129357 14.053984]\n",
      "Reset environment\n",
      "Episode reward: 1872.7789\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.057632 14.023571 14.047162 13.117529 13.129693 14.054379]\n",
      "Reset environment\n",
      "Episode reward: 4198.1323\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.058877 14.024806 14.048407 13.11887  13.130783 14.055623]\n",
      "Reset environment\n",
      "Episode reward: 1742.8752\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.059299  14.02523   14.04883   13.11935   13.131167  14.0560465]\n",
      "Reset environment\n",
      "Episode reward: 4722.7993\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.060713 14.026653 14.050234 13.120868 13.132405 14.057461]\n",
      "Reset environment\n",
      "Episode reward: 1796.0403\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.060993 14.026956 14.050491 13.12121  13.132657 14.057742]\n",
      "Reset environment\n",
      "Episode reward: 2125.7031\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.061776 14.02774  14.051274 13.122062 13.133348 14.058526]\n",
      "Reset environment\n",
      "Episode reward: 1617.6599\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.062387 14.028353 14.051886 13.122736 13.133893 14.059136]\n",
      "Reset environment\n",
      "Episode reward: 2089.9385\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.062893  14.028872  14.0523815 13.123295  13.1343565 14.059644 ]\n",
      "Reset environment\n",
      "Episode reward: 1702.7913\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.063323 14.02929  14.052824 13.123771 13.134738 14.060076]\n",
      "Reset environment\n",
      "Episode reward: 2656.935\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.06398  14.029932 14.0535   13.124494 13.135323 14.060732]\n",
      "Reset environment\n",
      "Episode reward: 1370.6824\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.0645075 14.030462  14.054026  13.125079  13.135797  14.061261 ]\n",
      "Reset environment\n",
      "Episode reward: 75.38522\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.063828 14.02971  14.053422 13.124363 13.135178 14.060588]\n",
      "Reset environment\n",
      "Episode reward: 5581.3403\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.065552 14.031429 14.055141 13.126201 13.136687 14.062307]\n",
      "Reset environment\n",
      "Episode reward: 4151.123\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.066783  14.032666  14.056368  13.127525  13.1377535 14.0635395]\n",
      "Reset environment\n",
      "Episode reward: 2325.6086\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.067633 14.033518 14.057217 13.128456 13.138505 14.064389]\n",
      "Reset environment\n",
      "Episode reward: 2143.9841\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.06814  14.034025 14.05773  13.129033 13.138955 14.064897]\n",
      "Reset environment\n",
      "Episode reward: 2132.0508\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.068682 14.034585 14.058257 13.129629 13.13945  14.065437]\n",
      "Reset environment\n",
      "Episode reward: 2931.2627\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.069457 14.035348 14.059048 13.130471 13.140157 14.066213]\n",
      "Reset environment\n",
      "Episode reward: 3407.1848\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.070413 14.036321 14.060001 13.131519 13.141015 14.067169]\n",
      "Reset environment\n",
      "Episode reward: 1836.8416\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.071091 14.037001 14.060679 13.132266 13.14162  14.067847]\n",
      "Reset environment\n",
      "Episode reward: 1933.0114\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.071611 14.037521 14.061199 13.132836 13.142098 14.068368]\n",
      "Reset environment\n",
      "Episode reward: 2452.9114\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.072514  14.038427  14.0620985 13.133814  13.142887  14.069271 ]\n",
      "Reset environment\n",
      "Episode reward: 1304.7277\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.072778 14.038678 14.062379 13.134119 13.143122 14.069538]\n",
      "Reset environment\n",
      "Episode reward: 2413.797\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.073429  14.039328  14.06303   13.134829  13.1437025 14.070189 ]\n",
      "Reset environment\n",
      "Episode reward: 1916.2493\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.07413  14.040033 14.063731 13.135605 13.144323 14.070891]\n",
      "Reset environment\n",
      "Episode reward: 2346.392\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.074756 14.040657 14.064358 13.136291 13.144886 14.071517]\n",
      "Reset environment\n",
      "Episode reward: 3254.886\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.075676 14.041577 14.065282 13.137289 13.145688 14.072436]\n",
      "Reset environment\n",
      "Episode reward: 2213.6382\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.0758505 14.0417795 14.065435  13.137532  13.145836  14.072611 ]\n",
      "Reset environment\n",
      "Episode reward: 3998.58\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.077017 14.042939 14.066601 13.138805 13.146859 14.073777]\n",
      "Reset environment\n",
      "Episode reward: 4143.028\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.0782385 14.044167  14.06782   13.1401205 13.147929  14.074999 ]\n",
      "Reset environment\n",
      "Episode reward: 3529.9856\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.079221 14.045144 14.068816 13.141185 13.148837 14.075983]\n",
      "Reset environment\n",
      "Episode reward: 1503.8586\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.079593 14.045515 14.069191 13.141601 13.149177 14.076355]\n",
      "Reset environment\n",
      "Episode reward: -100.77893\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.07883  14.044823 14.068368 13.140847 13.148494 14.075596]\n",
      "Reset environment\n",
      "Episode reward: 1833.627\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.079285 14.045283 14.068816 13.141352 13.148907 14.07605 ]\n",
      "Reset environment\n",
      "Episode reward: 2249.6313\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.079837 14.045847 14.069357 13.141961 13.149415 14.076603]\n",
      "Reset environment\n",
      "Episode reward: 1483.3745\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.080172 14.046167 14.069708 13.142331 13.149704 14.076939]\n",
      "Reset environment\n",
      "Episode reward: 1498.9557\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.080562 14.046566 14.070088 13.142761 13.150062 14.077329]\n",
      "Reset environment\n",
      "Episode reward: 2641.2036\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.081285 14.047286 14.070814 13.143552 13.150706 14.078053]\n",
      "Reset environment\n",
      "Episode reward: 1674.7678\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.081701 14.047711 14.071225 13.144014 13.151086 14.078468]\n",
      "Reset environment\n",
      "Episode reward: 4543.3223\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.083062 14.049069 14.072593 13.145478 13.152289 14.079831]\n",
      "Reset environment\n",
      "Episode reward: 1392.3477\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.083593 14.049601 14.073124 13.14607  13.152772 14.080362]\n",
      "Reset environment\n",
      "Episode reward: 1581.6948\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.083879 14.049856 14.073438 13.146403 13.153029 14.08065 ]\n",
      "Reset environment\n",
      "Episode reward: 5113.041\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.085417  14.051396  14.074973  13.148059  13.1543455 14.082187 ]\n",
      "Reset environment\n",
      "Episode reward: 2565.6514\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.086079  14.05206   14.075636  13.148782  13.15495   14.0828495]\n",
      "Reset environment\n",
      "Episode reward: 2374.367\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.086665 14.052659 14.076211 13.149426 13.155483 14.083435]\n",
      "Reset environment\n",
      "Episode reward: 1732.937\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.087088 14.05307  14.076641 13.149899 13.155858 14.083857]\n",
      "Reset environment\n",
      "Episode reward: 3720.7996\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.088151  14.054145  14.077698  13.1510515 13.156787  14.08492  ]\n",
      "Reset environment\n",
      "Episode reward: 4797.237\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.089596 14.055585 14.079139 13.152602 13.158038 14.086365]\n",
      "Reset environment\n",
      "Episode reward: -60.204926\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.089059 14.055067 14.078574 13.1519   13.157582 14.085818]\n",
      "Reset environment\n",
      "Episode reward: 4829.1943\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.09051   14.056514  14.080029  13.153456  13.1588545 14.087271 ]\n",
      "Reset environment\n",
      "Episode reward: 2981.1555\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.091293  14.057298  14.0808115 13.154315  13.159567  14.088054 ]\n",
      "Reset environment\n",
      "Episode reward: 2117.6685\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.091834 14.05784  14.081351 13.154914 13.160057 14.088594]\n",
      "Reset environment\n",
      "Episode reward: 1396.2827\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.092372 14.058378 14.081889 13.155511 13.160543 14.089132]\n",
      "Reset environment\n",
      "Episode reward: 3897.051\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.093508 14.059521 14.083025 13.156743 13.161526 14.090267]\n",
      "Reset environment\n",
      "Episode reward: 2128.599\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.0939665 14.059961  14.083502  13.157259  13.161914  14.090726 ]\n",
      "Reset environment\n",
      "Episode reward: 4285.465\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.095238 14.061228 14.084771 13.158626 13.163022 14.091996]\n",
      "Reset environment\n",
      "Episode reward: 2055.5063\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.095822  14.061816  14.085355  13.1592655 13.163563  14.092582 ]\n",
      "Reset environment\n",
      "Episode reward: 2009.8431\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.096569 14.062563 14.086101 13.16008  13.164225 14.093328]\n",
      "Reset environment\n",
      "Episode reward: 2117.9412\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.09713  14.063121 14.086669 13.160703 13.16474  14.093889]\n",
      "Reset environment\n",
      "Episode reward: 1704.7866\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.09758   14.063577  14.087116  13.161201  13.1651535 14.094339 ]\n",
      "Reset environment\n",
      "Episode reward: 1594.331\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.098019 14.06402  14.087553 13.161683 13.16556  14.094779]\n",
      "Reset environment\n",
      "Episode reward: 5217.32\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.099603  14.0655985 14.089136  13.163377  13.166954  14.096364 ]\n",
      "Reset environment\n",
      "Episode reward: 3242.5603\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.100516 14.066501 14.090049 13.164367 13.167754 14.097277]\n",
      "Reset environment\n",
      "Episode reward: 3570.731\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.101523 14.067501 14.091061 13.165462 13.168633 14.098284]\n",
      "Reset environment\n",
      "Episode reward: 1183.9629\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.101788 14.067757 14.091336 13.165763 13.168872 14.098548]\n",
      "Reset environment\n",
      "Episode reward: 1905.2478\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.102241 14.06822  14.091781 13.166268 13.169287 14.099002]\n",
      "Reset environment\n",
      "Episode reward: 1788.6228\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.102627 14.068593 14.092185 13.166703 13.16962  14.099388]\n",
      "Reset environment\n",
      "Episode reward: 5029.659\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.104148 14.070114 14.09371  13.168335 13.170945 14.100909]\n",
      "Reset environment\n",
      "Episode reward: 4042.2058\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.105318 14.071291 14.094879 13.169603 13.171965 14.10208 ]\n",
      "Reset environment\n",
      "Episode reward: 1725.0386\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.105761 14.071731 14.095326 13.170094 13.172371 14.102523]\n",
      "Reset environment\n",
      "Episode reward: 1609.2529\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.106011 14.072006 14.095556 13.170403 13.172597 14.102773]\n",
      "Reset environment\n",
      "Episode reward: 2039.7983\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.106766 14.072761 14.096312 13.171223 13.173267 14.103527]\n",
      "Reset environment\n",
      "Episode reward: 1384.1196\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.107303  14.073298  14.0968485 13.171815  13.173757  14.104064 ]\n",
      "Reset environment\n",
      "Episode reward: 4101.3975\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.108508 14.07451  14.098053 13.17312  13.174805 14.10527 ]\n",
      "Reset environment\n",
      "Episode reward: 3013.5996\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.109334 14.075322 14.098889 13.174022 13.175535 14.106094]\n",
      "Reset environment\n",
      "Episode reward: 1409.5612\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.10965  14.075655 14.099186 13.174379 13.175815 14.106409]\n",
      "Reset environment\n",
      "Episode reward: 3062.1982\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.110497 14.076501 14.100039 13.175303 13.176554 14.107257]\n",
      "Reset environment\n",
      "Episode reward: 1885.6677\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.110896  14.0769205 14.10042   13.175758  13.176908  14.1076565]\n",
      "Reset environment\n",
      "Episode reward: -681.6648\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.109882 14.075909 14.099406 13.174803 13.17596  14.106639]\n",
      "Reset environment\n",
      "Episode reward: 2220.6125\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.11044   14.076458  14.0999775 13.175415  13.176474  14.107197 ]\n",
      "Reset environment\n",
      "Episode reward: 2933.257\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.111241 14.077255 14.10079  13.176289 13.177181 14.108001]\n",
      "Reset environment\n",
      "Episode reward: 2448.9512\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.112133 14.078145 14.101682 13.177254 13.177963 14.108892]\n",
      "Reset environment\n",
      "Episode reward: 3389.9038\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.113104 14.07912  14.102648 13.178303 13.178817 14.109865]\n",
      "Reset environment\n",
      "Episode reward: 2675.429\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.113863 14.07988  14.103406 13.179112 13.179502 14.110623]\n",
      "Reset environment\n",
      "Episode reward: 1403.1119\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.114217  14.0802355 14.103763  13.179512  13.179821  14.110979 ]\n",
      "Reset environment\n",
      "Episode reward: 1328.108\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.114539 14.080564 14.104076 13.179878 13.18011  14.111302]\n",
      "Reset environment\n",
      "Episode reward: 2399.3264\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.115192 14.081223 14.104727 13.18059  13.180698 14.111957]\n",
      "Reset environment\n",
      "Episode reward: 2598.8413\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.115893 14.081927 14.10542  13.181358 13.181327 14.112658]\n",
      "Reset environment\n",
      "Episode reward: 2564.8115\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.116588  14.0826235 14.106114  13.182119  13.181949  14.113353 ]\n",
      "Reset environment\n",
      "Episode reward: 1598.1451\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.117014 14.083045 14.106544 13.182587 13.18234  14.113779]\n",
      "Reset environment\n",
      "Episode reward: 1660.965\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.117415  14.083446  14.106947  13.183042  13.182704  14.1141815]\n",
      "Reset environment\n",
      "Episode reward: 1027.9695\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.117654 14.083685 14.107184 13.183317 13.182918 14.114421]\n",
      "Reset environment\n",
      "Episode reward: 1322.5657\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.118147 14.084179 14.107678 13.183874 13.183359 14.114913]\n",
      "Reset environment\n",
      "Episode reward: 3244.7822\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.119069 14.0851   14.108604 13.184872 13.184167 14.115836]\n",
      "Reset environment\n",
      "Episode reward: 1798.1968\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.119525 14.085546 14.109061 13.185371 13.18458  14.11629 ]\n",
      "Reset environment\n",
      "Episode reward: -43.932312\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.118933 14.085    14.108417 13.18466  13.184027 14.115701]\n",
      "Reset environment\n",
      "Episode reward: 1872.9133\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.119627 14.085695 14.109112 13.185422 13.184645 14.116395]\n",
      "Reset environment\n",
      "Episode reward: 5022.547\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.121143 14.087209 14.110631 13.187041 13.185989 14.117912]\n",
      "Reset environment\n",
      "Episode reward: 2580.8145\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.121856 14.087923 14.111341 13.187814 13.186629 14.118625]\n",
      "Reset environment\n",
      "Episode reward: 3446.0325\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.122843 14.088914 14.112327 13.188877 13.187502 14.119612]\n",
      "Reset environment\n",
      "Episode reward: 1907.5322\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.12332   14.089392  14.1128025 13.189405  13.187938  14.120089 ]\n",
      "Reset environment\n",
      "Episode reward: 1485.8718\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.123671  14.089728  14.113167  13.1897955 13.188239  14.1204405]\n",
      "Reset environment\n",
      "Episode reward: 4594.8257\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.125012 14.091052 14.114514 13.191256 13.18944  14.121784]\n",
      "Reset environment\n",
      "Episode reward: 1932.083\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.125485 14.091529 14.11498  13.191781 13.18987  14.122258]\n",
      "Reset environment\n",
      "Episode reward: 2368.367\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.126105  14.092147  14.1156025 13.19246   13.190424  14.122877 ]\n",
      "Reset environment\n",
      "Episode reward: 1594.2123\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.126411 14.092423 14.115929 13.192807 13.190677 14.123183]\n",
      "Reset environment\n",
      "Episode reward: 2231.3054\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.127206 14.093224 14.116721 13.19368  13.191372 14.123978]\n",
      "Reset environment\n",
      "Episode reward: 2236.8948\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.127776 14.093799 14.117283 13.194308 13.191892 14.124548]\n",
      "Reset environment\n",
      "Episode reward: 3357.3245\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.128735 14.094757 14.118244 13.195348 13.192727 14.125505]\n",
      "Reset environment\n",
      "Episode reward: 3623.187\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.12977  14.095788 14.119285 13.196469 13.193632 14.126542]\n",
      "Reset environment\n",
      "Episode reward: 2151.8533\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.130561 14.096578 14.120073 13.197328 13.194332 14.127333]\n",
      "Reset environment\n",
      "Episode reward: 2575.5095\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.131202 14.09721  14.120731 13.198039 13.194911 14.127973]\n",
      "Reset environment\n",
      "Episode reward: 2084.3035\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.131713 14.09771  14.121256 13.198602 13.195368 14.128484]\n",
      "Reset environment\n",
      "Episode reward: 1853.054\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.132086 14.098101 14.1216   13.199029 13.195704 14.128856]\n",
      "Reset environment\n",
      "Episode reward: 2203.7454\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.132601  14.098605  14.122129  13.199604  13.196172  14.1293745]\n",
      "Reset environment\n",
      "Episode reward: 2939.8398\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.133415 14.099413 14.122947 13.200503 13.196907 14.130189]\n",
      "Reset environment\n",
      "Episode reward: 107.87753\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.132844 14.098782 14.122424 13.199863 13.196378 14.129627]\n",
      "Reset environment\n",
      "Episode reward: 1814.5144\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.13352  14.099459 14.123101 13.200609 13.196981 14.130303]\n",
      "Reset environment\n",
      "Episode reward: 2388.163\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.134199 14.100145 14.123777 13.20135  13.197609 14.130982]\n",
      "Reset environment\n",
      "Episode reward: 4778.244\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.1356125 14.1015625 14.125189  13.202878  13.1988125 14.132396 ]\n",
      "Reset environment\n",
      "Episode reward: 1846.7644\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.136071 14.102022 14.125649 13.20339  13.199232 14.132856]\n",
      "Reset environment\n",
      "Episode reward: 5204.302\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.137633  14.10358   14.127215  13.2050705 13.200593  14.134418 ]\n",
      "Reset environment\n",
      "Episode reward: 2162.1396\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.138429  14.1043825 14.128008  13.2059555 13.201323  14.135216 ]\n",
      "Reset environment\n",
      "Episode reward: 4661.6133\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.139815 14.105765 14.129392 13.207446 13.202544 14.136603]\n",
      "Reset environment\n",
      "Episode reward: 2092.4219\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.140354 14.10631  14.129928 13.208042 13.203033 14.137144]\n",
      "Reset environment\n",
      "Episode reward: 3867.8281\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.141478  14.1074295 14.131051  13.209254  13.204013  14.13827  ]\n",
      "Reset environment\n",
      "Episode reward: 5282.165\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.143059 14.109004 14.132639 13.210956 13.205383 14.139853]\n",
      "Reset environment\n",
      "Episode reward: 1422.8041\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.143401 14.109341 14.132992 13.211343 13.205689 14.140195]\n",
      "Reset environment\n",
      "Episode reward: 1093.3334\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.143652 14.109591 14.133245 13.211629 13.205915 14.140446]\n",
      "Reset environment\n",
      "Episode reward: 3772.7556\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.144738 14.110671 14.134335 13.212799 13.206864 14.141533]\n",
      "Reset environment\n",
      "Episode reward: 3523.0024\n",
      "Total Steps: 198\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.145063 14.111022 14.134636 13.213244 13.207145 14.141857]\n",
      "Reset environment\n",
      "Episode reward: 2911.4482\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.1458025 14.111743  14.135395  13.214049  13.207823  14.142598 ]\n",
      "Reset environment\n",
      "Episode reward: 5672.9873\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.147524  14.113458  14.137111  13.215891  13.209307  14.1443205]\n",
      "Reset environment\n",
      "Episode reward: 1088.8073\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.147768 14.113703 14.137356 13.216176 13.20953  14.144565]\n",
      "Reset environment\n",
      "Episode reward: 2050.969\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.148269  14.114219  14.137846  13.216732  13.2099905 14.145065 ]\n",
      "Reset environment\n",
      "Episode reward: 1401.1545\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.148497 14.11447  14.138048 13.217007 13.210194 14.145293]\n",
      "Reset environment\n",
      "Episode reward: 3808.8362\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.14954  14.115518 14.139092 13.21814  13.211148 14.146337]\n",
      "Reset environment\n",
      "Episode reward: 3096.2139\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.150401 14.116377 14.13996  13.219071 13.211907 14.147199]\n",
      "Reset environment\n",
      "Episode reward: 2135.3762\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.151179  14.117157  14.1407385 13.219921  13.212596  14.147977 ]\n",
      "Reset environment\n",
      "Episode reward: -492.2024\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.1503   14.116227 14.139908 13.218999 13.211784 14.147097]\n",
      "Reset environment\n",
      "Episode reward: 1973.568\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.150806 14.116721 14.140426 13.219557 13.212243 14.147606]\n",
      "Reset environment\n",
      "Episode reward: 2773.477\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.151563 14.117483 14.14118  13.220379 13.212931 14.148362]\n",
      "Reset environment\n",
      "Episode reward: 1829.3607\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.152244 14.118164 14.141862 13.221123 13.21354  14.149043]\n",
      "Reset environment\n",
      "Episode reward: 2157.9949\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.153034 14.118958 14.142651 13.221983 13.214245 14.149834]\n",
      "Reset environment\n",
      "Episode reward: 1568.1013\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.153309 14.11921  14.142947 13.222302 13.214496 14.150108]\n",
      "Reset environment\n",
      "Episode reward: 1781.2769\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.153727 14.119616 14.143375 13.22277  13.21487  14.150526]\n",
      "Reset environment\n",
      "Episode reward: 2892.994\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.154493 14.12038  14.144148 13.223609 13.215543 14.151294]\n",
      "Reset environment\n",
      "Episode reward: 4179.122\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.155718 14.121602 14.145374 13.224922 13.216619 14.152519]\n",
      "Reset environment\n",
      "Episode reward: 1770.02\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.15606   14.1219225 14.145736  13.225321  13.216905  14.152861 ]\n",
      "Reset environment\n",
      "Episode reward: 3145.1987\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.156936 14.122796 14.146614 13.22627  13.217676 14.153737]\n",
      "Reset environment\n",
      "Episode reward: 1601.8027\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.157361 14.123225 14.147037 13.226739 13.218063 14.154161]\n",
      "Reset environment\n",
      "Episode reward: 2087.855\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.157919 14.123788 14.147592 13.227348 13.218576 14.154719]\n",
      "Reset environment\n",
      "Episode reward: 2609.368\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.1585655 14.124424  14.148252  13.228058  13.219172  14.155367 ]\n",
      "Reset environment\n",
      "Episode reward: 2186.9878\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.15936   14.1252165 14.149042  13.228925  13.219873  14.156161 ]\n",
      "Reset environment\n",
      "Episode reward: 2056.7354\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.160114 14.125972 14.149798 13.229747 13.220541 14.156915]\n",
      "Reset environment\n",
      "Episode reward: 1988.5977\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.160608 14.126461 14.150295 13.230294 13.22099  14.15741 ]\n",
      "Reset environment\n",
      "Episode reward: 2366.5042\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.161167  14.127038  14.150835  13.230913  13.221502  14.1579685]\n",
      "Reset environment\n",
      "Episode reward: 1764.8768\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.161821 14.127694 14.15149  13.231634 13.222089 14.158623]\n",
      "Reset environment\n",
      "Episode reward: 4053.7097\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.162925  14.1288    14.152594  13.232831  13.2231045 14.159727 ]\n",
      "Reset environment\n",
      "Episode reward: 1732.141\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.163116  14.129016  14.15276   13.233081  13.2232685 14.159917 ]\n",
      "Reset environment\n",
      "Episode reward: 1624.3666\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.163506 14.129402 14.153157 13.23352  13.223624 14.160307]\n",
      "Reset environment\n",
      "Episode reward: 2576.2578\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.164027 14.129945 14.153655 13.234098 13.224098 14.160828]\n",
      "Reset environment\n",
      "Episode reward: 2178.2075\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.164821 14.130737 14.154446 13.234962 13.224795 14.16162 ]\n",
      "Reset environment\n",
      "Episode reward: 1908.262\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.1655245 14.131442  14.15515   13.235736  13.225421  14.162324 ]\n",
      "Reset environment\n",
      "Episode reward: 2303.229\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.165997  14.131887  14.1556425 13.23627   13.225816  14.162796 ]\n",
      "Reset environment\n",
      "Episode reward: 3829.3103\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.167039 14.132932 14.156685 13.237399 13.226773 14.163838]\n",
      "Reset environment\n",
      "Episode reward: 2571.4558\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.167725 14.133624 14.157368 13.238147 13.227403 14.164524]\n",
      "Reset environment\n",
      "Episode reward: 1395.3359\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.168045 14.133956 14.157678 13.238507 13.227695 14.164844]\n",
      "Reset environment\n",
      "Episode reward: 3522.3945\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.169033 14.134957 14.158665 13.239576 13.228575 14.165832]\n",
      "Reset environment\n",
      "Episode reward: 1970.8408\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.169532  14.135452  14.159166  13.2401285 13.229031  14.166331 ]\n",
      "Reset environment\n",
      "Episode reward: 2556.0833\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.170218 14.136142 14.159852 13.240876 13.229645 14.167018]\n",
      "Reset environment\n",
      "Episode reward: 1963.6985\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.170676 14.136587 14.16032  13.241382 13.230054 14.167476]\n",
      "Reset environment\n",
      "Episode reward: 2741.9514\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.171425 14.137336 14.161066 13.242197 13.230723 14.168224]\n",
      "Reset environment\n",
      "Episode reward: 3181.419\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.172285 14.138188 14.161938 13.243128 13.231498 14.169086]\n",
      "Reset environment\n",
      "Episode reward: 1932.1669\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.172747 14.138634 14.162413 13.243641 13.231899 14.169548]\n",
      "Reset environment\n",
      "Episode reward: 2208.2788\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.173338 14.139224 14.163005 13.244291 13.232435 14.17014 ]\n",
      "Reset environment\n",
      "Episode reward: 2116.132\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.173832 14.139734 14.163483 13.244838 13.232885 14.170632]\n",
      "Reset environment\n",
      "Episode reward: 2700.937\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.174546 14.14044  14.164201 13.245618 13.23352  14.171347]\n",
      "Reset environment\n",
      "Episode reward: 2369.0261\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.175156 14.141053 14.164807 13.246288 13.234077 14.171956]\n",
      "Reset environment\n",
      "Episode reward: 3808.0093\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.17624   14.142131  14.165895  13.247457  13.2350445 14.173042 ]\n",
      "Reset environment\n",
      "Episode reward: 4234.9424\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.177478  14.1433735 14.167132  13.248783  13.236136  14.174279 ]\n",
      "Reset environment\n",
      "Episode reward: 5065.422\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.179    14.144899 14.168653 13.250411 13.237455 14.175801]\n",
      "Reset environment\n",
      "Episode reward: 1754.1508\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.179431 14.145342 14.169078 13.250889 13.237853 14.176232]\n",
      "Reset environment\n",
      "Episode reward: 4090.4514\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.18061  14.14653  14.170252 13.252162 13.238896 14.177413]\n",
      "Reset environment\n",
      "Episode reward: 2096.0515\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.181369  14.147293  14.171012  13.2529955 13.239569  14.178173 ]\n",
      "Reset environment\n",
      "Episode reward: 1367.1853\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.181722  14.147644  14.171366  13.2533865 13.239893  14.178525 ]\n",
      "Reset environment\n",
      "Episode reward: 4191.776\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.182944 14.148863 14.17259  13.2547   13.240961 14.179749]\n",
      "Reset environment\n",
      "Episode reward: 1416.2042\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.183485 14.149405 14.173132 13.255295 13.241455 14.180289]\n",
      "Reset environment\n",
      "Episode reward: 4859.298\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.184933 14.150856 14.174578 13.256849 13.242718 14.181736]\n",
      "Reset environment\n",
      "Episode reward: 3956.5635\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.186065 14.151995 14.175699 13.258071 13.243702 14.182868]\n",
      "Reset environment\n",
      "Episode reward: 2038.7462\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.186549 14.15249  14.176181 13.258611 13.244143 14.183352]\n",
      "Reset environment\n",
      "Episode reward: 5454.121\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.188171 14.154104 14.177801 13.260358 13.245553 14.184974]\n",
      "Reset environment\n",
      "Episode reward: 1772.4052\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.188829 14.154765 14.17846  13.261079 13.246141 14.185632]\n",
      "Reset environment\n",
      "Episode reward: 1194.1692\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.189117 14.155057 14.178748 13.261404 13.246406 14.185922]\n",
      "Reset environment\n",
      "Episode reward: 2420.4258\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.189732 14.155678 14.179351 13.262086 13.246959 14.186535]\n",
      "Reset environment\n",
      "Episode reward: 1368.3423\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.190246 14.156196 14.179867 13.26266  13.247422 14.18705 ]\n",
      "Reset environment\n",
      "Episode reward: 3580.8594\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.1912565 14.15721   14.18087   13.263754  13.248335  14.188061 ]\n",
      "Reset environment\n",
      "Episode reward: 6081.791\n",
      "Total Steps: 205\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.19311  14.159061 14.182723 13.265746 13.249969 14.189915]\n",
      "Reset environment\n",
      "Episode reward: 4753.6865\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.194523 14.160472 14.184136 13.267259 13.251215 14.191328]\n",
      "Reset environment\n",
      "Episode reward: 5438.0645\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.196314  14.162266  14.185908  13.2691765 13.252769  14.193115 ]\n",
      "Reset environment\n",
      "Episode reward: 5695.8447\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.198029 14.163986 14.187613 13.271013 13.254254 14.19483 ]\n",
      "Reset environment\n",
      "Episode reward: 1456.5872\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.198317 14.164291 14.187874 13.271346 13.254515 14.195118]\n",
      "Reset environment\n",
      "Episode reward: 2336.5618\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.198918 14.164899 14.188471 13.272009 13.255062 14.195719]\n",
      "Reset environment\n",
      "Episode reward: 2006.9894\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.199654 14.165635 14.189208 13.272809 13.25572  14.196453]\n",
      "Reset environment\n",
      "Episode reward: 2994.3042\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.200429 14.166412 14.189983 13.273654 13.256431 14.197229]\n",
      "Reset environment\n",
      "Episode reward: 2175.0398\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.200951 14.16695  14.190488 13.274233 13.256903 14.197751]\n",
      "Reset environment\n",
      "Episode reward: 1444.0707\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.201254 14.167279 14.190773 13.274578 13.257182 14.198053]\n",
      "Reset environment\n",
      "Episode reward: 3258.2808\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.202172 14.1682   14.191689 13.275571 13.257994 14.198972]\n",
      "Reset environment\n",
      "Episode reward: 4743.835\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.203578  14.169602  14.193094  13.277074  13.259216  14.2003765]\n",
      "Reset environment\n",
      "Episode reward: 1455.1937\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.203872 14.169879 14.193409 13.277411 13.259477 14.200673]\n",
      "Reset environment\n",
      "Episode reward: 2940.4253\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.204649 14.170657 14.194186 13.278262 13.260175 14.20145 ]\n",
      "Reset environment\n",
      "Episode reward: 5196.5723\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2062   14.172205 14.195731 13.279924 13.261516 14.203002]\n",
      "Reset environment\n",
      "Episode reward: 1037.822\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.206422 14.172428 14.195953 13.280183 13.261716 14.203223]\n",
      "Reset environment\n",
      "Episode reward: 1416.7261\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.206961 14.17297  14.196493 13.280777 13.262204 14.203763]\n",
      "Reset environment\n",
      "Episode reward: 2184.564\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.207542  14.1735525 14.197073  13.281417  13.2627325 14.204344 ]\n",
      "Reset environment\n",
      "Episode reward: 3781.3196\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.208621 14.17463  14.198152 13.282584 13.263666 14.205423]\n",
      "Reset environment\n",
      "Episode reward: 1449.9926\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.208899 14.174886 14.198449 13.282906 13.263903 14.205705]\n",
      "Reset environment\n",
      "Episode reward: 1490.498\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.20917  14.175136 14.198746 13.28322  13.264148 14.205977]\n",
      "Reset environment\n",
      "Episode reward: -530.8696\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.208202 14.174096 14.197844 13.2822   13.263249 14.205013]\n",
      "Reset environment\n",
      "Episode reward: 1937.9954\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.208673 14.174565 14.198315 13.282726 13.263677 14.205483]\n",
      "Reset environment\n",
      "Episode reward: 26.494293\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.208074 14.174026 14.197661 13.282057 13.263117 14.204889]\n",
      "Reset environment\n",
      "Episode reward: 1263.3474\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.208385 14.17434  14.197974 13.282407 13.263403 14.205202]\n",
      "Reset environment\n",
      "Episode reward: 2268.721\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.208926 14.174878 14.198516 13.283008 13.263891 14.205742]\n",
      "Reset environment\n",
      "Episode reward: 5288.0586\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.21051  14.176467 14.200091 13.284703 13.265278 14.207326]\n",
      "Reset environment\n",
      "Episode reward: 1350.1964\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.210835  14.176794  14.200416  13.2850685 13.265575  14.207654 ]\n",
      "Reset environment\n",
      "Episode reward: 1625.8811\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.211094 14.177087 14.200651 13.285376 13.265817 14.207913]\n",
      "Reset environment\n",
      "Episode reward: 2507.5276\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2115345 14.177551  14.201059  13.285884  13.26621   14.208351 ]\n",
      "Reset environment\n",
      "Episode reward: 3668.2485\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2125635 14.178574  14.202089  13.286996  13.2671175 14.20938  ]\n",
      "Reset environment\n",
      "Episode reward: 1780.5391\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.212994 14.179018 14.202506 13.287478 13.267514 14.20981 ]\n",
      "Reset environment\n",
      "Episode reward: 1215.0212\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.21324  14.179265 14.202752 13.287768 13.267732 14.210056]\n",
      "Reset environment\n",
      "Episode reward: 1680.0281\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2136755 14.179701  14.203189  13.288253  13.268131  14.210492 ]\n",
      "Reset environment\n",
      "Episode reward: 4670.2485\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.215046 14.181079 14.204554 13.289725 13.269319 14.211863]\n",
      "Reset environment\n",
      "Episode reward: 2156.3853\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.215829 14.181862 14.205338 13.290576 13.270015 14.212645]\n",
      "Reset environment\n",
      "Episode reward: 1920.186\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.216298 14.182336 14.205802 13.291097 13.270443 14.213115]\n",
      "Reset environment\n",
      "Episode reward: 2117.2437\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.216874 14.18291  14.206387 13.291724 13.270977 14.213691]\n",
      "Reset environment\n",
      "Episode reward: 5217.332\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.218439 14.18447  14.207949 13.293393 13.272351 14.215253]\n",
      "Reset environment\n",
      "Episode reward: 5860.082\n",
      "Total Steps: 200\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.220195  14.1862135 14.209701  13.295276  13.273871  14.217007 ]\n",
      "Reset environment\n",
      "Episode reward: 2435.1553\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.221063  14.187081  14.210571  13.296219  13.274631  14.2178755]\n",
      "Reset environment\n",
      "Episode reward: 4259.079\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.222255 14.188274 14.211766 13.297499 13.275713 14.219067]\n",
      "Reset environment\n",
      "Episode reward: 3121.3313\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.223055  14.189058  14.2125845 13.298369  13.2764435 14.219868 ]\n",
      "Reset environment\n",
      "Episode reward: 1480.0787\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.223424 14.189425 14.212955 13.29878  13.276781 14.220236]\n",
      "Reset environment\n",
      "Episode reward: 2170.0261\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.223926 14.189928 14.213457 13.299342 13.277235 14.220737]\n",
      "Reset environment\n",
      "Episode reward: 4184.703\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.225124 14.191137 14.214651 13.300634 13.278287 14.221936]\n",
      "Reset environment\n",
      "Episode reward: 1775.9465\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.225553 14.191579 14.215069 13.301107 13.27868  14.222365]\n",
      "Reset environment\n",
      "Episode reward: 2941.5195\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.226343 14.192361 14.215868 13.301966 13.279387 14.223157]\n",
      "Reset environment\n",
      "Episode reward: 3583.1714\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.227355 14.193375 14.216873 13.303058 13.280284 14.224168]\n",
      "Reset environment\n",
      "Episode reward: 1556.4237\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.227689  14.193694  14.217229  13.303439  13.280573  14.2245035]\n",
      "Reset environment\n",
      "Episode reward: 2305.8928\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.228153 14.194129 14.217715 13.30398  13.280968 14.22497 ]\n",
      "Reset environment\n",
      "Episode reward: -642.3288\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.22729  14.193248 14.216873 13.302914 13.280181 14.224108]\n",
      "Reset environment\n",
      "Episode reward: 1965.3726\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.227765 14.193719 14.217358 13.303443 13.280612 14.224583]\n",
      "Reset environment\n",
      "Episode reward: 2370.7942\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.228388  14.194345  14.2179785 13.304122  13.281179  14.225206 ]\n",
      "Reset environment\n",
      "Episode reward: 3509.5881\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.229362  14.195328  14.2189455 13.305174  13.282043  14.22618  ]\n",
      "Reset environment\n",
      "Episode reward: 2941.5986\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.230169 14.196135 14.219753 13.306051 13.282753 14.226988]\n",
      "Reset environment\n",
      "Episode reward: 1908.1255\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2306385 14.196604  14.220226  13.306571  13.283179  14.227457 ]\n",
      "Reset environment\n",
      "Episode reward: 1800.7754\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.231068 14.19703  14.220658 13.307051 13.283568 14.227886]\n",
      "Reset environment\n",
      "Episode reward: 1984.5615\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.231484 14.197458 14.221055 13.307522 13.283934 14.228302]\n",
      "Reset environment\n",
      "Episode reward: 1411.5742\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.23202  14.197995 14.22159  13.308113 13.284418 14.228838]\n",
      "Reset environment\n",
      "Episode reward: 2238.8474\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.232482 14.198425 14.222078 13.30866  13.284825 14.229305]\n",
      "Reset environment\n",
      "Episode reward: 1979.6339\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.232978 14.198925 14.222571 13.309206 13.28528  14.2298  ]\n",
      "Reset environment\n",
      "Episode reward: 2037.1306\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.233713 14.199663 14.223305 13.310008 13.285933 14.230536]\n",
      "Reset environment\n",
      "Episode reward: 1929.1367\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.234204 14.200159 14.223787 13.310551 13.286384 14.231026]\n",
      "Reset environment\n",
      "Episode reward: 5428.011\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.235831 14.201783 14.225414 13.312292 13.287827 14.232652]\n",
      "Reset environment\n",
      "Episode reward: 2553.2598\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.236384 14.202355 14.225948 13.312906 13.288327 14.233206]\n",
      "Reset environment\n",
      "Episode reward: 5586.766\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.238062 14.204028 14.227626 13.314699 13.289795 14.23488 ]\n",
      "Reset environment\n",
      "Episode reward: 2595.489\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.23875  14.204715 14.228313 13.315451 13.290411 14.235569]\n",
      "Reset environment\n",
      "Episode reward: 2004.826\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.239237 14.205216 14.228777 13.315983 13.290853 14.236055]\n",
      "Reset environment\n",
      "Episode reward: 1696.185\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.239493  14.205447  14.229061  13.3162985 13.291078  14.236318 ]\n",
      "Reset environment\n",
      "Episode reward: 1294.6752\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.239814 14.205768 14.229381 13.316655 13.291369 14.236638]\n",
      "Reset environment\n",
      "Episode reward: 3098.6562\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.240659  14.206607  14.230229  13.3175745 13.29211   14.237483 ]\n",
      "Reset environment\n",
      "Episode reward: 3497.4534\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.241605 14.207557 14.231173 13.318598 13.292964 14.238429]\n",
      "Reset environment\n",
      "Episode reward: 2049.9556\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.242096 14.208054 14.231658 13.319149 13.293406 14.238921]\n",
      "Reset environment\n",
      "Episode reward: 2097.364\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.242856 14.208817 14.232419 13.319976 13.294083 14.239681]\n",
      "Reset environment\n",
      "Episode reward: 5067.6055\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.244364 14.210319 14.233932 13.321586 13.295408 14.241191]\n",
      "Reset environment\n",
      "Episode reward: 2115.338\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.245116  14.211071  14.234687  13.3224125 13.296077  14.241943 ]\n",
      "Reset environment\n",
      "Episode reward: 5385.7056\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.246714  14.2126665 14.236288  13.324126  13.297489  14.243542 ]\n",
      "Reset environment\n",
      "Episode reward: 4286.9326\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.24796  14.213917 14.237531 13.325467 13.298569 14.244788]\n",
      "Reset environment\n",
      "Episode reward: 3585.493\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.248955 14.21492  14.23851  13.326543 13.299452 14.245781]\n",
      "Reset environment\n",
      "Episode reward: 3710.2917\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.250014  14.215982  14.239568  13.327682  13.30038   14.2468405]\n",
      "Reset environment\n",
      "Episode reward: 5681.9673\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.251704 14.217673 14.24123  13.329493 13.301833 14.24853 ]\n",
      "Reset environment\n",
      "Episode reward: 4897.9224\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.253151  14.219126  14.242672  13.3310375 13.303076  14.249976 ]\n",
      "Reset environment\n",
      "Episode reward: 1682.7686\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.253405 14.2194   14.242904 13.331342 13.303302 14.250229]\n",
      "Reset environment\n",
      "Episode reward: 2650.4207\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.254119 14.220115 14.243615 13.332126 13.303933 14.250943]\n",
      "Reset environment\n",
      "Episode reward: 2189.1177\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.254586 14.220604 14.244055 13.33265  13.304356 14.251406]\n",
      "Reset environment\n",
      "Episode reward: 2521.2688\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.255253  14.221277  14.2447195 13.333381  13.3049555 14.252073 ]\n",
      "Reset environment\n",
      "Episode reward: 251.25668\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.254682 14.220638 14.244203 13.332762 13.304447 14.2515  ]\n",
      "Reset environment\n",
      "Episode reward: 2033.1866\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2551   14.221086 14.244594 13.333243 13.304822 14.251918]\n",
      "Reset environment\n",
      "Episode reward: 3840.7695\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.256192 14.222177 14.245687 13.334423 13.305772 14.25301 ]\n",
      "Reset environment\n",
      "Episode reward: 2119.5837\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.256734 14.22272  14.246237 13.335024 13.30627  14.253553]\n",
      "Reset environment\n",
      "Episode reward: 1366.3936\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.257079 14.22307  14.246577 13.335407 13.306585 14.253898]\n",
      "Reset environment\n",
      "Episode reward: 1758.4581\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2577095 14.223702  14.247208  13.336108  13.307144  14.254528 ]\n",
      "Reset environment\n",
      "Episode reward: 3378.9944\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.258625 14.224629 14.248118 13.337107 13.307967 14.255445]\n",
      "Reset environment\n",
      "Episode reward: 3051.028\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.259463 14.225465 14.24896  13.338018 13.308702 14.256283]\n",
      "Reset environment\n",
      "Episode reward: 1845.0126\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.259911 14.225923 14.249404 13.338513 13.309111 14.25673 ]\n",
      "Reset environment\n",
      "Episode reward: 1747.5779\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.260224 14.226255 14.249696 13.338874 13.309394 14.257043]\n",
      "Reset environment\n",
      "Episode reward: 5137.518\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.261751 14.227788 14.251222 13.340509 13.310716 14.258572]\n",
      "Reset environment\n",
      "Episode reward: 5026.0933\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.263223 14.229267 14.252688 13.342092 13.312014 14.260043]\n",
      "Reset environment\n",
      "Episode reward: 1983.6174\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.263693 14.229731 14.25317  13.34261  13.312446 14.260514]\n",
      "Reset environment\n",
      "Episode reward: 2564.4514\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.264602 14.230639 14.254081 13.343596 13.313242 14.261423]\n",
      "Reset environment\n",
      "Episode reward: 1985.4099\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.265068 14.231117 14.254538 13.344111 13.313669 14.261889]\n",
      "Reset environment\n",
      "Episode reward: 2533.984\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.265738 14.23179  14.255206 13.34485  13.314274 14.262559]\n",
      "Reset environment\n",
      "Episode reward: 2085.338\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.266488 14.232541 14.255959 13.34567  13.314944 14.26331 ]\n",
      "Reset environment\n",
      "Episode reward: 1685.2263\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.266835 14.232863 14.256325 13.346062 13.315234 14.263658]\n",
      "Reset environment\n",
      "Episode reward: 1386.4403\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.267353  14.233383  14.2568445 13.346637  13.315702  14.264175 ]\n",
      "Reset environment\n",
      "Episode reward: 3017.574\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.268173 14.234202 14.257665 13.347528 13.316419 14.264994]\n",
      "Reset environment\n",
      "Episode reward: 1.9143372\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.267581 14.23357  14.25711  13.346829 13.315878 14.264403]\n",
      "Reset environment\n",
      "Episode reward: 4799.073\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.26895  14.23494  14.258469 13.34831  13.317078 14.265772]\n",
      "Reset environment\n",
      "Episode reward: -466.92294\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.268149 14.234127 14.257681 13.347344 13.316347 14.264975]\n",
      "Reset environment\n",
      "Episode reward: 2830.1296\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.268906 14.23488  14.258442 13.348169 13.317014 14.265731]\n",
      "Reset environment\n",
      "Episode reward: -497.7531\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.267948 14.233854 14.257563 13.347277 13.316132 14.264781]\n",
      "Reset environment\n",
      "Episode reward: 2503.1528\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.268529 14.234419 14.258161 13.347918 13.316635 14.26536 ]\n",
      "Reset environment\n",
      "Episode reward: -494.80798\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.267708 14.233554 14.257382 13.347001 13.315895 14.264542]\n",
      "Reset environment\n",
      "Episode reward: 1987.1171\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.268208  14.234062  14.2578745 13.347549  13.316356  14.265041 ]\n",
      "Reset environment\n",
      "Episode reward: 4495.299\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.269504 14.235365 14.259165 13.348947 13.31748  14.266337]\n",
      "Reset environment\n",
      "Episode reward: 2167.351\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.270281 14.236146 14.259942 13.349795 13.318172 14.267116]\n",
      "Reset environment\n",
      "Episode reward: 1524.831\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.270658 14.236519 14.260321 13.350215 13.318515 14.26749 ]\n",
      "Reset environment\n",
      "Episode reward: 1968.595\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.271094  14.236942  14.260773  13.350707  13.3189125 14.267929 ]\n",
      "Reset environment\n",
      "Episode reward: 4112.0815\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.272266 14.238111 14.261948 13.351967 13.319933 14.269101]\n",
      "Reset environment\n",
      "Episode reward: 1861.2324\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2727165 14.238561  14.2624    13.352467  13.320343  14.269552 ]\n",
      "Reset environment\n",
      "Episode reward: 1976.958\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.273194 14.239037 14.262878 13.353    13.320778 14.270029]\n",
      "Reset environment\n",
      "Episode reward: 2356.471\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.273797 14.239645 14.263474 13.353661 13.321329 14.270632]\n",
      "Reset environment\n",
      "Episode reward: 1186.2828\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.274071  14.239918  14.26375   13.353974  13.321578  14.2709055]\n",
      "Reset environment\n",
      "Episode reward: 5488.4062\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.275716  14.241555  14.2653885 13.355729  13.323003  14.272549 ]\n",
      "Reset environment\n",
      "Episode reward: 4330.9355\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.276957  14.242803  14.2666235 13.357066  13.3240795 14.273788 ]\n",
      "Reset environment\n",
      "Episode reward: 1476.989\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.277281 14.243129 14.266949 13.357437 13.324372 14.274114]\n",
      "Reset environment\n",
      "Episode reward: 1408.6672\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.277809 14.24366  14.267477 13.358022 13.324852 14.274642]\n",
      "Reset environment\n",
      "Episode reward: 2885.9414\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.278593 14.244444 14.268261 13.358871 13.325542 14.275426]\n",
      "Reset environment\n",
      "Episode reward: 2821.102\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.279176  14.245048  14.268826  13.359525  13.3260765 14.276008 ]\n",
      "Reset environment\n",
      "Episode reward: 3065.0027\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.280003 14.24588  14.269647 13.360424 13.326806 14.276835]\n",
      "Reset environment\n",
      "Episode reward: 1923.062\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.280464 14.24634  14.270119 13.360933 13.327229 14.277297]\n",
      "Reset environment\n",
      "Episode reward: 2157.0815\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.280993 14.246879 14.270642 13.361517 13.327713 14.277825]\n",
      "Reset environment\n",
      "Episode reward: 1531.6224\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.281348 14.247217 14.271008 13.36191  13.328031 14.278181]\n",
      "Reset environment\n",
      "Episode reward: 1761.6605\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.281777 14.247633 14.271446 13.362384 13.328424 14.27861 ]\n",
      "Reset environment\n",
      "Episode reward: 3145.2537\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.2826395 14.2485    14.2723    13.363321  13.329206  14.279472 ]\n",
      "Reset environment\n",
      "Episode reward: 3066.6748\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.283493  14.249359  14.27315   13.3642435 13.329975  14.280325 ]\n",
      "Reset environment\n",
      "Episode reward: 1349.7637\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.283988 14.249858 14.273646 13.364798 13.330423 14.28082 ]\n",
      "Reset environment\n",
      "Episode reward: 1413.5952\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.284519 14.25039  14.274178 13.365384 13.330907 14.281351]\n",
      "Reset environment\n",
      "Episode reward: 2699.4229\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.285256 14.251131 14.274913 13.366179 13.331571 14.282089]\n",
      "Reset environment\n",
      "Episode reward: 3577.2795\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.286259  14.25214   14.275914  13.36726   13.33245   14.2830925]\n",
      "Reset environment\n",
      "Episode reward: 2669.3972\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.286971 14.25287  14.276616 13.368038 13.333106 14.283805]\n",
      "Reset environment\n",
      "Episode reward: 5224.8643\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.288518 14.25442  14.278162 13.369694 13.334445 14.285352]\n",
      "Reset environment\n",
      "Episode reward: 3384.4\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.289441 14.25534  14.27909  13.370694 13.335251 14.286276]\n",
      "Reset environment\n",
      "Episode reward: 5304.35\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.291016 14.256917 14.280666 13.372376 13.336619 14.28785 ]\n",
      "Reset environment\n",
      "Episode reward: 1443.087\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.291393 14.257296 14.281044 13.372795 13.336968 14.288228]\n",
      "Reset environment\n",
      "Episode reward: 1718.5886\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.291842 14.257745 14.281496 13.373292 13.337383 14.288677]\n",
      "Reset environment\n",
      "Episode reward: 2246.8916\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.292364 14.258256 14.28203  13.373875 13.337861 14.2892  ]\n",
      "Reset environment\n",
      "Episode reward: 1599.5529\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.292584 14.2585   14.282221 13.374144 13.338057 14.289419]\n",
      "Reset environment\n",
      "Episode reward: 2093.574\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.293335 14.259254 14.282971 13.374966 13.338723 14.290171]\n",
      "Reset environment\n",
      "Episode reward: 2866.245\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.294103 14.260029 14.283735 13.375811 13.339402 14.29094 ]\n",
      "Reset environment\n",
      "Episode reward: -177.61258\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.293471 14.259426 14.283091 13.375015 13.338837 14.290312]\n",
      "Reset environment\n",
      "Episode reward: 2136.0806\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.293983 14.259952 14.283593 13.375584 13.339309 14.290823]\n",
      "Reset environment\n",
      "Episode reward: 3868.2222\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.295078 14.261052 14.284687 13.376773 13.340262 14.291919]\n",
      "Reset environment\n",
      "Episode reward: 4153.2646\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.296258  14.262238  14.285866  13.378048  13.3412895 14.293099 ]\n",
      "Reset environment\n",
      "Episode reward: 2168.7805\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.29676  14.262726 14.286381 13.378599 13.341736 14.2936  ]\n",
      "Reset environment\n",
      "Episode reward: 3078.4238\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.297601 14.263566 14.287223 13.379518 13.342474 14.294442]\n",
      "Reset environment\n",
      "Episode reward: 4612.152\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.29894  14.264905 14.288565 13.380958 13.343664 14.29578 ]\n",
      "Reset environment\n",
      "Episode reward: 1924.238\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.299625 14.265593 14.289251 13.381711 13.344272 14.296466]\n",
      "Reset environment\n",
      "Episode reward: -460.5075\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.298686 14.264561 14.288384 13.380721 13.343384 14.295526]\n",
      "Reset environment\n",
      "Episode reward: 1847.0903\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.299138 14.265016 14.288833 13.38122  13.343797 14.295978]\n",
      "Reset environment\n",
      "Episode reward: 1907.2452\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.299597 14.265472 14.28929  13.38173  13.344214 14.296436]\n",
      "Reset environment\n",
      "Episode reward: 1741.4755\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.300032  14.265912  14.2897215 13.382217  13.344611  14.296871 ]\n",
      "Reset environment\n",
      "Episode reward: 3602.6096\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.301034  14.2669115 14.29073   13.3833    13.345479  14.2978735]\n",
      "Reset environment\n",
      "Episode reward: 4978.3247\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.302391  14.268271  14.2920885 13.384776  13.346712  14.299232 ]\n",
      "Reset environment\n",
      "Episode reward: 1853.7263\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.302833 14.268707 14.292539 13.385268 13.347114 14.299673]\n",
      "Reset environment\n",
      "Episode reward: 2433.4338\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.303458 14.26933  14.29317  13.385953 13.347683 14.300299]\n",
      "Reset environment\n",
      "Episode reward: 1719.5483\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.304084 14.269958 14.293796 13.386641 13.34824  14.300924]\n",
      "Reset environment\n",
      "Episode reward: 2422.4746\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.304664 14.270527 14.294393 13.38728  13.348761 14.301505]\n",
      "Reset environment\n",
      "Episode reward: 1405.7136\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.30519  14.271055 14.29492  13.387863 13.349239 14.302031]\n",
      "Reset environment\n",
      "Episode reward: 2563.4895\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.305821 14.271708 14.295535 13.388553 13.349821 14.302661]\n",
      "Reset environment\n",
      "Episode reward: 2670.8354\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.306512 14.272404 14.296221 13.389312 13.350456 14.303351]\n",
      "Reset environment\n",
      "Episode reward: 2152.8835\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.307283 14.273176 14.29699  13.390152 13.351142 14.304123]\n",
      "Reset environment\n",
      "Episode reward: 4434.182\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.308571 14.274467 14.298276 13.391527 13.352258 14.30541 ]\n",
      "Reset environment\n",
      "Episode reward: -522.5277\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.307644 14.273462 14.297419 13.390565 13.351391 14.304489]\n",
      "Reset environment\n",
      "Episode reward: 4591.233\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.308978 14.274802 14.298749 13.391992 13.35255  14.305824]\n",
      "Reset environment\n",
      "Episode reward: 2126.8594\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.309732 14.275558 14.299504 13.392817 13.353219 14.306579]\n",
      "Reset environment\n",
      "Episode reward: 1656.3071\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.310116 14.275932 14.2999   13.393244 13.353569 14.306962]\n",
      "Reset environment\n",
      "Episode reward: 2424.6863\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.310729 14.276557 14.300507 13.393915 13.354133 14.307575]\n",
      "Reset environment\n",
      "Episode reward: 1525.7894\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.311074 14.276903 14.300853 13.394308 13.354445 14.30792 ]\n",
      "Reset environment\n",
      "Episode reward: 2090.8345\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.311584 14.277409 14.301366 13.394873 13.354907 14.308431]\n",
      "Reset environment\n",
      "Episode reward: 4045.6646\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.312734  14.278564  14.302512  13.3961115 13.355912  14.309581 ]\n",
      "Reset environment\n",
      "Episode reward: 5223.926\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.314264 14.280096 14.304046 13.39775  13.357276 14.311111]\n",
      "Reset environment\n",
      "Episode reward: 2182.3616\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.314774 14.280622 14.304541 13.398317 13.357741 14.311621]\n",
      "Reset environment\n",
      "Episode reward: 1376.2367\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.315281 14.281131 14.305049 13.398883 13.358201 14.312128]\n",
      "Reset environment\n",
      "Episode reward: 1629.9011\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.315876 14.281727 14.305643 13.399536 13.358736 14.312723]\n",
      "Reset environment\n",
      "Episode reward: 5390.21\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.31747  14.283322 14.307234 13.401241 13.360119 14.314318]\n",
      "Reset environment\n",
      "Episode reward: 1547.2008\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.317857 14.283717 14.307615 13.40167  13.360468 14.314704]\n",
      "Reset environment\n",
      "Episode reward: 1416.319\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.318387 14.284247 14.308146 13.402253 13.360949 14.315233]\n",
      "Reset environment\n",
      "Episode reward: 2179.6792\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.318966 14.284831 14.308722 13.402884 13.36148  14.315813]\n",
      "Reset environment\n",
      "Episode reward: 894.8843\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.319148 14.285014 14.308904 13.403099 13.361645 14.315995]\n",
      "Reset environment\n",
      "Episode reward: 4600.4814\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.320472 14.286342 14.310224 13.404526 13.362778 14.317319]\n",
      "Reset environment\n",
      "Episode reward: 2401.0476\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.321093  14.286967  14.310841  13.40521   13.3633375 14.31794  ]\n",
      "Reset environment\n",
      "Episode reward: 1820.6553\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.32155   14.28742   14.311304  13.405721  13.363755  14.3183975]\n",
      "Reset environment\n",
      "Episode reward: 1879.5089\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.322011 14.287887 14.31176  13.40623  13.364179 14.318858]\n",
      "Reset environment\n",
      "Episode reward: 3653.175\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.323037 14.288913 14.312789 13.407342 13.365072 14.319884]\n",
      "Reset environment\n",
      "Episode reward: 4855.379\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.324439 14.290324 14.314186 13.408851 13.366304 14.321287]\n",
      "Reset environment\n",
      "Episode reward: 2058.8723\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.324944 14.290828 14.314691 13.409413 13.366764 14.321792]\n",
      "Reset environment\n",
      "Episode reward: 3503.0737\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.325915 14.291808 14.315657 13.410466 13.367646 14.322761]\n",
      "Reset environment\n",
      "Episode reward: 1923.1627\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.32661  14.292504 14.316352 13.411222 13.368269 14.323455]\n",
      "Reset environment\n",
      "Episode reward: 5832.1025\n",
      "Total Steps: 196\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.328342 14.294249 14.318082 13.413072 13.369791 14.325188]\n",
      "Reset environment\n",
      "Episode reward: 2712.3867\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.32907  14.29498  14.318809 13.413871 13.370454 14.325915]\n",
      "Reset environment\n",
      "Episode reward: 4505.8047\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.330366 14.29628  14.3201   13.415263 13.371595 14.327212]\n",
      "Reset environment\n",
      "Episode reward: 4101.4805\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.33154  14.29746  14.321269 13.416523 13.372619 14.328384]\n",
      "Reset environment\n",
      "Episode reward: 4866.624\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.332958  14.298883  14.322686  13.418043  13.373842  14.3298025]\n",
      "Reset environment\n",
      "Episode reward: 4466.2715\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.33425  14.300171 14.323979 13.419434 13.37497  14.331095]\n",
      "Reset environment\n",
      "Episode reward: 1484.3159\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.334604 14.300533 14.32432  13.419822 13.375298 14.331449]\n",
      "Reset environment\n",
      "Episode reward: 1190.2139\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.334866 14.300785 14.324592 13.420116 13.375534 14.331712]\n",
      "Reset environment\n",
      "Episode reward: 2429.3105\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.335474 14.301379 14.325208 13.420782 13.376083 14.33232 ]\n",
      "Reset environment\n",
      "Episode reward: 1366.2871\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.335975 14.301882 14.32571  13.421345 13.376538 14.332823]\n",
      "Reset environment\n",
      "Episode reward: 1186.4573\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.336258 14.302165 14.325997 13.421664 13.376799 14.333108]\n",
      "Reset environment\n",
      "Episode reward: 1817.8931\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.336691 14.3026   14.326429 13.422148 13.377192 14.333541]\n",
      "Reset environment\n",
      "Episode reward: 4180.0566\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.33787  14.303784 14.327599 13.423416 13.37823  14.334719]\n",
      "Reset environment\n",
      "Episode reward: 3860.6672\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.338976 14.304892 14.328701 13.424592 13.379223 14.335827]\n",
      "Reset environment\n",
      "Episode reward: 1739.0045\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.339424 14.305341 14.32915  13.425089 13.379637 14.336275]\n",
      "Reset environment\n",
      "Episode reward: 2465.2578\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.340053 14.305979 14.329769 13.425787 13.380211 14.336905]\n",
      "Reset environment\n",
      "Episode reward: 996.89484\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.340272 14.306201 14.329985 13.42604  13.380406 14.337123]\n",
      "Reset environment\n",
      "Episode reward: 1992.6233\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.340749 14.306675 14.330468 13.426567 13.380842 14.337601]\n",
      "Reset environment\n",
      "Episode reward: 2056.5754\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.341238 14.307159 14.33096  13.427112 13.381283 14.33809 ]\n",
      "Reset environment\n",
      "Episode reward: 2728.2705\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.3419285 14.307838  14.331663  13.427869  13.381889  14.33878  ]\n",
      "Reset environment\n",
      "Episode reward: 4218.1963\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.343113 14.309019 14.332848 13.429142 13.382921 14.339963]\n",
      "Reset environment\n",
      "Episode reward: 2505.4756\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.343763 14.309665 14.333499 13.429849 13.383509 14.340613]\n",
      "Reset environment\n",
      "Episode reward: 2432.223\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.344195 14.310119 14.333904 13.430342 13.383898 14.341044]\n",
      "Reset environment\n",
      "Episode reward: 3095.666\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.345034 14.310956 14.334745 13.431249 13.384633 14.341883]\n",
      "Reset environment\n",
      "Episode reward: 5393.7114\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.3466215 14.312547  14.336328  13.432948  13.386005  14.34347  ]\n",
      "Reset environment\n",
      "Episode reward: 3669.2178\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.347637 14.313576 14.337339 13.434041 13.386905 14.344486]\n",
      "Reset environment\n",
      "Episode reward: 4102.375\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.348802 14.314731 14.338507 13.435298 13.387919 14.345651]\n",
      "Reset environment\n",
      "Episode reward: 1819.3679\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.349226 14.31517  14.338919 13.435774 13.38831  14.346074]\n",
      "Reset environment\n",
      "Episode reward: 2664.97\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.349959 14.315919 14.339639 13.436564 13.388988 14.346807]\n",
      "Reset environment\n",
      "Episode reward: 4460.7607\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.3512335 14.317197  14.340909  13.437937  13.390099  14.348081 ]\n",
      "Reset environment\n",
      "Episode reward: 2155.6\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.35169  14.317674 14.341347 13.43845  13.390519 14.348536]\n",
      "Reset environment\n",
      "Episode reward: 1746.7144\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.352119 14.318089 14.341786 13.438922 13.390898 14.348966]\n",
      "Reset environment\n",
      "Episode reward: 2514.7852\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.3526945 14.318647  14.3423815 13.439557  13.391397  14.349543 ]\n",
      "Reset environment\n",
      "Episode reward: 5719.467\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.354371 14.320318 14.344058 13.441366 13.392862 14.351219]\n",
      "Reset environment\n",
      "Episode reward: 2065.684\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.354873 14.320817 14.344562 13.44192  13.39332  14.351721]\n",
      "Reset environment\n",
      "Episode reward: 1534.7277\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.355236  14.321183  14.344921  13.4423275 13.393652  14.352084 ]\n",
      "Reset environment\n",
      "Episode reward: 2414.9946\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.355673 14.321642 14.345337 13.442827 13.394052 14.352521]\n",
      "Reset environment\n",
      "Episode reward: 1828.0251\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.35633  14.322302 14.345994 13.443547 13.394638 14.353177]\n",
      "Reset environment\n",
      "Episode reward: 2363.6477\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.356971 14.322948 14.346625 13.444242 13.395228 14.353818]\n",
      "Reset environment\n",
      "Episode reward: 2401.1177\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.357493 14.323452 14.347167 13.444829 13.395674 14.354341]\n",
      "Reset environment\n",
      "Episode reward: 1255.6887\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.357792  14.323752  14.3474655 13.445163  13.395947  14.35464  ]\n",
      "Reset environment\n",
      "Episode reward: 2349.5513\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.358444  14.3244095 14.348116  13.445869  13.396543  14.355291 ]\n",
      "Reset environment\n",
      "Episode reward: 4080.8035\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.359582 14.325538 14.349259 13.447092 13.397541 14.356427]\n",
      "Reset environment\n",
      "Episode reward: 4782.635\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.360961 14.326913 14.350637 13.44857  13.398761 14.357806]\n",
      "Reset environment\n",
      "Episode reward: 2429.3535\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.3615465 14.327489  14.351235  13.449212  13.399296  14.358395 ]\n",
      "Reset environment\n",
      "Episode reward: 2276.1948\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.362112 14.328053 14.351803 13.449841 13.399806 14.35896 ]\n",
      "Reset environment\n",
      "Episode reward: 1384.0132\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.362628 14.328571 14.352318 13.450411 13.400276 14.359476]\n",
      "Reset environment\n",
      "Episode reward: 4539.014\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.363855 14.329801 14.353546 13.451734 13.401407 14.360704]\n",
      "Reset environment\n",
      "Episode reward: 2966.077\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.364655  14.330599  14.354346  13.4526005 13.402116  14.361504 ]\n",
      "Reset environment\n",
      "Episode reward: 1187.5172\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.364941 14.330885 14.354632 13.452924 13.402376 14.36179 ]\n",
      "Reset environment\n",
      "Episode reward: 4113.0205\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.366099 14.33205  14.355785 13.454178 13.403393 14.362949]\n",
      "Reset environment\n",
      "Episode reward: 2592.6113\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.366779 14.332732 14.356466 13.454918 13.404005 14.363631]\n",
      "Reset environment\n",
      "Episode reward: 5054.729\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.368244 14.3342   14.357935 13.45649  13.405306 14.365097]\n",
      "Reset environment\n",
      "Episode reward: 2259.589\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.368781 14.334748 14.358465 13.457083 13.4058   14.365635]\n",
      "Reset environment\n",
      "Episode reward: 4036.4392\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.369927 14.335892 14.359609 13.458316 13.406807 14.366778]\n",
      "Reset environment\n",
      "Episode reward: 4223.225\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.371119  14.337078  14.360809  13.459595  13.407852  14.3679695]\n",
      "Reset environment\n",
      "Episode reward: 2037.4022\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.371845 14.337805 14.361537 13.460385 13.408504 14.368696]\n",
      "Reset environment\n",
      "Episode reward: 2609.2979\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.372535 14.338497 14.362222 13.461136 13.409127 14.369386]\n",
      "Reset environment\n",
      "Episode reward: 2451.8052\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.373186  14.3391485 14.36287   13.461851  13.409716  14.370037 ]\n",
      "Reset environment\n",
      "Episode reward: 1296.9188\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.373483 14.339432 14.363177 13.462186 13.409982 14.370334]\n",
      "Reset environment\n",
      "Episode reward: 2004.1227\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.374198 14.34015  14.363893 13.462969 13.410617 14.371048]\n",
      "Reset environment\n",
      "Episode reward: 3092.6658\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.375033 14.340982 14.364731 13.463874 13.411347 14.371884]\n",
      "Reset environment\n",
      "Episode reward: 5221.4106\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.376588 14.342517 14.366285 13.46554  13.412706 14.373441]\n",
      "Reset environment\n",
      "Episode reward: 2029.0342\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.377074 14.343001 14.366781 13.46608  13.413151 14.373927]\n",
      "Reset environment\n",
      "Episode reward: 1391.3118\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.377588 14.343518 14.367294 13.466651 13.413613 14.374441]\n",
      "Reset environment\n",
      "Episode reward: 1281.6577\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.377905 14.343838 14.367609 13.467005 13.413902 14.37476 ]\n",
      "Reset environment\n",
      "Episode reward: 2031.6675\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.378356 14.344304 14.368044 13.467505 13.414318 14.375211]\n",
      "Reset environment\n",
      "Episode reward: 2481.391\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.378999 14.344945 14.368688 13.468214 13.414898 14.375854]\n",
      "Reset environment\n",
      "Episode reward: 1667.0896\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.379306 14.345236 14.369015 13.468568 13.415152 14.376161]\n",
      "Reset environment\n",
      "Episode reward: 2531.6052\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.379967 14.345899 14.369678 13.469294 13.415743 14.376823]\n",
      "Reset environment\n",
      "Episode reward: 4025.7969\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.381098 14.346998 14.370814 13.470513 13.416729 14.377952]\n",
      "Reset environment\n",
      "Episode reward: 2396.6606\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.381701 14.347598 14.371422 13.471177 13.417275 14.378555]\n",
      "Reset environment\n",
      "Episode reward: 1220.178\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.381983 14.347881 14.371703 13.471505 13.417535 14.378838]\n",
      "Reset environment\n",
      "Episode reward: -338.90015\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.381256 14.347158 14.371006 13.470748 13.416938 14.378128]\n",
      "Reset environment\n",
      "Episode reward: 4517.9287\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.382556 14.348456 14.372308 13.47214  13.418083 14.379428]\n",
      "Reset environment\n",
      "Episode reward: 2328.63\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.383172 14.349073 14.372926 13.472816 13.418646 14.380046]\n",
      "Reset environment\n",
      "Episode reward: 4414.024\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.384437 14.350344 14.374181 13.474168 13.419751 14.38131 ]\n",
      "Reset environment\n",
      "Episode reward: 5381.37\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.3860035 14.351917  14.375743  13.475846  13.421113  14.382877 ]\n",
      "Reset environment\n",
      "Episode reward: 6059.359\n",
      "Total Steps: 227\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.388023  14.35394   14.3777685 13.478008  13.422912  14.384899 ]\n",
      "Reset environment\n",
      "Episode reward: 1880.3778\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.388458 14.354378 14.378203 13.478496 13.423308 14.385334]\n",
      "Reset environment\n",
      "Episode reward: 4301.942\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.389675  14.355601  14.3794155 13.479804  13.424366  14.386551 ]\n",
      "Reset environment\n",
      "Episode reward: -314.892\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.388803 14.354796 14.378502 13.478921 13.423611 14.385692]\n",
      "Reset environment\n",
      "Episode reward: 3589.3142\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.389801 14.355797 14.379499 13.479997 13.424486 14.386689]\n",
      "Reset environment\n",
      "Episode reward: 1881.5775\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.390255 14.35625  14.379956 13.480499 13.4249   14.387143]\n",
      "Reset environment\n",
      "Episode reward: 5304.892\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.391704 14.357699 14.381406 13.482057 13.426228 14.388593]\n",
      "Reset environment\n",
      "Episode reward: 1729.1383\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.392083 14.358099 14.381767 13.482489 13.426577 14.388972]\n",
      "Reset environment\n",
      "Episode reward: 1739.4288\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.392502 14.358516 14.382193 13.482957 13.426961 14.389392]\n",
      "Reset environment\n",
      "Episode reward: 4052.5098\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.393605 14.359623 14.383299 13.484152 13.427958 14.390496]\n",
      "Reset environment\n",
      "Episode reward: 872.65784\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.393781 14.359796 14.383475 13.484354 13.428112 14.390671]\n",
      "Reset environment\n",
      "Episode reward: 1767.1968\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.394189 14.360197 14.383888 13.484811 13.428482 14.391079]\n",
      "Reset environment\n",
      "Episode reward: 2358.5146\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.394724 14.360755 14.384406 13.485405 13.428975 14.391615]\n",
      "Reset environment\n",
      "Episode reward: 3260.8523\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.3956   14.361642 14.385279 13.486352 13.429759 14.392491]\n",
      "Reset environment\n",
      "Episode reward: 1471.1149\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.395923 14.361979 14.385584 13.486712 13.430049 14.392814]\n",
      "Reset environment\n",
      "Episode reward: 1967.4661\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.396411 14.362457 14.386082 13.487245 13.430502 14.393302]\n",
      "Reset environment\n",
      "Episode reward: 330.66544\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.395881 14.361873 14.385597 13.486648 13.430025 14.392777]\n",
      "Reset environment\n",
      "Episode reward: 3688.9895\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.396903 14.362901 14.386618 13.487752 13.430926 14.3938  ]\n",
      "Reset environment\n",
      "Episode reward: 5009.776\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.398242 14.364247 14.387957 13.489201 13.43216  14.395143]\n",
      "Reset environment\n",
      "Episode reward: 1413.9795\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.398765 14.364772 14.388479 13.489778 13.432636 14.395665]\n",
      "Reset environment\n",
      "Episode reward: 3180.6223\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.399587 14.365578 14.389315 13.490674 13.433362 14.396486]\n",
      "Reset environment\n",
      "Episode reward: 2182.6257\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4001045 14.366106  14.38982   13.491245  13.433838  14.397004 ]\n",
      "Reset environment\n",
      "Episode reward: 2786.495\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.400843 14.366847 14.390555 13.492047 13.434499 14.397744]\n",
      "Reset environment\n",
      "Episode reward: 1188.21\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.401125 14.36713  14.390839 13.492367 13.434756 14.398026]\n",
      "Reset environment\n",
      "Episode reward: 5845.0176\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.40286   14.36886   14.392583  13.49422   13.4362955 14.399759 ]\n",
      "Reset environment\n",
      "Episode reward: 1350.3615\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.403174  14.369179  14.392893  13.494573  13.4365835 14.400072 ]\n",
      "Reset environment\n",
      "Episode reward: 1674.9032\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.403502 14.369488 14.393241 13.494948 13.43686  14.400403]\n",
      "Reset environment\n",
      "Episode reward: 1487.5316\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.403842 14.36983  14.393578 13.495333 13.437167 14.400742]\n",
      "Reset environment\n",
      "Episode reward: 1945.7378\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.404309 14.37031  14.394033 13.495842 13.437594 14.401209]\n",
      "Reset environment\n",
      "Episode reward: 2126.482\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.404811  14.370799  14.394548  13.496399  13.438043  14.4017105]\n",
      "Reset environment\n",
      "Episode reward: 2931.9265\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.405574  14.371575  14.3953    13.4972315 13.438728  14.402471 ]\n",
      "Reset environment\n",
      "Episode reward: 1369.4333\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.405912 14.371914 14.395636 13.497608 13.439032 14.402809]\n",
      "Reset environment\n",
      "Episode reward: 2069.966\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.406426 14.37244  14.396137 13.49818  13.439502 14.403322]\n",
      "Reset environment\n",
      "Episode reward: 6652.3926\n",
      "Total Steps: 228\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.408315 14.374318 14.39802  13.500205 13.441189 14.405204]\n",
      "Reset environment\n",
      "Episode reward: 3204.7297\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.409184  14.375187  14.3988905 13.50115   13.441954  14.4060755]\n",
      "Reset environment\n",
      "Episode reward: 1210.2281\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.409436 14.375427 14.399152 13.501442 13.442177 14.406327]\n",
      "Reset environment\n",
      "Episode reward: 3751.8613\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.410481 14.376473 14.4002   13.502569 13.443098 14.407372]\n",
      "Reset environment\n",
      "Episode reward: 4373.7036\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.411721 14.377697 14.40144  13.503904 13.444182 14.408614]\n",
      "Reset environment\n",
      "Episode reward: 5691.0034\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4133835 14.379364  14.4030905 13.5056925 13.445618  14.410276 ]\n",
      "Reset environment\n",
      "Episode reward: 2256.8113\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.413885 14.379848 14.403609 13.50625  13.446054 14.410779]\n",
      "Reset environment\n",
      "Episode reward: 1984.3936\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.414224 14.380157 14.403983 13.506662 13.446355 14.41112 ]\n",
      "Reset environment\n",
      "Episode reward: 1742.7971\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.414649  14.380589  14.404406  13.5071335 13.446744  14.411547 ]\n",
      "Reset environment\n",
      "Episode reward: 1772.3479\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.415287 14.381228 14.405044 13.507832 13.447312 14.412185]\n",
      "Reset environment\n",
      "Episode reward: 4435.7275\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.416505 14.38245  14.406261 13.509161 13.448349 14.413404]\n",
      "Reset environment\n",
      "Episode reward: 1402.6083\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.416844 14.382792 14.406599 13.509539 13.448661 14.413744]\n",
      "Reset environment\n",
      "Episode reward: 1366.9342\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.417107  14.383034  14.4068775 13.509839  13.448885  14.414009 ]\n",
      "Reset environment\n",
      "Episode reward: 1474.6373\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.417472 14.383409 14.407236 13.510243 13.449219 14.414374]\n",
      "Reset environment\n",
      "Episode reward: 988.29913\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4176655 14.383608  14.407425  13.510469  13.4493885 14.414568 ]\n",
      "Reset environment\n",
      "Episode reward: 2439.072\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.418103 14.384071 14.407835 13.510974 13.449789 14.415004]\n",
      "Reset environment\n",
      "Episode reward: 2434.683\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.418949 14.384915 14.408681 13.511892 13.450532 14.415849]\n",
      "Reset environment\n",
      "Episode reward: 1910.5094\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.419391 14.385367 14.409113 13.512382 13.450937 14.416291]\n",
      "Reset environment\n",
      "Episode reward: 2063.882\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4198475 14.385819  14.40958   13.512897  13.451352  14.416749 ]\n",
      "Reset environment\n",
      "Episode reward: 1538.4222\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.420404 14.386377 14.410135 13.513511 13.451853 14.417306]\n",
      "Reset environment\n",
      "Episode reward: 2419.7483\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.420983 14.386943 14.410725 13.514154 13.45238  14.417887]\n",
      "Reset environment\n",
      "Episode reward: 4410.7827\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.42223  14.388193 14.411969 13.515498 13.453473 14.419134]\n",
      "Reset environment\n",
      "Episode reward: 1913.122\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.422909 14.388873 14.412651 13.516242 13.454079 14.419815]\n",
      "Reset environment\n",
      "Episode reward: 3942.7004\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.423998 14.389974 14.413731 13.51742  13.455049 14.420905]\n",
      "Reset environment\n",
      "Episode reward: 4987.859\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.425419 14.391399 14.415146 13.518954 13.456288 14.422326]\n",
      "Reset environment\n",
      "Episode reward: 3060.2346\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.42623  14.39221  14.415959 13.51984  13.456999 14.423138]\n",
      "Reset environment\n",
      "Episode reward: 1957.0671\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.426699 14.392682 14.416427 13.52036  13.457427 14.423606]\n",
      "Reset environment\n",
      "Episode reward: 2074.745\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.427211  14.393189  14.4169445 13.520925  13.457896  14.424118 ]\n",
      "Reset environment\n",
      "Episode reward: 3094.3767\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.428005 14.393988 14.417737 13.521799 13.458604 14.424912]\n",
      "Reset environment\n",
      "Episode reward: 1809.6093\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.428648 14.394632 14.41838  13.522502 13.459175 14.425554]\n",
      "Reset environment\n",
      "Episode reward: 1847.8301\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.42906  14.395028 14.418813 13.522962 13.459534 14.425967]\n",
      "Reset environment\n",
      "Episode reward: 1941.8096\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.429544 14.395499 14.419309 13.523493 13.459973 14.426453]\n",
      "Reset environment\n",
      "Episode reward: 1297.3281\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.429838 14.395807 14.419592 13.52382  13.460242 14.426747]\n",
      "Reset environment\n",
      "Episode reward: 2223.0872\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.430335 14.396287 14.420107 13.524375 13.460665 14.427245]\n",
      "Reset environment\n",
      "Episode reward: 1719.7784\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.430746  14.39669   14.420523  13.52483   13.4610405 14.427656 ]\n",
      "Reset environment\n",
      "Episode reward: 2127.7856\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.431251 14.397205 14.421014 13.525382 13.461502 14.42816 ]\n",
      "Reset environment\n",
      "Episode reward: -274.2696\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.430572 14.396554 14.420294 13.524546 13.460886 14.427483]\n",
      "Reset environment\n",
      "Episode reward: 5112.054\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.432041 14.398027 14.421758 13.526126 13.462181 14.428951]\n",
      "Reset environment\n",
      "Episode reward: -460.91928\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4312525 14.397207  14.421004  13.525195  13.461466  14.428165 ]\n",
      "Reset environment\n",
      "Episode reward: 2502.341\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.431886  14.397858  14.421621  13.5258875 13.462042  14.4288025]\n",
      "Reset environment\n",
      "Episode reward: 2102.4592\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.432366 14.398326 14.422114 13.526415 13.462473 14.429283]\n",
      "Reset environment\n",
      "Episode reward: 2008.7438\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.432837 14.398777 14.422597 13.526935 13.462876 14.429753]\n",
      "Reset environment\n",
      "Episode reward: 1978.8773\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.433311 14.399255 14.423071 13.527465 13.463308 14.430229]\n",
      "Reset environment\n",
      "Episode reward: 2135.1804\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.434057 14.400003 14.423816 13.528277 13.46397  14.430974]\n",
      "Reset environment\n",
      "Episode reward: 2443.0999\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.434678 14.400628 14.424435 13.52896  13.464534 14.431595]\n",
      "Reset environment\n",
      "Episode reward: 5584.1304\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.436302 14.402248 14.426068 13.530709 13.465952 14.433219]\n",
      "Reset environment\n",
      "Episode reward: 1951.1292\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.436663 14.402631 14.426404 13.531121 13.466282 14.433577]\n",
      "Reset environment\n",
      "Episode reward: 3608.521\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.43766  14.403631 14.4274   13.532195 13.467156 14.434574]\n",
      "Reset environment\n",
      "Episode reward: 5123.613\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.439119 14.405097 14.428854 13.533763 13.468412 14.436033]\n",
      "Reset environment\n",
      "Episode reward: 259.41995\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.43851  14.404584 14.428171 13.533134 13.467888 14.43543 ]\n",
      "Reset environment\n",
      "Episode reward: 4995.971\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.439946 14.406016 14.429609 13.534671 13.469158 14.436863]\n",
      "Reset environment\n",
      "Episode reward: 2172.2126\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.440701  14.406774  14.430362  13.535501  13.4698305 14.437617 ]\n",
      "Reset environment\n",
      "Episode reward: 2257.9604\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4412565 14.407333  14.430915  13.536118  13.470331  14.438173 ]\n",
      "Reset environment\n",
      "Episode reward: 2152.645\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.442009 14.408088 14.43167  13.536937 13.471002 14.438927]\n",
      "Reset environment\n",
      "Episode reward: 1827.1151\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.442262 14.408314 14.431955 13.537255 13.471227 14.439184]\n",
      "Reset environment\n",
      "Episode reward: 2145.2485\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.442785 14.408841 14.432476 13.537834 13.471704 14.439706]\n",
      "Reset environment\n",
      "Episode reward: 4315.156\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.444    14.410047 14.433695 13.539131 13.472768 14.440921]\n",
      "Reset environment\n",
      "Episode reward: 1496.5621\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.444257  14.410328  14.4339285 13.539434  13.4730015 14.441178 ]\n",
      "Reset environment\n",
      "Episode reward: 1934.8939\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.444721 14.410793 14.434392 13.53995  13.473423 14.441643]\n",
      "Reset environment\n",
      "Episode reward: 5477.0503\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.446319 14.412396 14.435989 13.541658 13.47482  14.443241]\n",
      "Reset environment\n",
      "Episode reward: 2556.4336\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.446921 14.413019 14.436577 13.542322 13.475378 14.443844]\n",
      "Reset environment\n",
      "Episode reward: 1664.8572\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.447303 14.413402 14.436959 13.542752 13.475719 14.444226]\n",
      "Reset environment\n",
      "Episode reward: 2232.8604\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.447833  14.413923  14.437502  13.543336  13.476209  14.4447565]\n",
      "Reset environment\n",
      "Episode reward: 1962.3254\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.448314 14.414408 14.437979 13.543865 13.476648 14.445237]\n",
      "Reset environment\n",
      "Episode reward: 1568.0197\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.448725 14.41482  14.43839  13.544318 13.47703  14.445648]\n",
      "Reset environment\n",
      "Episode reward: 2041.3127\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.449201 14.415308 14.438858 13.544844 13.477466 14.446124]\n",
      "Reset environment\n",
      "Episode reward: 1577.0751\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.449564  14.415673  14.4392185 13.545252  13.4777975 14.446487 ]\n",
      "Reset environment\n",
      "Episode reward: 1376.031\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.450064 14.416173 14.439717 13.545807 13.478248 14.446987]\n",
      "Reset environment\n",
      "Episode reward: 3368.0981\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.450975 14.417088 14.440628 13.546795 13.479047 14.447899]\n",
      "Reset environment\n",
      "Episode reward: 5363.5283\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.452529 14.418641 14.442181 13.548459 13.480394 14.449453]\n",
      "Reset environment\n",
      "Episode reward: 2227.9531\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.453027  14.4191265 14.44269   13.54901   13.480849  14.449951 ]\n",
      "Reset environment\n",
      "Episode reward: 2074.8892\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.453462 14.419545 14.443144 13.549497 13.481229 14.450386]\n",
      "Reset environment\n",
      "Episode reward: 2833.8684\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.45421  14.420296 14.443893 13.550314 13.481903 14.451135]\n",
      "Reset environment\n",
      "Episode reward: 1896.455\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.454674 14.420762 14.444352 13.550826 13.482324 14.451598]\n",
      "Reset environment\n",
      "Episode reward: 2630.759\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.455326 14.421401 14.445017 13.551534 13.482924 14.452251]\n",
      "Reset environment\n",
      "Episode reward: 1795.2299\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.455688 14.421783 14.445359 13.551942 13.483252 14.452613]\n",
      "Reset environment\n",
      "Episode reward: 2340.4001\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4562235 14.422301  14.445909  13.552527  13.483719  14.453148 ]\n",
      "Reset environment\n",
      "Episode reward: 1789.677\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.456638 14.422709 14.446329 13.552989 13.484096 14.453563]\n",
      "Reset environment\n",
      "Episode reward: 4695.0127\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.45797   14.424047  14.4476595 13.554419  13.485254  14.454894 ]\n",
      "Reset environment\n",
      "Episode reward: 2218.5002\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.458746 14.424826 14.448435 13.555259 13.485943 14.45567 ]\n",
      "Reset environment\n",
      "Episode reward: 2478.0657\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4593725 14.425456  14.449061  13.55595   13.48651   14.456298 ]\n",
      "Reset environment\n",
      "Episode reward: 1413.7739\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.459703  14.4257965 14.449386  13.556317  13.486811  14.456628 ]\n",
      "Reset environment\n",
      "Episode reward: 3681.9136\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4607115 14.4268055 14.450396  13.557409  13.487695  14.457636 ]\n",
      "Reset environment\n",
      "Episode reward: 1648.0532\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.461108 14.427206 14.450793 13.55785  13.488058 14.458034]\n",
      "Reset environment\n",
      "Episode reward: 3344.5625\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.462006 14.428112 14.451681 13.558831 13.488883 14.458931]\n",
      "Reset environment\n",
      "Episode reward: 2049.493\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.462473 14.428568 14.452157 13.559346 13.489308 14.459397]\n",
      "Reset environment\n",
      "Episode reward: 1710.485\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.463065  14.429163  14.452749  13.560008  13.489834  14.4599905]\n",
      "Reset environment\n",
      "Episode reward: 3010.6206\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.463864 14.429967 14.453546 13.560872 13.490564 14.460789]\n",
      "Reset environment\n",
      "Episode reward: 1945.4869\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.464331 14.430438 14.454009 13.561387 13.490993 14.461256]\n",
      "Reset environment\n",
      "Episode reward: 1675.9397\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.464611 14.430697 14.454318 13.561716 13.491245 14.461538]\n",
      "Reset environment\n",
      "Episode reward: -687.11975\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.463639 14.429704 14.453387 13.560749 13.490399 14.460558]\n",
      "Reset environment\n",
      "Episode reward: 2438.4468\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.464233 14.43031  14.45397  13.561398 13.490941 14.461153]\n",
      "Reset environment\n",
      "Episode reward: 2042.7808\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.464945 14.431023 14.454683 13.562177 13.491578 14.461865]\n",
      "Reset environment\n",
      "Episode reward: 3678.9592\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.465944 14.432018 14.455689 13.563255 13.492444 14.462865]\n",
      "Reset environment\n",
      "Episode reward: 2067.0847\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.46644  14.432516 14.456186 13.563806 13.492898 14.463362]\n",
      "Reset environment\n",
      "Episode reward: 5003.9277\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.467879  14.433959  14.4576235 13.565347  13.494144  14.4648   ]\n",
      "Reset environment\n",
      "Episode reward: 2573.4326\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.468534 14.434616 14.458274 13.566066 13.494739 14.465455]\n",
      "Reset environment\n",
      "Episode reward: 1744.3927\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.468938 14.435021 14.458678 13.566516 13.495107 14.465859]\n",
      "Reset environment\n",
      "Episode reward: 4193.5547\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.470101 14.436184 14.459844 13.567773 13.496131 14.467023]\n",
      "Reset environment\n",
      "Episode reward: 5606.371\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.471731 14.437819 14.461466 13.569514 13.497553 14.468653]\n",
      "Reset environment\n",
      "Episode reward: 1978.5364\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.472198 14.438284 14.461943 13.570029 13.497978 14.469119]\n",
      "Reset environment\n",
      "Episode reward: 1414.687\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.472523 14.43861  14.462267 13.570396 13.498277 14.469444]\n",
      "Reset environment\n",
      "Episode reward: 5558.426\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.474159 14.440242 14.463903 13.572144 13.499709 14.471082]\n",
      "Reset environment\n",
      "Episode reward: 2886.2485\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.474873 14.440958 14.464615 13.572921 13.500363 14.471794]\n",
      "Reset environment\n",
      "Episode reward: 1992.7054\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.475326 14.441401 14.465079 13.573424 13.500779 14.472248]\n",
      "Reset environment\n",
      "Episode reward: 1578.133\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.475695  14.4417715 14.465448  13.573836  13.501114  14.472617 ]\n",
      "Reset environment\n",
      "Episode reward: 3757.3743\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.476728 14.442804 14.466485 13.574953 13.502019 14.473651]\n",
      "Reset environment\n",
      "Episode reward: 3377.7202\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.477555 14.443634 14.467312 13.575863 13.502777 14.474478]\n",
      "Reset environment\n",
      "Episode reward: 4654.7534\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.478882 14.444964 14.468637 13.577289 13.503948 14.475804]\n",
      "Reset environment\n",
      "Episode reward: 2945.1016\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.479646 14.445719 14.469411 13.578121 13.504632 14.476569]\n",
      "Reset environment\n",
      "Episode reward: 3936.2556\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.480742  14.4468155 14.470511  13.579304  13.505593  14.477666 ]\n",
      "Reset environment\n",
      "Episode reward: 3608.6667\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4817   14.447772 14.47147  13.580351 13.506421 14.478624]\n",
      "Reset environment\n",
      "Episode reward: 1858.9369\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.482354  14.448427  14.472122  13.581068  13.506996  14.4792795]\n",
      "Reset environment\n",
      "Episode reward: 1702.6337\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.482766 14.448841 14.472534 13.581523 13.507374 14.479692]\n",
      "Reset environment\n",
      "Episode reward: 1754.4714\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.483129 14.449184 14.472915 13.581937 13.507694 14.480054]\n",
      "Reset environment\n",
      "Episode reward: 2151.9387\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.483657 14.44971  14.473442 13.582519 13.508175 14.480583]\n",
      "Reset environment\n",
      "Episode reward: 1784.5525\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.48401  14.450048 14.47381  13.582921 13.508478 14.480936]\n",
      "Reset environment\n",
      "Episode reward: 1814.8877\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.48442  14.450452 14.474233 13.583382 13.508859 14.481348]\n",
      "Reset environment\n",
      "Episode reward: 2525.2249\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.48506   14.451092  14.474874  13.5840845 13.509425  14.481987 ]\n",
      "Reset environment\n",
      "Episode reward: 1666.9465\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.485225 14.451282 14.47501  13.584305 13.50957  14.482152]\n",
      "Reset environment\n",
      "Episode reward: 2613.2927\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.485872 14.451935 14.475655 13.585018 13.510163 14.4828  ]\n",
      "Reset environment\n",
      "Episode reward: 6085.72\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.487571 14.453635 14.477352 13.58684  13.511701 14.484499]\n",
      "Reset environment\n",
      "Episode reward: 1950.4373\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.488256 14.454323 14.47804  13.587586 13.512316 14.485186]\n",
      "Reset environment\n",
      "Episode reward: 2602.2058\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.488926  14.4549885 14.478711  13.588318  13.51291   14.485854 ]\n",
      "Reset environment\n",
      "Episode reward: 1766.6777\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4893465 14.455402  14.479136  13.588785  13.513296  14.486276 ]\n",
      "Reset environment\n",
      "Episode reward: 1931.7146\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.489799 14.455855 14.479587 13.589289 13.513707 14.486727]\n",
      "Reset environment\n",
      "Episode reward: 1557.6948\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.490172  14.456245  14.479952  13.589701  13.5140505 14.4871025]\n",
      "Reset environment\n",
      "Episode reward: 2520.7935\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.490787 14.456865 14.480558 13.590375 13.514613 14.487717]\n",
      "Reset environment\n",
      "Episode reward: 1896.8049\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.491215 14.457305 14.480978 13.590851 13.515009 14.488146]\n",
      "Reset environment\n",
      "Episode reward: 4036.1565\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.492333  14.45843   14.482089  13.592051  13.515986  14.4892645]\n",
      "Reset environment\n",
      "Episode reward: 4540.3813\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.493543  14.4596405 14.483299  13.59336   13.517096  14.490475 ]\n",
      "Reset environment\n",
      "Episode reward: 2278.5298\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.49409  14.460177 14.483851 13.593961 13.517591 14.491023]\n",
      "Reset environment\n",
      "Episode reward: 2860.6147\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.49483  14.460911 14.484597 13.594765 13.518242 14.491762]\n",
      "Reset environment\n",
      "Episode reward: 5829.3955\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.496538 14.46261  14.486305 13.596596 13.519764 14.49347 ]\n",
      "Reset environment\n",
      "Episode reward: 1576.3651\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.497096 14.463167 14.486862 13.597212 13.520269 14.494027]\n",
      "Reset environment\n",
      "Episode reward: 2414.2954\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.497722 14.463794 14.487484 13.597898 13.52083  14.494653]\n",
      "Reset environment\n",
      "Episode reward: 1701.7062\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.4981   14.464164 14.487874 13.59832  13.521178 14.495032]\n",
      "Reset environment\n",
      "Episode reward: 4426.173\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.499306 14.465371 14.489081 13.599612 13.522269 14.496238]\n",
      "Reset environment\n",
      "Episode reward: 2045.9719\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.499701 14.465744 14.489497 13.600065 13.522611 14.496633]\n",
      "Reset environment\n",
      "Episode reward: 2697.122\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.500392 14.466444 14.490187 13.600816 13.523246 14.497325]\n",
      "Reset environment\n",
      "Episode reward: 2416.9265\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.500908  14.466938  14.490719  13.60139   13.5236845 14.497841 ]\n",
      "Reset environment\n",
      "Episode reward: 1827.5043\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.501205 14.467257 14.490997 13.601737 13.523955 14.498137]\n",
      "Reset environment\n",
      "Episode reward: 1413.3792\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.501721  14.467773  14.491513  13.602303  13.5244255 14.498653 ]\n",
      "Reset environment\n",
      "Episode reward: -339.3247\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.500988 14.467038 14.490803 13.601576 13.523803 14.49794 ]\n",
      "Reset environment\n",
      "Episode reward: 2029.3142\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.501447 14.46751  14.491247 13.602086 13.524221 14.498398]\n",
      "Reset environment\n",
      "Episode reward: 3758.7148\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.502487  14.468549  14.49229   13.6032095 13.52513   14.499439 ]\n",
      "Reset environment\n",
      "Episode reward: 2824.1821\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.503185 14.469248 14.492989 13.603971 13.525767 14.500137]\n",
      "Reset environment\n",
      "Episode reward: 5020.249\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.504616 14.47069  14.494412 13.605503 13.527067 14.501569]\n",
      "Reset environment\n",
      "Episode reward: 1386.7795\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.505122 14.471197 14.494919 13.606062 13.52753  14.502074]\n",
      "Reset environment\n",
      "Episode reward: 2212.6492\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.50589   14.471966  14.495688  13.6068945 13.528211  14.502841 ]\n",
      "Reset environment\n",
      "Episode reward: 2675.83\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.506534 14.472596 14.496345 13.607599 13.528803 14.503488]\n",
      "Reset environment\n",
      "Episode reward: 2713.8599\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.50718  14.473231 14.497004 13.608314 13.529382 14.504136]\n",
      "Reset environment\n",
      "Episode reward: 3153.5195\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.50801  14.47406  14.497836 13.60922  13.530106 14.504966]\n",
      "Reset environment\n",
      "Episode reward: 5800.2456\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.509678 14.475724 14.499501 13.611016 13.531562 14.506635]\n",
      "Reset environment\n",
      "Episode reward: 1746.5427\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.509993 14.476017 14.499839 13.611383 13.531827 14.50695 ]\n",
      "Reset environment\n",
      "Episode reward: 1967.2748\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.510473  14.4765005 14.500317  13.611917  13.532267  14.507431 ]\n",
      "Reset environment\n",
      "Episode reward: 1948.9387\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.510939 14.47696  14.500791 13.612432 13.532692 14.507896]\n",
      "Reset environment\n",
      "Episode reward: 729.32996\n",
      "Total Steps: 131\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.510621 14.476593 14.500514 13.612079 13.532425 14.507582]\n",
      "Reset environment\n",
      "Episode reward: 1717.7572\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.510937 14.476937 14.500813 13.612447 13.532716 14.507897]\n",
      "Reset environment\n",
      "Episode reward: 2499.2087\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.51155  14.477567 14.501406 13.613115 13.533284 14.508512]\n",
      "Reset environment\n",
      "Episode reward: 3961.9138\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.512628 14.478654 14.502475 13.614284 13.534234 14.509588]\n",
      "Reset environment\n",
      "Episode reward: 1691.9814\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.513029 14.479058 14.502875 13.614727 13.5346   14.509991]\n",
      "Reset environment\n",
      "Episode reward: 1808.6979\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.513363  14.479368  14.503232  13.615108  13.53487   14.5103245]\n",
      "Reset environment\n",
      "Episode reward: 3717.113\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.514371 14.480369 14.504246 13.616191 13.535753 14.511332]\n",
      "Reset environment\n",
      "Episode reward: 1877.5002\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.514837  14.480841  14.50471   13.616703  13.5361805 14.511798 ]\n",
      "Reset environment\n",
      "Episode reward: 1539.4368\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.515126 14.4811   14.505023 13.617037 13.536434 14.512089]\n",
      "Reset environment\n",
      "Episode reward: 2672.1938\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.515812 14.481791 14.505703 13.617782 13.53706  14.512774]\n",
      "Reset environment\n",
      "Episode reward: 2059.3972\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.516256  14.48222   14.5061655 13.618277  13.537433  14.513219 ]\n",
      "Reset environment\n",
      "Episode reward: 1863.8948\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.516915 14.48288  14.506823 13.618993 13.538016 14.513878]\n",
      "Reset environment\n",
      "Episode reward: 2730.3545\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.517606 14.483568 14.507519 13.619752 13.538627 14.514568]\n",
      "Reset environment\n",
      "Episode reward: 4256.663\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.518795  14.484758  14.508711  13.621031  13.539667  14.5157585]\n",
      "Reset environment\n",
      "Episode reward: 1911.2191\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.518877  14.484863  14.508762  13.621177  13.5397215 14.515841 ]\n",
      "Reset environment\n",
      "Episode reward: 2308.0183\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.519464  14.485447  14.509347  13.621826  13.5402565 14.516427 ]\n",
      "Reset environment\n",
      "Episode reward: 1438.3745\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.519998 14.48598  14.509882 13.622416 13.54074  14.516962]\n",
      "Reset environment\n",
      "Episode reward: 1127.0996\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.520242 14.486219 14.510132 13.622694 13.540961 14.517207]\n",
      "Reset environment\n",
      "Episode reward: 1954.5076\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.520519 14.486518 14.510388 13.623021 13.541212 14.517484]\n",
      "Reset environment\n",
      "Episode reward: 1544.5308\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.520886 14.486886 14.510756 13.62343  13.541549 14.517851]\n",
      "Reset environment\n",
      "Episode reward: 1401.2856\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.521212 14.487211 14.51108  13.623796 13.541845 14.518175]\n",
      "Reset environment\n",
      "Episode reward: 1805.0156\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.521618  14.487622  14.511485  13.624261  13.5422125 14.518582 ]\n",
      "Reset environment\n",
      "Episode reward: 5711.687\n",
      "Total Steps: 197\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.523249  14.489253  14.513122  13.62601   13.5436735 14.520213 ]\n",
      "Reset environment\n",
      "Episode reward: 4726.2236\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.524515 14.490522 14.514383 13.627371 13.544834 14.521479]\n",
      "Reset environment\n",
      "Episode reward: 1863.9355\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.525172  14.491182  14.5150385 13.628086  13.545419  14.522137 ]\n",
      "Reset environment\n",
      "Episode reward: 2559.604\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.525729  14.491717  14.5156145 13.628709  13.545925  14.522694 ]\n",
      "Reset environment\n",
      "Episode reward: 1896.3402\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.526164 14.492143 14.516058 13.629187 13.546325 14.523128]\n",
      "Reset environment\n",
      "Episode reward: 5517.9385\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.527688  14.493673  14.517582  13.630827  13.547709  14.5246525]\n",
      "Reset environment\n",
      "Episode reward: 5050.684\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.529127 14.495111 14.519019 13.632373 13.548989 14.52609 ]\n",
      "Reset environment\n",
      "Episode reward: 4984.5664\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.530554  14.496517  14.520451  13.6339035 13.550233  14.527514 ]\n",
      "Reset environment\n",
      "Episode reward: 1972.8688\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.53101  14.496971 14.520909 13.634416 13.550647 14.527971]\n",
      "Reset environment\n",
      "Episode reward: 1907.6979\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.53124  14.497228 14.521118 13.634706 13.550856 14.528202]\n",
      "Reset environment\n",
      "Episode reward: 2166.6355\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.531981 14.497972 14.521858 13.635515 13.55152  14.528943]\n",
      "Reset environment\n",
      "Episode reward: 1857.8826\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.532418 14.498413 14.522286 13.635997 13.551921 14.52938 ]\n",
      "Reset environment\n",
      "Episode reward: 1844.7167\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.532797 14.498818 14.522649 13.636431 13.552272 14.529758]\n",
      "Reset environment\n",
      "Episode reward: 2357.086\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.533375 14.499409 14.523213 13.637066 13.552794 14.530335]\n",
      "Reset environment\n",
      "Episode reward: 2246.177\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.533878 14.499914 14.523718 13.637628 13.553255 14.530839]\n",
      "Reset environment\n",
      "Episode reward: 2212.4717\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.534642 14.500679 14.524484 13.638457 13.553939 14.531604]\n",
      "Reset environment\n",
      "Episode reward: 1551.2437\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.534877 14.50094  14.524694 13.63874  13.554151 14.531838]\n",
      "Reset environment\n",
      "Episode reward: 5531.421\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.5364    14.502465  14.526216  13.640365  13.555535  14.5333605]\n",
      "Reset environment\n",
      "Episode reward: 1379.0719\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.536902 14.502967 14.526716 13.64092  13.555991 14.533863]\n",
      "Reset environment\n",
      "Episode reward: 1693.9504\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.537242 14.50329  14.527071 13.641302 13.556289 14.534202]\n",
      "Reset environment\n",
      "Episode reward: 1579.804\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.53762  14.503667 14.527453 13.641722 13.556636 14.53458 ]\n",
      "Reset environment\n",
      "Episode reward: 5680.154\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.539248 14.505302 14.529074 13.643471 13.558053 14.536209]\n",
      "Reset environment\n",
      "Episode reward: 1373.0952\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.539557 14.505604 14.529388 13.643814 13.558333 14.536519]\n",
      "Reset environment\n",
      "Episode reward: 2911.2234\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.5402975 14.506354  14.530125  13.644622  13.559005  14.537259 ]\n",
      "Reset environment\n",
      "Episode reward: 2910.5842\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.541014 14.50706  14.530847 13.645408 13.559653 14.537978]\n",
      "Reset environment\n",
      "Episode reward: 2154.8447\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.541541 14.507594 14.531366 13.645986 13.560139 14.538506]\n",
      "Reset environment\n",
      "Episode reward: 2609.0955\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.542203 14.508254 14.532029 13.646709 13.560739 14.539168]\n",
      "Reset environment\n",
      "Episode reward: 4945.5\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.5435915 14.50965   14.53341   13.648203  13.561984  14.540558 ]\n",
      "Reset environment\n",
      "Episode reward: 5540.504\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.545108 14.511165 14.534923 13.649834 13.563358 14.542073]\n",
      "Reset environment\n",
      "Episode reward: 4860.0767\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.546474 14.512537 14.536285 13.651302 13.564547 14.543439]\n",
      "Reset environment\n",
      "Episode reward: 2760.0325\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.547177 14.513247 14.536981 13.652072 13.565191 14.544141]\n",
      "Reset environment\n",
      "Episode reward: 1792.7445\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.547797  14.513868  14.5376005 13.652756  13.565745  14.544761 ]\n",
      "Reset environment\n",
      "Episode reward: 1336.9404\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.548265  14.5143385 14.53807   13.653288  13.566171  14.54523  ]\n",
      "Reset environment\n",
      "Episode reward: 2058.6226\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.548979 14.515053 14.538784 13.654069 13.566816 14.545944]\n",
      "Reset environment\n",
      "Episode reward: 2080.444\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.54969  14.515766 14.539495 13.654849 13.567447 14.546655]\n",
      "Reset environment\n",
      "Episode reward: 4760.8604\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.550943 14.517024 14.540745 13.656205 13.568597 14.547907]\n",
      "Reset environment\n",
      "Episode reward: -489.3521\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.54993  14.516092 14.539677 13.655084 13.567678 14.546897]\n",
      "Reset environment\n",
      "Episode reward: 1368.9816\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.550205  14.516348  14.5399685 13.655395  13.567917  14.547175 ]\n",
      "Reset environment\n",
      "Episode reward: 4234.596\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.551396  14.517537  14.5411625 13.656677  13.568963  14.548367 ]\n",
      "Reset environment\n",
      "Episode reward: 1853.2467\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.551809 14.517945 14.541584 13.657143 13.569335 14.54878 ]\n",
      "Reset environment\n",
      "Episode reward: 2764.7031\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.552476 14.518613 14.54225  13.657872 13.569946 14.549446]\n",
      "Reset environment\n",
      "Episode reward: 2039.7667\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.553181 14.519321 14.54295  13.65865  13.57057  14.55015 ]\n",
      "Reset environment\n",
      "Episode reward: 1886.2584\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.553612 14.519764 14.543368 13.659127 13.570964 14.55058 ]\n",
      "Reset environment\n",
      "Episode reward: 5575.38\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.555221 14.521374 14.544973 13.660846 13.572409 14.552188]\n",
      "Reset environment\n",
      "Episode reward: 269.18576\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.554344  14.520379  14.544222  13.6600275 13.571584  14.551322 ]\n",
      "Reset environment\n",
      "Episode reward: 3768.4436\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.555378 14.521403 14.545259 13.661139 13.572502 14.552355]\n",
      "Reset environment\n",
      "Episode reward: 2411.1687\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.555963 14.521997 14.545838 13.661779 13.57303  14.552939]\n",
      "Reset environment\n",
      "Episode reward: 2235.5884\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.556452 14.522476 14.546346 13.662328 13.573471 14.55343 ]\n",
      "Reset environment\n",
      "Episode reward: 4626.1416\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.557743 14.523775 14.547636 13.663712 13.574619 14.554721]\n",
      "Reset environment\n",
      "Episode reward: 271.2394\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.55721  14.523201 14.547136 13.663066 13.574153 14.554193]\n",
      "Reset environment\n",
      "Episode reward: 1789.8142\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.557628 14.523617 14.547556 13.66353  13.574532 14.554611]\n",
      "Reset environment\n",
      "Episode reward: 4163.731\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.558778  14.5247755 14.548702  13.664765  13.575546  14.555763 ]\n",
      "Reset environment\n",
      "Episode reward: 1015.68353\n",
      "Total Steps: 33\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.558987 14.524984 14.54891  13.66501  13.575736 14.555971]\n",
      "Reset environment\n",
      "Episode reward: 3560.7368\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.55995   14.525951  14.5498705 13.666051  13.576591  14.556933 ]\n",
      "Reset environment\n",
      "Episode reward: 2050.7036\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.560414 14.526432 14.550323 13.666566 13.577019 14.557398]\n",
      "Reset environment\n",
      "Episode reward: 1960.6237\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.560859 14.526873 14.550771 13.667062 13.577422 14.557842]\n",
      "Reset environment\n",
      "Episode reward: 2634.5154\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.561501 14.527524 14.551399 13.667761 13.578    14.558484]\n",
      "Reset environment\n",
      "Episode reward: 4378.884\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.56272  14.528747 14.552618 13.669071 13.579066 14.559704]\n",
      "Reset environment\n",
      "Episode reward: 1449.963\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.562949 14.528952 14.552873 13.669338 13.579265 14.559937]\n",
      "Reset environment\n",
      "Episode reward: 1912.2954\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.563616 14.52962  14.553539 13.670069 13.579861 14.560603]\n",
      "Reset environment\n",
      "Episode reward: -333.35257\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.562758 14.528721 14.552746 13.669192 13.579101 14.559755]\n",
      "Reset environment\n",
      "Episode reward: 3110.2031\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.563557 14.529528 14.553535 13.670055 13.579813 14.560553]\n",
      "Reset environment\n",
      "Episode reward: 2139.025\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.564276 14.530249 14.554257 13.670848 13.580454 14.561273]\n",
      "Reset environment\n",
      "Episode reward: 3960.907\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.565357 14.531334 14.555338 13.672013 13.581407 14.562352]\n",
      "Reset environment\n",
      "Episode reward: 1495.6432\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.565713 14.531689 14.555694 13.672411 13.581732 14.562708]\n",
      "Reset environment\n",
      "Episode reward: 2523.8674\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.566327  14.532292  14.5563135 13.67308   13.582279  14.563322 ]\n",
      "Reset environment\n",
      "Episode reward: 3594.0137\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.567294 14.533259 14.557282 13.674125 13.583121 14.564289]\n",
      "Reset environment\n",
      "Episode reward: 2085.4783\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.567744 14.53373  14.557716 13.674627 13.583538 14.564739]\n",
      "Reset environment\n",
      "Episode reward: 2512.9478\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.56836   14.534349  14.5583315 13.675307  13.584099  14.565355 ]\n",
      "Reset environment\n",
      "Episode reward: 2052.7478\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.569068 14.535057 14.559039 13.676081 13.584738 14.566063]\n",
      "Reset environment\n",
      "Episode reward: 3342.1492\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.569957  14.535951  14.559926  13.677045  13.5855255 14.566952 ]\n",
      "Reset environment\n",
      "Episode reward: 1024.0812\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.569731 14.535754 14.559679 13.676718 13.585356 14.56673 ]\n",
      "Reset environment\n",
      "Episode reward: 4072.8271\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.570833 14.536864 14.560778 13.677907 13.586335 14.567833]\n",
      "Reset environment\n",
      "Episode reward: 4856.703\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.572199  14.538232  14.562147  13.6793785 13.587548  14.5692   ]\n",
      "Reset environment\n",
      "Episode reward: 1420.7852\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.572504 14.538526 14.562464 13.679726 13.587821 14.569505]\n",
      "Reset environment\n",
      "Episode reward: 2234.6147\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.573038  14.539074  14.5629835 13.680309  13.588317  14.570037 ]\n",
      "Reset environment\n",
      "Episode reward: -204.93903\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.572439 14.538495 14.562361 13.679532 13.587777 14.569441]\n",
      "Reset environment\n",
      "Episode reward: 3378.451\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.573319 14.53936  14.563252 13.680482 13.588568 14.570322]\n",
      "Reset environment\n",
      "Episode reward: 1162.006\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.573568 14.539599 14.563505 13.680765 13.58879  14.570572]\n",
      "Reset environment\n",
      "Episode reward: 3166.4485\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.574372 14.540413 14.564306 13.681643 13.589515 14.571375]\n",
      "Reset environment\n",
      "Episode reward: 2105.2788\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.574862 14.540897 14.564804 13.682185 13.589959 14.571865]\n",
      "Reset environment\n",
      "Episode reward: 5051.006\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.576278 14.542315 14.566224 13.683707 13.591224 14.573281]\n",
      "Reset environment\n",
      "Episode reward: 5510.894\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.5778475 14.543891  14.567784  13.685387  13.592589  14.574852 ]\n",
      "Reset environment\n",
      "Episode reward: 1882.1473\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.578298 14.544326 14.56824  13.685889 13.592996 14.575302]\n",
      "Reset environment\n",
      "Episode reward: 4498.638\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.579554 14.545584 14.569499 13.687235 13.594104 14.576558]\n",
      "Reset environment\n",
      "Episode reward: 2459.0244\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.580167 14.546201 14.570112 13.687907 13.594664 14.577172]\n",
      "Reset environment\n",
      "Episode reward: 3652.303\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.581153 14.547191 14.571096 13.688978 13.595532 14.578159]\n",
      "Reset environment\n",
      "Episode reward: 4898.883\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.582525  14.548563  14.5724745 13.690452  13.596738  14.579533 ]\n",
      "Reset environment\n",
      "Episode reward: 1731.6927\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.582937 14.54897  14.572893 13.69091  13.597113 14.579945]\n",
      "Reset environment\n",
      "Episode reward: 2833.2327\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.583618 14.549671 14.573555 13.691652 13.597738 14.580626]\n",
      "Reset environment\n",
      "Episode reward: 4794.792\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.584968 14.551024 14.574903 13.693098 13.598906 14.581975]\n",
      "Reset environment\n",
      "Episode reward: 5291.9546\n",
      "Total Steps: 202\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.58669   14.5527525 14.57662   13.694941  13.600413  14.583697 ]\n",
      "Reset environment\n",
      "Episode reward: 1899.707\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.587345 14.553408 14.577276 13.695654 13.601004 14.584354]\n",
      "Reset environment\n",
      "Episode reward: 1800.2748\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.58773  14.55381  14.577643 13.696085 13.601359 14.58474 ]\n",
      "Reset environment\n",
      "Episode reward: 2017.7739\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.588215 14.554296 14.578128 13.696619 13.601801 14.585224]\n",
      "Reset environment\n",
      "Episode reward: 2450.5132\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.588775 14.554845 14.578704 13.697234 13.602307 14.585785]\n",
      "Reset environment\n",
      "Episode reward: 2639.588\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.589446 14.555518 14.579373 13.697967 13.602914 14.586455]\n",
      "Reset environment\n",
      "Episode reward: 1803.9023\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.59007  14.556143 14.579998 13.698649 13.603475 14.587079]\n",
      "Reset environment\n",
      "Episode reward: 2118.7349\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.590795  14.5568695 14.580723  13.699443  13.604119  14.587804 ]\n",
      "Reset environment\n",
      "Episode reward: 3629.9897\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.591778 14.557851 14.581707 13.700504 13.604977 14.588789]\n",
      "Reset environment\n",
      "Episode reward: 5639.0986\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.59362  14.559692 14.583552 13.70247  13.606647 14.590631]\n",
      "Reset environment\n",
      "Episode reward: 2223.5588\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.594185  14.560259  14.584116  13.703089  13.6071615 14.591195 ]\n",
      "Reset environment\n",
      "Episode reward: 1379.9834\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.5946665 14.560744  14.584599  13.703626  13.607597  14.591679 ]\n",
      "Reset environment\n",
      "Episode reward: 5082.552\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.596096  14.5621805 14.586021  13.705154  13.608872  14.593106 ]\n",
      "Reset environment\n",
      "Episode reward: 1535.6707\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.596436 14.562522 14.586362 13.705542 13.609181 14.593446]\n",
      "Reset environment\n",
      "Episode reward: 1772.9961\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.596841 14.562927 14.586767 13.705992 13.609549 14.593851]\n",
      "Reset environment\n",
      "Episode reward: 6132.1504\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.598612 14.564696 14.588541 13.707883 13.611146 14.595622]\n",
      "Reset environment\n",
      "Episode reward: 2456.125\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.599231 14.565312 14.589164 13.708555 13.611712 14.596241]\n",
      "Reset environment\n",
      "Episode reward: 4342.964\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.600469 14.566553 14.590394 13.709885 13.612796 14.597479]\n",
      "Reset environment\n",
      "Episode reward: 2784.5852\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6011715 14.56726   14.59108   13.710659  13.613417  14.598184 ]\n",
      "Reset environment\n",
      "Episode reward: 2261.94\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.601933 14.568022 14.591839 13.711491 13.614098 14.598946]\n",
      "Reset environment\n",
      "Episode reward: 125.969086\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.601311 14.567336 14.591276 13.71079  13.613549 14.598328]\n",
      "Reset environment\n",
      "Episode reward: 2373.136\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.601892 14.567924 14.591854 13.711422 13.614084 14.59891 ]\n",
      "Reset environment\n",
      "Episode reward: 1899.662\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.602546 14.56858  14.592509 13.712138 13.614669 14.599564]\n",
      "Reset environment\n",
      "Episode reward: 2199.925\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.603294 14.56933  14.593256 13.712951 13.615347 14.600313]\n",
      "Reset environment\n",
      "Episode reward: 1995.749\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.603694 14.569713 14.593676 13.713403 13.615692 14.600711]\n",
      "Reset environment\n",
      "Episode reward: 3542.9927\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.60463   14.5706625 14.594611  13.714415  13.616535  14.601648 ]\n",
      "Reset environment\n",
      "Episode reward: 4296.321\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.605809 14.571839 14.595793 13.715682 13.617579 14.602827]\n",
      "Reset environment\n",
      "Episode reward: 2473.448\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.606439 14.572484 14.596411 13.716366 13.618169 14.603457]\n",
      "Reset environment\n",
      "Episode reward: 3232.177\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.607239  14.573286  14.59721   13.7172365 13.618906  14.604258 ]\n",
      "Reset environment\n",
      "Episode reward: 2336.3372\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.607795  14.5738325 14.597773  13.717846  13.6194105 14.604814 ]\n",
      "Reset environment\n",
      "Episode reward: 518.27264\n",
      "Total Steps: 19\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.607825 14.573863 14.597803 13.717906 13.61943  14.604844]\n",
      "Reset environment\n",
      "Episode reward: 2842.5447\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.608539 14.574585 14.598512 13.718684 13.620085 14.605557]\n",
      "Reset environment\n",
      "Episode reward: 2992.4722\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.609282 14.575315 14.599264 13.719488 13.620758 14.606304]\n",
      "Reset environment\n",
      "Episode reward: 2333.4377\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.609792 14.575842 14.599761 13.720062 13.621223 14.606814]\n",
      "Reset environment\n",
      "Episode reward: 2036.8125\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.610247 14.576304 14.600209 13.720569 13.621631 14.607267]\n",
      "Reset environment\n",
      "Episode reward: 2661.4558\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.610895 14.576965 14.600845 13.721278 13.622226 14.607916]\n",
      "Reset environment\n",
      "Episode reward: 1365.5054\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.611111 14.577205 14.601038 13.721534 13.622421 14.608133]\n",
      "Reset environment\n",
      "Episode reward: 1563.2349\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.611481 14.577587 14.601396 13.721946 13.622757 14.608501]\n",
      "Reset environment\n",
      "Episode reward: 2314.0977\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.612011 14.578102 14.601943 13.72253  13.623218 14.609033]\n",
      "Reset environment\n",
      "Episode reward: 3607.226\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.612975 14.579072 14.602902 13.723576 13.624083 14.609998]\n",
      "Reset environment\n",
      "Episode reward: 2017.1063\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.613495  14.579594  14.603422  13.724143  13.624564  14.6105175]\n",
      "Reset environment\n",
      "Episode reward: 4575.4106\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6147585 14.580857  14.604691  13.725499  13.625667  14.61178  ]\n",
      "Reset environment\n",
      "Episode reward: 1972.5701\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6151905 14.581305  14.605106  13.725977  13.626068  14.612212 ]\n",
      "Reset environment\n",
      "Episode reward: 1387.9738\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.615468 14.581566 14.605396 13.726293 13.626322 14.612492]\n",
      "Reset environment\n",
      "Episode reward: 1804.0636\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.615867 14.581973 14.605782 13.726731 13.626685 14.61289 ]\n",
      "Reset environment\n",
      "Episode reward: 1950.1075\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.61654  14.582648 14.606459 13.727469 13.627295 14.613564]\n",
      "Reset environment\n",
      "Episode reward: 5277.0615\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.618028  14.5841465 14.607942  13.729063  13.628606  14.615053 ]\n",
      "Reset environment\n",
      "Episode reward: -151.59137\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.617252 14.583301 14.607247 13.728257 13.627915 14.614278]\n",
      "Reset environment\n",
      "Episode reward: 101.36746\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.616609  14.582599  14.6066675 13.72756   13.627352  14.613641 ]\n",
      "Reset environment\n",
      "Episode reward: 1908.6255\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.616958 14.582924 14.607046 13.727973 13.627656 14.613998]\n",
      "Reset environment\n",
      "Episode reward: 993.62024\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.617161  14.583128  14.607245  13.728212  13.627838  14.6142025]\n",
      "Reset environment\n",
      "Episode reward: 1374.8357\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.617495 14.583467 14.607578 13.728586 13.628147 14.614536]\n",
      "Reset environment\n",
      "Episode reward: 3297.4575\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6183405 14.584324  14.608415  13.729499  13.628901  14.615381 ]\n",
      "Reset environment\n",
      "Episode reward: 4094.3357\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.619439 14.585421 14.609521 13.730689 13.629867 14.61648 ]\n",
      "Reset environment\n",
      "Episode reward: 3369.8367\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.620324 14.586303 14.610408 13.731647 13.630638 14.617365]\n",
      "Reset environment\n",
      "Episode reward: 3407.628\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.621167 14.587143 14.611255 13.732564 13.631409 14.618209]\n",
      "Reset environment\n",
      "Episode reward: 2007.6111\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.621664  14.587649  14.611743  13.7331085 13.631873  14.618706 ]\n",
      "Reset environment\n",
      "Episode reward: 2080.5725\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.622151 14.588141 14.612227 13.733646 13.63232  14.619195]\n",
      "Reset environment\n",
      "Episode reward: 1994.1765\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.622618  14.5886135 14.612689  13.73416   13.632745  14.619662 ]\n",
      "Reset environment\n",
      "Episode reward: 2286.154\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.62317   14.5891695 14.613239  13.734764  13.633249  14.6202135]\n",
      "Reset environment\n",
      "Episode reward: 2456.0088\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.623744  14.589763  14.613794  13.7353945 13.633782  14.620787 ]\n",
      "Reset environment\n",
      "Episode reward: 2729.1582\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.624398  14.590419  14.6144495 13.736111  13.634383  14.621441 ]\n",
      "Reset environment\n",
      "Episode reward: 2112.9531\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.624863 14.590872 14.614924 13.736623 13.634805 14.621906]\n",
      "Reset environment\n",
      "Episode reward: 2288.218\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.625411 14.591427 14.615464 13.737226 13.635307 14.622455]\n",
      "Reset environment\n",
      "Episode reward: 3973.576\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.626487 14.592513 14.616534 13.738385 13.636262 14.623532]\n",
      "Reset environment\n",
      "Episode reward: 1919.2567\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.626925 14.592948 14.616977 13.738873 13.636662 14.62397 ]\n",
      "Reset environment\n",
      "Episode reward: 4163.3066\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.628059 14.594091 14.618097 13.740091 13.637679 14.625103]\n",
      "Reset environment\n",
      "Episode reward: 3637.362\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.628996 14.595021 14.61904  13.741106 13.638511 14.626042]\n",
      "Reset environment\n",
      "Episode reward: 2101.303\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.629716 14.595743 14.619758 13.741888 13.639162 14.626763]\n",
      "Reset environment\n",
      "Episode reward: 2426.787\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.630293 14.596332 14.620325 13.742518 13.63968  14.62734 ]\n",
      "Reset environment\n",
      "Episode reward: 1893.7634\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.630711 14.596739 14.620755 13.742984 13.640064 14.627758]\n",
      "Reset environment\n",
      "Episode reward: 4496.1455\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6319475 14.597968  14.621997  13.744314  13.641153  14.628995 ]\n",
      "Reset environment\n",
      "Episode reward: -258.8511\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.631128  14.597182  14.621149  13.7434845 13.640442  14.628178 ]\n",
      "Reset environment\n",
      "Episode reward: 2103.9436\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.63157   14.597641  14.621576  13.743976  13.6408415 14.62862  ]\n",
      "Reset environment\n",
      "Episode reward: 3338.2144\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.632446  14.598512  14.6224575 13.74492   13.641618  14.629501 ]\n",
      "Reset environment\n",
      "Episode reward: 1827.835\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.63288  14.598946 14.622891 13.745404 13.642015 14.629936]\n",
      "Reset environment\n",
      "Episode reward: 1080.5885\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.633102 14.599161 14.623117 13.745656 13.642214 14.630159]\n",
      "Reset environment\n",
      "Episode reward: 1671.8596\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.633485 14.599532 14.623508 13.74608  13.642564 14.630541]\n",
      "Reset environment\n",
      "Episode reward: 2049.505\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.633964 14.600025 14.623974 13.746607 13.643009 14.631021]\n",
      "Reset environment\n",
      "Episode reward: 1984.2203\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.634339 14.600381 14.624371 13.747038 13.643328 14.631396]\n",
      "Reset environment\n",
      "Episode reward: 2586.9795\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.634958 14.600992 14.624995 13.747716 13.643884 14.632014]\n",
      "Reset environment\n",
      "Episode reward: 2034.5779\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.635365  14.6014185 14.625377  13.748174  13.644251  14.632421 ]\n",
      "Reset environment\n",
      "Episode reward: 2117.4375\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.635874  14.601925  14.6258955 13.748732  13.644719  14.63293  ]\n",
      "Reset environment\n",
      "Episode reward: 1742.4812\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.636483 14.602533 14.626503 13.749398 13.645269 14.633539]\n",
      "Reset environment\n",
      "Episode reward: 914.8007\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.636663 14.602716 14.626677 13.749606 13.645427 14.633719]\n",
      "Reset environment\n",
      "Episode reward: 2002.8828\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.637112  14.603178  14.6271105 13.750109  13.645837  14.634169 ]\n",
      "Reset environment\n",
      "Episode reward: 2042.2716\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.637613 14.603687 14.627606 13.750658 13.646298 14.634669]\n",
      "Reset environment\n",
      "Episode reward: 1530.9515\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.637818 14.603919 14.627787 13.750904 13.646491 14.634877]\n",
      "Reset environment\n",
      "Episode reward: 1974.7249\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.63849  14.604591 14.628459 13.75164  13.647088 14.63555 ]\n",
      "Reset environment\n",
      "Episode reward: 2459.4558\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.639084 14.605202 14.629039 13.75229  13.647642 14.636142]\n",
      "Reset environment\n",
      "Episode reward: 1872.9336\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.639538  14.605649  14.629499  13.7527895 13.64806   14.636596 ]\n",
      "Reset environment\n",
      "Episode reward: 1853.0454\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.639992 14.606107 14.629952 13.753294 13.648477 14.63705 ]\n",
      "Reset environment\n",
      "Episode reward: 4955.504\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.641376 14.607498 14.631333 13.754775 13.649712 14.638433]\n",
      "Reset environment\n",
      "Episode reward: 1132.462\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.641631 14.607756 14.63159  13.755063 13.649945 14.63869 ]\n",
      "Reset environment\n",
      "Episode reward: 1805.2378\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.642054  14.608174  14.632008  13.7555275 13.650327  14.6391115]\n",
      "Reset environment\n",
      "Episode reward: 5608.92\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.643586 14.609699 14.633535 13.75717  13.651706 14.640643]\n",
      "Reset environment\n",
      "Episode reward: 5282.9043\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.645062 14.611185 14.635009 13.758748 13.653002 14.642118]\n",
      "Reset environment\n",
      "Episode reward: 5421.7573\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.646573 14.612701 14.636518 13.760378 13.654314 14.643629]\n",
      "Reset environment\n",
      "Episode reward: 5468.215\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.648115 14.614245 14.638058 13.762032 13.655657 14.64517 ]\n",
      "Reset environment\n",
      "Episode reward: 2061.22\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.648819 14.61495  14.638762 13.7628   13.656288 14.645874]\n",
      "Reset environment\n",
      "Episode reward: 5743.5146\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.650446 14.61658  14.640382 13.764531 13.657719 14.6475  ]\n",
      "Reset environment\n",
      "Episode reward: 2947.5579\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6512   14.617335 14.641136 13.765352 13.658393 14.648255]\n",
      "Reset environment\n",
      "Episode reward: 2007.5627\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.651887 14.618023 14.641825 13.766104 13.659007 14.648942]\n",
      "Reset environment\n",
      "Episode reward: 2273.1978\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.652424 14.618568 14.642351 13.766689 13.659499 14.649477]\n",
      "Reset environment\n",
      "Episode reward: -528.1632\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.651613  14.6177225 14.641577  13.7657385 13.658759  14.648668 ]\n",
      "Reset environment\n",
      "Episode reward: 2473.6816\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.652222 14.618333 14.642184 13.766415 13.659311 14.649277]\n",
      "Reset environment\n",
      "Episode reward: 2476.098\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.652847 14.618963 14.642806 13.767099 13.659875 14.649902]\n",
      "Reset environment\n",
      "Episode reward: 2776.8389\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.653508 14.619626 14.643468 13.767823 13.660484 14.650564]\n",
      "Reset environment\n",
      "Episode reward: 2585.1216\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.654146  14.62027   14.644097  13.7685175 13.66107   14.651201 ]\n",
      "Reset environment\n",
      "Episode reward: 5615.891\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.655732  14.6218605 14.645681  13.770213  13.662444  14.652789 ]\n",
      "Reset environment\n",
      "Episode reward: 2658.2544\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.656354 14.6225   14.646288 13.770895 13.663023 14.653411]\n",
      "Reset environment\n",
      "Episode reward: 2051.4653\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.657052  14.6231985 14.646986  13.771656  13.663643  14.654109 ]\n",
      "Reset environment\n",
      "Episode reward: 1864.891\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.657463 14.623619 14.647389 13.772113 13.664021 14.65452 ]\n",
      "Reset environment\n",
      "Episode reward: 2450.084\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.658038 14.624208 14.647952 13.772742 13.664552 14.655095]\n",
      "Reset environment\n",
      "Episode reward: 1972.7377\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.658354 14.62455  14.648234 13.773109 13.664841 14.65541 ]\n",
      "Reset environment\n",
      "Episode reward: 1956.3582\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.658768 14.624947 14.648671 13.773574 13.665193 14.655825]\n",
      "Reset environment\n",
      "Episode reward: 951.06116\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.658946 14.625121 14.648851 13.773782 13.66535  14.656003]\n",
      "Reset environment\n",
      "Episode reward: 1383.4056\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.659433 14.625609 14.649336 13.774321 13.665793 14.656493]\n",
      "Reset environment\n",
      "Episode reward: 1566.7625\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.659789 14.625961 14.649695 13.774717 13.666118 14.656848]\n",
      "Reset environment\n",
      "Episode reward: 3205.9072\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.660641 14.626817 14.650546 13.775639 13.666893 14.657701]\n",
      "Reset environment\n",
      "Episode reward: 5233.779\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.662103  14.62828   14.652011  13.7772045 13.668211  14.6591625]\n",
      "Reset environment\n",
      "Episode reward: 1997.4127\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.662573 14.628749 14.652485 13.777724 13.668641 14.659633]\n",
      "Reset environment\n",
      "Episode reward: 2094.0623\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.663113 14.629299 14.653021 13.778311 13.669144 14.660172]\n",
      "Reset environment\n",
      "Episode reward: 3337.9524\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.663988 14.630174 14.653899 13.779255 13.669916 14.661048]\n",
      "Reset environment\n",
      "Episode reward: 2285.0686\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.664541 14.630727 14.654452 13.779861 13.670423 14.661601]\n",
      "Reset environment\n",
      "Episode reward: 2052.028\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.665236 14.631424 14.655149 13.780622 13.671041 14.662297]\n",
      "Reset environment\n",
      "Episode reward: 2770.889\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.665938 14.63213  14.655848 13.781384 13.671679 14.662999]\n",
      "Reset environment\n",
      "Episode reward: 2663.5237\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6665745 14.632777  14.656476  13.782079  13.6722555 14.663635 ]\n",
      "Reset environment\n",
      "Episode reward: 1941.3031\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.66706  14.633263 14.656961 13.782611 13.672705 14.664121]\n",
      "Reset environment\n",
      "Episode reward: 1822.6117\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.667471 14.633673 14.657375 13.783073 13.673081 14.664532]\n",
      "Reset environment\n",
      "Episode reward: 2006.2917\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.667948  14.634142  14.657864  13.783596  13.673522  14.6650095]\n",
      "Reset environment\n",
      "Episode reward: 4194.7\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.669082 14.635265 14.659001 13.784815 13.674501 14.666142]\n",
      "Reset environment\n",
      "Episode reward: 3547.4539\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.670028 14.636211 14.659947 13.785838 13.675337 14.667089]\n",
      "Reset environment\n",
      "Episode reward: 1716.0635\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.670419 14.636608 14.660335 13.786275 13.675695 14.66748 ]\n",
      "Reset environment\n",
      "Episode reward: 2409.3794\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.671047 14.637242 14.660959 13.786961 13.676267 14.668109]\n",
      "Reset environment\n",
      "Episode reward: 2763.217\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.671726 14.637922 14.661639 13.787712 13.676867 14.668789]\n",
      "Reset environment\n",
      "Episode reward: 1611.3077\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.671996 14.638211 14.661889 13.788027 13.677116 14.669058]\n",
      "Reset environment\n",
      "Episode reward: 2367.0854\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.672574 14.638796 14.662462 13.788657 13.677641 14.669637]\n",
      "Reset environment\n",
      "Episode reward: 1847.7725\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.672966 14.639175 14.662862 13.789095 13.67799  14.670028]\n",
      "Reset environment\n",
      "Episode reward: 4401.4883\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.67418   14.640389  14.664085  13.790396  13.6790495 14.671246 ]\n",
      "Reset environment\n",
      "Episode reward: 1378.1897\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.674662 14.640873 14.664567 13.790934 13.679486 14.671727]\n",
      "Reset environment\n",
      "Episode reward: 3005.6487\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.67543   14.64164   14.6653385 13.791769  13.680173  14.672497 ]\n",
      "Reset environment\n",
      "Episode reward: 2471.3198\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.676031 14.642236 14.665941 13.792425 13.680713 14.673097]\n",
      "Reset environment\n",
      "Episode reward: 1742.3898\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.676636 14.642839 14.666543 13.793087 13.681255 14.673701]\n",
      "Reset environment\n",
      "Episode reward: 3588.1606\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.677601 14.643806 14.667504 13.794118 13.682127 14.674666]\n",
      "Reset environment\n",
      "Episode reward: 2670.191\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.678228 14.64442  14.668147 13.794802 13.682701 14.675295]\n",
      "Reset environment\n",
      "Episode reward: 1945.1243\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.678682 14.644878 14.668598 13.795301 13.683116 14.675749]\n",
      "Reset environment\n",
      "Episode reward: 2359.2512\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.679214 14.645429 14.669111 13.795891 13.683605 14.676279]\n",
      "Reset environment\n",
      "Episode reward: 4576.5293\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.680483 14.646696 14.670383 13.79725  13.684716 14.677549]\n",
      "Reset environment\n",
      "Episode reward: 1874.269\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.68089  14.647088 14.670798 13.797701 13.685087 14.677957]\n",
      "Reset environment\n",
      "Episode reward: 2297.5508\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.681442 14.647646 14.671349 13.798309 13.685595 14.678508]\n",
      "Reset environment\n",
      "Episode reward: 2090.0132\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.681929 14.648132 14.671839 13.798845 13.686039 14.678995]\n",
      "Reset environment\n",
      "Episode reward: 4963.6455\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.683308 14.649515 14.673216 13.800326 13.687237 14.680374]\n",
      "Reset environment\n",
      "Episode reward: 1949.3018\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.683962 14.650171 14.673871 13.80105  13.687836 14.681029]\n",
      "Reset environment\n",
      "Episode reward: 1866.074\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.684296 14.650523 14.674185 13.801429 13.688137 14.68136 ]\n",
      "Reset environment\n",
      "Episode reward: 1637.2145\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.684662 14.650897 14.67454  13.801833 13.68847  14.681726]\n",
      "Reset environment\n",
      "Episode reward: 5480.833\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.686226  14.652459  14.676101  13.803495  13.689859  14.6832905]\n",
      "Reset environment\n",
      "Episode reward: 5267.7695\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.687602 14.653833 14.67748  13.804982 13.691128 14.684668]\n",
      "Reset environment\n",
      "Episode reward: 1975.653\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.688033 14.654286 14.677896 13.805463 13.691527 14.6851  ]\n",
      "Reset environment\n",
      "Episode reward: 2604.2185\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.688665 14.65493  14.678524 13.806156 13.692103 14.685733]\n",
      "Reset environment\n",
      "Episode reward: 2207.171\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.68941  14.655678 14.679265 13.806968 13.692764 14.686479]\n",
      "Reset environment\n",
      "Episode reward: 2893.044\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.690115 14.656374 14.679979 13.807721 13.693409 14.687183]\n",
      "Reset environment\n",
      "Episode reward: 3616.8037\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.691063 14.657332 14.680923 13.808751 13.69426  14.688129]\n",
      "Reset environment\n",
      "Episode reward: 5612.9604\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6928625 14.659135  14.68272   13.810672  13.695837  14.689929 ]\n",
      "Reset environment\n",
      "Episode reward: 1519.8352\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.693196 14.659472 14.683051 13.81105  13.696142 14.690264]\n",
      "Reset environment\n",
      "Episode reward: 1381.729\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.6936865 14.659964  14.683543  13.811597  13.696588  14.690756 ]\n",
      "Reset environment\n",
      "Episode reward: 2012.2719\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.694057  14.6603155 14.683932  13.812025  13.696899  14.691126 ]\n",
      "Reset environment\n",
      "Episode reward: 1070.8062\n",
      "Total Steps: 38\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.694263  14.660526  14.6841345 13.8122635 13.697081  14.691333 ]\n",
      "Reset environment\n",
      "Episode reward: 1434.3088\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.694582 14.660858 14.68444  13.812617 13.697371 14.691651]\n",
      "Reset environment\n",
      "Episode reward: 2072.2788\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.695081 14.661354 14.684941 13.813161 13.697828 14.692149]\n",
      "Reset environment\n",
      "Episode reward: -342.62714\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.694299 14.660574 14.684164 13.812321 13.697114 14.691373]\n",
      "Reset environment\n",
      "Episode reward: 2176.434\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.694848 14.661135 14.684707 13.812925 13.697622 14.691921]\n",
      "Reset environment\n",
      "Episode reward: 1867.5835\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.695265 14.661563 14.685113 13.813388 13.698009 14.69234 ]\n",
      "Reset environment\n",
      "Episode reward: 3319.327\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.696126 14.662428 14.685967 13.814318 13.698795 14.693204]\n",
      "Reset environment\n",
      "Episode reward: 2433.4856\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.69694  14.663244 14.686779 13.815201 13.699524 14.694017]\n",
      "Reset environment\n",
      "Episode reward: 1456.0415\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.697293 14.663603 14.687125 13.815594 13.69985  14.694372]\n",
      "Reset environment\n",
      "Episode reward: 1989.4874\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.697755  14.664053  14.687596  13.816104  13.7002735 14.694834 ]\n",
      "Reset environment\n",
      "Episode reward: 1474.606\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.698112 14.664407 14.687959 13.8165   13.700601 14.695191]\n",
      "Reset environment\n",
      "Episode reward: 1355.1553\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.698582 14.664878 14.688427 13.817029 13.701026 14.695662]\n",
      "Reset environment\n",
      "Episode reward: 2535.7036\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.699423  14.66572   14.68927   13.817945  13.7017765 14.696503 ]\n",
      "Reset environment\n",
      "Episode reward: 4880.546\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.700777 14.667077 14.690622 13.819394 13.702965 14.697855]\n",
      "Reset environment\n",
      "Episode reward: 3500.6362\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.701697 14.668004 14.691538 13.820384 13.703805 14.698775]\n",
      "Reset environment\n",
      "Episode reward: 2133.4983\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.70211  14.668382 14.691971 13.820852 13.704144 14.699188]\n",
      "Reset environment\n",
      "Episode reward: 1413.9198\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.70261  14.668882 14.692468 13.821405 13.704597 14.699688]\n",
      "Reset environment\n",
      "Episode reward: 4694.2236\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.703896  14.670168  14.693758  13.822784  13.705751  14.7009735]\n",
      "Reset environment\n",
      "Episode reward: 4971.8867\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.705277 14.671547 14.695142 13.824267 13.706983 14.702357]\n",
      "Reset environment\n",
      "Episode reward: 1386.792\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.705774 14.672043 14.695637 13.824811 13.707431 14.702851]\n",
      "Reset environment\n",
      "Episode reward: 1793.111\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.706222  14.672484  14.69609   13.825298  13.707843  14.7032995]\n",
      "Reset environment\n",
      "Episode reward: 1554.9098\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.706486  14.6727705 14.696337  13.825607  13.708087  14.703563 ]\n",
      "Reset environment\n",
      "Episode reward: 1668.8289\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.706888 14.673179 14.696727 13.826051 13.708457 14.703966]\n",
      "Reset environment\n",
      "Episode reward: 5259.6504\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.708345  14.674641  14.69818   13.827606  13.709724  14.7054205]\n",
      "Reset environment\n",
      "Episode reward: 2408.786\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.708795 14.67507  14.698659 13.828126 13.710124 14.705871]\n",
      "Reset environment\n",
      "Episode reward: 4234.189\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.709891  14.67617   14.699751  13.8293085 13.7111225 14.706966 ]\n",
      "Reset environment\n",
      "Episode reward: 3930.87\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.710945 14.677224 14.700803 13.830444 13.712081 14.70802 ]\n",
      "Reset environment\n",
      "Episode reward: 1531.502\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.711315 14.677586 14.701176 13.83085  13.71242  14.70839 ]\n",
      "Reset environment\n",
      "Episode reward: 2093.8452\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.711791 14.678074 14.701648 13.831375 13.712856 14.708867]\n",
      "Reset environment\n",
      "Episode reward: 1491.3806\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.712145 14.678423 14.702002 13.831773 13.713178 14.709221]\n",
      "Reset environment\n",
      "Episode reward: 4141.1714\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.713252 14.679543 14.703107 13.832963 13.71416  14.710328]\n",
      "Reset environment\n",
      "Episode reward: 1650.5416\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.713649 14.67994  14.703503 13.8334   13.714524 14.710724]\n",
      "Reset environment\n",
      "Episode reward: 1836.4938\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.713934 14.680252 14.70376  13.833731 13.714786 14.71101 ]\n",
      "Reset environment\n",
      "Episode reward: 2212.9634\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.714325 14.680668 14.704129 13.83418  13.71514  14.711401]\n",
      "Reset environment\n",
      "Episode reward: 1955.7008\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.714777 14.681121 14.704584 13.834684 13.715552 14.711853]\n",
      "Reset environment\n",
      "Episode reward: 2117.9944\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.71526  14.681616 14.705055 13.835219 13.715997 14.712336]\n",
      "Reset environment\n",
      "Episode reward: 4979.7695\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.716629 14.682992 14.706421 13.836682 13.717187 14.713706]\n",
      "Reset environment\n",
      "Episode reward: 1612.8787\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.716929  14.683274  14.7067375 13.837025  13.717443  14.714008 ]\n",
      "Reset environment\n",
      "Episode reward: 5475.1006\n",
      "Total Steps: 187\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.718454 14.684804 14.708262 13.83866  13.718771 14.715533]\n",
      "Reset environment\n",
      "Episode reward: 2022.2178\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.718823  14.6852    14.708615  13.8390875 13.719105  14.715904 ]\n",
      "Reset environment\n",
      "Episode reward: 1366.6729\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.719126 14.685502 14.708918 13.839428 13.71938  14.716206]\n",
      "Reset environment\n",
      "Episode reward: 2390.1047\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.719686 14.686052 14.709482 13.840047 13.71989  14.716766]\n",
      "Reset environment\n",
      "Episode reward: 1840.0581\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.720126 14.686498 14.709915 13.840535 13.72029  14.717206]\n",
      "Reset environment\n",
      "Episode reward: 1804.2554\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.720467 14.686821 14.710274 13.840925 13.720588 14.717547]\n",
      "Reset environment\n",
      "Episode reward: 2769.3726\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.72117  14.687523 14.710977 13.841698 13.721219 14.718251]\n",
      "Reset environment\n",
      "Episode reward: 4154.7974\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.722296 14.688639 14.712103 13.842902 13.722193 14.719377]\n",
      "Reset environment\n",
      "Episode reward: 4745.41\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.723605 14.689953 14.713407 13.844304 13.723335 14.720685]\n",
      "Reset environment\n",
      "Episode reward: -400.56122\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.722737 14.689026 14.712612 13.843498 13.722535 14.71983 ]\n",
      "Reset environment\n",
      "Episode reward: 1647.6589\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.723069 14.68938  14.712929 13.843872 13.722842 14.720162]\n",
      "Reset environment\n",
      "Episode reward: 1831.9436\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.723697  14.690007  14.713555  13.844558  13.7234125 14.72079  ]\n",
      "Reset environment\n",
      "Episode reward: 2804.886\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.724396 14.690713 14.714251 13.845326 13.724045 14.721491]\n",
      "Reset environment\n",
      "Episode reward: 5175.5107\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.725849 14.692165 14.715703 13.846879 13.725338 14.722945]\n",
      "Reset environment\n",
      "Episode reward: 5102.02\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.727261 14.693586 14.717109 13.848388 13.726587 14.724357]\n",
      "Reset environment\n",
      "Episode reward: 909.0609\n",
      "Total Steps: 29\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.727433 14.693759 14.71728  13.848593 13.726743 14.724529]\n",
      "Reset environment\n",
      "Episode reward: 2458.1514\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.728022 14.694353 14.717865 13.849242 13.727279 14.725119]\n",
      "Reset environment\n",
      "Episode reward: 1515.4941\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.728363 14.694685 14.718218 13.849621 13.727588 14.72546 ]\n",
      "Reset environment\n",
      "Episode reward: 2554.4668\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.728954 14.695277 14.718808 13.850268 13.72813  14.72605 ]\n",
      "Reset environment\n",
      "Episode reward: 5677.4316\n",
      "Total Steps: 192\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.73056  14.696882 14.720415 13.851983 13.729562 14.727657]\n",
      "Reset environment\n",
      "Episode reward: 2183.1335\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.731291 14.697612 14.721147 13.852781 13.730213 14.728386]\n",
      "Reset environment\n",
      "Episode reward: 2046.0922\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.731981  14.698298  14.721834  13.853533  13.7308235 14.7290745]\n",
      "Reset environment\n",
      "Episode reward: 3299.5195\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.7328415 14.699157  14.722694  13.854462  13.731575  14.729935 ]\n",
      "Reset environment\n",
      "Episode reward: 1963.8647\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.733299 14.69961  14.723155 13.854967 13.731994 14.730392]\n",
      "Reset environment\n",
      "Episode reward: 2646.3257\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.733948 14.700255 14.723811 13.855673 13.732584 14.731042]\n",
      "Reset environment\n",
      "Episode reward: 869.8628\n",
      "Total Steps: 27\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.734115 14.700421 14.723977 13.855868 13.732734 14.731208]\n",
      "Reset environment\n",
      "Episode reward: 1566.4744\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.734158 14.700433 14.724049 13.855972 13.732781 14.731253]\n",
      "Reset environment\n",
      "Episode reward: 2047.0101\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.734563 14.700823 14.72447  13.856429 13.733125 14.731657]\n",
      "Reset environment\n",
      "Episode reward: 1910.8994\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.735025 14.701281 14.72494  13.856935 13.73355  14.73212 ]\n",
      "Reset environment\n",
      "Episode reward: 1982.6826\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.735401  14.701643  14.725338  13.857364  13.7338705 14.732497 ]\n",
      "Reset environment\n",
      "Episode reward: 1481.1134\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.735741 14.701982 14.725681 13.857743 13.734182 14.732837]\n",
      "Reset environment\n",
      "Episode reward: 4026.4836\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.736826 14.703067 14.726769 13.858907 13.735148 14.733922]\n",
      "Reset environment\n",
      "Episode reward: 2129.4272\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.737321 14.703563 14.727265 13.859455 13.735602 14.734418]\n",
      "Reset environment\n",
      "Episode reward: 2250.169\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.737723 14.703989 14.727649 13.859912 13.735972 14.734819]\n",
      "Reset environment\n",
      "Episode reward: 2246.2642\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.738218 14.704473 14.728156 13.860456 13.736426 14.735312]\n",
      "Reset environment\n",
      "Episode reward: 1995.4731\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.738595 14.704866 14.728512 13.860883 13.736773 14.735689]\n",
      "Reset environment\n",
      "Episode reward: 1559.2832\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.738951  14.705221  14.728868  13.8612795 13.737098  14.736045 ]\n",
      "Reset environment\n",
      "Episode reward: 1387.0078\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.739439 14.70571  14.729357 13.861818 13.737543 14.736534]\n",
      "Reset environment\n",
      "Episode reward: 1746.9191\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.739865  14.706146  14.729767  13.8622875 13.737936  14.7369585]\n",
      "Reset environment\n",
      "Episode reward: 4143.6875\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.740974 14.707263 14.730868 13.863481 13.73893  14.73807 ]\n",
      "Reset environment\n",
      "Episode reward: 3042.0242\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.741554 14.707866 14.731427 13.864128 13.739465 14.738647]\n",
      "Reset environment\n",
      "Episode reward: 3700.6877\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.742513 14.708831 14.732385 13.865172 13.7403   14.739607]\n",
      "Reset environment\n",
      "Episode reward: 2750.6406\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.7430525 14.709342  14.732943  13.865782  13.740748  14.740145 ]\n",
      "Reset environment\n",
      "Episode reward: 1845.7057\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.74346  14.709762 14.733339 13.866235 13.741122 14.740554]\n",
      "Reset environment\n",
      "Episode reward: 2233.0986\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.743941 14.71026  14.733805 13.866769 13.741564 14.741035]\n",
      "Reset environment\n",
      "Episode reward: 2146.3008\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.744432 14.710752 14.7343   13.867314 13.742014 14.741527]\n",
      "Reset environment\n",
      "Episode reward: 4633.382\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.745715 14.712033 14.735588 13.868681 13.743128 14.742809]\n",
      "Reset environment\n",
      "Episode reward: 1411.3793\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.746209 14.712528 14.736082 13.869227 13.743577 14.743304]\n",
      "Reset environment\n",
      "Episode reward: 2175.8982\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.746712 14.713031 14.736585 13.869785 13.744035 14.743808]\n",
      "Reset environment\n",
      "Episode reward: 148.58255\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.746072 14.712335 14.736011 13.869091 13.743438 14.743179]\n",
      "Reset environment\n",
      "Episode reward: -428.02646\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.745314 14.711607 14.735228 13.868216 13.742757 14.742422]\n",
      "Reset environment\n",
      "Episode reward: 2194.863\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.745678 14.711994 14.735567 13.868634 13.743085 14.742784]\n",
      "Reset environment\n",
      "Episode reward: 2118.5408\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.7463875 14.712705  14.736274  13.869407  13.743725  14.743492 ]\n",
      "Reset environment\n",
      "Episode reward: 350.06583\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.746004 14.712344 14.735862 13.868907 13.743421 14.743111]\n",
      "Reset environment\n",
      "Episode reward: 3104.7239\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.746776 14.713113 14.736638 13.869747 13.744102 14.743884]\n",
      "Reset environment\n",
      "Episode reward: 2027.1\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.747234 14.713563 14.7371   13.870253 13.744515 14.744343]\n",
      "Reset environment\n",
      "Episode reward: 4519.943\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.748454  14.714784  14.738321  13.871571  13.7456045 14.745564 ]\n",
      "Reset environment\n",
      "Episode reward: 5738.125\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.750086 14.716413 14.739952 13.873313 13.747026 14.747197]\n",
      "Reset environment\n",
      "Episode reward: 2428.1108\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.750698 14.717027 14.740562 13.873982 13.74758  14.747809]\n",
      "Reset environment\n",
      "Episode reward: 3132.9158\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.751452 14.717782 14.741317 13.874805 13.748273 14.748564]\n",
      "Reset environment\n",
      "Episode reward: 3688.991\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.752416 14.718753 14.742276 13.875846 13.749149 14.749527]\n",
      "Reset environment\n",
      "Episode reward: 2714.8364\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.753054 14.719386 14.742923 13.87655  13.749708 14.750165]\n",
      "Reset environment\n",
      "Episode reward: 2282.1262\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.753608 14.71994  14.743477 13.877158 13.750218 14.75072 ]\n",
      "Reset environment\n",
      "Episode reward: 1797.7422\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.754214  14.720549  14.744084  13.877827  13.750771  14.7513275]\n",
      "Reset environment\n",
      "Episode reward: 5216.826\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.75567  14.722002 14.745544 13.879382 13.752048 14.752783]\n",
      "Reset environment\n",
      "Episode reward: 2157.425\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.756392 14.722726 14.746266 13.880167 13.752698 14.753507]\n",
      "Reset environment\n",
      "Episode reward: 2061.4062\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.756777 14.723134 14.74663  13.880605 13.753049 14.753888]\n",
      "Reset environment\n",
      "Episode reward: 5051.127\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.758196 14.724554 14.748052 13.882121 13.754302 14.755308]\n",
      "Reset environment\n",
      "Episode reward: 5266.841\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.759664 14.726017 14.749526 13.883691 13.755597 14.756774]\n",
      "Reset environment\n",
      "Episode reward: 2702.916\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.76032  14.726681 14.750179 13.884412 13.756196 14.757431]\n",
      "Reset environment\n",
      "Episode reward: 3774.3093\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.761319 14.727675 14.751182 13.88549  13.757066 14.758432]\n",
      "Reset environment\n",
      "Episode reward: 2428.763\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.761883  14.7282295 14.751757  13.88611   13.757584  14.758997 ]\n",
      "Reset environment\n",
      "Episode reward: 3254.1255\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.762715 14.729068 14.752586 13.887014 13.758349 14.75983 ]\n",
      "Reset environment\n",
      "Episode reward: 2529.2532\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.763346 14.729702 14.753213 13.887704 13.75892  14.760459]\n",
      "Reset environment\n",
      "Episode reward: 1420.1168\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.763649 14.729995 14.753522 13.888049 13.759191 14.760763]\n",
      "Reset environment\n",
      "Episode reward: 4819.748\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.76498   14.73132   14.754859  13.889474  13.760369  14.7620945]\n",
      "Reset environment\n",
      "Episode reward: 1331.3927\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.765271 14.73161  14.755149 13.889803 13.760633 14.762385]\n",
      "Reset environment\n",
      "Episode reward: 3510.8464\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.766201 14.732543 14.756077 13.890803 13.761456 14.763315]\n",
      "Reset environment\n",
      "Episode reward: -518.52136\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.765162  14.731611  14.754951  13.889721  13.7605295 14.762285 ]\n",
      "Reset environment\n",
      "Episode reward: 2329.2966\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.765695 14.732128 14.755496 13.890303 13.761003 14.762817]\n",
      "Reset environment\n",
      "Episode reward: 2440.8691\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.766237 14.73267  14.756041 13.890903 13.761498 14.76336 ]\n",
      "Reset environment\n",
      "Episode reward: 4121.1514\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.76733  14.733772 14.75713  13.892077 13.762474 14.764454]\n",
      "Reset environment\n",
      "Episode reward: 5083.2056\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.768739 14.735184 14.758535 13.893584 13.763708 14.765858]\n",
      "Reset environment\n",
      "Episode reward: 2186.1436\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.769476 14.735925 14.759271 13.894383 13.764377 14.766597]\n",
      "Reset environment\n",
      "Episode reward: 3174.0938\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.770261 14.736726 14.760037 13.895235 13.765106 14.767382]\n",
      "Reset environment\n",
      "Episode reward: 2577.6619\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.770879  14.737357  14.7606535 13.895911  13.765675  14.768001 ]\n",
      "Reset environment\n",
      "Episode reward: 1383.9971\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.771365  14.7378435 14.761141  13.896446  13.766118  14.768486 ]\n",
      "Reset environment\n",
      "Episode reward: 1864.4193\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.771755 14.738213 14.761551 13.896881 13.766457 14.768876]\n",
      "Reset environment\n",
      "Episode reward: 2924.3809\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.772486  14.7389555 14.762266  13.897673  13.767121  14.7696085]\n",
      "Reset environment\n",
      "Episode reward: 1371.1516\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.7729645 14.739435  14.762745  13.898203  13.767556  14.770087 ]\n",
      "Reset environment\n",
      "Episode reward: 2072.7998\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.77333   14.739822  14.76309   13.898619  13.767894  14.7704525]\n",
      "Reset environment\n",
      "Episode reward: 4818.313\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.774565  14.741059  14.764326  13.899951  13.769034  14.7716875]\n",
      "Reset environment\n",
      "Episode reward: 1473.9038\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.774821 14.741334 14.764562 13.900246 13.769266 14.771942]\n",
      "Reset environment\n",
      "Episode reward: 2328.493\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775353 14.741871 14.765089 13.900833 13.76975  14.772474]\n",
      "Reset environment\n",
      "Episode reward: 1422.4855\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775697  14.742218  14.7654295 13.901215  13.770064  14.7728195]\n",
      "Reset environment\n",
      "Episode reward: 1718.3029\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775939 14.742484 14.765654 13.901504 13.770287 14.773061]\n",
      "Reset environment\n",
      "Episode reward: 59.953156\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775282 14.741891 14.764935 13.900836 13.769722 14.772407]\n",
      "Reset environment\n",
      "Episode reward: 1512.7695\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775635 14.742247 14.765284 13.901229 13.770048 14.772759]\n",
      "Reset environment\n",
      "Episode reward: 471.31076\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775182  14.741739  14.764869  13.9006815 13.769666  14.772305 ]\n",
      "Reset environment\n",
      "Episode reward: 2179.9163\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775691 14.74226  14.765368 13.90124  13.770135 14.772814]\n",
      "Reset environment\n",
      "Episode reward: 1852.6732\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.775967 14.742561 14.765624 13.901564 13.770383 14.773088]\n",
      "Reset environment\n",
      "Episode reward: 1992.2782\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.776412 14.743013 14.766063 13.902059 13.770789 14.773534]\n",
      "Reset environment\n",
      "Episode reward: 1896.4056\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.776821 14.743436 14.766459 13.902513 13.771164 14.773943]\n",
      "Reset environment\n",
      "Episode reward: 1015.0899\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.77703  14.743641 14.766671 13.902749 13.771354 14.774152]\n",
      "Reset environment\n",
      "Episode reward: 1579.4331\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.777393 14.744001 14.767037 13.903154 13.771685 14.774515]\n",
      "Reset environment\n",
      "Episode reward: 2619.4421\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.778025 14.744623 14.767675 13.90384  13.772257 14.775148]\n",
      "Reset environment\n",
      "Episode reward: 1353.2787\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.778303 14.74489  14.767964 13.904155 13.772508 14.775427]\n",
      "Reset environment\n",
      "Episode reward: 1810.467\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.778713  14.745303  14.7683735 13.904611  13.772882  14.775837 ]\n",
      "Reset environment\n",
      "Episode reward: 1602.363\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.779071 14.745662 14.768731 13.905013 13.77321  14.776196]\n",
      "Reset environment\n",
      "Episode reward: 1892.781\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.779501 14.746092 14.769159 13.905489 13.773602 14.776625]\n",
      "Reset environment\n",
      "Episode reward: 3362.3423\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.780376 14.746969 14.770033 13.906434 13.774387 14.7775  ]\n",
      "Reset environment\n",
      "Episode reward: 2300.5408\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.780857 14.747469 14.77049  13.906973 13.774831 14.777982]\n",
      "Reset environment\n",
      "Episode reward: 2622.4614\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.7815    14.7481165 14.771131  13.907676  13.775415  14.778625 ]\n",
      "Reset environment\n",
      "Episode reward: 5721.353\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.783109 14.749724 14.772743 13.909394 13.776854 14.780232]\n",
      "Reset environment\n",
      "Episode reward: 3472.4883\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.784006 14.75062  14.773644 13.910363 13.777645 14.781129]\n",
      "Reset environment\n",
      "Episode reward: 4859.175\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.785266 14.751882 14.774907 13.911722 13.778796 14.782391]\n",
      "Reset environment\n",
      "Episode reward: 1845.169\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.785677 14.752296 14.775314 13.912181 13.779166 14.782802]\n",
      "Reset environment\n",
      "Episode reward: 1480.1301\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.786025 14.752642 14.775672 13.912566 13.779488 14.783151]\n",
      "Reset environment\n",
      "Episode reward: 3353.645\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.786893  14.7535095 14.776542  13.913504  13.780251  14.7840185]\n",
      "Reset environment\n",
      "Episode reward: 1906.1935\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.787345  14.753964  14.776993  13.914004  13.780667  14.7844715]\n",
      "Reset environment\n",
      "Episode reward: 5584.0425\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.788821 14.755441 14.778466 13.915592 13.78201  14.785947]\n",
      "Reset environment\n",
      "Episode reward: 5494.544\n",
      "Total Steps: 186\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.790352 14.756973 14.779999 13.917226 13.783388 14.787478]\n",
      "Reset environment\n",
      "Episode reward: 2255.1318\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.79087  14.757479 14.780532 13.917792 13.78385  14.787996]\n",
      "Reset environment\n",
      "Episode reward: 2418.2437\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.791322 14.75795  14.780967 13.918301 13.784266 14.788448]\n",
      "Reset environment\n",
      "Episode reward: 1802.412\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.791722 14.758359 14.781358 13.918745 13.784635 14.788851]\n",
      "Reset environment\n",
      "Episode reward: 1534.9365\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.792045 14.758667 14.781697 13.919104 13.784924 14.789175]\n",
      "Reset environment\n",
      "Episode reward: 1386.0823\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.792533  14.759154  14.782185  13.9196415 13.785365  14.789663 ]\n",
      "Reset environment\n",
      "Episode reward: 1856.2595\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.792904  14.759507  14.782572  13.9200535 13.785689  14.790034 ]\n",
      "Reset environment\n",
      "Episode reward: 1913.3539\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.79355  14.760155 14.783217 13.920763 13.786268 14.790679]\n",
      "Reset environment\n",
      "Episode reward: 2483.312\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.794114  14.760729  14.7837715 13.921379  13.786789  14.7912445]\n",
      "Reset environment\n",
      "Episode reward: 668.65515\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.793755  14.7603445 14.783443  13.920931  13.786477  14.79089  ]\n",
      "Reset environment\n",
      "Episode reward: 2862.3745\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.79447  14.761059 14.78416  13.921708 13.787119 14.791605]\n",
      "Reset environment\n",
      "Episode reward: -684.92316\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.79351   14.760105  14.783206  13.920777  13.7862835 14.79065  ]\n",
      "Reset environment\n",
      "Episode reward: 5037.2417\n",
      "Total Steps: 172\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.794888 14.761488 14.784583 13.922252 13.787504 14.792028]\n",
      "Reset environment\n",
      "Episode reward: 1870.2421\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.795315  14.761905  14.785023  13.922721  13.7878895 14.792456 ]\n",
      "Reset environment\n",
      "Episode reward: 1318.1765\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.795623 14.762216 14.785324 13.923062 13.788168 14.792764]\n",
      "Reset environment\n",
      "Episode reward: 1665.8472\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.796011 14.762595 14.785719 13.92349  13.788526 14.793152]\n",
      "Reset environment\n",
      "Episode reward: 6214.458\n",
      "Total Steps: 210\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.797752  14.764344  14.7874565 13.925348  13.790051  14.794891 ]\n",
      "Reset environment\n",
      "Episode reward: 2667.7678\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.798366 14.764975 14.788045 13.926018 13.79061  14.795506]\n",
      "Reset environment\n",
      "Episode reward: 2793.612\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.7990675 14.7656765 14.788748  13.926783  13.79125   14.796208 ]\n",
      "Reset environment\n",
      "Episode reward: 1517.2355\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.799313  14.7659445 14.788971  13.927071  13.791473  14.796453 ]\n",
      "Reset environment\n",
      "Episode reward: 1780.3289\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.799723  14.766353  14.789384  13.9275255 13.791851  14.7968645]\n",
      "Reset environment\n",
      "Episode reward: 511.91495\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.799224 14.765908 14.788838 13.92694  13.791416 14.79637 ]\n",
      "Reset environment\n",
      "Episode reward: 5332.602\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.800688 14.767377 14.7903   13.928505 13.792729 14.797834]\n",
      "Reset environment\n",
      "Episode reward: 1566.2644\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.801063 14.767749 14.790676 13.92892  13.793075 14.798209]\n",
      "Reset environment\n",
      "Episode reward: 2357.5002\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.801598 14.768295 14.7912   13.929505 13.793566 14.798744]\n",
      "Reset environment\n",
      "Episode reward: 1909.4121\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.802241 14.768939 14.791843 13.930207 13.794139 14.79939 ]\n",
      "Reset environment\n",
      "Episode reward: 2023.029\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.802695 14.769396 14.792297 13.930715 13.794554 14.799847]\n",
      "Reset environment\n",
      "Episode reward: 2125.603\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.803161  14.769873  14.792751  13.9312315 13.794979  14.800311 ]\n",
      "Reset environment\n",
      "Episode reward: 2843.5789\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.803831 14.770559 14.793413 13.931968 13.795599 14.800982]\n",
      "Reset environment\n",
      "Episode reward: 4610.5215\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.805078 14.771809 14.794656 13.933309 13.796684 14.802231]\n",
      "Reset environment\n",
      "Episode reward: 1975.2913\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.805491 14.772234 14.795062 13.933771 13.797066 14.802647]\n",
      "Reset environment\n",
      "Episode reward: 1926.6017\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.805933  14.7726755 14.795507  13.934261  13.797471  14.803088 ]\n",
      "Reset environment\n",
      "Episode reward: 1369.0764\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.806415 14.773154 14.795983 13.934793 13.797903 14.803569]\n",
      "Reset environment\n",
      "Episode reward: 1428.2089\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.806736  14.7734785 14.796301  13.935152  13.798196  14.803893 ]\n",
      "Reset environment\n",
      "Episode reward: 1365.6526\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.80705  14.773796 14.796614 13.935499 13.798485 14.804207]\n",
      "Reset environment\n",
      "Episode reward: 2670.486\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.807647 14.774413 14.797188 13.936158 13.799027 14.804803]\n",
      "Reset environment\n",
      "Episode reward: 2617.9377\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.808317 14.7751   14.797847 13.936889 13.799648 14.805474]\n",
      "Reset environment\n",
      "Episode reward: 1305.0724\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8086195 14.775401  14.798152  13.937223  13.799928  14.805778 ]\n",
      "Reset environment\n",
      "Episode reward: 523.1748\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.808181 14.774914 14.797746 13.936711 13.799553 14.805341]\n",
      "Reset environment\n",
      "Episode reward: 2456.6458\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.808759 14.775482 14.798333 13.937345 13.800085 14.80592 ]\n",
      "Reset environment\n",
      "Episode reward: 2857.2812\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.809427 14.776153 14.799003 13.938078 13.8007   14.806589]\n",
      "Reset environment\n",
      "Episode reward: 2181.7927\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.810144 14.776872 14.79972  13.938862 13.801346 14.807306]\n",
      "Reset environment\n",
      "Episode reward: 3355.0732\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.810989 14.777715 14.800569 13.939783 13.802095 14.808151]\n",
      "Reset environment\n",
      "Episode reward: 2098.2314\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8116865 14.778416  14.801266  13.940545  13.802732  14.808848 ]\n",
      "Reset environment\n",
      "Episode reward: 2398.4324\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.812229 14.778968 14.801795 13.941142 13.803232 14.809392]\n",
      "Reset environment\n",
      "Episode reward: 2415.019\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.812776 14.779521 14.802336 13.94175  13.80373  14.809939]\n",
      "Reset environment\n",
      "Episode reward: 3642.7344\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.813714 14.780459 14.803275 13.942768 13.804562 14.810877]\n",
      "Reset environment\n",
      "Episode reward: 4858.3267\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.815059 14.781805 14.804607 13.944192 13.80574  14.812221]\n",
      "Reset environment\n",
      "Episode reward: 3905.6658\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.816087 14.782833 14.805639 13.945297 13.80665  14.813249]\n",
      "Reset environment\n",
      "Episode reward: 2074.4497\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.816575  14.783323  14.806127  13.945837  13.8070965 14.813737 ]\n",
      "Reset environment\n",
      "Episode reward: 496.78885\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8161955 14.782909  14.805782  13.945362  13.806777  14.813362 ]\n",
      "Reset environment\n",
      "Episode reward: 3547.0393\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.817114 14.783821 14.806709 13.946349 13.807584 14.814284]\n",
      "Reset environment\n",
      "Episode reward: 4435.2197\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.818304 14.785004 14.807905 13.947632 13.808635 14.815475]\n",
      "Reset environment\n",
      "Episode reward: 1819.5328\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.818713 14.785426 14.808303 13.948088 13.809014 14.815886]\n",
      "Reset environment\n",
      "Episode reward: 1376.7979\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.818967  14.785664  14.808573  13.9483795 13.809238  14.816141 ]\n",
      "Reset environment\n",
      "Episode reward: 5053.423\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.820347 14.787045 14.809941 13.949857 13.810437 14.817521]\n",
      "Reset environment\n",
      "Episode reward: 5263.54\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.821777 14.788482 14.81137  13.951391 13.811693 14.818952]\n",
      "Reset environment\n",
      "Episode reward: 5465.9395\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.82329  14.789997 14.812884 13.953009 13.813061 14.820466]\n",
      "Reset environment\n",
      "Episode reward: 1912.8284\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.823719 14.790436 14.813303 13.953482 13.813455 14.820895]\n",
      "Reset environment\n",
      "Episode reward: 2013.9188\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.824238 14.790964 14.813815 13.954046 13.813938 14.821414]\n",
      "Reset environment\n",
      "Episode reward: -443.86563\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.823474  14.790183  14.813063  13.9530945 13.813242  14.82065  ]\n",
      "Reset environment\n",
      "Episode reward: 1650.8406\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.823857 14.790576 14.813439 13.95352  13.813597 14.821034]\n",
      "Reset environment\n",
      "Episode reward: 2560.7341\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.82446   14.79117   14.8140545 13.954178  13.814142  14.821637 ]\n",
      "Reset environment\n",
      "Episode reward: 1569.3235\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8247385 14.79147   14.814314  13.954497  13.814396  14.821917 ]\n",
      "Reset environment\n",
      "Episode reward: 1934.033\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.825152 14.791873 14.81474  13.954958 13.814777 14.822331]\n",
      "Reset environment\n",
      "Episode reward: 1692.58\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.825491 14.792194 14.815094 13.955336 13.815068 14.82267 ]\n",
      "Reset environment\n",
      "Episode reward: 1354.6318\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.825961 14.792665 14.815565 13.955854 13.81549  14.823143]\n",
      "Reset environment\n",
      "Episode reward: 3558.038\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.826885 14.793589 14.816491 13.956853 13.816314 14.824067]\n",
      "Reset environment\n",
      "Episode reward: 4836.498\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.828219 14.794921 14.817828 13.958278 13.817499 14.825401]\n",
      "Reset environment\n",
      "Episode reward: 1431.3418\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.828539 14.79524  14.818146 13.958634 13.817791 14.82572 ]\n",
      "Reset environment\n",
      "Episode reward: 2171.895\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.829255  14.795957  14.818863  13.9594145 13.818434  14.826437 ]\n",
      "Reset environment\n",
      "Episode reward: 1855.9194\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.82967  14.79638  14.819266 13.959875 13.818812 14.826853]\n",
      "Reset environment\n",
      "Episode reward: 1344.8159\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.830131  14.796842  14.819727  13.960388  13.8192215 14.827314 ]\n",
      "Reset environment\n",
      "Episode reward: 1690.7188\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.830535  14.797251  14.820127  13.9608345 13.819593  14.827719 ]\n",
      "Reset environment\n",
      "Episode reward: 5185.473\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.831953 14.798669 14.821547 13.962358 13.82085  14.829136]\n",
      "Reset environment\n",
      "Episode reward: 2549.7795\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.832574 14.79929  14.822173 13.963033 13.821421 14.829757]\n",
      "Reset environment\n",
      "Episode reward: 2205.894\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.833307 14.80002  14.822904 13.96383  13.822079 14.830488]\n",
      "Reset environment\n",
      "Episode reward: 528.07764\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.83292   14.799582  14.822569  13.963377  13.8217325 14.830104 ]\n",
      "Reset environment\n",
      "Episode reward: 3858.6372\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.833936  14.800606  14.82358   13.964469  13.8226595 14.83112  ]\n",
      "Reset environment\n",
      "Episode reward: 2679.514\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.834592 14.801267 14.824233 13.965182 13.82326  14.831776]\n",
      "Reset environment\n",
      "Episode reward: 1104.9332\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.834812 14.801497 14.824449 13.965434 13.823461 14.831996]\n",
      "Reset environment\n",
      "Episode reward: 1981.6383\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.835184 14.801854 14.82484  13.965856 13.82379  14.832368]\n",
      "Reset environment\n",
      "Episode reward: -406.79312\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.834301 14.800952 14.824003 13.964935 13.822996 14.831495]\n",
      "Reset environment\n",
      "Episode reward: 1017.931\n",
      "Total Steps: 33\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.834504 14.801162 14.824198 13.965165 13.82318  14.831699]\n",
      "Reset environment\n",
      "Episode reward: 2494.1387\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.835085  14.801733  14.824783  13.9657955 13.823707  14.83228  ]\n",
      "Reset environment\n",
      "Episode reward: 1375.9119\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.835397 14.80204  14.825099 13.966139 13.823992 14.832592]\n",
      "Reset environment\n",
      "Episode reward: 4184.928\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.836516 14.803161 14.82622  13.96734  13.824983 14.833711]\n",
      "Reset environment\n",
      "Episode reward: 1843.81\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.836945 14.803599 14.826636 13.967811 13.825381 14.834138]\n",
      "Reset environment\n",
      "Episode reward: 2016.5537\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.837456 14.804115 14.827147 13.968371 13.825857 14.83465 ]\n",
      "Reset environment\n",
      "Episode reward: 2021.0883\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.837881 14.804528 14.827582 13.968842 13.826245 14.835074]\n",
      "Reset environment\n",
      "Episode reward: 1990.1675\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.838205 14.804831 14.827924 13.969222 13.826519 14.835398]\n",
      "Reset environment\n",
      "Episode reward: 3424.0469\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.839083  14.805706  14.828801  13.97017   13.8272915 14.836275 ]\n",
      "Reset environment\n",
      "Episode reward: 2358.735\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.839588 14.806193 14.82932  13.970725 13.827753 14.83678 ]\n",
      "Reset environment\n",
      "Episode reward: 5421.435\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.841022 14.807629 14.830753 13.972261 13.829042 14.838215]\n",
      "Reset environment\n",
      "Episode reward: 3366.0388\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.841824 14.808434 14.831557 13.97314  13.829779 14.839019]\n",
      "Reset environment\n",
      "Episode reward: 2158.2837\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8421755 14.808809  14.831885  13.973546  13.830097  14.839372 ]\n",
      "Reset environment\n",
      "Episode reward: 5429.9834\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.843564 14.810203 14.83327  13.975059 13.831384 14.840759]\n",
      "Reset environment\n",
      "Episode reward: 295.65286\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.842935  14.809646  14.832585  13.9743595 13.83083   14.840136 ]\n",
      "Reset environment\n",
      "Episode reward: 3248.1665\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.843739  14.810457  14.8333845 13.975239  13.831569  14.8409395]\n",
      "Reset environment\n",
      "Episode reward: 4235.9746\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.844871 14.811589 14.834519 13.976459 13.832576 14.842072]\n",
      "Reset environment\n",
      "Episode reward: 5590.239\n",
      "Total Steps: 213\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.846636  14.8133545 14.836281  13.978339  13.834157  14.843836 ]\n",
      "Reset environment\n",
      "Episode reward: 2414.4336\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.847184 14.813894 14.836838 13.978943 13.834655 14.844384]\n",
      "Reset environment\n",
      "Episode reward: 1868.8783\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.84758  14.814297 14.837225 13.979388 13.835014 14.84478 ]\n",
      "Reset environment\n",
      "Episode reward: 2122.4802\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.848274 14.814993 14.837918 13.980147 13.835638 14.845475]\n",
      "Reset environment\n",
      "Episode reward: 4605.765\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.84951  14.816235 14.839152 13.981472 13.83674  14.846711]\n",
      "Reset environment\n",
      "Episode reward: 3063.633\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.850245 14.816962 14.839898 13.98228  13.837406 14.847451]\n",
      "Reset environment\n",
      "Episode reward: 4098.522\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8513365 14.818054  14.840985  13.983454  13.838363  14.848537 ]\n",
      "Reset environment\n",
      "Episode reward: 1743.1394\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.851713  14.8184185 14.84137   13.983873  13.838704  14.848914 ]\n",
      "Reset environment\n",
      "Episode reward: 2406.0015\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.852297  14.819006  14.8419485 13.984511  13.839229  14.8495   ]\n",
      "Reset environment\n",
      "Episode reward: 5643.4683\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.853843 14.82055  14.843496 13.986165 13.840633 14.851046]\n",
      "Reset environment\n",
      "Episode reward: 1826.1755\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.854455  14.821164  14.844111  13.9868355 13.841187  14.851658 ]\n",
      "Reset environment\n",
      "Episode reward: 2047.0171\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.855126  14.8218355 14.844784  13.98757   13.841791  14.85233  ]\n",
      "Reset environment\n",
      "Episode reward: 2749.5012\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.855762 14.822486 14.845401 13.98826  13.842372 14.852965]\n",
      "Reset environment\n",
      "Episode reward: 1888.0555\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.85623  14.822954 14.845867 13.988773 13.842804 14.853433]\n",
      "Reset environment\n",
      "Episode reward: 1998.1691\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.856646 14.823389 14.846264 13.989237 13.843186 14.853848]\n",
      "Reset environment\n",
      "Episode reward: 1858.0667\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.857057 14.823801 14.846675 13.989697 13.84356  14.85426 ]\n",
      "Reset environment\n",
      "Episode reward: 5370.951\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.858552 14.825296 14.848169 13.991291 13.844903 14.855756]\n",
      "Reset environment\n",
      "Episode reward: 4736.7295\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.85978  14.826527 14.849398 13.992608 13.846018 14.856985]\n",
      "Reset environment\n",
      "Episode reward: 2401.1228\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8603945 14.827154  14.850002  13.993274  13.846587  14.857599 ]\n",
      "Reset environment\n",
      "Episode reward: 2049.818\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.86084  14.827587 14.850459 13.993765 13.846995 14.858044]\n",
      "Reset environment\n",
      "Episode reward: 4223.4106\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8619585 14.8287115 14.851574  13.994974  13.84797   14.859165 ]\n",
      "Reset environment\n",
      "Episode reward: 4662.007\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.863185  14.829943  14.8527975 13.996286  13.849084  14.86039  ]\n",
      "Reset environment\n",
      "Episode reward: 1989.5112\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.863657 14.830414 14.853266 13.996805 13.849515 14.860861]\n",
      "Reset environment\n",
      "Episode reward: 3032.9458\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.864412 14.831176 14.854014 13.997623 13.850206 14.861616]\n",
      "Reset environment\n",
      "Episode reward: 2100.509\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.864896 14.831665 14.854497 13.998161 13.850645 14.8621  ]\n",
      "Reset environment\n",
      "Episode reward: 1690.5957\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.865273 14.832051 14.854866 13.99858  13.850992 14.862477]\n",
      "Reset environment\n",
      "Episode reward: -27.288391\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.864571  14.8312435 14.854272  13.997929  13.850352  14.861781 ]\n",
      "Reset environment\n",
      "Episode reward: 3678.7832\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.865504 14.832176 14.855211 13.998939 13.851169 14.862717]\n",
      "Reset environment\n",
      "Episode reward: 1658.115\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.865873 14.832546 14.855583 13.999349 13.851508 14.863087]\n",
      "Reset environment\n",
      "Episode reward: 1458.7349\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.866205 14.832874 14.855918 13.999719 13.851812 14.863419]\n",
      "Reset environment\n",
      "Episode reward: 1307.7606\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.866645  14.833307  14.856356  14.000205  13.8522005 14.863859 ]\n",
      "Reset environment\n",
      "Episode reward: 3904.4634\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.867676 14.83434  14.857383 14.001314 13.853142 14.864888]\n",
      "Reset environment\n",
      "Episode reward: 3978.89\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.868726 14.835391 14.858437 14.002446 13.854067 14.865938]\n",
      "Reset environment\n",
      "Episode reward: 4308.0938\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.869876 14.836537 14.859591 14.003685 13.855065 14.867088]\n",
      "Reset environment\n",
      "Episode reward: 2102.9395\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.870349  14.837009  14.8600645 14.004209  13.855497  14.867562 ]\n",
      "Reset environment\n",
      "Episode reward: 2635.7551\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.87099  14.837648 14.860706 14.004908 13.856082 14.868203]\n",
      "Reset environment\n",
      "Episode reward: 602.2064\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.870604 14.837192 14.860381 14.004482 13.855736 14.867821]\n",
      "Reset environment\n",
      "Episode reward: 2724.1323\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.871254  14.8378525 14.861022  14.00519   13.856334  14.868472 ]\n",
      "Reset environment\n",
      "Episode reward: 2028.1471\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.871686 14.838295 14.861446 14.005668 13.856733 14.868904]\n",
      "Reset environment\n",
      "Episode reward: 3475.688\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.872579 14.839197 14.862328 14.006631 13.857549 14.869797]\n",
      "Reset environment\n",
      "Episode reward: 1273.8253\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.872857  14.8394785 14.862603  14.006947  13.857801  14.870075 ]\n",
      "Reset environment\n",
      "Episode reward: 2500.7515\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.873416 14.84004  14.863161 14.007564 13.858312 14.870635]\n",
      "Reset environment\n",
      "Episode reward: 3452.207\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.874296 14.840928 14.864032 14.008513 13.859115 14.871515]\n",
      "Reset environment\n",
      "Episode reward: 2499.2698\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.874841 14.841492 14.864557 14.009113 13.859616 14.872058]\n",
      "Reset environment\n",
      "Episode reward: 4283.14\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.875981 14.84263  14.865707 14.010339 13.860622 14.873201]\n",
      "Reset environment\n",
      "Episode reward: 4703.342\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.877255 14.843907 14.866976 14.011703 13.86174  14.874476]\n",
      "Reset environment\n",
      "Episode reward: 2330.1116\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.878025 14.844679 14.86774  14.012535 13.862436 14.875247]\n",
      "Reset environment\n",
      "Episode reward: 1411.8594\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.878512 14.845165 14.868224 14.013075 13.862879 14.875735]\n",
      "Reset environment\n",
      "Episode reward: 5577.243\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.880038 14.846695 14.869748 14.014717 13.864219 14.877261]\n",
      "Reset environment\n",
      "Episode reward: 7259.189\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.869816 14.836492 14.85953  14.00141  13.854771 14.867023]\n",
      "Reset environment\n",
      "Episode reward: 4326.379\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.87097   14.837647  14.860675  14.002642  13.855815  14.8681755]\n",
      "Reset environment\n",
      "Episode reward: 1534.668\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.871338 14.838014 14.861047 14.003045 13.856157 14.868544]\n",
      "Reset environment\n",
      "Episode reward: 4117.2515\n",
      "Total Steps: 142\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.87242  14.839085 14.862137 14.004204 13.857114 14.86963 ]\n",
      "Reset environment\n",
      "Episode reward: 4210.4224\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.873532 14.840197 14.863253 14.005403 13.858114 14.870742]\n",
      "Reset environment\n",
      "Episode reward: 5226.1504\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.874948  14.841613  14.86467   14.006918  13.8594055 14.872157 ]\n",
      "Reset environment\n",
      "Episode reward: 5681.0723\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.87644  14.843102 14.866163 14.008516 13.860756 14.873649]\n",
      "Reset environment\n",
      "Episode reward: 2301.4902\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8769865 14.843665  14.866695  14.009112  13.861267  14.874195 ]\n",
      "Reset environment\n",
      "Episode reward: 1721.1047\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.877372 14.844055 14.867075 14.00954  13.861618 14.87458 ]\n",
      "Reset environment\n",
      "Episode reward: 3247.976\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.878198 14.844884 14.867894 14.010434 13.862355 14.875404]\n",
      "Reset environment\n",
      "Episode reward: 1383.9065\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.878668 14.845354 14.868365 14.010954 13.862782 14.875875]\n",
      "Reset environment\n",
      "Episode reward: 2762.23\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.879141 14.845814 14.86885  14.011506 13.86319  14.876352]\n",
      "Reset environment\n",
      "Episode reward: 2270.263\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.87963  14.846316 14.869329 14.012046 13.863635 14.876842]\n",
      "Reset environment\n",
      "Episode reward: 3536.663\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.880513 14.847196 14.870221 14.013006 13.864404 14.877726]\n",
      "Reset environment\n",
      "Episode reward: 3444.0078\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.881391 14.848078 14.871095 14.013955 13.865198 14.878602]\n",
      "Reset environment\n",
      "Episode reward: 5174.7827\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.882794 14.849482 14.872499 14.015456 13.86647  14.880005]\n",
      "Reset environment\n",
      "Episode reward: 1734.0647\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.883076 14.849741 14.872803 14.015785 13.866712 14.880285]\n",
      "Reset environment\n",
      "Episode reward: 1383.466\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.883553 14.850214 14.873279 14.016312 13.86714  14.880762]\n",
      "Reset environment\n",
      "Episode reward: 4543.6943\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.884755 14.851418 14.874474 14.017594 13.868222 14.881963]\n",
      "Reset environment\n",
      "Episode reward: 2758.2832\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.885416 14.852076 14.875142 14.018312 13.868806 14.882624]\n",
      "Reset environment\n",
      "Episode reward: 2445.4482\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.885978 14.852643 14.875699 14.018935 13.86932  14.883184]\n",
      "Reset environment\n",
      "Episode reward: 2863.111\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.88668   14.853352  14.876391  14.0197    13.8699665 14.883887 ]\n",
      "Reset environment\n",
      "Episode reward: 1413.5947\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.887177  14.8538475 14.8768835 14.020239  13.870409  14.884384 ]\n",
      "Reset environment\n",
      "Episode reward: 1762.0281\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.887563 14.854224 14.877284 14.020669 13.870765 14.884769]\n",
      "Reset environment\n",
      "Episode reward: 2261.8875\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.88806  14.854712 14.87779  14.02122  13.871221 14.885266]\n",
      "Reset environment\n",
      "Episode reward: 5147.9316\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.889462 14.856111 14.879197 14.022726 13.872484 14.886671]\n",
      "Reset environment\n",
      "Episode reward: 1523.4456\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.889725 14.856392 14.879437 14.023028 13.872725 14.886933]\n",
      "Reset environment\n",
      "Episode reward: 1489.4333\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.890027 14.856711 14.879718 14.023363 13.873002 14.887235]\n",
      "Reset environment\n",
      "Episode reward: 2900.7832\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.890707 14.857403 14.880393 14.02411  13.873623 14.887915]\n",
      "Reset environment\n",
      "Episode reward: 1802.9993\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8911295 14.857834  14.880809  14.024575  13.874015  14.888338 ]\n",
      "Reset environment\n",
      "Episode reward: 2085.984\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.891815  14.858519  14.8814945 14.025322  13.874624  14.889022 ]\n",
      "Reset environment\n",
      "Episode reward: 1976.1174\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.892244 14.858951 14.881925 14.02581  13.875016 14.889453]\n",
      "Reset environment\n",
      "Episode reward: -421.3106\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.891425  14.858192  14.881062  14.024908  13.874257  14.8886385]\n",
      "Reset environment\n",
      "Episode reward: 913.64484\n",
      "Total Steps: 28\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.891602 14.85837  14.881239 14.025113 13.874417 14.888816]\n",
      "Reset environment\n",
      "Episode reward: 2365.6492\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.892152 14.858922 14.881785 14.025729 13.874919 14.889365]\n",
      "Reset environment\n",
      "Episode reward: 2610.542\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.892752  14.859512  14.88239   14.0263815 13.875457  14.889965 ]\n",
      "Reset environment\n",
      "Episode reward: 2414.968\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.893298 14.86005  14.882951 14.026981 13.875963 14.890512]\n",
      "Reset environment\n",
      "Episode reward: 1429.4694\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8936205 14.860375  14.883272  14.027345  13.876259  14.890835 ]\n",
      "Reset environment\n",
      "Episode reward: 1780.0361\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.89402  14.860767 14.883676 14.027784 13.876624 14.891234]\n",
      "Reset environment\n",
      "Episode reward: 3248.516\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.894824  14.8615675 14.884488  14.028657  13.877346  14.892038 ]\n",
      "Reset environment\n",
      "Episode reward: 2773.3086\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8954735 14.862206  14.885147  14.029361  13.877931  14.892687 ]\n",
      "Reset environment\n",
      "Episode reward: 3113.2532\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.896218 14.86296  14.885875 14.030172 13.878616 14.893435]\n",
      "Reset environment\n",
      "Episode reward: 4839.1724\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.8975315 14.864271  14.887192  14.031573  13.879784  14.894747 ]\n",
      "Reset environment\n",
      "Episode reward: 2070.249\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.89821  14.864952 14.887871 14.032314 13.880398 14.895426]\n",
      "Reset environment\n",
      "Episode reward: 2323.3096\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.898688  14.865451  14.8883295 14.032848  13.880841  14.895905 ]\n",
      "Reset environment\n",
      "Episode reward: 2782.6611\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.899339 14.866096 14.888987 14.03356  13.881433 14.896561]\n",
      "Reset environment\n",
      "Episode reward: 3390.2266\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.900148  14.866907  14.889797  14.034442  13.8821745 14.897371 ]\n",
      "Reset environment\n",
      "Episode reward: 1197.5967\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.900401  14.8671665 14.890046  14.034728  13.882403  14.897624 ]\n",
      "Reset environment\n",
      "Episode reward: -364.09363\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.899683 14.866465 14.889331 14.033933 13.881811 14.896906]\n",
      "Reset environment\n",
      "Episode reward: 4599.1704\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.900902 14.867684 14.89055  14.035247 13.882904 14.898125]\n",
      "Reset environment\n",
      "Episode reward: 2363.784\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.901441 14.868209 14.891101 14.035835 13.8834   14.898664]\n",
      "Reset environment\n",
      "Episode reward: 5229.8433\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.902859  14.869628  14.892519  14.0373535 13.8846855 14.900084 ]\n",
      "Reset environment\n",
      "Episode reward: 1164.3308\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.903115  14.8698845 14.892776  14.0376425 13.884921  14.90034  ]\n",
      "Reset environment\n",
      "Episode reward: -103.08096\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.902365  14.869052  14.892102  14.036876  13.8842325 14.899602 ]\n",
      "Reset environment\n",
      "Episode reward: 5090.8325\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.903743 14.870434 14.893478 14.038356 13.885444 14.900979]\n",
      "Reset environment\n",
      "Episode reward: 3703.8564\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.904712 14.871403 14.89445  14.039398 13.886302 14.901952]\n",
      "Reset environment\n",
      "Episode reward: 1987.6418\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.905195  14.871893  14.894924  14.0399275 13.88675   14.902435 ]\n",
      "Reset environment\n",
      "Episode reward: 4113.5625\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.906259  14.872954  14.8959875 14.041077  13.887691  14.903499 ]\n",
      "Reset environment\n",
      "Episode reward: 1376.7964\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.906727  14.873424  14.896452  14.0415945 13.888111  14.903967 ]\n",
      "Reset environment\n",
      "Episode reward: -170.90842\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.905997 14.872634 14.895781 14.040809 13.887444 14.903241]\n",
      "Reset environment\n",
      "Episode reward: 5152.1475\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9074   14.874037 14.897179 14.042309 13.888674 14.904644]\n",
      "Reset environment\n",
      "Episode reward: 1447.1304\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.907631 14.874246 14.897429 14.042577 13.888873 14.904875]\n",
      "Reset environment\n",
      "Episode reward: 323.07516\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.907024 14.873716 14.896775 14.041921 13.888356 14.904276]\n",
      "Reset environment\n",
      "Episode reward: 2137.7224\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.907729 14.874425 14.897477 14.042691 13.888987 14.904981]\n",
      "Reset environment\n",
      "Episode reward: 2025.9662\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.908149  14.874832  14.897911  14.0431595 13.889368  14.905399 ]\n",
      "Reset environment\n",
      "Episode reward: 6405.715\n",
      "Total Steps: 219\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.909829 14.876503 14.899596 14.044961 13.89091  14.907078]\n",
      "Reset environment\n",
      "Episode reward: 1716.4608\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.910065 14.876759 14.899809 14.045243 13.891121 14.907313]\n",
      "Reset environment\n",
      "Episode reward: 3783.498\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.911044 14.877734 14.900788 14.0463   13.891986 14.908291]\n",
      "Reset environment\n",
      "Episode reward: 1131.9998\n",
      "Total Steps: 35\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.91129  14.87798  14.901035 14.046576 13.892211 14.908537]\n",
      "Reset environment\n",
      "Episode reward: 2094.4941\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.911716 14.878418 14.90145  14.047054 13.892601 14.908961]\n",
      "Reset environment\n",
      "Episode reward: 2111.2073\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.912194 14.878898 14.90193  14.047584 13.89304  14.909441]\n",
      "Reset environment\n",
      "Episode reward: 3477.4412\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.913088 14.879797 14.902821 14.048547 13.893858 14.910336]\n",
      "Reset environment\n",
      "Episode reward: 3096.54\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.913857 14.880565 14.903593 14.049384 13.894551 14.911105]\n",
      "Reset environment\n",
      "Episode reward: 1144.1162\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.914104 14.880816 14.903837 14.049662 13.894776 14.911351]\n",
      "Reset environment\n",
      "Episode reward: 1933.0256\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.914535 14.881246 14.904256 14.050138 13.895159 14.911781]\n",
      "Reset environment\n",
      "Episode reward: 1979.9415\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.915195 14.881903 14.904906 14.050859 13.89574  14.912438]\n",
      "Reset environment\n",
      "Episode reward: 4317.4385\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.916352 14.883064 14.906053 14.052098 13.896759 14.913596]\n",
      "Reset environment\n",
      "Episode reward: 1393.354\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.916653 14.883363 14.906359 14.052435 13.897033 14.913897]\n",
      "Reset environment\n",
      "Episode reward: 1763.1179\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.917007 14.88373  14.906697 14.052833 13.897359 14.91425 ]\n",
      "Reset environment\n",
      "Episode reward: 1869.3811\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.917421 14.884146 14.907105 14.053288 13.897735 14.914664]\n",
      "Reset environment\n",
      "Episode reward: 4159.544\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.918498 14.885224 14.908187 14.054454 13.898698 14.915742]\n",
      "Reset environment\n",
      "Episode reward: 3599.298\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.919396 14.886122 14.909087 14.055439 13.899488 14.916641]\n",
      "Reset environment\n",
      "Episode reward: 4026.705\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.92046  14.887185 14.910146 14.056585 13.90044  14.917707]\n",
      "Reset environment\n",
      "Episode reward: 1837.828\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.921074 14.887795 14.910755 14.057252 13.900983 14.91832 ]\n",
      "Reset environment\n",
      "Episode reward: 2670.7573\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.921694 14.888404 14.911383 14.05793  13.901543 14.918941]\n",
      "Reset environment\n",
      "Episode reward: 1828.6847\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.92197  14.888705 14.911641 14.058254 13.901795 14.919216]\n",
      "Reset environment\n",
      "Episode reward: 1541.6941\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.922291 14.889038 14.911948 14.058613 13.902092 14.919536]\n",
      "Reset environment\n",
      "Episode reward: 1631.47\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.922639  14.8893795 14.912301  14.059002  13.902412  14.919885 ]\n",
      "Reset environment\n",
      "Episode reward: 3450.1533\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.923523 14.890266 14.91318  14.059964 13.903213 14.92077 ]\n",
      "Reset environment\n",
      "Episode reward: -48.99832\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.922939 14.889654 14.912614 14.059266 13.902668 14.920189]\n",
      "Reset environment\n",
      "Episode reward: 4548.9116\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9241495 14.890864  14.913825  14.060564  13.903755  14.921398 ]\n",
      "Reset environment\n",
      "Episode reward: 1932.3378\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.924541 14.891273 14.914195 14.061    13.904115 14.921787]\n",
      "Reset environment\n",
      "Episode reward: 2157.8071\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.925238  14.891966  14.914894  14.061762  13.9047365 14.922484 ]\n",
      "Reset environment\n",
      "Episode reward: 2678.941\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.925881  14.8926115 14.915534  14.0624695 13.90532   14.923128 ]\n",
      "Reset environment\n",
      "Episode reward: 2207.1724\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.926389 14.893122 14.916036 14.063032 13.905777 14.923632]\n",
      "Reset environment\n",
      "Episode reward: 278.18387\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.925828 14.892631 14.915408 14.062383 13.905275 14.923071]\n",
      "Reset environment\n",
      "Episode reward: 2550.9375\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.926649  14.893447  14.9162245 14.063271  13.906013  14.923892 ]\n",
      "Reset environment\n",
      "Episode reward: 1390.3021\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.927125 14.89392  14.916695 14.063792 13.906439 14.924365]\n",
      "Reset environment\n",
      "Episode reward: 1806.2131\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.927364  14.894184  14.916905  14.064079  13.906658  14.9246025]\n",
      "Reset environment\n",
      "Episode reward: 2191.637\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.927851 14.89468  14.917383 14.064623 13.907102 14.925089]\n",
      "Reset environment\n",
      "Episode reward: 1746.4485\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.928238 14.895063 14.917774 14.06505  13.907457 14.925476]\n",
      "Reset environment\n",
      "Episode reward: 1769.2322\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.928612 14.895438 14.918149 14.065471 13.907797 14.925851]\n",
      "Reset environment\n",
      "Episode reward: 2202.6174\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.928971  14.895823  14.9184885 14.065886  13.908129  14.926209 ]\n",
      "Reset environment\n",
      "Episode reward: 4546.588\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.930178 14.89704  14.919682 14.06718  13.909228 14.927418]\n",
      "Reset environment\n",
      "Episode reward: 1409.4468\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.930679 14.897532 14.920173 14.067724 13.909664 14.927918]\n",
      "Reset environment\n",
      "Episode reward: 2069.9644\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.931355 14.89821  14.92085  14.068462 13.910277 14.928595]\n",
      "Reset environment\n",
      "Episode reward: 1986.6545\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.932012 14.898869 14.9215   14.069183 13.910865 14.929253]\n",
      "Reset environment\n",
      "Episode reward: 2375.6587\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.932571 14.899429 14.922052 14.069792 13.911369 14.929812]\n",
      "Reset environment\n",
      "Episode reward: 1823.9398\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.932901 14.899777 14.922367 14.070168 13.911673 14.930141]\n",
      "Reset environment\n",
      "Episode reward: 3901.8186\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.933909  14.900785  14.923376  14.071256  13.912563  14.9311495]\n",
      "Reset environment\n",
      "Episode reward: 1488.0714\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.934262 14.901146 14.923726 14.071645 13.91289  14.931503]\n",
      "Reset environment\n",
      "Episode reward: 1545.1619\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.934374 14.901279 14.923819 14.071797 13.912992 14.931613]\n",
      "Reset environment\n",
      "Episode reward: 1541.5374\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.934653 14.901536 14.924118 14.072119 13.91324  14.931891]\n",
      "Reset environment\n",
      "Episode reward: 2432.5134\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.935201 14.902076 14.92467  14.07272  13.913739 14.932439]\n",
      "Reset environment\n",
      "Episode reward: 3409.9749\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.936056 14.902931 14.925526 14.073646 13.914494 14.933294]\n",
      "Reset environment\n",
      "Episode reward: 1846.7915\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.936462  14.903329  14.925939  14.074099  13.914864  14.9337015]\n",
      "Reset environment\n",
      "Episode reward: 3724.6096\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.937397 14.90427  14.926862 14.075115 13.915711 14.934634]\n",
      "Reset environment\n",
      "Episode reward: 4554.4927\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.938606 14.905481 14.928065 14.076412 13.916785 14.935844]\n",
      "Reset environment\n",
      "Episode reward: 1673.27\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.938978 14.905867 14.928419 14.07682  13.917129 14.936216]\n",
      "Reset environment\n",
      "Episode reward: 3948.7227\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.939999 14.906883 14.929441 14.077918 13.918029 14.937236]\n",
      "Reset environment\n",
      "Episode reward: 2179.116\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.940705 14.90759  14.930152 14.07869  13.918661 14.937943]\n",
      "Reset environment\n",
      "Episode reward: 4702.592\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.941944 14.908826 14.931395 14.08002  13.919766 14.939182]\n",
      "Reset environment\n",
      "Episode reward: 1795.9229\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.942347 14.909228 14.931793 14.080467 13.920133 14.939585]\n",
      "Reset environment\n",
      "Episode reward: 1351.317\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.942646  14.9095335 14.932085  14.080802  13.920404  14.939885 ]\n",
      "Reset environment\n",
      "Episode reward: 2039.456\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.943085 14.90998  14.932517 14.081287 13.920806 14.940324]\n",
      "Reset environment\n",
      "Episode reward: 3563.873\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.94399  14.910883 14.933426 14.082267 13.921611 14.941229]\n",
      "Reset environment\n",
      "Episode reward: 1890.2\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9444   14.911292 14.933839 14.082724 13.921985 14.941639]\n",
      "Reset environment\n",
      "Episode reward: 4246.896\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.945519 14.912397 14.934965 14.083928 13.922966 14.94276 ]\n",
      "Reset environment\n",
      "Episode reward: 2934.922\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.94625  14.913126 14.935681 14.084723 13.923621 14.943487]\n",
      "Reset environment\n",
      "Episode reward: 1892.3806\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9466715 14.913546  14.9361    14.08519   13.924003  14.94391  ]\n",
      "Reset environment\n",
      "Episode reward: 1951.5958\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9471035 14.913976  14.936536  14.085668  13.924398  14.944342 ]\n",
      "Reset environment\n",
      "Episode reward: 1368.4397\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.947411 14.914284 14.936841 14.086007 13.924681 14.944649]\n",
      "Reset environment\n",
      "Episode reward: 1850.3997\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.947579  14.914417  14.937038  14.086231  13.9248085 14.944817 ]\n",
      "Reset environment\n",
      "Episode reward: 1532.7921\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9479065 14.914746  14.937363  14.086606  13.925103  14.945143 ]\n",
      "Reset environment\n",
      "Episode reward: 1359.1921\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9483795 14.915214  14.93783   14.087122  13.925519  14.945618 ]\n",
      "Reset environment\n",
      "Episode reward: 3137.7495\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.949153 14.915985 14.938608 14.087967 13.926212 14.946393]\n",
      "Reset environment\n",
      "Episode reward: 1351.4324\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.949458 14.916289 14.938915 14.088309 13.926494 14.946698]\n",
      "Reset environment\n",
      "Episode reward: 1859.6523\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9497595 14.916572  14.939235  14.088661  13.926752  14.946998 ]\n",
      "Reset environment\n",
      "Episode reward: 3872.6606\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.950774 14.917577 14.940234 14.089742 13.927655 14.948004]\n",
      "Reset environment\n",
      "Episode reward: 1798.8633\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.951174 14.917965 14.940638 14.090182 13.928018 14.948402]\n",
      "Reset environment\n",
      "Episode reward: 1649.6428\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.951389 14.918202 14.940826 14.090441 13.928209 14.948615]\n",
      "Reset environment\n",
      "Episode reward: -646.23914\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.950537  14.917323  14.940002  14.0894375 13.927424  14.947763 ]\n",
      "Reset environment\n",
      "Episode reward: 4819.1406\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.951722 14.91851  14.941189 14.090719 13.928517 14.94895 ]\n",
      "Reset environment\n",
      "Episode reward: 3629.7415\n",
      "Total Steps: 126\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.952651 14.919437 14.942111 14.091727 13.929353 14.949879]\n",
      "Reset environment\n",
      "Episode reward: 5791.521\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.954456 14.921235 14.943917 14.093654 13.930988 14.951685]\n",
      "Reset environment\n",
      "Episode reward: 2250.5686\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.954957  14.9217415 14.944409  14.094205  13.931446  14.952185 ]\n",
      "Reset environment\n",
      "Episode reward: 2023.6066\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.955393 14.922178 14.944845 14.094695 13.931842 14.952623]\n",
      "Reset environment\n",
      "Episode reward: 1717.694\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.95596  14.922746 14.945412 14.095326 13.93236  14.953191]\n",
      "Reset environment\n",
      "Episode reward: 977.5076\n",
      "Total Steps: 32\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.956145  14.922924  14.9456005 14.095539  13.932522  14.953375 ]\n",
      "Reset environment\n",
      "Episode reward: 1921.151\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.95672  14.923498 14.946171 14.096165 13.933038 14.95395 ]\n",
      "Reset environment\n",
      "Episode reward: 2124.3318\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.957155 14.923917 14.946618 14.096643 13.933436 14.954383]\n",
      "Reset environment\n",
      "Episode reward: 2032.946\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.957816 14.924576 14.947281 14.097377 13.934033 14.955043]\n",
      "Reset environment\n",
      "Episode reward: 1905.8495\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.958235  14.924985  14.947703  14.097837  13.934417  14.9554615]\n",
      "Reset environment\n",
      "Episode reward: 2381.3154\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.958753 14.925522 14.948204 14.098407 13.934896 14.95598 ]\n",
      "Reset environment\n",
      "Episode reward: 1091.8483\n",
      "Total Steps: 34\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.958983 14.925753 14.948434 14.098666 13.935106 14.95621 ]\n",
      "Reset environment\n",
      "Episode reward: 4594.733\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.960203  14.9269705 14.949653  14.099973  13.936206  14.957431 ]\n",
      "Reset environment\n",
      "Episode reward: 2303.5874\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.960684  14.927465  14.950121  14.100506  13.936643  14.9579115]\n",
      "Reset environment\n",
      "Episode reward: 3259.06\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.961452 14.928234 14.950879 14.10134  13.937346 14.958676]\n",
      "Reset environment\n",
      "Episode reward: 2267.9097\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.961969 14.92875  14.9514   14.101908 13.937822 14.959195]\n",
      "Reset environment\n",
      "Episode reward: 1780.2461\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.962365 14.92914  14.951801 14.102346 13.938183 14.959592]\n",
      "Reset environment\n",
      "Episode reward: 2004.2412\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.962723 14.929518 14.952138 14.102752 13.938506 14.959949]\n",
      "Reset environment\n",
      "Episode reward: 1444.4207\n",
      "Total Steps: 48\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.963041 14.929837 14.952455 14.103109 13.938798 14.960268]\n",
      "Reset environment\n",
      "Episode reward: 6157.672\n",
      "Total Steps: 207\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.964738 14.931533 14.954141 14.10492  13.940286 14.961964]\n",
      "Reset environment\n",
      "Episode reward: -88.64642\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.96395  14.930813 14.953285 14.104129 13.939577 14.961184]\n",
      "Reset environment\n",
      "Episode reward: 1823.0481\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.964178 14.93106  14.953491 14.104405 13.939779 14.961411]\n",
      "Reset environment\n",
      "Episode reward: 1706.4562\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.964582 14.931466 14.953895 14.104852 13.940148 14.961816]\n",
      "Reset environment\n",
      "Episode reward: 624.71704\n",
      "Total Steps: 20\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.964658 14.931543 14.95397  14.104952 13.940211 14.961891]\n",
      "Reset environment\n",
      "Episode reward: 4621.3247\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.965892 14.932779 14.955195 14.106267 13.941326 14.96312 ]\n",
      "Reset environment\n",
      "Episode reward: 1921.555\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.96651  14.933399 14.955815 14.106952 13.941877 14.963739]\n",
      "Reset environment\n",
      "Episode reward: 1369.9033\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.966813 14.933706 14.956119 14.107292 13.942158 14.964043]\n",
      "Reset environment\n",
      "Episode reward: 3023.5813\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.967544  14.93444   14.9568405 14.108083  13.942827  14.964771 ]\n",
      "Reset environment\n",
      "Episode reward: 2081.325\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.968012 14.934907 14.957309 14.108597 13.943254 14.96524 ]\n",
      "Reset environment\n",
      "Episode reward: 2619.618\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.968635 14.935532 14.95792  14.109273 13.943823 14.965862]\n",
      "Reset environment\n",
      "Episode reward: 2080.3796\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.96931   14.936208  14.958594  14.110015  13.944425  14.9665365]\n",
      "Reset environment\n",
      "Episode reward: 3648.0718\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.97022  14.937127 14.959499 14.110998 13.945251 14.967446]\n",
      "Reset environment\n",
      "Episode reward: 2074.206\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.970881 14.93779  14.960158 14.111719 13.945843 14.968109]\n",
      "Reset environment\n",
      "Episode reward: 1849.1165\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.971282  14.9381895 14.960562  14.112166  13.946212  14.968512 ]\n",
      "Reset environment\n",
      "Episode reward: 3538.545\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.97218  14.939082 14.96146  14.113135 13.947018 14.969408]\n",
      "Reset environment\n",
      "Episode reward: 3331.4514\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.973012 14.939911 14.962292 14.114035 13.947774 14.970241]\n",
      "Reset environment\n",
      "Episode reward: 1386.7233\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9734955 14.940391  14.9627695 14.114563  13.948203  14.970724 ]\n",
      "Reset environment\n",
      "Episode reward: 2127.4785\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.973976 14.940862 14.963241 14.115087 13.948623 14.971204]\n",
      "Reset environment\n",
      "Episode reward: 1510.5449\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.97418   14.94104   14.963476  14.1153345 13.948812  14.9714155]\n",
      "Reset environment\n",
      "Episode reward: 4751.507\n",
      "Total Steps: 164\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.975445 14.942304 14.964728 14.116685 13.949903 14.972674]\n",
      "Reset environment\n",
      "Episode reward: 4026.2126\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.976484 14.943346 14.965761 14.117816 13.950814 14.973714]\n",
      "Reset environment\n",
      "Episode reward: 3832.6025\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.977461 14.944334 14.96673  14.118862 13.951694 14.97469 ]\n",
      "Reset environment\n",
      "Episode reward: 1682.6842\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.977842  14.9447155 14.967103  14.119282  13.952031  14.975073 ]\n",
      "Reset environment\n",
      "Episode reward: 3569.7378\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.9787445 14.945625  14.967997  14.120254  13.952862  14.975975 ]\n",
      "Reset environment\n",
      "Episode reward: 2327.4885\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.979251 14.94613  14.968502 14.120814 13.953317 14.976481]\n",
      "Reset environment\n",
      "Episode reward: 2474.8083\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.979827 14.946711 14.969072 14.121446 13.953846 14.97706 ]\n",
      "Reset environment\n",
      "Episode reward: 1996.8513\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.980267 14.947149 14.969514 14.121935 13.954247 14.9775  ]\n",
      "Reset environment\n",
      "Episode reward: 2358.1248\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.980738 14.947603 14.970004 14.122461 13.954671 14.977971]\n",
      "Reset environment\n",
      "Episode reward: 1975.3246\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.981332  14.9481945 14.970589  14.12311   13.955202  14.978568 ]\n",
      "Reset environment\n",
      "Episode reward: 2082.4146\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.981795 14.948658 14.97105  14.123628 13.955614 14.979033]\n",
      "Reset environment\n",
      "Episode reward: 1379.1674\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.982263 14.949124 14.971517 14.124155 13.956041 14.979504]\n",
      "Reset environment\n",
      "Episode reward: 1381.219\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.982585 14.949448 14.971839 14.124514 13.956339 14.979826]\n",
      "Reset environment\n",
      "Episode reward: 2012.3391\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.98323   14.950091  14.9724865 14.125227  13.9569235 14.980472 ]\n",
      "Reset environment\n",
      "Episode reward: 1692.3186\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.983594 14.950459 14.972845 14.125638 13.95725  14.980841]\n",
      "Reset environment\n",
      "Episode reward: 4960.7827\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.984905  14.9517765 14.9741535 14.127043  13.958416  14.982151 ]\n",
      "Reset environment\n",
      "Episode reward: 4729.1167\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.986168 14.953046 14.975411 14.128391 13.959521 14.983414]\n",
      "Reset environment\n",
      "Episode reward: 1369.9625\n",
      "Total Steps: 46\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.986448 14.953329 14.975691 14.128711 13.959775 14.983696]\n",
      "Reset environment\n",
      "Episode reward: 2092.9426\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.986874 14.953771 14.9761   14.129186 13.960167 14.984121]\n",
      "Reset environment\n",
      "Episode reward: 2794.0642\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.987489 14.954373 14.97673  14.129858 13.960722 14.984737]\n",
      "Reset environment\n",
      "Episode reward: 2214.3208\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.98822  14.955107 14.97745  14.130648 13.961379 14.985467]\n",
      "Reset environment\n",
      "Episode reward: 4008.8208\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.989198  14.956082  14.978422  14.131703  13.962272  14.9864435]\n",
      "Reset environment\n",
      "Episode reward: 2007.679\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.989865  14.9567375 14.979084  14.132431  13.962863  14.987111 ]\n",
      "Reset environment\n",
      "Episode reward: 2261.8062\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.990411 14.957286 14.979617 14.133025 13.96335  14.987656]\n",
      "Reset environment\n",
      "Episode reward: 4286.025\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.991541 14.958414 14.980752 14.134235 13.964342 14.988785]\n",
      "Reset environment\n",
      "Episode reward: 2749.415\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.992199 14.959071 14.981412 14.13495  13.964951 14.989443]\n",
      "Reset environment\n",
      "Episode reward: 1710.0088\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.992405 14.959297 14.981595 14.135201 13.965136 14.989646]\n",
      "Reset environment\n",
      "Episode reward: 2564.869\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.993239 14.96013  14.982416 14.136099 13.965881 14.990479]\n",
      "Reset environment\n",
      "Episode reward: 2657.1663\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.993819 14.960728 14.982981 14.136741 13.966417 14.991059]\n",
      "Reset environment\n",
      "Episode reward: 2130.4507\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.994531 14.961434 14.983684 14.137505 13.967041 14.991767]\n",
      "Reset environment\n",
      "Episode reward: 4655.004\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.995775 14.962679 14.984919 14.138825 13.968134 14.99301 ]\n",
      "Reset environment\n",
      "Episode reward: 1629.4324\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.995951 14.962877 14.985074 14.139047 13.968295 14.993184]\n",
      "Reset environment\n",
      "Episode reward: 1659.6537\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.996236 14.963143 14.985375 14.139372 13.968548 14.993469]\n",
      "Reset environment\n",
      "Episode reward: 2459.9314\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.996709 14.963602 14.985869 14.139903 13.968971 14.993943]\n",
      "Reset environment\n",
      "Episode reward: 2123.1047\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.997386 14.964279 14.986546 14.140641 13.969585 14.994621]\n",
      "Reset environment\n",
      "Episode reward: 1556.645\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.997731  14.964621  14.986891  14.141025  13.9699    14.9949665]\n",
      "Reset environment\n",
      "Episode reward: 5365.082\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.999174  14.966063  14.988337  14.142564  13.9711895 14.996409 ]\n",
      "Reset environment\n",
      "Episode reward: 1345.2826\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.999466 14.966351 14.988627 14.14289  13.971449 14.996702]\n",
      "Reset environment\n",
      "Episode reward: 1910.5249\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [14.99976  14.966624 14.988941 14.143235 13.9717   14.996995]\n",
      "Reset environment\n",
      "Episode reward: 5548.7637\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.001254  14.96812   14.9904375 14.1448345 13.973037  14.99849  ]\n",
      "Reset environment\n",
      "Episode reward: 1630.3824\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.001594 14.968454 14.990785 14.145222 13.973343 14.998829]\n",
      "Reset environment\n",
      "Episode reward: 2096.805\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.002276  14.969142  14.9914665 14.145967  13.973967  14.999512 ]\n",
      "Reset environment\n",
      "Episode reward: 1608.9507\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.002622 14.969482 14.991816 14.146349 13.974283 14.999857]\n",
      "Reset environment\n",
      "Episode reward: 1686.4827\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.003     14.969853  14.992206  14.146766  13.974632  15.0002365]\n",
      "Reset environment\n",
      "Episode reward: 1319.3744\n",
      "Total Steps: 44\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.003278 14.970129 14.992483 14.147081 13.97488  15.000514]\n",
      "Reset environment\n",
      "Episode reward: 1721.8348\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.003664 14.970515 14.99287  14.147516 13.975229 15.0009  ]\n",
      "Reset environment\n",
      "Episode reward: 2055.9958\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.004142 14.970989 14.99335  14.148042 13.975668 15.001378]\n",
      "Reset environment\n",
      "Episode reward: -661.00214\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.003099 14.969858 14.992393 14.146959 13.974699 15.000344]\n",
      "Reset environment\n",
      "Episode reward: 2258.0505\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.003589  14.970361  14.992871  14.147496  13.975151  15.0008335]\n",
      "Reset environment\n",
      "Episode reward: 2960.6582\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.004309 14.971069 14.993591 14.148279 13.97579  15.001553]\n",
      "Reset environment\n",
      "Episode reward: 3922.759\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.005249 14.97201  14.994531 14.149299 13.976646 15.002495]\n",
      "Reset environment\n",
      "Episode reward: 1888.551\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.005652 14.972427 14.994925 14.149748 13.977019 15.002898]\n",
      "Reset environment\n",
      "Episode reward: 1545.3917\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.006    14.972781 14.995262 14.150133 13.97734  15.003246]\n",
      "Reset environment\n",
      "Episode reward: 1675.6884\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.006199 14.973001 14.995442 14.150372 13.977517 15.003441]\n",
      "Reset environment\n",
      "Episode reward: 2427.865\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.006575 14.973358 14.995837 14.150806 13.977826 15.003818]\n",
      "Reset environment\n",
      "Episode reward: 1278.9391\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.006853 14.973639 14.996116 14.151123 13.97808  15.004096]\n",
      "Reset environment\n",
      "Episode reward: 6005.114\n",
      "Total Steps: 204\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.008488  14.975269  14.997754  14.1528635 13.979537  15.005729 ]\n",
      "Reset environment\n",
      "Episode reward: 1816.3412\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.008881 14.975676 14.998135 14.1533   13.979898 15.006123]\n",
      "Reset environment\n",
      "Episode reward: 1682.6445\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.009442  14.976234  14.998693  14.153918  13.980406  15.0066805]\n",
      "Reset environment\n",
      "Episode reward: 1804.0543\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.009835 14.97663  14.999083 14.154358 13.980761 15.00708 ]\n",
      "Reset environment\n",
      "Episode reward: 1810.2437\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.010436 14.977232 14.999671 14.155009 13.981302 15.007683]\n",
      "Reset environment\n",
      "Episode reward: 1378.5283\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.010724 14.97751  14.999972 14.155336 13.981563 15.007971]\n",
      "Reset environment\n",
      "Episode reward: 4532.457\n",
      "Total Steps: 154\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.011864 14.978652 15.001109 14.156556 13.982594 15.009111]\n",
      "Reset environment\n",
      "Episode reward: 4543.048\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.013069 14.979856 15.002313 14.157854 13.983642 15.010316]\n",
      "Reset environment\n",
      "Episode reward: 1425.2937\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.013384  14.980167  15.00263   14.158206  13.983929  15.0106325]\n",
      "Reset environment\n",
      "Episode reward: 1741.1927\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.013689 14.980497 15.002917 14.158556 13.984208 15.010937]\n",
      "Reset environment\n",
      "Episode reward: 4425.2754\n",
      "Total Steps: 149\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.014864 14.981671 15.004091 14.15981  13.985253 15.012111]\n",
      "Reset environment\n",
      "Episode reward: 2102.0886\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.015548 14.982356 15.004772 14.160555 13.985871 15.012795]\n",
      "Reset environment\n",
      "Episode reward: 93.58908\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.015031  14.98188   15.0042095 14.159906  13.985412  15.012279 ]\n",
      "Reset environment\n",
      "Episode reward: 3708.552\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.015952 14.982799 15.005134 14.160905 13.986218 15.0132  ]\n",
      "Reset environment\n",
      "Episode reward: 2239.4475\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0164795 14.983329  15.005648  14.16147   13.986683  15.013726 ]\n",
      "Reset environment\n",
      "Episode reward: 2256.7183\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.016986 14.983829 15.006158 14.162025 13.987146 15.014233]\n",
      "Reset environment\n",
      "Episode reward: 4105.1245\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.018063  14.984906  15.007228  14.163195  13.9880905 15.015307 ]\n",
      "Reset environment\n",
      "Episode reward: 2312.5542\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.018595 14.98544  15.007761 14.16378  13.988581 15.015841]\n",
      "Reset environment\n",
      "Episode reward: 2439.495\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.019141 14.985977 15.008316 14.164374 13.989078 15.016386]\n",
      "Reset environment\n",
      "Episode reward: 2206.6309\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0196   14.986422 15.008786 14.16488  13.989498 15.016845]\n",
      "Reset environment\n",
      "Episode reward: 4929.21\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.020891 14.987716 15.010079 14.166268 13.990676 15.018137]\n",
      "Reset environment\n",
      "Episode reward: 1970.7117\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.021356 14.988194 15.010538 14.166775 13.991105 15.018601]\n",
      "Reset environment\n",
      "Episode reward: 3240.7493\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.022176 14.989015 15.011342 14.167647 13.991838 15.01942 ]\n",
      "Reset environment\n",
      "Episode reward: 1690.5256\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.022544 14.989378 15.011713 14.168055 13.992173 15.019788]\n",
      "Reset environment\n",
      "Episode reward: 5344.841\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.023975 14.990811 15.013147 14.169587 13.993474 15.021219]\n",
      "Reset environment\n",
      "Episode reward: 4063.3247\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.025019 14.991856 15.014194 14.170709 13.994407 15.022263]\n",
      "Reset environment\n",
      "Episode reward: 1410.0171\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.025221 14.992033 15.014419 14.17095  13.994585 15.022467]\n",
      "Reset environment\n",
      "Episode reward: 2176.2144\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0257    14.9925165 15.014896  14.171485  13.995015  15.022948 ]\n",
      "Reset environment\n",
      "Episode reward: 1386.7146\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.026184  14.992996  15.015373  14.172     13.9954405 15.023433 ]\n",
      "Reset environment\n",
      "Episode reward: 2114.6975\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.026595 14.993431 15.015773 14.172465 13.995823 15.023844]\n",
      "Reset environment\n",
      "Episode reward: 1217.9612\n",
      "Total Steps: 42\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.026836 14.99366  15.016025 14.172739 13.996037 15.024084]\n",
      "Reset environment\n",
      "Episode reward: 102.0892\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.026139 14.993032 15.015262 14.172008 13.995421 15.023388]\n",
      "Reset environment\n",
      "Episode reward: 2575.504\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.026707 14.993604 15.015831 14.17264  13.995937 15.023958]\n",
      "Reset environment\n",
      "Episode reward: 1748.6241\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.027083 14.993965 15.016215 14.173051 13.996281 15.024335]\n",
      "Reset environment\n",
      "Episode reward: 1895.0298\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.027357 14.994263 15.016467 14.17337  13.996534 15.024608]\n",
      "Reset environment\n",
      "Episode reward: 1975.9127\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.028007 14.99491  15.017113 14.17408  13.997104 15.025256]\n",
      "Reset environment\n",
      "Episode reward: 2338.458\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0283   14.995231 15.017391 14.174438 13.997376 15.02555 ]\n",
      "Reset environment\n",
      "Episode reward: 1380.7197\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.028756 14.995683 15.017846 14.174951 13.997785 15.026004]\n",
      "Reset environment\n",
      "Episode reward: 2126.912\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.02928  14.996216 15.018358 14.175516 13.998272 15.026528]\n",
      "Reset environment\n",
      "Episode reward: 1525.7479\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.029457 14.996417 15.018508 14.175731 13.998435 15.026705]\n",
      "Reset environment\n",
      "Episode reward: 1907.5822\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.029876 14.996844 15.018921 14.176195 13.99882  15.027123]\n",
      "Reset environment\n",
      "Episode reward: 2779.0154\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.030539 14.997511 15.019579 14.176921 13.999427 15.027785]\n",
      "Reset environment\n",
      "Episode reward: 2028.646\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.030943 14.997902 15.019998 14.177373 13.999796 15.02819 ]\n",
      "Reset environment\n",
      "Episode reward: 4488.1875\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.03212  14.999075 15.021173 14.178635 14.000842 15.029365]\n",
      "Reset environment\n",
      "Episode reward: 1647.1744\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.032313 14.999292 15.021348 14.178878 14.001017 15.02956 ]\n",
      "Reset environment\n",
      "Episode reward: 1297.7802\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.032603 14.999586 15.021635 14.179201 14.001284 15.02985 ]\n",
      "Reset environment\n",
      "Episode reward: 1952.2212\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.033065  15.000059  15.022089  14.179709  14.001709  15.0303135]\n",
      "Reset environment\n",
      "Episode reward: 2791.3708\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0336895 15.000679  15.02272   14.180394  14.002278  15.030943 ]\n",
      "Reset environment\n",
      "Episode reward: 2038.072\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.034122 15.001109 15.023156 14.180876 14.002672 15.031378]\n",
      "Reset environment\n",
      "Episode reward: 5103.9497\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.035415  15.002401  15.0244465 14.182262  14.003844  15.032668 ]\n",
      "Reset environment\n",
      "Episode reward: 3910.0762\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.03639   15.003377  15.025426  14.183321  14.0047245 15.033644 ]\n",
      "Reset environment\n",
      "Episode reward: 5630.4595\n",
      "Total Steps: 194\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.037888 15.004882 15.026913 14.184932 14.006037 15.035138]\n",
      "Reset environment\n",
      "Episode reward: 2002.9343\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.038322  15.005316  15.02735   14.1854105 14.006434  15.035573 ]\n",
      "Reset environment\n",
      "Episode reward: 1966.0654\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.038702  15.005684  15.027746  14.185837  14.00678   15.0359535]\n",
      "Reset environment\n",
      "Episode reward: 187.2308\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.038197 15.005229 15.027194 14.185248 14.00635  15.035455]\n",
      "Reset environment\n",
      "Episode reward: 4540.2466\n",
      "Total Steps: 155\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.039375 15.006409 15.028375 14.186517 14.007412 15.036634]\n",
      "Reset environment\n",
      "Episode reward: 3390.434\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.040218 15.007258 15.029211 14.187425 14.008183 15.037475]\n",
      "Reset environment\n",
      "Episode reward: 3197.6655\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.041032 15.008076 15.030019 14.188302 14.008907 15.038288]\n",
      "Reset environment\n",
      "Episode reward: 4278.6104\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0421505 15.009195  15.031137  14.189501  14.009904  15.039408 ]\n",
      "Reset environment\n",
      "Episode reward: 2159.0706\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.042849 15.00989  15.031838 14.190261 14.010531 15.040109]\n",
      "Reset environment\n",
      "Episode reward: 1362.0581\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.043314 15.010347 15.0323   14.190769 14.010943 15.040575]\n",
      "Reset environment\n",
      "Episode reward: 1919.9773\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.043642 15.010698 15.032612 14.191154 14.011241 15.040904]\n",
      "Reset environment\n",
      "Episode reward: 1386.7573\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.044118 15.011173 15.033085 14.191675 14.011665 15.041379]\n",
      "Reset environment\n",
      "Episode reward: 5133.061\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.045456 15.012519 15.034418 14.193116 14.012858 15.042716]\n",
      "Reset environment\n",
      "Episode reward: 1154.1614\n",
      "Total Steps: 36\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.045703 15.012769 15.034661 14.193396 14.013082 15.042964]\n",
      "Reset environment\n",
      "Episode reward: 3854.4724\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.046701  15.013761  15.035654  14.194472  14.013961  15.0439625]\n",
      "Reset environment\n",
      "Episode reward: 2081.7876\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0471525 15.014226  15.036098  14.194969  14.014371  15.0444145]\n",
      "Reset environment\n",
      "Episode reward: 2057.4946\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.047573 15.014657 15.036507 14.195437 14.014754 15.044835]\n",
      "Reset environment\n",
      "Episode reward: 2984.2625\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.048292  15.015381  15.037213  14.196217  14.0154085 15.045555 ]\n",
      "Reset environment\n",
      "Episode reward: 1967.3718\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.048756 15.015849 15.037667 14.196725 14.015839 15.046019]\n",
      "Reset environment\n",
      "Episode reward: 2715.6594\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.049378 15.016475 15.038287 14.197408 14.016404 15.04664 ]\n",
      "Reset environment\n",
      "Episode reward: 4425.7715\n",
      "Total Steps: 150\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.050558 15.01765  15.039452 14.198664 14.017425 15.047815]\n",
      "Reset environment\n",
      "Episode reward: 2179.3953\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.051262 15.018351 15.040152 14.199425 14.018054 15.048517]\n",
      "Reset environment\n",
      "Episode reward: 4453.587\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.052399  15.0194845 15.04128   14.20065   14.01906   15.04965  ]\n",
      "Reset environment\n",
      "Episode reward: 3028.6694\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.053092  15.020164  15.041977  14.201391  14.019678  15.0503435]\n",
      "Reset environment\n",
      "Episode reward: 2623.6711\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.053578 15.020629 15.042486 14.201948 14.020087 15.05083 ]\n",
      "Reset environment\n",
      "Episode reward: 5083.7954\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.054907 15.021967 15.043808 14.203363 14.021278 15.052159]\n",
      "Reset environment\n",
      "Episode reward: 5167.857\n",
      "Total Steps: 176\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.056291 15.023341 15.045184 14.204839 14.022478 15.053538]\n",
      "Reset environment\n",
      "Episode reward: 2198.094\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.056762  15.0238085 15.045651  14.205361  14.022901  15.054012 ]\n",
      "Reset environment\n",
      "Episode reward: 3777.0322\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0577135 15.024765  15.046592  14.206381  14.023765  15.054965 ]\n",
      "Reset environment\n",
      "Episode reward: 1178.055\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.057927 15.024988 15.046798 14.206627 14.02396  15.055179]\n",
      "Reset environment\n",
      "Episode reward: 1972.436\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.058294 15.025369 15.047151 14.207039 14.024296 15.055545]\n",
      "Reset environment\n",
      "Episode reward: 2098.1313\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.058799 15.025883 15.047649 14.207593 14.024762 15.056052]\n",
      "Reset environment\n",
      "Episode reward: 2393.8647\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.059253 15.026323 15.048121 14.208107 14.025159 15.056504]\n",
      "Reset environment\n",
      "Episode reward: 1387.3503\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.059546 15.026609 15.048426 14.208438 14.02543  15.056801]\n",
      "Reset environment\n",
      "Episode reward: -329.98163\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.058893 15.025964 15.047774 14.207745 14.024843 15.056151]\n",
      "Reset environment\n",
      "Episode reward: 5653.0405\n",
      "Total Steps: 189\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.060438 15.027507 15.049323 14.209391 14.026219 15.057696]\n",
      "Reset environment\n",
      "Episode reward: 3523.8032\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.061308 15.028384 15.050185 14.210333 14.027018 15.058568]\n",
      "Reset environment\n",
      "Episode reward: 1395.7162\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.061776 15.028846 15.05065  14.210851 14.027438 15.059032]\n",
      "Reset environment\n",
      "Episode reward: 4208.1147\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.062844 15.029921 15.051708 14.211994 14.028396 15.060098]\n",
      "Reset environment\n",
      "Episode reward: 3839.0762\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0638075 15.030891  15.052664  14.213036  14.029278  15.061059 ]\n",
      "Reset environment\n",
      "Episode reward: 5590.7417\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.065519  15.032602  15.0543785 14.214861  14.03083   15.062771 ]\n",
      "Reset environment\n",
      "Episode reward: 1956.9778\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.06595  15.033034 15.054813 14.215346 14.031225 15.063205]\n",
      "Reset environment\n",
      "Episode reward: 1785.8357\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.066202 15.03331  15.055039 14.215648 14.031455 15.063456]\n",
      "Reset environment\n",
      "Episode reward: 2508.6543\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.0667715 15.033887  15.055605  14.216274  14.031977  15.064027 ]\n",
      "Reset environment\n",
      "Episode reward: 1407.4153\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.067072 15.034182 15.055913 14.21661  14.032252 15.064326]\n",
      "Reset environment\n",
      "Episode reward: 2416.621\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.067644 15.034755 15.056478 14.217238 14.032765 15.064901]\n",
      "Reset environment\n",
      "Episode reward: 1498.648\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.067946 15.035046 15.056794 14.217573 14.033045 15.065203]\n",
      "Reset environment\n",
      "Episode reward: 1696.2743\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.068249 15.035329 15.057116 14.217922 14.033321 15.065505]\n",
      "Reset environment\n",
      "Episode reward: 1986.7196\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.068685 15.035758 15.057561 14.218401 14.033724 15.065941]\n",
      "Reset environment\n",
      "Episode reward: 3811.4075\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.069651 15.036736 15.058522 14.219445 14.034602 15.066908]\n",
      "Reset environment\n",
      "Episode reward: 1325.3119\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.069882 15.036982 15.058742 14.219714 14.034812 15.06714 ]\n",
      "Reset environment\n",
      "Episode reward: 922.1736\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.069992 15.037098 15.058839 14.219848 14.03491  15.06725 ]\n",
      "Reset environment\n",
      "Episode reward: 2011.5687\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.07065  15.037752 15.05949  14.220563 14.03549  15.067908]\n",
      "Reset environment\n",
      "Episode reward: 3109.373\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.071405  15.0385065 15.060248  14.221382  14.036178  15.068665 ]\n",
      "Reset environment\n",
      "Episode reward: 1830.8081\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.071993 15.039088 15.060835 14.222037 14.036707 15.069253]\n",
      "Reset environment\n",
      "Episode reward: 1371.3241\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.072464 15.039556 15.06129  14.222549 14.037113 15.069722]\n",
      "Reset environment\n",
      "Episode reward: 4855.0513\n",
      "Total Steps: 166\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.073753 15.040846 15.062569 14.223932 14.038245 15.071008]\n",
      "Reset environment\n",
      "Episode reward: 2373.559\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.074246  15.041349  15.063049  14.224483  14.0386915 15.071504 ]\n",
      "Reset environment\n",
      "Episode reward: 2186.4526\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.074588 15.041674 15.063411 14.224883 14.038979 15.071845]\n",
      "Reset environment\n",
      "Episode reward: 1293.0212\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.074873 15.041958 15.063696 14.225204 14.039242 15.07213 ]\n",
      "Reset environment\n",
      "Episode reward: 2558.095\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.075462 15.042546 15.06429  14.22585  14.039785 15.072722]\n",
      "Reset environment\n",
      "Episode reward: 2020.6132\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.075919 15.043003 15.064744 14.22636  14.040188 15.073179]\n",
      "Reset environment\n",
      "Episode reward: 5358.7563\n",
      "Total Steps: 181\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.07735  15.044434 15.066176 14.227889 14.041479 15.074609]\n",
      "Reset environment\n",
      "Episode reward: 3180.3022\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.078151 15.045229 15.066965 14.228753 14.042199 15.075405]\n",
      "Reset environment\n",
      "Episode reward: -552.2331\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.077269  15.044406  15.066029  14.2277775 14.041377  15.074526 ]\n",
      "Reset environment\n",
      "Episode reward: 3274.767\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.078063 15.045211 15.06681  14.228638 14.042097 15.07532 ]\n",
      "Reset environment\n",
      "Episode reward: 2441.8699\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.078592 15.045749 15.067328 14.229216 14.042583 15.07585 ]\n",
      "Reset environment\n",
      "Episode reward: 2831.7087\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.079256 15.046414 15.067995 14.229942 14.043196 15.076513]\n",
      "Reset environment\n",
      "Episode reward: 1764.3046\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.079621  15.046778  15.068364  14.230358  14.043527  15.0768795]\n",
      "Reset environment\n",
      "Episode reward: 1902.331\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.080027 15.047182 15.068766 14.230813 14.043882 15.077285]\n",
      "Reset environment\n",
      "Episode reward: 3567.688\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.080937 15.048089 15.06966  14.231802 14.044688 15.078193]\n",
      "Reset environment\n",
      "Episode reward: 1658.4031\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.081339  15.0484915 15.070062  14.232243  14.045061  15.078594 ]\n",
      "Reset environment\n",
      "Episode reward: 2564.0505\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.081819 15.048954 15.070563 14.23278  14.045491 15.079073]\n",
      "Reset environment\n",
      "Episode reward: 2180.4468\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.082279 15.04943  15.071011 14.233288 14.04592  15.079534]\n",
      "Reset environment\n",
      "Episode reward: 2962.0635\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.082994  15.05014   15.071725  14.234059  14.0465765 15.08025  ]\n",
      "Reset environment\n",
      "Episode reward: 1977.8575\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.083426 15.050572 15.072156 14.234545 14.046972 15.080682]\n",
      "Reset environment\n",
      "Episode reward: 3115.809\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.084182 15.051327 15.072898 14.235362 14.047659 15.081435]\n",
      "Reset environment\n",
      "Episode reward: 1668.0245\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.084548 15.051682 15.073269 14.235769 14.047995 15.081801]\n",
      "Reset environment\n",
      "Episode reward: 2525.056\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.085126  15.0522585 15.073854  14.236405  14.048526  15.082379 ]\n",
      "Reset environment\n",
      "Episode reward: 2193.9946\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.085824 15.052952 15.074554 14.237171 14.049155 15.083078]\n",
      "Reset environment\n",
      "Episode reward: 2394.319\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.086206 15.053354 15.074918 14.237615 14.049503 15.083458]\n",
      "Reset environment\n",
      "Episode reward: 1378.0503\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.086671  15.053819  15.0753765 14.2381315 14.0499115 15.083921 ]\n",
      "Reset environment\n",
      "Episode reward: 1671.835\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.08705  15.054201 15.07575  14.238554 14.050251 15.084305]\n",
      "Reset environment\n",
      "Episode reward: 3865.043\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.088044 15.055196 15.076737 14.239623 14.051122 15.085299]\n",
      "Reset environment\n",
      "Episode reward: 4604.407\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.089243  15.056392  15.077938  14.240908  14.052206  15.0864935]\n",
      "Reset environment\n",
      "Episode reward: 2094.277\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.089934  15.057074  15.078624  14.2416525 14.052813  15.087183 ]\n",
      "Reset environment\n",
      "Episode reward: 2329.817\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.090411 15.057561 15.07909  14.242185 14.053248 15.08766 ]\n",
      "Reset environment\n",
      "Episode reward: 5933.723\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.092014 15.059162 15.08068  14.243905 14.054671 15.089262]\n",
      "Reset environment\n",
      "Episode reward: 1499.0853\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.092341 15.059489 15.081    14.244267 14.054958 15.089594]\n",
      "Reset environment\n",
      "Episode reward: 2423.4524\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.092804 15.059928 15.081481 14.244784 14.055359 15.090056]\n",
      "Reset environment\n",
      "Episode reward: 1955.3397\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.093151 15.060294 15.081806 14.245175 14.055675 15.090403]\n",
      "Reset environment\n",
      "Episode reward: 1659.5463\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.093475 15.060603 15.082148 14.245541 14.055975 15.090727]\n",
      "Reset environment\n",
      "Episode reward: 2423.5974\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.093995  15.061123  15.082666  14.246115  14.05645   15.0912485]\n",
      "Reset environment\n",
      "Episode reward: 2078.9077\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.094653 15.061781 15.083325 14.246837 14.05705  15.091907]\n",
      "Reset environment\n",
      "Episode reward: 2585.071\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.09523   15.062347  15.08391   14.247462  14.057577  15.0924835]\n",
      "Reset environment\n",
      "Episode reward: 1815.7286\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.095585 15.062717 15.084248 14.247858 14.057904 15.092839]\n",
      "Reset environment\n",
      "Episode reward: 1993.9279\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.096032 15.063162 15.084695 14.248348 14.058315 15.093287]\n",
      "Reset environment\n",
      "Episode reward: 4750.2817\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.097233 15.064357 15.08589  14.24963  14.059392 15.094484]\n",
      "Reset environment\n",
      "Episode reward: 4753.4014\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.098461 15.065582 15.087122 14.250943 14.060493 15.095712]\n",
      "Reset environment\n",
      "Episode reward: 2780.9844\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.099114 15.066234 15.087777 14.251656 14.061093 15.096365]\n",
      "Reset environment\n",
      "Episode reward: 2078.6216\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.099775  15.0668955 15.088438  14.2523775 14.061691  15.097027 ]\n",
      "Reset environment\n",
      "Episode reward: 1742.7992\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.099678  15.066821  15.0883255 14.252239  14.061625  15.096931 ]\n",
      "Reset environment\n",
      "Episode reward: 1816.3307\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.100064  15.067203  15.088716  14.2526655 14.061978  15.097317 ]\n",
      "Reset environment\n",
      "Episode reward: 3061.901\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.100827 15.067968 15.089475 14.253498 14.062671 15.098081]\n",
      "Reset environment\n",
      "Episode reward: 2790.3425\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.101486 15.068632 15.090125 14.25421  14.06327  15.098737]\n",
      "Reset environment\n",
      "Episode reward: 2113.1982\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.102012 15.069162 15.090651 14.254787 14.063759 15.099264]\n",
      "Reset environment\n",
      "Episode reward: 2180.8882\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1025095 15.06965   15.091142  14.255331  14.064194  15.099761 ]\n",
      "Reset environment\n",
      "Episode reward: 2926.668\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.103176 15.0703   15.091811 14.256069 14.064796 15.10043 ]\n",
      "Reset environment\n",
      "Episode reward: 6137.59\n",
      "Total Steps: 228\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.105049 15.072166 15.093688 14.258068 14.066487 15.102302]\n",
      "Reset environment\n",
      "Episode reward: 1706.6305\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.105274  15.0724125 15.09389   14.258337  14.066689  15.102528 ]\n",
      "Reset environment\n",
      "Episode reward: 1877.782\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.105681 15.072815 15.094294 14.258796 14.067058 15.102939]\n",
      "Reset environment\n",
      "Episode reward: 6517.606\n",
      "Total Steps: 218\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.107453 15.074583 15.096062 14.260695 14.068628 15.10471 ]\n",
      "Reset environment\n",
      "Episode reward: 3363.3225\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.108287 15.075416 15.096894 14.261589 14.069382 15.105543]\n",
      "Reset environment\n",
      "Episode reward: -604.4526\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.107449 15.07458  15.096058 14.260535 14.068622 15.10471 ]\n",
      "Reset environment\n",
      "Episode reward: 4733.258\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1086855 15.075817  15.097297  14.261866  14.06973   15.105947 ]\n",
      "Reset environment\n",
      "Episode reward: 2456.5134\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.109379 15.076509 15.09799  14.262625 14.070359 15.10664 ]\n",
      "Reset environment\n",
      "Episode reward: 1916.646\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1097555 15.076906  15.0983515 14.263051  14.070708  15.107017 ]\n",
      "Reset environment\n",
      "Episode reward: 1482.528\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.110074 15.077215 15.098678 14.263409 14.071    15.107336]\n",
      "Reset environment\n",
      "Episode reward: 2568.699\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.110652 15.07779  15.099255 14.264045 14.071512 15.107918]\n",
      "Reset environment\n",
      "Episode reward: 2435.4268\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.111208 15.078342 15.099814 14.264651 14.072024 15.108473]\n",
      "Reset environment\n",
      "Episode reward: 1711.3555\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.111449 15.078562 15.100078 14.264944 14.072232 15.108714]\n",
      "Reset environment\n",
      "Episode reward: 1906.2838\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.111849  15.0789585 15.100489  14.265389  14.072597  15.109114 ]\n",
      "Reset environment\n",
      "Episode reward: 2524.86\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.112345  15.079438  15.1010065 14.265946  14.073049  15.10961  ]\n",
      "Reset environment\n",
      "Episode reward: 4936.0024\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.113648 15.080743 15.102306 14.267334 14.074192 15.110915]\n",
      "Reset environment\n",
      "Episode reward: 1571.5911\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.113982 15.081076 15.102639 14.267707 14.074494 15.111256]\n",
      "Reset environment\n",
      "Episode reward: 2309.5078\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.114486  15.0815935 15.103125  14.26826   14.074962  15.111758 ]\n",
      "Reset environment\n",
      "Episode reward: 2593.0488\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.115054  15.082173  15.1036825 14.268885  14.075479  15.112326 ]\n",
      "Reset environment\n",
      "Episode reward: 2691.3945\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1157   15.082824 15.104318 14.269588 14.076051 15.112977]\n",
      "Reset environment\n",
      "Episode reward: 1337.5784\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.116154 15.083276 15.104765 14.270089 14.076439 15.11343 ]\n",
      "Reset environment\n",
      "Episode reward: 1720.7158\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.116473  15.083573  15.105105  14.270448  14.076731  15.1137495]\n",
      "Reset environment\n",
      "Episode reward: 2352.4553\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.116996 15.084087 15.105634 14.271018 14.077208 15.114272]\n",
      "Reset environment\n",
      "Episode reward: 5453.567\n",
      "Total Steps: 185\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.118447 15.085543 15.107076 14.272584 14.078493 15.115722]\n",
      "Reset environment\n",
      "Episode reward: 4793.0854\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.119703 15.086796 15.108344 14.27393  14.079602 15.116977]\n",
      "Reset environment\n",
      "Episode reward: 3349.9275\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.120533 15.087623 15.109165 14.274811 14.080359 15.117806]\n",
      "Reset environment\n",
      "Episode reward: 1762.2317\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.120873 15.08798  15.109491 14.275193 14.080677 15.118148]\n",
      "Reset environment\n",
      "Episode reward: 1885.7136\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.12128  15.08838  15.109903 14.275646 14.081045 15.118554]\n",
      "Reset environment\n",
      "Episode reward: 2011.8079\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.121924 15.089024 15.110555 14.276356 14.081634 15.119201]\n",
      "Reset environment\n",
      "Episode reward: 4903.0693\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1232   15.090301 15.111832 14.27772  14.082794 15.120477]\n",
      "Reset environment\n",
      "Episode reward: 1646.6718\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1235285 15.090646  15.112142  14.27809   14.083093  15.120804 ]\n",
      "Reset environment\n",
      "Episode reward: 723.0317\n",
      "Total Steps: 22\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.123639 15.090757 15.112252 14.278226 14.08319  15.120915]\n",
      "Reset environment\n",
      "Episode reward: 3200.9565\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.124418  15.091533  15.113031  14.279076  14.083899  15.1216955]\n",
      "Reset environment\n",
      "Episode reward: 2603.1147\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.124982 15.092111 15.113584 14.279691 14.084417 15.122258]\n",
      "Reset environment\n",
      "Episode reward: 2034.6862\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.125431 15.092572 15.114023 14.280185 14.084835 15.12271 ]\n",
      "Reset environment\n",
      "Episode reward: 1788.3372\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.125811 15.092949 15.114407 14.280606 14.085183 15.12309 ]\n",
      "Reset environment\n",
      "Episode reward: 1403.9712\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.126297 15.093432 15.114883 14.281136 14.085605 15.123574]\n",
      "Reset environment\n",
      "Episode reward: 2316.733\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.126739 15.093888 15.115308 14.281628 14.086012 15.124017]\n",
      "Reset environment\n",
      "Episode reward: 1896.0543\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.127358  15.094508  15.115923  14.2823105 14.086559  15.124638 ]\n",
      "Reset environment\n",
      "Episode reward: 1871.1799\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.127958  15.095101  15.116515  14.282978  14.087086  15.1252365]\n",
      "Reset environment\n",
      "Episode reward: 1528.056\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.128309 15.095456 15.116864 14.283364 14.08741  15.125587]\n",
      "Reset environment\n",
      "Episode reward: 5249.7495\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.129716 15.096863 15.118259 14.284872 14.088647 15.126994]\n",
      "Reset environment\n",
      "Episode reward: -161.51044\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.129114 15.096247 15.117674 14.284165 14.08811  15.126392]\n",
      "Reset environment\n",
      "Episode reward: 1517.6235\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.129442 15.096568 15.117999 14.284526 14.088404 15.126721]\n",
      "Reset environment\n",
      "Episode reward: 4698.1064\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.130682  15.097809  15.11923   14.2858515 14.089482  15.127963 ]\n",
      "Reset environment\n",
      "Episode reward: 2322.2185\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.131203  15.098324  15.119756  14.2864275 14.089955  15.128484 ]\n",
      "Reset environment\n",
      "Episode reward: 4932.068\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.132478 15.099593 15.12103  14.287809 14.091115 15.129753]\n",
      "Reset environment\n",
      "Episode reward: 1906.1184\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.132864 15.099973 15.121427 14.28824  14.091472 15.13014 ]\n",
      "Reset environment\n",
      "Episode reward: 2706.8435\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.133501 15.10061  15.122065 14.288931 14.092058 15.130777]\n",
      "Reset environment\n",
      "Episode reward: 1814.1725\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.133881 15.100991 15.122448 14.289355 14.092406 15.131158]\n",
      "Reset environment\n",
      "Episode reward: 2112.2175\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.134551  15.101655  15.123112  14.2900915 14.09301   15.131829 ]\n",
      "Reset environment\n",
      "Episode reward: 2418.7979\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.135119  15.102227  15.1236725 14.290703  14.093509  15.132396 ]\n",
      "Reset environment\n",
      "Episode reward: 1713.167\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.13546   15.102558  15.1240225 14.291082  14.093822  15.132737 ]\n",
      "Reset environment\n",
      "Episode reward: 1805.5236\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.135834 15.102941 15.124386 14.291495 14.094165 15.133112]\n",
      "Reset environment\n",
      "Episode reward: 1797.0691\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.136431 15.103533 15.124976 14.29215  14.094684 15.133707]\n",
      "Reset environment\n",
      "Episode reward: 1419.6407\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.136709 15.103809 15.125248 14.292468 14.094922 15.133987]\n",
      "Reset environment\n",
      "Episode reward: 1377.1764\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.136878 15.103958 15.12544  14.292681 14.095074 15.134155]\n",
      "Reset environment\n",
      "Episode reward: 3147.562\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.137674 15.104754 15.126228 14.293543 14.095794 15.13495 ]\n",
      "Reset environment\n",
      "Episode reward: 2666.7812\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.138253 15.105318 15.126821 14.294177 14.096319 15.135529]\n",
      "Reset environment\n",
      "Episode reward: 1778.3312\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.138504 15.105604 15.127044 14.294474 14.096554 15.135781]\n",
      "Reset environment\n",
      "Episode reward: 1382.0013\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.138972 15.106068 15.127503 14.295    14.09697  15.136252]\n",
      "Reset environment\n",
      "Episode reward: 4308.8154\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.140088  15.1071825 15.128623  14.296193  14.0979595 15.137368 ]\n",
      "Reset environment\n",
      "Episode reward: 2014.8132\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.140447 15.107516 15.128998 14.296604 14.098276 15.137726]\n",
      "Reset environment\n",
      "Episode reward: 1882.8569\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.141024 15.108093 15.129574 14.297249 14.0988   15.138304]\n",
      "Reset environment\n",
      "Episode reward: 5434.0635\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.142474 15.109536 15.13102  14.298799 14.10011  15.139751]\n",
      "Reset environment\n",
      "Episode reward: 1598.2842\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.142814 15.109872 15.131362 14.299178 14.10041  15.140091]\n",
      "Reset environment\n",
      "Episode reward: 2136.0044\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.143499 15.110552 15.132043 14.299927 14.10102  15.140776]\n",
      "Reset environment\n",
      "Episode reward: 1963.0758\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.143928 15.110975 15.132465 14.300396 14.101402 15.141203]\n",
      "Reset environment\n",
      "Episode reward: 2171.5942\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.144621 15.111665 15.133158 14.301155 14.102029 15.141896]\n",
      "Reset environment\n",
      "Episode reward: 2399.8052\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.145145 15.112199 15.133675 14.301733 14.102508 15.142422]\n",
      "Reset environment\n",
      "Episode reward: 2069.5874\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.145811  15.112866  15.134337  14.302464  14.103107  15.1430855]\n",
      "Reset environment\n",
      "Episode reward: 1959.5245\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.146209 15.113279 15.134724 14.302908 14.103476 15.143484]\n",
      "Reset environment\n",
      "Episode reward: 3672.6816\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.147113  15.11419   15.135615  14.303883  14.1043005 15.144386 ]\n",
      "Reset environment\n",
      "Episode reward: 1508.1342\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.14744  15.114514 15.135944 14.304245 14.104596 15.144715]\n",
      "Reset environment\n",
      "Episode reward: -254.91757\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.146752  15.1138735 15.13522   14.303445  14.103975  15.144024 ]\n",
      "Reset environment\n",
      "Episode reward: 1742.0525\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.147353  15.114469  15.135813  14.3040905 14.104488  15.144626 ]\n",
      "Reset environment\n",
      "Episode reward: 2775.7437\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.14802  15.115138 15.136472 14.304824 14.105088 15.14529 ]\n",
      "Reset environment\n",
      "Episode reward: 5163.311\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.149382 15.116503 15.137819 14.306283 14.106279 15.146651]\n",
      "Reset environment\n",
      "Episode reward: 2682.2063\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.149991 15.117109 15.138432 14.306951 14.106836 15.147262]\n",
      "Reset environment\n",
      "Episode reward: 2025.4619\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.150424  15.1175375 15.138868  14.307428  14.107234  15.147695 ]\n",
      "Reset environment\n",
      "Episode reward: 2642.8013\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.151062 15.118174 15.139497 14.308117 14.107801 15.14833 ]\n",
      "Reset environment\n",
      "Episode reward: 3351.6367\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.151882 15.119    15.140314 14.309003 14.108545 15.149154]\n",
      "Reset environment\n",
      "Episode reward: 1879.7506\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.152295  15.1194105 15.14073   14.309461  14.108927  15.149567 ]\n",
      "Reset environment\n",
      "Episode reward: 3046.6294\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.153034 15.120155 15.141457 14.310257 14.109594 15.150302]\n",
      "Reset environment\n",
      "Episode reward: 4713.5967\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.15419  15.121309 15.142607 14.311499 14.110637 15.151459]\n",
      "Reset environment\n",
      "Episode reward: 1996.0674\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.154584 15.121689 15.14301  14.311938 14.110995 15.151852]\n",
      "Reset environment\n",
      "Episode reward: 2427.6533\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.155114 15.122216 15.143547 14.312524 14.111482 15.152383]\n",
      "Reset environment\n",
      "Episode reward: 2218.0835\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.155605 15.122705 15.144039 14.313068 14.111931 15.152875]\n",
      "Reset environment\n",
      "Episode reward: 1322.5956\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.156032 15.123131 15.144461 14.313547 14.112306 15.153301]\n",
      "Reset environment\n",
      "Episode reward: 1414.1606\n",
      "Total Steps: 47\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.156333 15.12343  15.144765 14.313885 14.112581 15.153604]\n",
      "Reset environment\n",
      "Episode reward: 1832.0686\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.15695  15.124044 15.145376 14.314556 14.113113 15.154219]\n",
      "Reset environment\n",
      "Episode reward: 2445.3843\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.157504 15.124597 15.145931 14.315165 14.113622 15.154772]\n",
      "Reset environment\n",
      "Episode reward: 5035.066\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.158801 15.125895 15.147231 14.316559 14.1148   15.156069]\n",
      "Reset environment\n",
      "Episode reward: 5018.5215\n",
      "Total Steps: 173\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.160096 15.127187 15.148528 14.317959 14.115973 15.157363]\n",
      "Reset environment\n",
      "Episode reward: 2870.0051\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.160756 15.127858 15.149183 14.318678 14.116582 15.158024]\n",
      "Reset environment\n",
      "Episode reward: 1881.6198\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.161082 15.12816  15.149531 14.319047 14.116869 15.158349]\n",
      "Reset environment\n",
      "Episode reward: 1907.7604\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.161307  15.128409  15.149733  14.3193245 14.117066  15.158573 ]\n",
      "Reset environment\n",
      "Episode reward: 4919.6997\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.162616 15.129722 15.151028 14.320719 14.118183 15.159879]\n",
      "Reset environment\n",
      "Episode reward: 1721.7961\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.162984 15.130087 15.151399 14.321126 14.118523 15.160248]\n",
      "Reset environment\n",
      "Episode reward: 1403.72\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.163462 15.130566 15.151875 14.321665 14.118943 15.160726]\n",
      "Reset environment\n",
      "Episode reward: 1515.8402\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.163807 15.130906 15.152225 14.322045 14.119263 15.161072]\n",
      "Reset environment\n",
      "Episode reward: 2004.0507\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.164431 15.131524 15.152848 14.322738 14.119831 15.161695]\n",
      "Reset environment\n",
      "Episode reward: 2565.3062\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.165017 15.132111 15.153438 14.323378 14.120373 15.162281]\n",
      "Reset environment\n",
      "Episode reward: 1720.0422\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.165387 15.132476 15.153799 14.323791 14.120698 15.162653]\n",
      "Reset environment\n",
      "Episode reward: 1383.324\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.165846 15.132939 15.154257 14.324309 14.121107 15.163115]\n",
      "Reset environment\n",
      "Episode reward: 300.9517\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.165351 15.132394 15.153813 14.323742 14.120649 15.162622]\n",
      "Reset environment\n",
      "Episode reward: 3957.992\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.166298  15.133339  15.154755  14.324769  14.121514  15.1635685]\n",
      "Reset environment\n",
      "Episode reward: 1984.9136\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.166946 15.133984 15.155396 14.325482 14.122082 15.164219]\n",
      "Reset environment\n",
      "Episode reward: 1966.0951\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1673565 15.134378  15.155817  14.325933  14.12246   15.16463  ]\n",
      "Reset environment\n",
      "Episode reward: 4084.4204\n",
      "Total Steps: 139\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.168326  15.135345  15.1567955 14.326992  14.123349  15.165602 ]\n",
      "Reset environment\n",
      "Episode reward: 3655.9072\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.169241 15.136256 15.157711 14.327975 14.124171 15.166516]\n",
      "Reset environment\n",
      "Episode reward: 5954.728\n",
      "Total Steps: 199\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.170856 15.13787  15.159327 14.329693 14.125626 15.168131]\n",
      "Reset environment\n",
      "Episode reward: 2579.1418\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.171282 15.138317 15.159735 14.330178 14.126014 15.168556]\n",
      "Reset environment\n",
      "Episode reward: 1933.3087\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.171753 15.138791 15.160202 14.330691 14.126451 15.169028]\n",
      "Reset environment\n",
      "Episode reward: 4016.5413\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.172789 15.139819 15.161226 14.331802 14.127363 15.170061]\n",
      "Reset environment\n",
      "Episode reward: 4936.9043\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.174066 15.141101 15.162496 14.333182 14.1285   15.171338]\n",
      "Reset environment\n",
      "Episode reward: 2277.1846\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.174791 15.141825 15.163209 14.333974 14.129141 15.172067]\n",
      "Reset environment\n",
      "Episode reward: 2133.1785\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.175271 15.142303 15.163681 14.334512 14.129572 15.172548]\n",
      "Reset environment\n",
      "Episode reward: 4802.6455\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.176502  15.143533  15.164915  14.3358345 14.130695  15.173778 ]\n",
      "Reset environment\n",
      "Episode reward: 2848.1997\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.177101 15.144113 15.165532 14.336481 14.131234 15.174378]\n",
      "Reset environment\n",
      "Episode reward: 5652.502\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.178554 15.145568 15.166974 14.338017 14.132541 15.175832]\n",
      "Reset environment\n",
      "Episode reward: 4601.8286\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.179748 15.14676  15.168176 14.339294 14.133591 15.177027]\n",
      "Reset environment\n",
      "Episode reward: 2353.9302\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.18008  15.147111 15.168489 14.339682 14.133891 15.177359]\n",
      "Reset environment\n",
      "Episode reward: 2429.4736\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.18065   15.1476755 15.169047  14.340294  14.134392  15.177923 ]\n",
      "Reset environment\n",
      "Episode reward: 5724.7363\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.182182 15.149205 15.170584 14.34193  14.135768 15.179456]\n",
      "Reset environment\n",
      "Episode reward: 3631.1099\n",
      "Total Steps: 124\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.183095 15.150115 15.1715   14.342911 14.136588 15.180368]\n",
      "Reset environment\n",
      "Episode reward: 2152.1235\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.183778 15.150797 15.172183 14.343658 14.137202 15.181054]\n",
      "Reset environment\n",
      "Episode reward: 2119.528\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.184447 15.151461 15.17285  14.344389 14.1378   15.181721]\n",
      "Reset environment\n",
      "Episode reward: 1391.3225\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.184908 15.151922 15.173305 14.344903 14.138209 15.182182]\n",
      "Reset environment\n",
      "Episode reward: 2334.2292\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.185448  15.15246   15.1738405 14.345501  14.138684  15.182723 ]\n",
      "Reset environment\n",
      "Episode reward: 3494.523\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.186297 15.153318 15.174684 14.346417 14.13946  15.183575]\n",
      "Reset environment\n",
      "Episode reward: 1540.801\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.186618 15.153638 15.175004 14.346782 14.139749 15.183895]\n",
      "Reset environment\n",
      "Episode reward: 2762.8823\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.187291 15.15431  15.175672 14.347508 14.140343 15.184568]\n",
      "Reset environment\n",
      "Episode reward: 2433.6985\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.187739 15.154745 15.176142 14.348015 14.14075  15.185018]\n",
      "Reset environment\n",
      "Episode reward: 1580.8936\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.187915 15.154943 15.176298 14.348236 14.140911 15.185192]\n",
      "Reset environment\n",
      "Episode reward: 1833.4971\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.188525  15.155544  15.176908  14.3489065 14.141447  15.185799 ]\n",
      "Reset environment\n",
      "Episode reward: 2435.342\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.1890745 15.156085  15.177465  14.349503  14.141953  15.186348 ]\n",
      "Reset environment\n",
      "Episode reward: 2546.9504\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.189668 15.156691 15.178045 14.35015  14.142506 15.18694 ]\n",
      "Reset environment\n",
      "Episode reward: 2220.4824\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.19013  15.157163 15.178496 14.350658 14.142932 15.187403]\n",
      "Reset environment\n",
      "Episode reward: 2762.5122\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.190777 15.157808 15.179149 14.351371 14.143527 15.18805 ]\n",
      "Reset environment\n",
      "Episode reward: 1400.8134\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.19125  15.158281 15.179614 14.351892 14.143941 15.188524]\n",
      "Reset environment\n",
      "Episode reward: 3989.0972\n",
      "Total Steps: 137\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.192244  15.159274  15.180611  14.352961  14.1448345 15.189518 ]\n",
      "Reset environment\n",
      "Episode reward: 2910.7969\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.192882 15.159928 15.181227 14.353656 14.145427 15.190156]\n",
      "Reset environment\n",
      "Episode reward: 1743.0173\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.193444 15.160485 15.181784 14.354274 14.145924 15.190719]\n",
      "Reset environment\n",
      "Episode reward: 2327.3765\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.194199 15.161241 15.182525 14.355087 14.146589 15.191471]\n",
      "Reset environment\n",
      "Episode reward: 5415.86\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.195642  15.1626835 15.18397   14.356626  14.14789   15.192911 ]\n",
      "Reset environment\n",
      "Episode reward: 1746.6256\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.19602  15.163054 15.184343 14.357047 14.148219 15.193291]\n",
      "Reset environment\n",
      "Episode reward: 1759.9708\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.196399 15.16344  15.18471  14.357468 14.148565 15.193669]\n",
      "Reset environment\n",
      "Episode reward: 4619.011\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.197601 15.164639 15.185902 14.358743 14.149624 15.194866]\n",
      "Reset environment\n",
      "Episode reward: 3009.958\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.198321  15.165364  15.1866045 14.359508  14.15027   15.195589 ]\n",
      "Reset environment\n",
      "Episode reward: 2452.1885\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.198834  15.1658945 15.187101  14.36007   14.150747  15.196103 ]\n",
      "Reset environment\n",
      "Episode reward: 2147.4355\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.199056  15.166139  15.187298  14.360349  14.15094   15.1963215]\n",
      "Reset environment\n",
      "Episode reward: 2305.3027\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.199806 15.166894 15.188029 14.361158 14.151601 15.197075]\n",
      "Reset environment\n",
      "Episode reward: 5033.9946\n",
      "Total Steps: 171\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.201119 15.168206 15.189345 14.362565 14.152777 15.19839 ]\n",
      "Reset environment\n",
      "Episode reward: 1997.3047\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.201537 15.168621 15.189767 14.363026 14.153159 15.198807]\n",
      "Reset environment\n",
      "Episode reward: 2289.5898\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.201987 15.169089 15.190202 14.36353  14.153576 15.199258]\n",
      "Reset environment\n",
      "Episode reward: 2156.4824\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.20267  15.169773 15.190887 14.364271 14.154189 15.199944]\n",
      "Reset environment\n",
      "Episode reward: 1285.5273\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.202944 15.170053 15.191161 14.364583 14.154442 15.200218]\n",
      "Reset environment\n",
      "Episode reward: 1889.328\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.203354 15.170461 15.191574 14.365036 14.154817 15.200628]\n",
      "Reset environment\n",
      "Episode reward: 3065.337\n",
      "Total Steps: 115\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.204027  15.171121  15.192258  14.365756  14.155424  15.2013035]\n",
      "Reset environment\n",
      "Episode reward: 3856.9856\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.204987 15.172082 15.193212 14.366785 14.156289 15.202267]\n",
      "Reset environment\n",
      "Episode reward: 2052.6702\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.205432 15.172524 15.193665 14.367275 14.156698 15.202711]\n",
      "Reset environment\n",
      "Episode reward: 4601.6587\n",
      "Total Steps: 157\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.206607 15.173699 15.194846 14.368534 14.157745 15.203887]\n",
      "Reset environment\n",
      "Episode reward: 1931.0782\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.207041 15.174124 15.195275 14.369013 14.158128 15.204321]\n",
      "Reset environment\n",
      "Episode reward: 4493.761\n",
      "Total Steps: 153\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.208196 15.175273 15.196435 14.37025  14.159144 15.205476]\n",
      "Reset environment\n",
      "Episode reward: 2652.7612\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.208798  15.175881  15.197031  14.370908  14.159698  15.2060795]\n",
      "Reset environment\n",
      "Episode reward: 503.23233\n",
      "Total Steps: 132\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.208333 15.175452 15.196529 14.370328 14.159299 15.205616]\n",
      "Reset environment\n",
      "Episode reward: 2112.0332\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.208763 15.175901 15.196941 14.37081  14.159695 15.206047]\n",
      "Reset environment\n",
      "Episode reward: 4246.6025\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.209855 15.176989 15.198036 14.371981 14.160659 15.207139]\n",
      "Reset environment\n",
      "Episode reward: 1302.5381\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.210138  15.177277  15.1983185 14.372298  14.160919  15.207424 ]\n",
      "Reset environment\n",
      "Episode reward: 1937.3954\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.210546 15.177696 15.198716 14.372748 14.161292 15.20783 ]\n",
      "Reset environment\n",
      "Episode reward: 2037.9292\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.210952 15.178122 15.199101 14.373198 14.161667 15.208234]\n",
      "Reset environment\n",
      "Episode reward: 1691.0259\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.211307 15.178482 15.199448 14.373591 14.161992 15.208589]\n",
      "Reset environment\n",
      "Episode reward: 2240.4255\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.211768 15.178957 15.199898 14.374103 14.162418 15.20905 ]\n",
      "Reset environment\n",
      "Episode reward: 1811.0209\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.212186 15.179371 15.200313 14.374556 14.162797 15.209467]\n",
      "Reset environment\n",
      "Episode reward: 2330.8015\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.212684 15.179876 15.200804 14.375106 14.163254 15.209965]\n",
      "Reset environment\n",
      "Episode reward: 4429.3184\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.213833 15.181028 15.201948 14.376331 14.164275 15.211114]\n",
      "Reset environment\n",
      "Episode reward: 1873.0914\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.214274 15.181473 15.202382 14.376819 14.164666 15.211558]\n",
      "Reset environment\n",
      "Episode reward: 1924.8219\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.214719 15.181923 15.202819 14.377304 14.165078 15.212004]\n",
      "Reset environment\n",
      "Episode reward: 1566.1285\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.215053  15.182258  15.203151  14.377682  14.165371  15.2123375]\n",
      "Reset environment\n",
      "Episode reward: 3770.1316\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.215987 15.183188 15.204088 14.378684 14.166208 15.213272]\n",
      "Reset environment\n",
      "Episode reward: 2947.8958\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.216699 15.183894 15.204794 14.379471 14.166843 15.213981]\n",
      "Reset environment\n",
      "Episode reward: 1387.0209\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.217176 15.184366 15.205264 14.379991 14.167256 15.214457]\n",
      "Reset environment\n",
      "Episode reward: 1415.7289\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.217658 15.184838 15.205741 14.380523 14.167676 15.21494 ]\n",
      "Reset environment\n",
      "Episode reward: 2346.763\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.218005  15.185209  15.206068  14.380931  14.1679945 15.215287 ]\n",
      "Reset environment\n",
      "Episode reward: 2673.3171\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.218589 15.185789 15.206659 14.381576 14.168521 15.215871]\n",
      "Reset environment\n",
      "Episode reward: 1862.2412\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.219016  15.1862135 15.207071  14.382035  14.168884  15.216298 ]\n",
      "Reset environment\n",
      "Episode reward: 2306.2705\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.219515 15.18672  15.207556 14.382589 14.169333 15.216798]\n",
      "Reset environment\n",
      "Episode reward: 2722.8037\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.220159  15.187374  15.208189  14.3832855 14.1699295 15.2174425]\n",
      "Reset environment\n",
      "Episode reward: 1487.387\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.220479  15.1876955 15.208509  14.383648  14.170224  15.217763 ]\n",
      "Reset environment\n",
      "Episode reward: 2503.551\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.221029  15.188254  15.209051  14.3842535 14.170726  15.218313 ]\n",
      "Reset environment\n",
      "Episode reward: 4633.228\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.222234 15.189452 15.210248 14.385539 14.171807 15.219518]\n",
      "Reset environment\n",
      "Episode reward: 1861.6854\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.222851 15.190059 15.210855 14.386214 14.172346 15.220135]\n",
      "Reset environment\n",
      "Episode reward: 2389.5166\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.223377 15.190581 15.211385 14.386791 14.172828 15.220661]\n",
      "Reset environment\n",
      "Episode reward: 2206.904\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.223878 15.191089 15.211875 14.387343 14.173273 15.221166]\n",
      "Reset environment\n",
      "Episode reward: 2066.7908\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.224178 15.191411 15.212152 14.387691 14.173546 15.221461]\n",
      "Reset environment\n",
      "Episode reward: 4622.4946\n",
      "Total Steps: 159\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.225379 15.192615 15.213348 14.388968 14.174606 15.222663]\n",
      "Reset environment\n",
      "Episode reward: 2026.4474\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.225811 15.193044 15.213784 14.389446 14.175001 15.223095]\n",
      "Reset environment\n",
      "Episode reward: 1640.9651\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.22612  15.193333 15.214109 14.389795 14.17528  15.223405]\n",
      "Reset environment\n",
      "Episode reward: 1718.4508\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.226513  15.193723  15.214491  14.3902235 14.175613  15.223798 ]\n",
      "Reset environment\n",
      "Episode reward: -318.60455\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.225879  15.193097  15.213858  14.389422  14.175043  15.2231655]\n",
      "Reset environment\n",
      "Episode reward: 5123.6304\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.227224 15.194441 15.215203 14.390867 14.176203 15.22451 ]\n",
      "Reset environment\n",
      "Episode reward: 6651.6426\n",
      "Total Steps: 2001\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.216268 15.18361  15.204346 14.376972 14.166448 15.213665]\n",
      "Reset environment\n",
      "Episode reward: 1413.5991\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.216752  15.184087  15.204822  14.377503  14.166866  15.2141485]\n",
      "Reset environment\n",
      "Episode reward: 1799.7253\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.217096 15.184419 15.205178 14.377888 14.167181 15.214493]\n",
      "Reset environment\n",
      "Episode reward: 2166.4988\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.217541 15.184876 15.20561  14.378378 14.167591 15.214935]\n",
      "Reset environment\n",
      "Episode reward: 5111.5522\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.218888 15.186224 15.206948 14.379823 14.168782 15.216282]\n",
      "Reset environment\n",
      "Episode reward: 3188.1406\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.219219 15.186564 15.207262 14.380217 14.169064 15.216613]\n",
      "Reset environment\n",
      "Episode reward: 1799.2247\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.21962  15.186962 15.207656 14.380644 14.169411 15.217015]\n",
      "Reset environment\n",
      "Episode reward: 2168.2021\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.220084  15.187422  15.2080965 14.38115   14.169813  15.217475 ]\n",
      "Reset environment\n",
      "Episode reward: 1570.2863\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.220274  15.1876335 15.2082615 14.381383  14.169987  15.217664 ]\n",
      "Reset environment\n",
      "Episode reward: 2196.6484\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.220743 15.188091 15.208743 14.381896 14.17042  15.218135]\n",
      "Reset environment\n",
      "Episode reward: 1751.7151\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.221318 15.188668 15.209309 14.382522 14.170918 15.21871 ]\n",
      "Reset environment\n",
      "Episode reward: 1366.7517\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.221781 15.189127 15.209768 14.383037 14.171313 15.219175]\n",
      "Reset environment\n",
      "Episode reward: 4569.713\n",
      "Total Steps: 156\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.222947 15.190293 15.210932 14.384302 14.172368 15.220339]\n",
      "Reset environment\n",
      "Episode reward: 1982.8761\n",
      "Total Steps: 69\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.223401  15.190739  15.211373  14.384806  14.1727495 15.220792 ]\n",
      "Reset environment\n",
      "Episode reward: 2403.4343\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.223918 15.191253 15.2119   14.385377 14.173216 15.22131 ]\n",
      "Reset environment\n",
      "Episode reward: 4886.7593\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.225202  15.1925335 15.213176  14.386736  14.174339  15.22259  ]\n",
      "Reset environment\n",
      "Episode reward: 1637.738\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.225518 15.192839 15.213503 14.387089 14.174628 15.222906]\n",
      "Reset environment\n",
      "Episode reward: 1942.8098\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.225929 15.193239 15.213909 14.387544 14.174982 15.223318]\n",
      "Reset environment\n",
      "Episode reward: 2718.8564\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.226544  15.193858  15.214515  14.3882065 14.175532  15.223931 ]\n",
      "Reset environment\n",
      "Episode reward: 2104.2305\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.227228 15.194542 15.215198 14.38894  14.176125 15.224613]\n",
      "Reset environment\n",
      "Episode reward: 2098.154\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.227902 15.195211 15.215875 14.389682 14.176723 15.225291]\n",
      "Reset environment\n",
      "Episode reward: 3112.3726\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.228677 15.195987 15.216643 14.390513 14.177405 15.226065]\n",
      "Reset environment\n",
      "Episode reward: -54.27893\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.2282915 15.195601  15.216259  14.390028  14.177069  15.225682 ]\n",
      "Reset environment\n",
      "Episode reward: 2056.436\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.228724  15.196032  15.216701  14.390507  14.1774645 15.226115 ]\n",
      "Reset environment\n",
      "Episode reward: 1576.8857\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.229058  15.196371  15.21703   14.3908825 14.177767  15.226452 ]\n",
      "Reset environment\n",
      "Episode reward: 1680.561\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.229434 15.196744 15.217396 14.3913   14.178088 15.22683 ]\n",
      "Reset environment\n",
      "Episode reward: 1969.6938\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.229817 15.197116 15.217795 14.391728 14.178442 15.227214]\n",
      "Reset environment\n",
      "Episode reward: 1615.8324\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.230126 15.197417 15.218112 14.392078 14.178722 15.227524]\n",
      "Reset environment\n",
      "Episode reward: 1879.961\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.230546 15.197832 15.21852  14.392534 14.179089 15.227944]\n",
      "Reset environment\n",
      "Episode reward: 3215.934\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.23135   15.198627  15.219313  14.393401  14.179793  15.2287445]\n",
      "Reset environment\n",
      "Episode reward: 4835.629\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.232563  15.1998415 15.220529  14.394706  14.180899  15.229957 ]\n",
      "Reset environment\n",
      "Episode reward: 1554.6667\n",
      "Total Steps: 53\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.232899 15.200186 15.220857 14.395084 14.18121  15.230294]\n",
      "Reset environment\n",
      "Episode reward: 3410.73\n",
      "Total Steps: 117\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.233724  15.20101   15.2216835 14.395976  14.181961  15.231119 ]\n",
      "Reset environment\n",
      "Episode reward: 2186.2976\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.234211  15.2015    15.2221575 14.396502  14.1823845 15.231609 ]\n",
      "Reset environment\n",
      "Episode reward: 5471.7896\n",
      "Total Steps: 184\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.235609 15.2029   15.223547 14.398    14.183633 15.233006]\n",
      "Reset environment\n",
      "Episode reward: 1388.6691\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.236086 15.203376 15.224012 14.398523 14.184039 15.233483]\n",
      "Reset environment\n",
      "Episode reward: 2329.625\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.236822  15.204104  15.22475   14.399325  14.18469   15.2342205]\n",
      "Reset environment\n",
      "Episode reward: 2018.6311\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.237238 15.204538 15.225144 14.399783 14.185074 15.234635]\n",
      "Reset environment\n",
      "Episode reward: 2863.9194\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.237874 15.205182 15.225768 14.400477 14.18565  15.235268]\n",
      "Reset environment\n",
      "Episode reward: 1913.9147\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.23821  15.20554  15.226085 14.400862 14.185958 15.235602]\n",
      "Reset environment\n",
      "Episode reward: 3164.6943\n",
      "Total Steps: 112\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.238962 15.2063   15.226825 14.401671 14.186636 15.236352]\n",
      "Reset environment\n",
      "Episode reward: 3152.4387\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.239754 15.207097 15.227609 14.402515 14.187335 15.237143]\n",
      "Reset environment\n",
      "Episode reward: 2987.7278\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.240474 15.207818 15.228318 14.403284 14.187981 15.237863]\n",
      "Reset environment\n",
      "Episode reward: 1273.9106\n",
      "Total Steps: 41\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.240741 15.208086 15.228583 14.403585 14.188221 15.23813 ]\n",
      "Reset environment\n",
      "Episode reward: 3704.7502\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.241645 15.208989 15.229489 14.404562 14.189036 15.239035]\n",
      "Reset environment\n",
      "Episode reward: 972.84845\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.241824 15.209168 15.22967  14.40477  14.189197 15.239214]\n",
      "Reset environment\n",
      "Episode reward: 1856.7678\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.242123 15.209446 15.229985 14.405114 14.189464 15.239511]\n",
      "Reset environment\n",
      "Episode reward: 2773.621\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.242762  15.210083  15.230626  14.405819  14.190051  15.2401495]\n",
      "Reset environment\n",
      "Episode reward: 2519.792\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.243371 15.210691 15.231227 14.406486 14.190578 15.240762]\n",
      "Reset environment\n",
      "Episode reward: 2029.3887\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.243568 15.210916 15.231402 14.406746 14.190755 15.240959]\n",
      "Reset environment\n",
      "Episode reward: 1568.0576\n",
      "Total Steps: 52\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.243911 15.211262 15.231741 14.407123 14.191072 15.241302]\n",
      "Reset environment\n",
      "Episode reward: 4746.8174\n",
      "Total Steps: 160\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.245151 15.212497 15.232981 14.408446 14.192179 15.24254 ]\n",
      "Reset environment\n",
      "Episode reward: 2039.832\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.245816 15.213164 15.23364  14.409175 14.192755 15.243209]\n",
      "Reset environment\n",
      "Episode reward: 5303.7544\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.247234  15.214579  15.2350445 14.410674  14.193981  15.244626 ]\n",
      "Reset environment\n",
      "Episode reward: 2615.1995\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.247841  15.215178  15.235653  14.411327  14.1945305 15.2452345]\n",
      "Reset environment\n",
      "Episode reward: 1771.3601\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.248241 15.215584 15.236049 14.411767 14.194899 15.245635]\n",
      "Reset environment\n",
      "Episode reward: 2705.0405\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.24884  15.216171 15.236659 14.412418 14.195436 15.246235]\n",
      "Reset environment\n",
      "Episode reward: 1390.0509\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.24932  15.216641 15.237126 14.412947 14.195848 15.246716]\n",
      "Reset environment\n",
      "Episode reward: 1216.5466\n",
      "Total Steps: 39\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.249576 15.2169   15.237374 14.413233 14.196078 15.24697 ]\n",
      "Reset environment\n",
      "Episode reward: 1398.2981\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.2500515 15.217369  15.237849  14.413763  14.196488  15.247446 ]\n",
      "Reset environment\n",
      "Episode reward: -288.7893\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.249214 15.216557 15.236983 14.412926 14.195749 15.24661 ]\n",
      "Reset environment\n",
      "Episode reward: 2167.6487\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.249661 15.216997 15.237436 14.41342  14.196157 15.247058]\n",
      "Reset environment\n",
      "Episode reward: 1568.5869\n",
      "Total Steps: 51\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.25001   15.217348  15.2377825 14.41381   14.196477  15.247406 ]\n",
      "Reset environment\n",
      "Episode reward: 3490.0806\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.250872 15.218205 15.238639 14.41475  14.197241 15.248265]\n",
      "Reset environment\n",
      "Episode reward: 1995.1714\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.2512865 15.21863   15.239048  14.415206  14.197618  15.248681 ]\n",
      "Reset environment\n",
      "Episode reward: 2827.4185\n",
      "Total Steps: 109\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.251887 15.219247 15.239631 14.415865 14.198166 15.249279]\n",
      "Reset environment\n",
      "Episode reward: 1915.3594\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.2523365 15.219705  15.240072  14.416354  14.198585  15.249727 ]\n",
      "Reset environment\n",
      "Episode reward: 2111.5562\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.252796  15.220159  15.240539  14.4168625 14.199006  15.250189 ]\n",
      "Reset environment\n",
      "Episode reward: 1714.183\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.253168 15.220534 15.240907 14.417274 14.199349 15.25056 ]\n",
      "Reset environment\n",
      "Episode reward: 1972.8564\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.25355  15.22093  15.241279 14.417702 14.199705 15.250942]\n",
      "Reset environment\n",
      "Episode reward: 2146.584\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.254011 15.221389 15.241742 14.418211 14.200125 15.251403]\n",
      "Reset environment\n",
      "Episode reward: 3492.8948\n",
      "Total Steps: 122\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.254853 15.22223  15.242574 14.419116 14.200892 15.252245]\n",
      "Reset environment\n",
      "Episode reward: 4277.129\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.255909 15.223282 15.243638 14.420255 14.201832 15.253301]\n",
      "Reset environment\n",
      "Episode reward: 1834.4211\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.256512  15.2238865 15.244234  14.420917  14.202363  15.253904 ]\n",
      "Reset environment\n",
      "Episode reward: 2045.7104\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.257144 15.224511 15.244871 14.42161  14.202929 15.254539]\n",
      "Reset environment\n",
      "Episode reward: 3817.882\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.258133 15.225497 15.245849 14.422657 14.2038   15.255527]\n",
      "Reset environment\n",
      "Episode reward: 2459.9333\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.258658 15.226015 15.246367 14.423233 14.204244 15.256051]\n",
      "Reset environment\n",
      "Episode reward: 1715.0461\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.259016 15.226359 15.246738 14.423633 14.204573 15.256411]\n",
      "Reset environment\n",
      "Episode reward: 5243.5444\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.260373 15.227712 15.248105 14.425086 14.205779 15.257769]\n",
      "Reset environment\n",
      "Episode reward: 2005.3627\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.260718 15.22808  15.248433 14.42548  14.206094 15.258112]\n",
      "Reset environment\n",
      "Episode reward: 1952.8514\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.261377 15.228731 15.249086 14.42619  14.206654 15.258769]\n",
      "Reset environment\n",
      "Episode reward: 2122.0254\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.261821 15.229171 15.249521 14.426682 14.207036 15.259216]\n",
      "Reset environment\n",
      "Episode reward: 4975.955\n",
      "Total Steps: 168\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.263113  15.230459  15.250817  14.4280615 14.2081995 15.260509 ]\n",
      "Reset environment\n",
      "Episode reward: 1616.1716\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.263358 15.230728 15.251036 14.428353 14.208426 15.260753]\n",
      "Reset environment\n",
      "Episode reward: 4503.0728\n",
      "Total Steps: 152\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.264482  15.231852  15.2521515 14.429561  14.209427  15.261875 ]\n",
      "Reset environment\n",
      "Episode reward: 2304.8274\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.264976 15.232337 15.25265  14.430106 14.209879 15.262369]\n",
      "Reset environment\n",
      "Episode reward: 1376.7456\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.265445 15.232801 15.253111 14.430622 14.210283 15.262837]\n",
      "Reset environment\n",
      "Episode reward: 5609.5\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.266911 15.234263 15.254579 14.432185 14.211613 15.264298]\n",
      "Reset environment\n",
      "Episode reward: 2942.0793\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.267584  15.234927  15.255246  14.4329195 14.212203  15.264972 ]\n",
      "Reset environment\n",
      "Episode reward: 3093.4727\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.268313 15.235648 15.255986 14.433708 14.212864 15.265699]\n",
      "Reset environment\n",
      "Episode reward: 2128.9656\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.268757 15.236077 15.25644  14.434196 14.213272 15.266142]\n",
      "Reset environment\n",
      "Episode reward: 1869.9993\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.269102 15.236408 15.256804 14.434585 14.213594 15.266485]\n",
      "Reset environment\n",
      "Episode reward: 1722.0875\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.269417  15.236741  15.257104  14.434939  14.2138815 15.266801 ]\n",
      "Reset environment\n",
      "Episode reward: 3188.471\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.270208  15.237525  15.257887  14.435785  14.214578  15.2675905]\n",
      "Reset environment\n",
      "Episode reward: 1941.3923\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.270612  15.2379265 15.258293  14.4362335 14.214947  15.267995 ]\n",
      "Reset environment\n",
      "Episode reward: 1447.4065\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.270941  15.2382555 15.258622  14.436596  14.215251  15.268324 ]\n",
      "Reset environment\n",
      "Episode reward: 1575.5195\n",
      "Total Steps: 54\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.271277 15.238585 15.258967 14.436967 14.215561 15.26866 ]\n",
      "Reset environment\n",
      "Episode reward: 578.6812\n",
      "Total Steps: 103\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.270655 15.237879 15.258433 14.436394 14.214975 15.268046]\n",
      "Reset environment\n",
      "Episode reward: 5558.3306\n",
      "Total Steps: 191\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.272106  15.2393265 15.25988   14.437954  14.216224  15.269496 ]\n",
      "Reset environment\n",
      "Episode reward: 1789.4941\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.272499 15.239721 15.260255 14.438366 14.216565 15.269888]\n",
      "Reset environment\n",
      "Episode reward: 3083.4482\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.273207 15.240429 15.260948 14.439136 14.217188 15.270595]\n",
      "Reset environment\n",
      "Episode reward: 3541.2239\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.27409  15.241307 15.261828 14.44008  14.217971 15.271478]\n",
      "Reset environment\n",
      "Episode reward: 1435.028\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.27438  15.241585 15.262131 14.440405 14.218235 15.271769]\n",
      "Reset environment\n",
      "Episode reward: 3143.0498\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.275106 15.242309 15.262868 14.441191 14.218893 15.272496]\n",
      "Reset environment\n",
      "Episode reward: 4350.805\n",
      "Total Steps: 148\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.276215  15.243411  15.263972  14.442372  14.219897  15.2736025]\n",
      "Reset environment\n",
      "Episode reward: 3946.2383\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.277214 15.24441  15.264959 14.443428 14.220785 15.274603]\n",
      "Reset environment\n",
      "Episode reward: 3422.9492\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.278067 15.245265 15.265801 14.444351 14.221546 15.275457]\n",
      "Reset environment\n",
      "Episode reward: 1381.6221\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.278542 15.245741 15.266274 14.444875 14.221956 15.275933]\n",
      "Reset environment\n",
      "Episode reward: 839.65\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.278176  15.245401  15.2658825 14.444416  14.221648  15.275568 ]\n",
      "Reset environment\n",
      "Episode reward: 1988.8185\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.278787 15.246009 15.266492 14.445095 14.222188 15.276178]\n",
      "Reset environment\n",
      "Episode reward: 2517.1604\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.279366  15.2465925 15.267052  14.445715  14.222699  15.276759 ]\n",
      "Reset environment\n",
      "Episode reward: 5495.4526\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.280807 15.248039 15.268483 14.447265 14.223952 15.278199]\n",
      "Reset environment\n",
      "Episode reward: 1323.623\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.281041 15.248262 15.268732 14.447532 14.224158 15.278434]\n",
      "Reset environment\n",
      "Episode reward: 2705.0278\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.281462 15.24871  15.269129 14.448011 14.224539 15.278854]\n",
      "Reset environment\n",
      "Episode reward: 1627.9161\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.281802 15.249045 15.269466 14.448399 14.224829 15.279197]\n",
      "Reset environment\n",
      "Episode reward: 1727.0114\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.282206 15.249448 15.269871 14.448841 14.225202 15.279602]\n",
      "Reset environment\n",
      "Episode reward: -518.7722\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.281388 15.248635 15.269051 14.447782 14.224455 15.278779]\n",
      "Reset environment\n",
      "Episode reward: 2111.9214\n",
      "Total Steps: 76\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.281841 15.249099 15.269494 14.448281 14.224874 15.279232]\n",
      "Reset environment\n",
      "Episode reward: 2419.6182\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.282346 15.249616 15.269982 14.448835 14.225338 15.279737]\n",
      "Reset environment\n",
      "Episode reward: 3505.3652\n",
      "Total Steps: 123\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.283173 15.250441 15.270815 14.449728 14.226064 15.280563]\n",
      "Reset environment\n",
      "Episode reward: 3393.339\n",
      "Total Steps: 119\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.284    15.251274 15.271632 14.450617 14.226801 15.281389]\n",
      "Reset environment\n",
      "Episode reward: 1915.8591\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.284626 15.251894 15.272246 14.451295 14.227329 15.282015]\n",
      "Reset environment\n",
      "Episode reward: 2181.054\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.285045 15.252301 15.272679 14.451759 14.227711 15.282433]\n",
      "Reset environment\n",
      "Episode reward: 2026.3116\n",
      "Total Steps: 70\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.285503 15.252757 15.273133 14.452266 14.228104 15.282894]\n",
      "Reset environment\n",
      "Episode reward: 2237.0981\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.285985 15.253237 15.27362  14.452796 14.228547 15.283378]\n",
      "Reset environment\n",
      "Episode reward: 5712.8486\n",
      "Total Steps: 195\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.287459  15.254708  15.2751    14.4543705 14.229897  15.284852 ]\n",
      "Reset environment\n",
      "Episode reward: 5556.6865\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.289109 15.256354 15.276746 14.456122 14.231399 15.286498]\n",
      "Reset environment\n",
      "Episode reward: 372.60953\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.28877   15.256037  15.276389  14.455637  14.231109  15.2861595]\n",
      "Reset environment\n",
      "Episode reward: 5194.1875\n",
      "Total Steps: 174\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.290142 15.25741  15.277756 14.457107 14.232322 15.287534]\n",
      "Reset environment\n",
      "Episode reward: 2385.475\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.290629  15.257913  15.2782345 14.457644  14.232772  15.288021 ]\n",
      "Reset environment\n",
      "Episode reward: 2166.2957\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.291074 15.258347 15.278685 14.458136 14.233176 15.288464]\n",
      "Reset environment\n",
      "Episode reward: 2161.6848\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.291441 15.258691 15.279071 14.458553 14.233483 15.28883 ]\n",
      "Reset environment\n",
      "Episode reward: 2089.3687\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.291813 15.259053 15.279456 14.458974 14.233825 15.289203]\n",
      "Reset environment\n",
      "Episode reward: 2268.7834\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.292211 15.259431 15.279881 14.459428 14.234184 15.289598]\n",
      "Reset environment\n",
      "Episode reward: 1928.2543\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.292663 15.259888 15.280332 14.459922 14.234599 15.290052]\n",
      "Reset environment\n",
      "Episode reward: 1996.234\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.2933   15.260513 15.280969 14.460621 14.235163 15.29069 ]\n",
      "Reset environment\n",
      "Episode reward: 5664.6562\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.294767  15.261965  15.2824335 14.462188  14.236509  15.292157 ]\n",
      "Reset environment\n",
      "Episode reward: 5194.853\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.296128  15.2633295 15.2837715 14.463636  14.237682  15.293517 ]\n",
      "Reset environment\n",
      "Episode reward: 2116.789\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.296616  15.263811  15.284255  14.464174  14.2380905 15.294004 ]\n",
      "Reset environment\n",
      "Episode reward: 1614.2134\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.296948 15.264157 15.284574 14.464546 14.238397 15.294337]\n",
      "Reset environment\n",
      "Episode reward: 3201.9993\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.297745  15.264954  15.285359  14.4654045 14.2391    15.295129 ]\n",
      "Reset environment\n",
      "Episode reward: 266.3576\n",
      "Total Steps: 7\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.297723 15.264933 15.285337 14.465395 14.239077 15.295107]\n",
      "Reset environment\n",
      "Episode reward: 1642.1864\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.2980795 15.2652855 15.285691  14.465795  14.239388  15.295464 ]\n",
      "Reset environment\n",
      "Episode reward: 1605.3362\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.298385 15.265608 15.285983 14.466139 14.239675 15.29577 ]\n",
      "Reset environment\n",
      "Episode reward: 3091.699\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.299103 15.266324 15.286702 14.46692  14.240334 15.296488]\n",
      "Reset environment\n",
      "Episode reward: 5144.122\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.300363 15.267588 15.287964 14.468269 14.241458 15.29775 ]\n",
      "Reset environment\n",
      "Episode reward: 5318.9927\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.301736 15.268959 15.289339 14.469732 14.242714 15.299127]\n",
      "Reset environment\n",
      "Episode reward: -435.48743\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.300971 15.268212 15.288551 14.468886 14.242016 15.298361]\n",
      "Reset environment\n",
      "Episode reward: 5367.6006\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.302381 15.269627 15.289942 14.470397 14.243239 15.29977 ]\n",
      "Reset environment\n",
      "Episode reward: 2999.9219\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.303081  15.270325  15.290647  14.471154  14.2438755 15.30047  ]\n",
      "Reset environment\n",
      "Episode reward: 1658.8138\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.303438 15.270678 15.291    14.47154  14.244193 15.300828]\n",
      "Reset environment\n",
      "Episode reward: 1592.9222\n",
      "Total Steps: 79\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.303969 15.271212 15.291518 14.472134 14.244653 15.30136 ]\n",
      "Reset environment\n",
      "Episode reward: 2157.5168\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.304679 15.271922 15.292223 14.472898 14.245262 15.302067]\n",
      "Reset environment\n",
      "Episode reward: 3127.3135\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.305478 15.272716 15.293015 14.473765 14.245977 15.302865]\n",
      "Reset environment\n",
      "Episode reward: 3859.799\n",
      "Total Steps: 134\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.306437 15.27368  15.293962 14.474776 14.246838 15.303826]\n",
      "Reset environment\n",
      "Episode reward: 4768.0303\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.307651 15.274887 15.295177 14.476072 14.247939 15.305039]\n",
      "Reset environment\n",
      "Episode reward: 3959.8027\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.30863  15.275866 15.296161 14.477125 14.248832 15.306018]\n",
      "Reset environment\n",
      "Episode reward: 5299.119\n",
      "Total Steps: 183\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.309931 15.277156 15.297454 14.478516 14.25     15.307317]\n",
      "Reset environment\n",
      "Episode reward: 5105.5547\n",
      "Total Steps: 175\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.31123  15.278444 15.298757 14.479906 14.251186 15.308615]\n",
      "Reset environment\n",
      "Episode reward: 1413.9526\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.311726 15.27894  15.299235 14.480436 14.251598 15.30911 ]\n",
      "Reset environment\n",
      "Episode reward: 1737.919\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.312282 15.279488 15.299782 14.481049 14.25208  15.309663]\n",
      "Reset environment\n",
      "Episode reward: 1495.2069\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.312566 15.279785 15.300057 14.481371 14.252346 15.309947]\n",
      "Reset environment\n",
      "Episode reward: 1384.204\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.313046 15.280256 15.300536 14.481893 14.252752 15.31043 ]\n",
      "Reset environment\n",
      "Episode reward: 2436.262\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.313547 15.280736 15.301054 14.482443 14.253213 15.31093 ]\n",
      "Reset environment\n",
      "Episode reward: 2533.8938\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.3140335 15.281202  15.301566  14.48299   14.253664  15.311417 ]\n",
      "Reset environment\n",
      "Episode reward: 2046.9641\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.314676 15.281844 15.302204 14.483692 14.254237 15.31206 ]\n",
      "Reset environment\n",
      "Episode reward: 4144.468\n",
      "Total Steps: 143\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.315692 15.282858 15.303224 14.484785 14.255153 15.313075]\n",
      "Reset environment\n",
      "Episode reward: 4684.071\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.316898 15.284064 15.304428 14.486082 14.256194 15.314281]\n",
      "Reset environment\n",
      "Episode reward: 1830.1765\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.317276 15.284434 15.304811 14.486499 14.256538 15.314659]\n",
      "Reset environment\n",
      "Episode reward: 2130.3994\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.317696 15.284867 15.305216 14.486959 14.256926 15.31508 ]\n",
      "Reset environment\n",
      "Episode reward: 2722.599\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.318295 15.285476 15.305808 14.487621 14.257477 15.315681]\n",
      "Reset environment\n",
      "Episode reward: 3863.1082\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.319246 15.28642  15.306763 14.488643 14.258331 15.316635]\n",
      "Reset environment\n",
      "Episode reward: 3754.6008\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.32016  15.287329 15.307676 14.489625 14.259168 15.317549]\n",
      "Reset environment\n",
      "Episode reward: -804.9536\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.319233 15.286368 15.306781 14.488538 14.258319 15.316623]\n",
      "Reset environment\n",
      "Episode reward: 4983.354\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.320509  15.2876425 15.308063  14.489904  14.259468  15.317899 ]\n",
      "Reset environment\n",
      "Episode reward: 2202.22\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.321228 15.288363 15.308773 14.490683 14.260085 15.318622]\n",
      "Reset environment\n",
      "Episode reward: 1375.322\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.321522 15.288663 15.309058 14.491005 14.260353 15.318916]\n",
      "Reset environment\n",
      "Episode reward: 1950.0809\n",
      "Total Steps: 91\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.322162 15.289288 15.309702 14.491706 14.260909 15.319555]\n",
      "Reset environment\n",
      "Episode reward: 1775.0618\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.322502 15.28962  15.310053 14.492085 14.261222 15.319896]\n",
      "Reset environment\n",
      "Episode reward: 1977.2386\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.322899  15.290025  15.310437  14.492521  14.261583  15.3202915]\n",
      "Reset environment\n",
      "Episode reward: 1570.5356\n",
      "Total Steps: 61\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.323175 15.290287 15.310728 14.492833 14.261835 15.320568]\n",
      "Reset environment\n",
      "Episode reward: 4029.081\n",
      "Total Steps: 140\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.324151 15.291258 15.311709 14.493885 14.262713 15.321543]\n",
      "Reset environment\n",
      "Episode reward: 1416.0203\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.324639 15.291745 15.312188 14.494425 14.263127 15.322031]\n",
      "Reset environment\n",
      "Episode reward: 3736.1152\n",
      "Total Steps: 130\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.325554 15.29266  15.313081 14.495407 14.263954 15.322944]\n",
      "Reset environment\n",
      "Episode reward: 3445.7476\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.326424  15.293518  15.313943  14.496335  14.264713  15.3238125]\n",
      "Reset environment\n",
      "Episode reward: 2573.3616\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.326958  15.294066  15.3144655 14.4969225 14.265206  15.324347 ]\n",
      "Reset environment\n",
      "Episode reward: 1600.9047\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.327307  15.294414  15.314813  14.497314  14.265493  15.3246975]\n",
      "Reset environment\n",
      "Episode reward: 2233.712\n",
      "Total Steps: 83\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.327763 15.294881 15.315253 14.497825 14.265912 15.325154]\n",
      "Reset environment\n",
      "Episode reward: 3194.8418\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.328547  15.295656  15.316029  14.498648  14.2666025 15.325939 ]\n",
      "Reset environment\n",
      "Episode reward: 2441.5283\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.329062 15.296168 15.316549 14.499214 14.267077 15.326456]\n",
      "Reset environment\n",
      "Episode reward: 1921.6544\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.329504 15.296601 15.316988 14.499695 14.267455 15.326897]\n",
      "Reset environment\n",
      "Episode reward: 2208.6362\n",
      "Total Steps: 81\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.329962 15.297067 15.317434 14.500204 14.267867 15.327353]\n",
      "Reset environment\n",
      "Episode reward: 1867.5101\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.330387 15.297494 15.317847 14.500676 14.268231 15.327778]\n",
      "Reset environment\n",
      "Episode reward: -384.2956\n",
      "Total Steps: 99\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.3296995 15.29679   15.317168  14.499819  14.267609  15.327088 ]\n",
      "Reset environment\n",
      "Episode reward: 5553.5796\n",
      "Total Steps: 190\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.331145 15.298244 15.318606 14.501369 14.268891 15.328534]\n",
      "Reset environment\n",
      "Episode reward: 1819.6221\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.331538 15.298637 15.318987 14.50181  14.269225 15.32893 ]\n",
      "Reset environment\n",
      "Episode reward: 4659.356\n",
      "Total Steps: 158\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.332757  15.2998495 15.3201885 14.503099  14.270278  15.330146 ]\n",
      "Reset environment\n",
      "Episode reward: 289.2358\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.332273 15.299329 15.319741 14.50254  14.269874 15.329667]\n",
      "Reset environment\n",
      "Episode reward: 1818.3162\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.332636 15.299687 15.320104 14.502942 14.2702   15.330031]\n",
      "Reset environment\n",
      "Episode reward: 2238.3489\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.333078 15.30014  15.320536 14.503432 14.27061  15.330473]\n",
      "Reset environment\n",
      "Episode reward: 4403.655\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.334132 15.301192 15.321586 14.504568 14.271547 15.331526]\n",
      "Reset environment\n",
      "Episode reward: 2035.2024\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.334777 15.301832 15.32222  14.50527  14.272105 15.332172]\n",
      "Reset environment\n",
      "Episode reward: 1999.9823\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.335216 15.302271 15.322644 14.505763 14.272475 15.33261 ]\n",
      "Reset environment\n",
      "Episode reward: 1833.4352\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.335833 15.302885 15.323252 14.506428 14.272999 15.333222]\n",
      "Reset environment\n",
      "Episode reward: 2024.4387\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.336254 15.303296 15.323683 14.506891 14.273389 15.333645]\n",
      "Reset environment\n",
      "Episode reward: 3007.9106\n",
      "Total Steps: 110\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.336924  15.30395   15.3243685 14.507613  14.27398   15.334314 ]\n",
      "Reset environment\n",
      "Episode reward: 2417.2563\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.337446 15.304469 15.324894 14.508185 14.274463 15.334837]\n",
      "Reset environment\n",
      "Episode reward: 1989.7084\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.338099 15.305116 15.325537 14.508899 14.27502  15.335487]\n",
      "Reset environment\n",
      "Episode reward: 3785.2693\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.339063 15.30608  15.326494 14.509928 14.275866 15.336451]\n",
      "Reset environment\n",
      "Episode reward: 2618.7737\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.339645 15.306657 15.327062 14.510566 14.276368 15.337031]\n",
      "Reset environment\n",
      "Episode reward: 1907.3251\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.340074  15.30709   15.327487  14.511044  14.276739  15.3374605]\n",
      "Reset environment\n",
      "Episode reward: 921.44495\n",
      "Total Steps: 31\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.340223  15.30724   15.327638  14.5112295 14.276872  15.337611 ]\n",
      "Reset environment\n",
      "Episode reward: 5402.226\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.341622 15.308638 15.329036 14.512716 14.27813  15.339007]\n",
      "Reset environment\n",
      "Episode reward: 1646.3141\n",
      "Total Steps: 56\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.341966 15.308976 15.32938  14.513095 14.278442 15.339352]\n",
      "Reset environment\n",
      "Episode reward: 1416.0967\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.342452 15.309469 15.329854 14.513634 14.278854 15.339836]\n",
      "Reset environment\n",
      "Episode reward: 2097.4875\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.342887 15.309901 15.330291 14.514118 14.279252 15.340272]\n",
      "Reset environment\n",
      "Episode reward: 2592.2188\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.34348  15.310495 15.330865 14.514753 14.279766 15.340864]\n",
      "Reset environment\n",
      "Episode reward: 2184.3115\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.344154 15.311169 15.331538 14.515491 14.280368 15.341539]\n",
      "Reset environment\n",
      "Episode reward: 4707.2437\n",
      "Total Steps: 162\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.345322 15.312335 15.332717 14.516743 14.281406 15.342709]\n",
      "Reset environment\n",
      "Episode reward: 2622.8726\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.345761  15.312799  15.333137  14.5172415 14.281809  15.343148 ]\n",
      "Reset environment\n",
      "Episode reward: 1711.4071\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.346113 15.313146 15.333491 14.51763  14.282125 15.343501]\n",
      "Reset environment\n",
      "Episode reward: -682.3668\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.345231 15.312266 15.33261  14.516752 14.281305 15.34262 ]\n",
      "Reset environment\n",
      "Episode reward: 1939.6042\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.34568  15.312718 15.333056 14.51725  14.2817   15.34307 ]\n",
      "Reset environment\n",
      "Episode reward: 2575.02\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.346283 15.313315 15.333646 14.517889 14.282227 15.343673]\n",
      "Reset environment\n",
      "Episode reward: 2038.6023\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.34695  15.31398  15.334305 14.518611 14.282793 15.344339]\n",
      "Reset environment\n",
      "Episode reward: 1623.3623\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.347238 15.314288 15.334576 14.518938 14.283059 15.344628]\n",
      "Reset environment\n",
      "Episode reward: 6243.0815\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.348801 15.315836 15.336134 14.520609 14.284471 15.346188]\n",
      "Reset environment\n",
      "Episode reward: 3780.9734\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.349726  15.316763  15.3370495 14.521602  14.285297  15.347117 ]\n",
      "Reset environment\n",
      "Episode reward: 4703.494\n",
      "Total Steps: 161\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.350938 15.317971 15.338258 14.522899 14.286349 15.348328]\n",
      "Reset environment\n",
      "Episode reward: 1854.8184\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.351329 15.318377 15.33864  14.523328 14.28671  15.348719]\n",
      "Reset environment\n",
      "Episode reward: 2877.7192\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.351981 15.319024 15.339298 14.524036 14.28731  15.349371]\n",
      "Reset environment\n",
      "Episode reward: 2680.1467\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.352619  15.319659  15.3399315 14.524736  14.287866  15.350007 ]\n",
      "Reset environment\n",
      "Episode reward: 5601.693\n",
      "Total Steps: 193\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.353995  15.321037  15.341303  14.526215  14.2890835 15.351383 ]\n",
      "Reset environment\n",
      "Episode reward: 3020.8826\n",
      "Total Steps: 104\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.354717 15.321751 15.342017 14.526991 14.289727 15.352104]\n",
      "Reset environment\n",
      "Episode reward: 2150.3132\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.35514  15.322185 15.342433 14.52746  14.29012  15.352528]\n",
      "Reset environment\n",
      "Episode reward: 2087.143\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.355799 15.322834 15.343097 14.528191 14.290706 15.353188]\n",
      "Reset environment\n",
      "Episode reward: 4971.0986\n",
      "Total Steps: 169\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.357074 15.324106 15.344366 14.529556 14.291863 15.354465]\n",
      "Reset environment\n",
      "Episode reward: 2210.5918\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.357426  15.324428  15.344736  14.529958  14.292155  15.3548155]\n",
      "Reset environment\n",
      "Episode reward: 2080.323\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.357903 15.324902 15.345199 14.530478 14.292549 15.355294]\n",
      "Reset environment\n",
      "Episode reward: 3617.782\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.358782 15.325774 15.346067 14.531429 14.293325 15.356172]\n",
      "Reset environment\n",
      "Episode reward: 4093.048\n",
      "Total Steps: 141\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.359812 15.326806 15.347082 14.532542 14.294246 15.357198]\n",
      "Reset environment\n",
      "Episode reward: 3961.9011\n",
      "Total Steps: 138\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.360757 15.327747 15.348035 14.533555 14.295083 15.358143]\n",
      "Reset environment\n",
      "Episode reward: 2314.9172\n",
      "Total Steps: 94\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.361115  15.328126  15.348374  14.533967  14.295411  15.3585005]\n",
      "Reset environment\n",
      "Episode reward: 1734.8594\n",
      "Total Steps: 59\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.361486 15.328495 15.348744 14.534387 14.29574  15.358879]\n",
      "Reset environment\n",
      "Episode reward: 2008.768\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.361893 15.328896 15.349155 14.534837 14.296112 15.359286]\n",
      "Reset environment\n",
      "Episode reward: 2804.6772\n",
      "Total Steps: 105\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.362495 15.329514 15.349743 14.535496 14.296664 15.359888]\n",
      "Reset environment\n",
      "Episode reward: 1147.2874\n",
      "Total Steps: 37\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.36272  15.329736 15.349968 14.535749 14.296869 15.360111]\n",
      "Reset environment\n",
      "Episode reward: 1864.0394\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.363068 15.330069 15.35033  14.536137 14.297189 15.360459]\n",
      "Reset environment\n",
      "Episode reward: 3677.8784\n",
      "Total Steps: 127\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.363988 15.330997 15.351247 14.537117 14.298002 15.36138 ]\n",
      "Reset environment\n",
      "Episode reward: 2231.575\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.3644085 15.331405  15.351679  14.537584  14.298393  15.3618   ]\n",
      "Reset environment\n",
      "Episode reward: 1440.3882\n",
      "Total Steps: 50\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.364691  15.331684  15.351965  14.537903  14.298648  15.3620825]\n",
      "Reset environment\n",
      "Episode reward: 5343.867\n",
      "Total Steps: 182\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.366059 15.333041 15.353332 14.539362 14.299896 15.363448]\n",
      "Reset environment\n",
      "Episode reward: 3503.8354\n",
      "Total Steps: 120\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.366909 15.333887 15.354179 14.540282 14.300661 15.3643  ]\n",
      "Reset environment\n",
      "Episode reward: 1371.9453\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.367358 15.334333 15.35462  14.540793 14.301043 15.364751]\n",
      "Reset environment\n",
      "Episode reward: 2704.0837\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.36796   15.334929  15.3552265 14.541452  14.301597  15.365354 ]\n",
      "Reset environment\n",
      "Episode reward: 3748.6086\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.368866 15.335828 15.356136 14.542424 14.302403 15.36626 ]\n",
      "Reset environment\n",
      "Episode reward: 1401.7244\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.369353 15.336314 15.35662  14.542954 14.302806 15.366746]\n",
      "Reset environment\n",
      "Episode reward: 2014.3412\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.3697195 15.336706  15.356969  14.543371  14.30315   15.367113 ]\n",
      "Reset environment\n",
      "Episode reward: 1391.7075\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.370207  15.337188  15.357452  14.543901  14.303547  15.3675995]\n",
      "Reset environment\n",
      "Episode reward: 3623.9033\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.37107  15.338051 15.358321 14.544836 14.304338 15.368463]\n",
      "Reset environment\n",
      "Episode reward: 3933.7014\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.372065  15.339047  15.3593025 14.545905  14.305217  15.369458 ]\n",
      "Reset environment\n",
      "Episode reward: 1727.3975\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.372425 15.33941  15.359657 14.546316 14.305521 15.369819]\n",
      "Reset environment\n",
      "Episode reward: 3652.886\n",
      "Total Steps: 128\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.37331  15.340301 15.360533 14.547261 14.306317 15.370699]\n",
      "Reset environment\n",
      "Episode reward: 1649.3907\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.373646 15.340628 15.360872 14.54764  14.306624 15.371036]\n",
      "Reset environment\n",
      "Episode reward: 2120.1914\n",
      "Total Steps: 98\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.374309 15.34128  15.361547 14.548371 14.307207 15.371698]\n",
      "Reset environment\n",
      "Episode reward: 1699.2288\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.374867 15.341829 15.362103 14.548986 14.307678 15.372255]\n",
      "Reset environment\n",
      "Episode reward: 2593.984\n",
      "Total Steps: 87\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.375415 15.342372 15.362648 14.549581 14.308176 15.372804]\n",
      "Reset environment\n",
      "Episode reward: 1820.2733\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.375779 15.342748 15.363007 14.54998  14.30851  15.373172]\n",
      "Reset environment\n",
      "Episode reward: 4216.5317\n",
      "Total Steps: 145\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.376841  15.343808  15.3640585 14.55113   14.309447  15.374231 ]\n",
      "Reset environment\n",
      "Episode reward: 1718.1534\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.37741  15.344377 15.364615 14.551756 14.309931 15.374799]\n",
      "Reset environment\n",
      "Episode reward: 2440.427\n",
      "Total Steps: 86\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.377985 15.344952 15.365176 14.552369 14.310416 15.375368]\n",
      "Reset environment\n",
      "Episode reward: 3179.2402\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.378758 15.345733 15.365941 14.553199 14.311091 15.376143]\n",
      "Reset environment\n",
      "Episode reward: 2079.2708\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.379216 15.34619  15.366389 14.553696 14.311472 15.376599]\n",
      "Reset environment\n",
      "Episode reward: 3024.719\n",
      "Total Steps: 107\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.379899 15.346869 15.367075 14.554435 14.312089 15.377282]\n",
      "Reset environment\n",
      "Episode reward: 1272.9215\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.380136 15.347118 15.367303 14.5547   14.312309 15.37752 ]\n",
      "Reset environment\n",
      "Episode reward: 1984.1921\n",
      "Total Steps: 67\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.380578 15.347558 15.367758 14.555187 14.312719 15.377961]\n",
      "Reset environment\n",
      "Episode reward: 4162.4272\n",
      "Total Steps: 144\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.3815975 15.348567  15.36878   14.556279  14.313633  15.378981 ]\n",
      "Reset environment\n",
      "Episode reward: 3935.794\n",
      "Total Steps: 135\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.382589 15.349554 15.369766 14.557351 14.314512 15.379971]\n",
      "Reset environment\n",
      "Episode reward: 1542.3969\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.38293  15.349895 15.370107 14.557727 14.314827 15.380311]\n",
      "Reset environment\n",
      "Episode reward: 1820.214\n",
      "Total Steps: 63\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.383332 15.35029  15.370498 14.558169 14.315161 15.380714]\n",
      "Reset environment\n",
      "Episode reward: 2453.6707\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.383838 15.350789 15.371012 14.55873  14.315625 15.381222]\n",
      "Reset environment\n",
      "Episode reward: 3470.787\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.384653  15.351601  15.371815  14.5596075 14.316331  15.382034 ]\n",
      "Reset environment\n",
      "Episode reward: 3221.588\n",
      "Total Steps: 111\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.3854265 15.352367  15.372579  14.560444  14.317023  15.382812 ]\n",
      "Reset environment\n",
      "Episode reward: 2880.8975\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.386075 15.353013 15.373229 14.56115  14.317619 15.383461]\n",
      "Reset environment\n",
      "Episode reward: 2123.9553\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.386484 15.353412 15.373651 14.561604 14.317992 15.383873]\n",
      "Reset environment\n",
      "Episode reward: 5211.5522\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.387831 15.354759 15.374989 14.563045 14.319184 15.385218]\n",
      "Reset environment\n",
      "Episode reward: 1677.0074\n",
      "Total Steps: 57\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.388203 15.355133 15.375355 14.563454 14.319494 15.38559 ]\n",
      "Reset environment\n",
      "Episode reward: 2212.04\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.388922 15.355856 15.376071 14.56423  14.320112 15.386309]\n",
      "Reset environment\n",
      "Episode reward: 4398.39\n",
      "Total Steps: 151\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.390015 15.35696  15.377144 14.565407 14.321104 15.387403]\n",
      "Reset environment\n",
      "Episode reward: 1807.4207\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.390417 15.357365 15.377542 14.565836 14.321453 15.387805]\n",
      "Reset environment\n",
      "Episode reward: 2194.1943\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.391124 15.358072 15.378238 14.566599 14.32206  15.388513]\n",
      "Reset environment\n",
      "Episode reward: 5844.3003\n",
      "Total Steps: 212\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.392809 15.359751 15.379916 14.568395 14.32358  15.390198]\n",
      "Reset environment\n",
      "Episode reward: 1468.0378\n",
      "Total Steps: 49\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.393114  15.360059  15.3802185 14.568737  14.32386   15.390504 ]\n",
      "Reset environment\n",
      "Episode reward: 1267.3452\n",
      "Total Steps: 43\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.393362 15.36031  15.380464 14.569021 14.324085 15.390752]\n",
      "Reset environment\n",
      "Episode reward: 4260.212\n",
      "Total Steps: 147\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.394437 15.361388 15.381534 14.570167 14.325032 15.391825]\n",
      "Reset environment\n",
      "Episode reward: 3141.5288\n",
      "Total Steps: 114\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.395137 15.362072 15.382242 14.570911 14.325666 15.392527]\n",
      "Reset environment\n",
      "Episode reward: 1788.7139\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.395527 15.362459 15.382631 14.571336 14.326019 15.392919]\n",
      "Reset environment\n",
      "Episode reward: 1724.9386\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.395744 15.362698 15.382828 14.571599 14.326217 15.393136]\n",
      "Reset environment\n",
      "Episode reward: 1772.4192\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.396326 15.363276 15.383402 14.572241 14.326718 15.393719]\n",
      "Reset environment\n",
      "Episode reward: 2184.597\n",
      "Total Steps: 77\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.396819 15.363768 15.383883 14.572791 14.327137 15.39421 ]\n",
      "Reset environment\n",
      "Episode reward: 2451.317\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.39733  15.36429  15.384384 14.573355 14.327605 15.394721]\n",
      "Reset environment\n",
      "Episode reward: 4807.4766\n",
      "Total Steps: 165\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.398559 15.365522 15.385611 14.574681 14.328696 15.395951]\n",
      "Reset environment\n",
      "Episode reward: 1588.3363\n",
      "Total Steps: 55\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.398888  15.365842  15.385951  14.575046  14.3289995 15.396281 ]\n",
      "Reset environment\n",
      "Episode reward: 2098.5183\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.399547 15.366492 15.386611 14.575764 14.329587 15.396941]\n",
      "Reset environment\n",
      "Episode reward: 2191.6008\n",
      "Total Steps: 89\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.399961  15.366928  15.387     14.576227  14.3299675 15.397354 ]\n",
      "Reset environment\n",
      "Episode reward: 2197.1165\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.400653  15.367614  15.38769   14.576974  14.330571  15.3980465]\n",
      "Reset environment\n",
      "Episode reward: 1288.5459\n",
      "Total Steps: 40\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.400927 15.367888 15.387963 14.577279 14.330826 15.39832 ]\n",
      "Reset environment\n",
      "Episode reward: 2766.5908\n",
      "Total Steps: 101\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.401522 15.368473 15.388573 14.577927 14.331362 15.398915]\n",
      "Reset environment\n",
      "Episode reward: 4820.0913\n",
      "Total Steps: 167\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.402668 15.369622 15.389719 14.579166 14.332382 15.400063]\n",
      "Reset environment\n",
      "Episode reward: 1883.7766\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.4030905 15.370033  15.390134  14.579632  14.332743  15.400482 ]\n",
      "Reset environment\n",
      "Episode reward: 2301.4038\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.403561 15.37049  15.390617 14.580145 14.333176 15.400952]\n",
      "Reset environment\n",
      "Episode reward: 2276.998\n",
      "Total Steps: 82\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.404045  15.370978  15.3910885 14.580669  14.33361   15.40144  ]\n",
      "Reset environment\n",
      "Episode reward: 2677.612\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.404635 15.371562 15.391672 14.581314 14.33412  15.402034]\n",
      "Reset environment\n",
      "Episode reward: 2094.7185\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.405315 15.372242 15.392347 14.582053 14.334706 15.402715]\n",
      "Reset environment\n",
      "Episode reward: 1738.929\n",
      "Total Steps: 62\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.40567   15.372585  15.39272   14.582452  14.3350315 15.403071 ]\n",
      "Reset environment\n",
      "Episode reward: 1741.6991\n",
      "Total Steps: 60\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.406049 15.372957 15.393095 14.582868 14.335349 15.40345 ]\n",
      "Reset environment\n",
      "Episode reward: 2670.6\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.40665  15.373557 15.393701 14.583527 14.335904 15.404054]\n",
      "Reset environment\n",
      "Episode reward: 2005.173\n",
      "Total Steps: 93\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.407301 15.374204 15.394343 14.584243 14.336465 15.404706]\n",
      "Reset environment\n",
      "Episode reward: 4736.432\n",
      "Total Steps: 163\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.408474  15.375371  15.395521  14.5855055 14.337543  15.405881 ]\n",
      "Reset environment\n",
      "Episode reward: 5259.4272\n",
      "Total Steps: 177\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.409832 15.376724 15.396878 14.586954 14.338762 15.407239]\n",
      "Reset environment\n",
      "Episode reward: 3338.5984\n",
      "Total Steps: 116\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.410649 15.377543 15.397691 14.587834 14.339478 15.408056]\n",
      "Reset environment\n",
      "Episode reward: 1731.1898\n",
      "Total Steps: 72\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.410924 15.377802 15.397988 14.588153 14.339731 15.408331]\n",
      "Reset environment\n",
      "Episode reward: 2058.5164\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.4115715 15.378442  15.398629  14.588857  14.340302  15.408978 ]\n",
      "Reset environment\n",
      "Episode reward: 2487.854\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.4121685 15.379036  15.39922   14.589505  14.340817  15.409576 ]\n",
      "Reset environment\n",
      "Episode reward: 5298.248\n",
      "Total Steps: 180\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.4135475 15.380413  15.400595  14.590974  14.342001  15.410955 ]\n",
      "Reset environment\n",
      "Episode reward: 3668.3691\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.414403 15.381268 15.401458 14.591893 14.342767 15.411812]\n",
      "Reset environment\n",
      "Episode reward: 2091.1855\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.414851 15.38171  15.401905 14.592387 14.343162 15.412261]\n",
      "Reset environment\n",
      "Episode reward: 5479.5073\n",
      "Total Steps: 188\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.416258 15.383114 15.403307 14.593895 14.344397 15.41367 ]\n",
      "Reset environment\n",
      "Episode reward: 1637.2758\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.416485  15.383359  15.403516  14.594159  14.3446045 15.4138975]\n",
      "Reset environment\n",
      "Episode reward: 5490.9897\n",
      "Total Steps: 208\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.418108 15.384984 15.405124 14.5959   14.346018 15.41552 ]\n",
      "Reset environment\n",
      "Episode reward: 3957.6875\n",
      "Total Steps: 136\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.419106  15.385977  15.4061165 14.596969  14.346891  15.416517 ]\n",
      "Reset environment\n",
      "Episode reward: 2462.5513\n",
      "Total Steps: 90\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.419653 15.386523 15.406652 14.59757  14.34736  15.417064]\n",
      "Reset environment\n",
      "Episode reward: 2391.7502\n",
      "Total Steps: 108\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.420392 15.387255 15.407387 14.598374 14.348006 15.417803]\n",
      "Reset environment\n",
      "Episode reward: 3357.3416\n",
      "Total Steps: 118\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.421194  15.388066  15.4081745 14.599241  14.348734  15.418603 ]\n",
      "Reset environment\n",
      "Episode reward: -282.11865\n",
      "Total Steps: 129\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.4203415 15.387143  15.407397  14.598341  14.347971  15.417764 ]\n",
      "Reset environment\n",
      "Episode reward: 3530.73\n",
      "Total Steps: 121\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.421217 15.388024 15.408269 14.599285 14.348744 15.418643]\n",
      "Reset environment\n",
      "Episode reward: 1802.6466\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.421579 15.388399 15.408622 14.59969  14.349084 15.419006]\n",
      "Reset environment\n",
      "Episode reward: 5235.0005\n",
      "Total Steps: 178\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.422909 15.389722 15.409955 14.601116 14.350286 15.420332]\n",
      "Reset environment\n",
      "Episode reward: 2044.518\n",
      "Total Steps: 71\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.4233465 15.390154  15.410387  14.601595  14.350673  15.420772 ]\n",
      "Reset environment\n",
      "Episode reward: 5257.055\n",
      "Total Steps: 179\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.424691 15.391499 15.411731 14.603037 14.351893 15.422117]\n",
      "Reset environment\n",
      "Episode reward: 2155.5305\n",
      "Total Steps: 80\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.425113 15.391911 15.412164 14.6035   14.352279 15.42254 ]\n",
      "Reset environment\n",
      "Episode reward: 2052.6733\n",
      "Total Steps: 73\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.425572 15.392371 15.412609 14.604004 14.352659 15.422999]\n",
      "Reset environment\n",
      "Episode reward: 3259.4941\n",
      "Total Steps: 113\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.426369  15.393173  15.4134    14.604866  14.353351  15.4237995]\n",
      "Reset environment\n",
      "Episode reward: 2094.5894\n",
      "Total Steps: 96\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.427039 15.393838 15.414064 14.605591 14.353932 15.424468]\n",
      "Reset environment\n",
      "Episode reward: 2196.7717\n",
      "Total Steps: 85\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.427464 15.394278 15.414478 14.606062 14.354326 15.424893]\n",
      "Reset environment\n",
      "Episode reward: 2810.4038\n",
      "Total Steps: 106\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.428061  15.394889  15.415058  14.60671   14.354868  15.4254875]\n",
      "Reset environment\n",
      "Episode reward: 2944.2207\n",
      "Total Steps: 102\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.428737 15.395561 15.415733 14.607444 14.355488 15.426161]\n",
      "Reset environment\n",
      "Episode reward: 4877.0034\n",
      "Total Steps: 170\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.42993   15.396749  15.416927  14.6087265 14.356582  15.427354 ]\n",
      "Reset environment\n",
      "Episode reward: 2759.4207\n",
      "Total Steps: 97\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.430582  15.397397  15.4175625 14.609408  14.357142  15.428005 ]\n",
      "Reset environment\n",
      "Episode reward: 2363.8289\n",
      "Total Steps: 84\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.431086 15.397899 15.418074 14.609963 14.357608 15.428509]\n",
      "Reset environment\n",
      "Episode reward: 1384.0598\n",
      "Total Steps: 45\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.43137  15.398186 15.418357 14.610282 14.357869 15.428794]\n",
      "Reset environment\n",
      "Episode reward: 2069.1367\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.43203  15.398834 15.419016 14.611001 14.358443 15.429454]\n",
      "Reset environment\n",
      "Episode reward: 2005.132\n",
      "Total Steps: 66\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.432489 15.399301 15.419475 14.611503 14.358872 15.429915]\n",
      "Reset environment\n",
      "Episode reward: 1863.945\n",
      "Total Steps: 88\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.433105  15.399914  15.420089  14.612171  14.359396  15.4305315]\n",
      "Reset environment\n",
      "Episode reward: 1899.0588\n",
      "Total Steps: 68\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.433514 15.400314 15.420482 14.612629 14.359728 15.430938]\n",
      "Reset environment\n",
      "Episode reward: 2596.0425\n",
      "Total Steps: 92\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.434078 15.400874 15.421049 14.613251 14.360244 15.431503]\n",
      "Reset environment\n",
      "Episode reward: 2057.374\n",
      "Total Steps: 74\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.434526  15.4013195 15.42148   14.61372   14.360621  15.431952 ]\n",
      "Reset environment\n",
      "Episode reward: 1737.7272\n",
      "Total Steps: 58\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.434914 15.401707 15.42186  14.61415  14.360959 15.432342]\n",
      "Reset environment\n",
      "Episode reward: 3600.557\n",
      "Total Steps: 125\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.435793 15.402593 15.422729 14.61508  14.361739 15.43322 ]\n",
      "Reset environment\n",
      "Episode reward: 3838.5522\n",
      "Total Steps: 133\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.436745 15.403544 15.423662 14.616077 14.362586 15.434172]\n",
      "Reset environment\n",
      "Episode reward: 1627.6963\n",
      "Total Steps: 64\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.437013 15.403832 15.423909 14.616386 14.362832 15.434437]\n",
      "Reset environment\n",
      "Episode reward: 2071.5244\n",
      "Total Steps: 78\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.4374075 15.404216  15.424315  14.616824  14.363195  15.434832 ]\n",
      "Reset environment\n",
      "Episode reward: 2189.722\n",
      "Total Steps: 100\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.438109  15.404918  15.4250145 14.617585  14.363794  15.435534 ]\n",
      "Reset environment\n",
      "Episode reward: 2290.8943\n",
      "Total Steps: 95\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.438506  15.405332  15.425387  14.6180315 14.364157  15.435929 ]\n",
      "Reset environment\n",
      "Episode reward: 1885.9952\n",
      "Total Steps: 65\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.438919 15.405733 15.425798 14.618495 14.364506 15.436345]\n",
      "Reset environment\n",
      "Episode reward: 1900.0133\n",
      "Total Steps: 75\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.43927  15.406103 15.426129 14.618886 14.364825 15.436692]\n",
      "Reset environment\n",
      "Episode reward: 4267.884\n",
      "Total Steps: 146\n",
      "Agent status: Game started\n",
      "Mean Q-values: [15.440316 15.407147 15.427183 14.620012 14.365764 15.437739]\n",
      "Training completed and model saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = FighterJetEnv()\n",
    "env = Monitor(env)  \n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Set the model path\n",
    "model_path = \"fighter_jet_dqn_2.zip\"\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "reload = False\n",
    "# Check if a saved model exists\n",
    "if os.path.exists(model_path) and reload:\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    model = DQN.load(model_path, env=env, tensorboard_log=\"./fighter_jet_dqn_2/\",  device=device)\n",
    "    print(\"Model loaded successfully. Continuing training...\")\n",
    "else:\n",
    "    print(\"No existing model found. Creating a new DQN agent.\")\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\", \n",
    "        env, \n",
    "        verbose=0,\n",
    "        tensorboard_log=\"./fighter_jet_dqn_2/\",\n",
    "        learning_rate=5e-5,\n",
    "        buffer_size=500000,\n",
    "        learning_starts=50000,\n",
    "        batch_size=256,\n",
    "        tau=0.001,\n",
    "        gamma=0.99,\n",
    "        train_freq=1,\n",
    "        gradient_steps=1,\n",
    "        target_update_interval=5000,\n",
    "        exploration_fraction=0.7,\n",
    "        exploration_initial_eps=1.0,\n",
    "        exploration_final_eps=0.1,\n",
    "        max_grad_norm=10,\n",
    "        policy_kwargs=dict(net_arch=[256, 256,256]),\n",
    "        device=device\n",
    "        # double_q=True\n",
    "    )   \n",
    "\n",
    "print_hyperparameters(model)\n",
    "# Create the callback\n",
    "callback = TensorboardCallback()\n",
    "early_stopping_callback = EarlyStoppingCallback(patience=100000, min_delta=1.0, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(\n",
    "    total_timesteps=int(2e6),\n",
    "    callback=[callback, early_stopping_callback],\n",
    "    reset_num_timesteps=False\n",
    ")\n",
    "\n",
    "# model_path = \"fighter_jet_dqn_v12.zip\"\n",
    "# Save the trained model\n",
    "model.save(model_path)\n",
    "\n",
    "print(\"Training completed and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorboardCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_reward = 0\n",
    "        self.q_values = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Access the VecEnv\n",
    "        env = self.training_env.envs[0]  # Extract the original environment\n",
    "        if isinstance(env, Monitor):\n",
    "            env = env.env  # Unwrap the Monitor to access the original FighterJetEnv\n",
    "\n",
    "        self.episode_reward += self.locals['rewards'][0]\n",
    "\n",
    "        # Log epsilon value\n",
    "        epsilon = self.model.exploration_rate\n",
    "        self.logger.record(\"exploration/epsilon\", epsilon)\n",
    "\n",
    "        # Log Q-values\n",
    "        obs = self.locals['new_obs']\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model.q_net(torch.as_tensor(obs).to(self.model.device))\n",
    "        q_values = q_values.cpu().numpy()\n",
    "        self.q_values.append(q_values)\n",
    "\n",
    "        if self.locals['dones']:\n",
    "            self.episode_lengths.append(self.locals['infos'][0]['episode']['l'])\n",
    "            self.logger.record('main/ep_rew_total', self.episode_reward)\n",
    "            self.logger.record('main/ep_len_mean', sum(self.episode_lengths) / len(self.episode_lengths))\n",
    "\n",
    "            # Log Q-values\n",
    "            mean_q_values = np.mean(self.q_values, axis=0)\n",
    "            for i, q_value in enumerate(mean_q_values[0]):\n",
    "                self.logger.record(f'q_values/action_{i}', q_value)\n",
    "            self.logger.record('q_values/max', np.max(mean_q_values))\n",
    "            self.logger.record('q_values/min', np.min(mean_q_values))\n",
    "            self.logger.record('q_values/mean', np.mean(mean_q_values))\n",
    "\n",
    "            # Print debug information\n",
    "            print(\"Episode reward:\", self.episode_reward)\n",
    "            print(\"Total Steps:\", self.episode_lengths[-1])\n",
    "            print(\"Agent status:\", env.agent_status)  # Access the original environment's attribute\n",
    "            print(\"Mean Q-values:\", mean_q_values[0])\n",
    "\n",
    "            self.episode_reward = 0\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorboardCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_reward = 0\n",
    "        self.q_values = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Access the VecEnv\n",
    "        env = self.training_env.envs[0]  # Extract the original environment\n",
    "        if isinstance(env, Monitor):\n",
    "            env = env.env  # Unwrap the Monitor to access the original FighterJetEnv\n",
    "\n",
    "        self.episode_reward += self.locals['rewards'][0]\n",
    "\n",
    "        # Log epsilon value\n",
    "        epsilon = self.model.exploration_rate\n",
    "        self.logger.record(\"exploration/epsilon\", epsilon)\n",
    "\n",
    "        # Log Q-values\n",
    "        obs = self.locals['new_obs']\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model.q_net(torch.as_tensor(obs).to(self.model.device))\n",
    "        q_values = q_values.cpu().numpy()\n",
    "        self.q_values.append(q_values)\n",
    "\n",
    "        if self.locals['dones']:\n",
    "            self.episode_lengths.append(self.locals['infos'][0]['episode']['l'])\n",
    "            self.logger.record('main/ep_rew_total', self.episode_reward)\n",
    "            self.logger.record('main/ep_len_mean', sum(self.episode_lengths) / len(self.episode_lengths))\n",
    "\n",
    "            # Log Q-values\n",
    "            mean_q_values = np.mean(self.q_values, axis=0)\n",
    "            for i, q_value in enumerate(mean_q_values[0]):\n",
    "                self.logger.record(f'q_values/action_{i}', q_value)\n",
    "            self.logger.record('q_values/max', np.max(mean_q_values))\n",
    "            self.logger.record('q_values/min', np.min(mean_q_values))\n",
    "            self.logger.record('q_values/mean', np.mean(mean_q_values))\n",
    "\n",
    "            # Print debug information\n",
    "            print(\"Episode reward:\", self.episode_reward)\n",
    "            print(\"Total Steps:\", self.episode_lengths[-1])\n",
    "            print(\"Agent status:\", env.agent_status)  # Access the original environment's attribute\n",
    "            print(\"Mean Q-values:\", mean_q_values[0])\n",
    "\n",
    "            self.episode_reward = 0\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment\n",
      "Initial observation shape: (13,)\n",
      "Reset environment\n"
     ]
    }
   ],
   "source": [
    "env = FighterJetEnv()\n",
    "# env = Monitor(env)  # Wrap with Monitor to get episode stats\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "jetArrray = []\n",
    "targetArray = []\n",
    "# Load the saved model\n",
    "modelname = r\"C:\\Users\\raced\\Autonomous-Fighter-Jet-Navigation-and-Combat\\fighter_jet_dqn_2.zip\"\n",
    "model = DQN.load(modelname)\n",
    "\n",
    "# Test the loaded model\n",
    "obs, _ = env.reset()\n",
    "print(f\"Initial observation shape: {obs.shape}\")\n",
    "\n",
    "for _ in range(100):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    jetArrray.append(env.jet_pos)\n",
    "    targetArray.append(env.target_pos)\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scalar tags: ['exploration/epsilon', 'main/ep_len_mean', 'main/ep_rew_total', 'q_values/action_0', 'q_values/action_1', 'q_values/action_2', 'q_values/action_3', 'q_values/action_4', 'q_values/action_5', 'q_values/max', 'q_values/mean', 'q_values/min', 'rollout/ep_len_mean', 'rollout/ep_rew_mean', 'rollout/exploration_rate', 'time/fps', 'train/learning_rate', 'train/loss']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAA3fJJREFUeJzsnQeY3MTZx9+94oo7uGGbajBgsGmmt4BtOHqvCSGNL5CEEkIJoXeS0Ammhd4Jprob9957r3cudy7nq76+3zOzp11JqzLq0u7/9zz27Wql0Wg0Gr3vvGVi8Xg8TgAAAAAAAAAAODmJPwAAAAAAAAAAGFCSAAAAAAAAAEAGlCQAAAAAAAAAkAElCQAAAAAAAABkQEkCAAAAAAAAABlQkgAAAAAAAABABpQkAAAAAAAAAJABJQkAAAAAAAAAZEBJAgAAAAAAAAAZUJIAACAD+PWvf00HHnigrWMfffRRisVirtcJRIOzzz6b/wMAAJACShIAAHgIUz5E/k2cOJGyVbnbZ599KArE43H66KOP6Mwzz6SOHTtSmzZt6Oijj6bHH3+cqqqqKCxs3LhRuN+xfQEAAKQTi7NRHwAAgCd8/PHHiu8ffvghjR07lgvbcgYPHkzdunWzfZ76+npqamqili1bWj62oaGB/2vVqhUFoSR9/fXXVFlZSWGmsbGRbrjhBvryyy/pjDPOoCuuuIIrSVOmTKFPP/2UjjzySBo3bpyje+gWTGEbPny4Ytu///1vKioqohdffFGx/fLLL6f8/Hz+uUWLFr7WEwAAwgyUJAAA8JE//elP9Prrr3OrhBHV1dVcCM90oqIkPfPMM/T3v/+d7rnnHvrnP/+p+O2HH36gyy67jIYMGUIjR470tV6i/eSiiy6ipUuXwnIEAACCwN0OAAAChsWD9O/fn+bNm8dduZjQywRyxnfffUcXXngh9ezZk1uJDjnkEHriiSe4ZcMoJklyufrXv/5Fb731Fj+OHX/iiSfSnDlzTGOS2Hem0H377be8buzYo446ikaNGpVWf+YqeMIJJ3BLFDvPm2++6Xqc01dffUXHH388tW7dmvbdd1+66aabaMuWLYp9tm/fTrfccgv16tWL17dHjx506aWXKhSDuXPn0tChQ3kZrKyDDjqIfvOb3xiee+/evVwxOuyww7iypObiiy+mm2++mbfNzJkzk0rJwQcfrFneKaecwttLbXGUrq9z58503XXXUWFhoXA/cTMmid1Pdu+Y1eyxxx6j/fffn9q1a0dXXXUVlZWVUW1tLd15553UtWtX7irJ2pxtUyNyTQAAEFbygq4AAAAAol27dtEFF1zABUmmAEhuW++//z4XRO+++27+9+eff6aHH36YysvL0ywaWjBXsIqKCrr11lu54Pv8889zV7H169cn3az0mDp1Kn3zzTd02223cSH5lVdeoSuvvJI2b95MXbp04fssWLCAzj//fK6QMIGaKW8sRme//fZzqWUSbcAEcabgMSWluLiYXn75ZZo2bRo/P4sPYrC6LVu2jP785z9zhbGkpIS7NrL6St+ZtYfV7f777+fHMQWKXaNZO5SWltIdd9xBeXnar81f/epX9N5779GPP/5IJ598Ml177bV8G1NIWb0lNm3axBUp+b176qmn6KGHHqJrrrmGfve739GOHTvo1Vdf5YqQ/PqM+okXsLZmCg5rq7Vr1/I6sT6Tk5PD24Mpwuxa2P1hyibrl3auCQAAQglztwMAAOAPt99+O/OzU2w766yz+LZhw4al7V9dXZ227dZbb423adMmXlNTk9x28803xw844IDk9w0bNvAyu3TpEt+9e3dy+3fffce3//DDD8ltjzzySFqd2PcWLVrE165dm9y2aNEivv3VV19Nbrv44ot5XbZs2ZLctmbNmnheXl5amVqwerdt21b397q6unjXrl3j/fv3j+/duze5/ccff+TlP/zww/x7aWkp//7Pf/5Tt6zhw4fzfebMmRO3wksvvcSPY8frwdqY7XPFFVfw72VlZfGWLVvG//rXvyr2e/755+OxWCy+adMm/n3jxo3x3Nzc+FNPPaXYb8mSJbwN5duN+okZF154oaJ/yGHlsn8SEyZM4Odhbc7aX+L666/ndb/gggsUx59yyimKsq1cEwAAhBW42wEAQAhg7mHMWqKGzeRLMIvQzp07eeIAFouycuVK03KZRaNTp07J7+xYBrMkmXHeeedx9zmJY445htq3b588llmNWLICFo/D3AElDj30UG7tcAPmHscsQMyaJU8swVwQ+/XrRz/99FOynVjiAeYqxqwcWkjWC2btYYkuRGHtzmDWND2k35iFj8HaibUBc1mTx5998cUX3NLUp08f/p1ZsVjCDWZxYfdW+te9e3fq27cvTZgwQaifeAGzhMmtjSeddBK/FrV7ItvO3OhY8g871wQAAGEEShIAAIQAFvehlV2MuY+xDGQdOnTggjdzFWNuVgwWH2KGJIxLSAqTniJhdKx0vHQsU15YvA5TitRobbMDc09jHH744Wm/MSVJ+p0pD8899xxPnMBc0JhbF3MtZHFKEmeddRZ3yWNugSwmicUrMRc5rXgaLQVIUpZEFSmmoDLlYcaMGfz7unXreDwR2y6xZs0arngw5YHdW/m/FStW8DYW6SdeoL7/rA8yevfunbadKUVSf7R6TQAAEEYQkwQAACFAbjGS2LNnDxfsmXLE4nyYVYdZU+bPn0/33XcfF0zNyM3N1dwuktjUybFBwJIJsCQKLNnE6NGjeUwMi6thcVzHHnssj8limfRYHA3LSMf2YVYRlh6bbdNbr+mII47gfxcvXsytZlqw3xgsFbgEqwtLrsCsSaeeeir/y+J5rr766uQ+7B6yejHlTqu91XXS6ideoXf/zfqF1WsCAIAwAiUJAABCCnMdY4H6zH2JWUYkNmzYQGGAZTdjShsL6lejtc0OBxxwAP+7atUq+sUvfqH4jW2TfpdgiuRf//pX/o9ZNAYOHMiVIPl6Vczdjf1jyQVYYosbb7yRPv/8c55gQIvTTz+du+qxfR988EFNwZ+tfyVltZNo27Yt/84y873wwgvc1Y65O8pdE1l9mXLBEh+w7HmZQCZeEwAg+4C7HQAAhBRJGJdbburq6ug///kPhaV+LG6JWW62bt2qUJDcWi+IpcpmytiwYcMUbnGsfOa6xWKTGCxGq6amJk1YZ+5v0nHMTVBtBWNKFMPI5Y5Zg9j6SEwpY0qSGhYXxTK8sdTiTPmSw1zrWNu88847tGjRIoWrHYNlGmTtyFwA1XVj35mSHDUy8ZoAANkHLEkAABBSmIsWiwFia/D85S9/4S5MH330Uajc3Vga6DFjxtBpp51Gf/zjH3kyh9dee42v57Nw4UKhMlgShSeffDJtO1tbhyVsYLFGLFkBcz28/vrrkynAWVrvu+66i++7evVqOvfcc3myAObyxlJ1Dx8+nO/L0mUzPvjgA65gshgvpkCxOKK3336buzMWFBQY1pGlwWapq1ldWIwRi21irm8sPTizUjGXPFa+GlYuU9SYksUUB3acHFYPdu0PPPAAT0fO3PnY/sxayOr/hz/8gR8bJTLxmgAA2QeUJAAACClsLSKWiY25jv3jH//gChNL2sCUAWa1CANssVBm1WFCL4sBYkH9LH6KWXlEsu9J1jF2rJawzZQktlAus+Y8++yzPBaLubExRYcpLFLGOnZepkCNHz+eK5JMSWKJHVgckKSYMCVr9uzZ3LWOKU8s4cCgQYPok08+4a5hRjAFh5XF3OqYVYjVl9Wb1fGRRx7h94jVSw1zR7zkkkv4OZjVjVnFtBQw5pb24osvcuuLdD1sTSd2bBTJxGsCAGQXMZYHPOhKAAAAyCyY9YBl5mNxQQAAAEDUQEwSAAAAR7A04HKYYjRixAg6++yzA6sTAAAA4ARYkgAAADiiR48e3CXu4IMP5usWvfHGGzwRAovhYWvlAAAAAFEDMUkAAAAccf7559Nnn33GF25li7qecsop9PTTT0NBAgAAEFlgSQIAAAAAAAAAGYhJAgAAAAAAAAAZUJIAAAAAAAAAIJtikpqamvhq52whO7YQIwAAAAAAACA7icfjfDHxnj17Uk5OTvYqSUxBYgvYAQAAAAAAAACjsLCQevXqRVmrJDELktQQ7du3t1VGfX09jRkzhq8Unp+f73INgQTa2T/Q1v6AdvYHtLN/oK39Ae3sD2jn7Gzr8vJybkCRdISsVZIkFzumIDlRktq0acOPD/rGZjJoZ/9AW/sD2tkf0M7+gbb2B7SzP6Cds7utYyZhOEjcAAAAAAAAAAAyoCQBAAAAAAAAgAwoSQAAAAAAAACQTTFJAAAAAAAARJHGxkYezxN16uvrKS8vj2pqavg1eUlubi4/l9Olf6AkAQAAAAAAEDIqKyupqKiIr+sTdeLxOHXv3p1nm/Zj3VKWJKJHjx7UokUL22VASQIAAAAAACBEMGsLU5CYsL/ffvv5olh4SVNTE1f69tlnH8MFXN1Qxurq6mjHjh20YcMG6tu3r+3zQUkCAAAAAAAgZO5pTOBnClLr1q0p6jQ1NXHlpVWrVp4qSQzWXizN+KZNm5LntAMSNwAAAAAAABBCom5BCgo3FDEoSQAAAAAAAAAgA0oSAAAAAAAAAMiAkgQAAAAAAAAAMqAkAQAAAAAAAFzh17/+NV122WUUdaAkAQAAAAAAAIAMKEkAAAAAAACEGJYOvLquIZB/cRcXs500aRINGjSIWrZsyRd7vf/++6mhoSH5+9dff01HH300T+PdpUsXOu+886iqqor/NnHiRH5s27ZtqWPHjnTaaafxNN9egXWSAAAAAAAACDF76xvpyIdHB3Lu5Y8PpTYtnKsMW7dupYsuuoi743344Ye0cuVK+v3vf8/XMXr00Udp27ZtdP3119Pzzz9Pl19+OVVUVNCUKVO4ksYUKebCx/b/7LPP+PpHs2fP9jRFOpQkAAAAAAAAgKe8++671Lt3b3rttde4ctOvXz+uON1333308MMPcyWJKUNXXHEFHXDAAfwYZlVi7N69m8rKyriSdcghh/BtRxxxhKf1hZLkIz+vLKa6hiY67dB9qV2r/KCrAwAAAAAAIkDr/Fxu0Qnq3G6wevVqOvnkkxXWH+YyV1lZSUVFRTRgwAA699xzuWI0dOhQGjJkCF111VXUqVMn6ty5M7dAse2DBw/mbnjXXHMNd9nzCsQk+cjfvlpM//fxfNpWVhN0VQAAAAAAQERgigVzeQviX8xDlzY5ubm5NHbsWBo5ciQdeeSR9Oqrr9Lhhx9OGzZs4L+/9957NGPGDDr11FPpiy++oMMOO4xmzpzpWX2gJAWAi/FvAAAAAAAAhJ7DmpUaeSKIadOmUbt27ahXr178O1PImHXpscceowULFlCLFi1o+PDhyf2PPfZYeuCBB2j69OnUv39/+vTTTz2rL9ztfERSxOMELQkAAAAAAGQmZWVltHDhwuT3pqYmuvnmm2nYsGH05z//mf70pz/RqlWr6JFHHqG7776bcnJyaNasWTR+/HjuZte1a1f+fceOHTz2iFmT3nrrLbrkkkuoZ8+e/Ng1a9bQr371K8+uAUqSr/hjrgQAAAAAACAoJk6cyK0+cn75y1/Sjz/+yBM1sPgjFmf029/+lv7xj3/w39u3b0+TJ0+ml156icrLy3nyhn//+990wQUXUHFxMc+G98EHH9CuXbt4LNLtt99Ot956q2fXACUpAOBuBwAAAAAAMpH333+f/5PDLElM8WGKEEvdrQWzGI0aNUrzt27duinc7vwAMUlBuNtBSQIAAAAAACC0QEnyETjbAQAAAAAAEH4CVZKY3+HFF1/MA7BYNotvv/02+Vt9fT33WWS50tu2bcv3YcFZbNGpqIPEDQAAAAAAAISXQJWkqqoqHrj1+uuvp/1WXV1N8+fPp4ceeoj//eabb3gmC5bVIqrA3Q4AAAAAAIDwE2jiBpatgv3TokOHDnxBKTmvvfYaDRo0iDZv3kx9+vShqBGDwx0AAAAAABBEvqYQ8Lfd8qKWc5255XXs2FF3n9raWv5PgmXSkNz32D87SMfZPV7tZtfQ0OC4rEzErXYG5qCt/QHt7A9oZ/9AW/sD2tkfwtzOTMhn/5hM27JlS8oUpSUej/NMd15TWVmZPKf6/ore71g8JCoqU35Yar/LLrtM8/eamhq+Am+/fv3ok08+0S3n0Ucf5av0qmEr8rZp04aC5JF5ubSnLkb3HN1AvfcJtCoAAAAAACDEsHWEOnXqRPvttx+Xk4E5TK2pq6ujnTt3UmlpKVVUVGiG9Nxwww3c+MJSkkdaSWIa35VXXklFRUV8cSqjC9KyJPXu3Zs3ltFxRrDzM9e/wYMHU35+PtnlzH9Npm1lNTT8/06m/vvbq0sm41Y7A3PQ1v6AdvYHtLN/oK39Ae3sD2FvZ1Y/FmLih+XFa+LxODd4tGrVyheFj8n8Xbt21TwX0w323XdfUyUp9O52rINcc801tGnTJvr5559NFR1mktQyS7LO7/QBcFqGdJty83JD+TCGBTfuFRADbe0PaGd/QDv7B9raH9DO2d3OrE6HHXYYt4xEnfr6ep7V+swzz/S8rVn5ubm5hr+LkBcFBWnNmjU0YcIE6tKlC0UZSZsNh+0OACBCTX0jvT99I/2iX1c6rFu7oKsDAAAgi8jJyeHWl6iTm5vLY/LZtYRRIQ2dksSCqtauXZv8vmHDBlq4cCH3wezRowddddVVPP33jz/+SI2NjbR9+3a+H/u9RYsWAdYcAJAt/GfiOnpl/Bp6duRK2vjshUFXBwAAAACZriTNnTuXzjnnnOT3u+++m/+9+eabeQKG77//nn8fOHCg4jhmVTr77LN9rq17wJAEQHRYVLgn6CoAAAAAIJuUJKboGOWNCElOCQ8Wk82s6wIAAAAAACCTyAm6AtkEsjcCAAAAAAAQfqAkBQDsSAAAAAAAAIQXKEk+EmtOAg5vOwAAAAAAAMILlCQfgbsdANEDcxoAAABA9gElKRAgdgEAAAAAABBWoCT5iGRIgrsdAAAAAAAA4QVKko/E4G8HAAAAAABA6IGSFAAwJAEAAAAAABBeoCT5CNztAAAAAAAACD9QkvwE3nYARA48tgAAAED2ASUpAOIwJQEQGfC0AgAAANkHlKQg3O0CrgcAAAAAAABAHyhJPoLsdgAAAAAAAIQfKEkBAG87AAAAAAAAwguUpEDc7aAlAQAAAAAAEFagJPkIvO0AAAAAAAAIP1CSggCGJAAAAAAAAEILlCQfiTU73EFHAiA6IGU/AAAAkH1ASfIRuNsBAAAAAAAQfqAkBQAmpgEAAAAAAAgvUJICANntAIgOWN8MAAAAyD6gJPkIhC0AAAAAAADCD5SkAIC7HQAAAAAAAOEFSlIgi8kCAKICstsBAAAA2QeUJB+Btx0AAAAAAADhB0pSAGBmGgAAAAAAgPACJSkASxJUJAAAAAAAAMILlCQfiSWjkgAAAAAAAABhBUpSEMCUBAAAAAAQecpr6um5UStpxbbyoKsCXAZKUiDudtCSAAAAAACiztM/raA3Jq6jC16eEnRVgMtASfIRONsBAAAAAGQOS7eWBV0F4BFQkgIAye0AAAAAAAAIL1CSAvC3g5IEAAAAAABAeIGS5CNwtwMAAAAAACD8QEkKABiSAAAAAAAACC9QkoLIbgd/OwAAAAAAAEILlCQfgbsdAAAAAEDmgHnvzAVKUgDgeQIAAAAAACC8QEnykRiy2wEAAAAAABB6oCQF4m4HLQkAAAAAAICwAiUJAAAAAAAAAGRASQoku13QNQEAAAAAAADoASXJR2LNDnfQkQAAAAAAMmcCHGQeUJL8BA8SAAAAAAAAoQdKUgDA3Q4AAAAAIPpApstcoCQFYEiKw+EOAAAAAACA0AIlyUfgtwoAAAAAAED4gZIUADDNAgAAAAAAEF6gJPkIstsBAAAAAAAQfqAk+Qjc7QCIHrD8AgAAANkHlKQAiEPqAgAAAAAAILRASfIRWJIAAAAAADIHzHtnLlCSAohJAgAAAAAAAIQXKEkBgFkHAAAAAAAAwguUpADc7bCYLADRAW6yAESfeZtK6fUJa6mxCe9f4C54R2QueUFXAAAAAADAS658Yzr/27ltC7p+UJ+gqwMAiACwJAUA3O0AiA54XgHIHNaVVAZdBQBARICS5COxZpsshC4AAAAAAADCS6BK0uTJk+niiy+mnj17cgXi22+/TVtP6OGHH6YePXpQ69at6bzzzqM1a9ZQVIHbKgAAAABA5oCJ78wlUCWpqqqKBgwYQK+//rrm788//zy98sorNGzYMJo1axa1bduWhg4dSjU1NRRl8DwBAAAAAAAQXgJN3HDBBRfwf1owK9JLL71E//jHP+jSSy/l2z788EPq1q0btzhdd911FNnsdph2AAAAAAAAILSENrvdhg0baPv27dzFTqJDhw500kkn0YwZM3SVpNraWv5Pory8nP+tr6/n/+wgHWf3eAlJOWpsbHRcVibiVjsDc9DW4jTFm5KfrbYX2tkf0M7+EfW2bmpqikTdo97OUcGNdpZPfON+RaNPi9YhtEoSU5AYzHIkh32XftPimWeeocceeyxt+5gxY6hNmzaO6jR27FhHx+8oYd6NObRo8WJqvX2Ro7IyGaftDMRBW5uzc2fiuWWMGDHCVhloZ39AO/tH9No6Ie6s37CBRoxYR1Eheu0cTZy0c3l5bjLq3O47IpsYG4I+XV1dHW0lyS4PPPAA3X333QpLUu/evWnIkCHUvn172xonu6mDBw+m/Px823Ubvms+Ld+zk44++hgqOH5/2+VkKm61MzAHbS3OF8VzaXXZbv65oKDA0rFoZ39AO/tHVNv6jhlj+N+DDzqICi44nMJOVNs5arjRzsM2zKAt1RW23hHZRH2I+rTkZRZZJal79+78b3FxMc9uJ8G+Dxw4UPe4li1b8n9q2A1xelOclpGbk5iNzsvNDbyDhBk37hUQA21tTiwnlZfSbluhnf0B7ewfUW3r3NycSNU7qu0cNZy0s7S8i1QOCH+fFj1/aNdJOuigg7iiNH78eIXmx7LcnXLKKRRl4shvB0BkiCF5PwAAAJB1BGpJqqyspLVr1yqSNSxcuJA6d+5Mffr0oTvvvJOefPJJ6tu3L1eaHnroIb6m0mWXXUZRJJXdLuiaAAAAANkH3r8AgEgoSXPnzqVzzjkn+V2KJbr55pvp/fffp3vvvZevpfSHP/yB9uzZQ6effjqNGjWKWrVqRdEEM9IAAAAAY/aG3fTN/CJ64IIjqEMbuCkBAMJFoErS2WefbbhmEPPzfPzxx/m/TAITWQAAALKda96ckfz87JXHBFoXAACITExSJgJ3OwCiB2IIAfCWjbuqgq4CAACkASXJR+BsBwAAAAAAQPiBkhQAmJkGAAAAAAAgvEBJ8hG42wEAAAAAABB+oCT5CNZbAQAAAIJ7N8rW/QTAFTDvnblASQoAPFAAAAAAAACEFyhJPpKcwYK/HQAAAAAAAKEFSpKPwMwPAAAAAABA+IGSFACwIwEAAAD+A0cOAIAoUJICCE7FIA0AAAAAEH3gJJS5QEnyEzxJAAAAAAAAhB4oSQEQhykJAAAA4CBeFwAQRqAk+UgyuV3A9QAAAACyEShkwG2yVabbumcvbd5VTZlMXtAVyCZiGJ0BiBww/AIAAAApmpridOqzP/PPyx4bSm1bZqY6AUtSAEDoAgAAAAAAUaS+qSn5eWdlLWUqUJJ8BO52AAAAAAAAhB8oST4CbzsAAAAAAADCD5SkAEB2OwAAAAAAEHXiGSzSQknykaraBv53Rwb7bwKQacACDAAAAKSIZcnCn1CSfGTcihL+981J64OuCgBAkEyeJQMgDGAiAkSZbPQOimdJdD2UpIB4cexqGrNse9DVAAAAAAAAwBaxDJ7kyMzE5hHg5fFr+N+Nz14YdFUAAAAAAIANsn0NzHgGG5VgSQIAAAAAAAAIEUNMEgAAAACAPwJXY1Oc5m7cTTX1jUFXCQAAoCQFDXspAAAAANmKFAT+8rjVdNWwGfTnzxYEXSUANPls9mb6dsGWoKsBfAJKko+cfHDntG1QkgAAAGQqy7eW07n/nkijlm4z3ffdqRv437HLi32oGQDWKKmooQe+WUJ3frGQGhqbgq4O8AEoST5yRt/9+N/9O7bOujSKAESVTA5KBcBrbvtkHq3bUUX/9/F8yvb4BhBtqmpTbqDxLE8Bni1ASQoYPFsAAAAylao6xBcBAKIJlCQAAAAAZAXZnq4ZACAOlKQAkJtmYUkCINxApgIAAAC0yWQxFkpSwMIWYpIAAABkM35ORCB+BAAgCpSkgMF4DQAAAAAQbqBgZ98EP5SkgMmObgZAdMF7EQBvnx88YyBqyI2fiHPLXKAk+YhWmlPMTAAAAAAARAdIbtkBlKSAwYMGAAAgm8FEPIgCehYjTHZnLlCSAkC5CFmAFQEAAAAAAACkASXJRzQnIaAkAQAAyFBgJQIARBUoSQGTLRlCAAAAgKBBkD2wixdudVF11YvHo38NIkBJCpgM7lsAAACyHLzjgBWiInC7oWq/9vMaOvGpcVS4u9qF0oAXQEkKmGgMBwAAAAAA3rFgcykNeno8fbdwC2UD/xqzmnZW1tHzo1cFWo+Z63fRac/+TBNWltg6PpbB1lkoST4Si/CsCQAAAACAV9z60TzaUVFLd3y+MOiqZBXXvTWTtuzZS7e8PyfoqoQOKElB+3IGWREAAAAAgBDQ0BQdiSg6NfWeeAZP9kNJCjhZQwb3LQAAACBUZLJAB7wlk93KgDZQknxEer7kkyXIbgcAyFYqaxuCrgIAAACgCZSkoIGOBADIQiasKqH+j4ymp0esCLoqAIAQEHY7DayQ2QeUpABATBIAINt58sfl/O9bk9cHXRWQRcBlCgAgCpQkH4k1z5PIZyMwMQFAuIFLLADeAsUle5m3qZTemLiOmiKUtMFt0PvDS17QFchG5EMBBDAAAAAAZCNXvjGd/92vXcugqwJAGrAkBQAsSQCAbAdDHwBAYt2OSspWMBaGFyhJgVuSAAAAAACUYBI1vGT7vYlnSWw9lCQfkdyuFZ0r2580AAAAACj4acl2enBuLs3asJuyBYSmgbABJSkA4G4HAADATwp3V9MLY1fTrspan8+Ml5wd7vxyMVU1xOh3H833/FyYrAVOiFHmAiUpAOTD0Z8/W0A/Ld4WYG0AACAAIJf5yjVvzqBXxq+hOz5fGHRVgAW81l9en7CWBj09nopKq709EYgs63dU0luT19HeusasG8qhJAU86C0s3EO3f+r9TBEAAIDsZVtZDf87c/0uChuZPBNth2/mF/l2rn+OXkU7KmrpX6NXUfBkZ08I+1X/4t+T6OkRK+mFsWHoI/4CJSkAYNoGAGQ9YZcMAAiIu79c5Ps5wyGVhKMWQJu5m0op24CSFAAYBgAAAAAAQBSJZ4kkCyUpgFXFm2BJAgBkOxgGs6TZYTIEmdFXsn3IimdhA4RaSWpsbKSHHnqIDjroIGrdujUdcsgh9MQTT8BdDQAAAAAARN6SAok2vORRiHnuuefojTfeoA8++ICOOuoomjt3Lt1yyy3UoUMH+stf/kJRBToeAACA7AAvPJAZhNvO5T2xLGyAUCtJ06dPp0svvZQuvPBC/v3AAw+kzz77jGbPnk1RROpfUJIAiA54XkEmkYVyDogI2SiER4l4Fr4LQ60knXrqqfTWW2/R6tWr6bDDDqNFixbR1KlT6YUXXtA9pra2lv+TKC8v53/r6+v5PztIx9k9XqKxqVHXTOu07EzArXYG5qCtxZG791ptL7SzPvLYTKftg3a2hpN2strWcsFK75h4vCntN6/uJXPjj1o/EalvVW0DjVxWTL84fD/q3LaF5XM0NaXfAz9pamxSdBa/6mKlPzc0NMiOa6CceJPjdwQ/PuC2l2NUj3g8LmsvZVuI1D9M47RoHUKtJN1///1cyenXrx/l5ubywe2pp56iG2+8UfeYZ555hh577LG07WPGjKE2bdo4qs/YsWMdHb98G5smyaXGJvZgKadMRowY4ajsTMJpO4PsauumONGWKqIebYjyPIiy3L07N/m82n1OM6Gd3aaqynm7qkE7m7/umTDsRnuLtnVtndF9TtRpx44d/LeGBvf7hPpcG9ZvoBEj1pnuXdNI9N6qHBrYJU6ndPN7Cj0lmjU1Ngq1xcdrc2jOjhzq1TZOfzum0fK5tm7dSiNG+Lc+k/r869ato9ramIf333l/Ltmbqu/oUaOS75vyCrv9Nui2V9ZDv/55/P89e/Ykf69tTG2fPHkSrWodrXG6uro6+krSl19+SZ988gl9+umnPCZp4cKFdOedd1LPnj3p5ptv1jzmgQceoLvvvjv5nSlZvXv3piFDhlD79u1ta5zspg4ePJjy8/NtX0/JjE00fOMqisVy0uyWBQUFlO241c4gu9r6rSkb6F8z19DgI7rSf24Y6Hr5n2ybQ1Reaus5zaR2dpuXVk+lHTXVrox/aGdz7pgxhv+N5eRQQcFQ39r68cUTqbK+TvM+S3Xqul9XKig4jv4+bzzV1jV68k6UznXwIQdTwdDDTPd/9ed1tLKM/SN64pYh5CdSXRk5ublC9+vex8YxlYqKqmKW2k46F5OrCgqOIb+Rzs8Scy0q30Kk01e8wkp/Xr+jip5aOI1/Hnr++dSyWUv6z/rptK26kn+OUtur66FX/zuaf+/YsSMVFJyUtFzeO/tn/vnMM8+iQ/ZrG6lxWvIyi7SS9Le//Y1bk6677jr+/eijj6ZNmzZxa5GektSyZUv+Tw27IU5vitMy8nJzdReTDbrDhAk37hXInrb+77RN/O/YFSWeXEtOTsrqa7f8TGhnLwMQ3GobeTvXNjRSy7zEmAuUuNHeon1aHmeit38sJ5b2m1fPS25OjlDZlXVNntdFFKvnt1PfHMF28Yqc3BxPxgQ3+3Nefkpkzs/Po/zk+BKLdNvLMapHLJZ6TvOb5NecZ6n+YXgfip4/1CnAmTmMdR45zO2OuQtEmSyMfQPAM/A8ATUvjF1Nh/9jFM1cvyvoqmQtczfupktfn0Y7KxOWgSiPF+U19bR1D/e1AgBkUUKHUCtJF198MY9B+umnn2jjxo00fPhwnrTh8ssvpyiTyR0KAL/xet00PK/R45Xxa/jfR79fRpnAfV8vpktem0r1LLg9Ilw1bAYtKtxDmcAxj46hU5/9mYrLayhTCcM4J5rcrrI2lTRAlL11jbaOs9pe28syuI9Q9hFqJenVV1+lq666im677TY64ogj6J577qFbb72VLygbRZDdEgAAgFW+mFtIi4vKaMY6WMa8oqa+kR7+bilNWr1Dd58FmzND6ZP4fPZmihrfLthC/R8ZTW9OMk++IZ9IO+qRUfw4dp9FYXE3n8zaRCUVNcIy3NS1O4XLB+En1EpSu3bt6KWXXuJxSHv37uXZT5588klq0cJ6eksAQGaSjbNbmYDXFkAArPDetI304YxNdPN/Z+su1ZFp3P/NksitUXT3lwv532dGrhQ+pqEpzrOgMrZYcJtklugHhy+l696cab2iGUhM9jnzn44IKEkAAGAGZG2QLeTKkohkEmG4qqJS85TAUVEkosruKvP4tbiP74uxK4r53/U7qwzPnS39Ik7ZR6iz22UaLDMIAMBdYJEA2UIO3iHAI4IeRt+YKO4+ZxXlU4P3BRAHliQAAAAgAuTlOleSsn1SQbQFY6GwbwE1drovJqiBXaAkAQAiTXaLfCDTaZKCKWBJ8pRsb9psuX4v5giyfN4ho4GSBACINh6/oPD+A0HSKJPA3AhJCuOsehjqJCLoBl9L4Od4jvstapHO3LcklCQfCcF7AICMI3OHZ+CUTJjhbZRZkjI1cUMYXQC1stuFQZnzihDegsD7VwY3CRAEShIAINJ4LWBlrlgEokCTwpKEmCQAgsKrd0FkdO949o0dUJIAAJEm+4btzAD3TYxssCQF3e+Ky2toUVFmLRSbsYJ6gHK+V2NW9HWPGGUqSAHuI5nbjQAIjui/YADQp6mJMl5JCtqN7aSnx6dtQ3a7zMTKIsHoASp0n9PMfQnDkgQAAABkSeIGYJ9Mbn5MNgFT4tnXSaAkAQCyZmbQXvkAhCMmKWiLSyYQC8m4kkk0NMrMndmYAjxL+sqiojK69aO5/HN2XDGUJH/BCw4A18nCyS0gSLYIL9lIZW0DLdhc6msiCrzC03l/2gbq99Aomr1hN0UBre7y3aYcem3CuiCqEzlGLytWrN2W6UBJAgBEmuwZrgHITOzoHpe9Po0u/890+nbhFg9qlH3YVQAf/WE5NTTF6e4vF1IU3xFb9uyln7fm0Ms/r1MkSbFCtsWvxbLocqEkAQAAyEiyTXjJJtaWVPK/3y7YGnRVMoJstcjvrWsMvL2ySemIGlCSAADRJktf7lHHD6EsE9zt5O2UqYJsPCICJoRZfaLSN9Vjgvwbbi9QAyXJR/AAAuA+mSAIA+AXmfa0eLbAJ97Y2aHMySch/K5MRIlnUUNBSQIAAABAYDhRR7zK+Kc1+ZLJilO2WskwyWaPeBZYuBlQkgAAkSaTB2gA3CbTZOFMu56gyNZx1Oi6RRVwp4pWtrZ9FICS5CPZOlMDgJfg/QIyGcx0G4P3KnCikBg9XX6mlwfhBEoSACDS4EUGsgfnfT2MTwsUHeegDfUxekUo3caMnw68arKv70FJAgBEGry3gB4QarKBWEaeyu++nsmCbtgttVFr+7j6e/BN6BlQknwkk4M+AQiKTB6gg6Bsbz1NWFlCDY1NQVcFgHClAKdoM23tTrrwlSm0pKgsa8fRtBTgNmOSwqBcAe+BkhQixq8oppvemUXbyvYGXRUAQJZyzbAZdMv7c+jNyes9PQ+EDEHQTJ4qLtKitFHl01mbadTS7UL73vjOLFq2tZxuencWBUFNvb2FWz2NSYpnrsXHU+KUFUBJChG//WAuTV27k/4xfGnQVQEAZNnLQGJVcQX/+/3CrUFXBXhApsl5TgTXnZW1dN4LkyiqrN9RSX8fvoT+7+N5lq3FfvOv0auo30OjaPranRQkhokabJQ3fd1OWl0cbUUb6AMlKYSD+c6qOq+rAgAAIAvJMp2fM255seL7y+PW0KWvT6OlW9LdzqLEbgNZgVltmFtdWBLbvDZhLf/7+I/LKUw4tWjf8LZ1q9zmXdX0wfSNlCnEKXPJC7oCAAAAADAnJPJu5GJ9f/fhXMX3F8et5n+/mFNo7VwB+lvVNTTRzf+dTccf0InuGXq46f7Xvz2TFmzeQ/+86hi6+oTevtQxCqiVxqa4/8/fOf+eSI1WThwy4joNsbakgiau2kE3nXwAtcrPpUwAliQAAAAZKfBHVwzJrGvwkhwHUky9QXKSsCmko5ZtpxnrdyUtMmrU+htTkBhfzrWmCNolLBYrJ9Yivy4hygqSFlLXO++FyfTkTyto2KR1lClASQohmeYzDgCIHkisAKLw1rOcNVa2e4jlek1Lkhp59aN0LWEizMpdVFnQrKBnAlCSfER0KMcjC0CIwKyFJ/jhuYRblwU4uMl412Yfbq3xk+26VVzWkpncFFCSQgJmMwAAwF0wqgKjThGzqMRnstLtV7hV0KJOWgpwg33VTYIU4GJkUjtBSQoJQQ8cAAAdsvTZ9Hrxa4x51tsJTZZOLEuEP61Tu1md7Hke1YvJyi0iqt98q1O0iJv8nkE6EpQkCskAG8/QDgYAAAB4hZOMc1ESguMhV/biEbUyWGnX7FEkgQSUpJAAdzsAQJhA4gYQBWIeHRuFV7JictVCQwR5baFzt4vAfY4asbBpwg6AkhQSFFlqmv8W7q6mBoMUpQAAEFUgnARDprW7E3ksSk3htdjpVK6NRbTPKxIQxKNzTcAfoCSFxMe/SfV0TlxVQmc8P4F+9d/ZPtQMABBF9lTX0XcLt9DeusagqwI88i6ARS9EMUkhFpudKr+Oj6doEoZJg/D2qnC3mx9ASQphh2MPzIczNvHP09ftCq5SAIBQ8+v35tAdny+kx35YFnRVQkkQbszsnNPX7aRdlbVpv9XUNwotJFnb0EhDX5pMd32xUFU2UdneeqqqbaBMwlfvnFi0hVM3CNIbKmilP4yyfRjrZEQ8ahV2AJQkAAAI8UvdiIWFiUX7vlu4NXKz5n4KaiOXbKOv5xX5c66l2+mGt2fR2f+aqNheXlNP/R4aRQUvTzEtY/LqnbS6uJKGL9ii2L63vpEGPDaGjnpktO36ZVC4gKeJGzRTgIes7USqM2djKf35swVU77HrvhXBedranbRiWzkFgbqeai8e4XIouyea6mT9KZPdFKEkhYT0YMJseQQBANmoHPo1xDU1xemPn8yne75aRMXlNZ6fb9yKYv63okZp7Zm9fjf/u6q4wrQMvfGfxak6JRNeLVv27PVcIItCO4lW8YdFW9MUbiswy+aSojJX5JLNu6vpxndm0QUCkwVqpq7Z6fj8RtfAFKbPZ2+mtSXaz2jYlGSn4+LyreWGlu3ZG3bzSRk1u6vq6KSnx+sel0ntBCXJTwxTgCM/PwAAuI18LK2oqaeokUnrJJVUuKOknvbsz6kvThI3REETEsRMMC3fa7/v/+HDeXTxa1Pp/ekbbZ1fsngzaurtW7T+8vkCcht5F2DW5vu/WULnvTDZdN8osXJ7OV386lQe6y7xzMgVVPDKFHrix+W6x/32/TlUrprsYYxYsi1jlSI1UJJCgoCbOgAgAMIcrB0Fl0DgDVEU8L1IMOLn8xn+kcAbJq3ewf9+YKAkGXXHbx1YsdwmbiB7LdycUuYyCabkLtlSxmNYJd6esoH/NVJ8RUm/95nzpEBJCukLL4LvPwAACB1RVCaAh8iTJEVoCtysqujmzgmqCWM+ZEF1kzhlD1CSfMRw4Tof6wEAyCyiYO0KgvRx1Yd2cnkwLyrdmzEKnxfVd7ROktUK4THLOIys8BHSoX0lHvFxyApQksKYAjwGpQkAIA7c7TILuYXj/m8Wa+6TSXKKE1nUKzk2bAJyJt3vcCXJCqomESAWdAWCB0pSWJAH58azS1MHIMxAAYn2O17pUhWNeykf//dURy/ZhJ9YVmYE98crODNJS5JlcKOzvg/EM2OCwXclqbCwkIqKUmtOzJ49m+68805666233KxbxmHk/wxBDAAA3IWNqpk04ZRBl+Ia2eJqGnbBMzIyjNqSJP9s4QFzc1yJSMsJE/Ku6r2SdMMNN9CECRP45+3bt9PgwYO5ovTggw/S448/7nYdswKvs9tlkqAAQNRZXVxB70/b4PkCjyCar2/5hJre2I0R3YWYJKvnCnH/CbsSFVayQTSyfYmx7G0zR0rS0qVLadCgQfzzl19+Sf3796fp06fTJ598Qu+//77bdcwK5C9Ctwe7T2ZtooGPj6VFsrUKAADBMeTFyfToD8vpwxmbgq4KCDnxLLgWJ+88R8f6eC4vyCZh1S3UTRaP0P2OCrFYlitJ9fX11LJlS/553LhxdMkll/DP/fr1o23blItMAXvZ7dwc/B4cvpTK9tbTnV8sdK9QAIBjFheFd+IiUwSwDLkMTlOm3BQV0mXZS8mdQRKZA6x0jWxrMaO2kU9QZ2oKcLfLj8Ui6mrpl5J01FFH0bBhw2jKlCk0duxYOv/88/n2rVu3UpcuXdyuY1YQVydu8KDTweUOAAAygyiO5zEPrslPd7uwkUkz9oEh6wTfLdxKmYjdfh7TKy8eXbdUX5Sk5557jt588006++yz6frrr6cBAwbw7d9//33SDQ9Yww9NPOovBABANNafyVQhP2ywmLai0mrH5eyuqqMdFbWKbVW1Dfyfm3hxx2MO+tPEVTsoE1m6pczw92x+8tJSgAdVkQgQ192ePa1mS0liytHOnTv5v//+97/J7X/4wx+4hQm4sE6SB33QqMyfVxbTyu3l7p8UAACCgi+nQJFGXv9GVYafq4fNoNOfm0Az1++yXT4r87gnxtKJT43j7p8PfLOECndX01GPjOb/GlxOLrJgcykNfmESTV69w7WYpM27qmnQ0+Np2KR17lRS71welDlvUyk9/F3CJV6L2oYmqqipp58Wp4cy6PXti16d6qhOZdX1vE2jQmVtA23dk1p02Qi1gG/NhTVuuV5uwJ7RscuLqaSihsLI/E17aMW2zJQfbSlJe/fupdraWurUqRP/vmnTJnrppZdo1apV1LVrV7frmDEYvQj8WOBMT/tns06/eX8unf/SFPdPCgDwHLjdZG47yS0kf/s6tbAs27qwORnPl3MLbZdf29CY/HzJa9Pos9mb6YZ3Zia3VdQ0uHotv3x3Nq0pqaRf/Xe2a+U+PWIFt4Q9O3IlRY0r35jOE7hc9vo0XWvYNW/OpPErS5LfRy3d7qhvm+064PExdOY/J3BlWZQgJyOOe3wsnfrsz0KKkl/1/G7hFur/yGj6z8S1jsv6Yk4h/f7DuXTuvycZ7jdiyTY6/6XJtLakQrHd7rAXE9zv78OX0AUvp+TH1arzZ52SdOmll9KHH37IP+/Zs4dOOukk+ve//02XXXYZvfHGG27XMSsI0nzJ0hGDzGRvXSPPbritTGyWDQCJqFtggiITmq1wt3fjhVuz6/L4h0xIaLFhZxX9LFOE5Khn6b9yoBRbYf7mUgoKtaBvJLTXNVs752zczf/+a/QqOu+FSVReY38hZjMLqlmP+9tXiQmN50etIqdI/cJswuK2T+bTyu0VdNcXi6ipKU51DYlrcPvpiJsUuH5HFY1Zlq7IZ42SNH/+fDrjjDP456+//pq6devGrUlMcXrllVfcrmOW+sl6kbiBIs/GnVX0+A/LaXtZOM3OYeO5USt5dkM2Qwwyl0x4tkHm9x2z7HV2stv5aR20l31PnEyNkbLDHZ+nZ+MV7aqvTVhLa0sq6eOZm2zLU1/OLdLYGg1TNHPPvPyN6XTs42Oous7dSQlRvpm/hbJWSaqurqZ27drxz2PGjKErrriCcnJy6OSTT+bKErDhbhfgyzDsLijvTduQNFlfNWwG/XfaBip4ZQrV1KfcRPyC+dMPX6A1eIaTiasSM1DqoGwAsoUoBhnHMlQx1nMnc5INK+SvL0/7qvzdbaU/RKHr2EkaolZimTXF7nIrhTwhSiwk4461shrjcb4uZlVdI495s+1uF8ukp8seeXYOOvTQQ+nbb7+lyy+/nEaPHk133XUX315SUkLt27d3u45ZgdbDDIibix/7YTn/fNVxvWhnZW0yG1PBy1Po/P7d6fgDOtG5R3TzvC53fbGQhi9IzI707tSGTjiwM4UdDHIA+IvbT5zQm8HB6yMMQ4QkUNpLAR7z7RrC0FZyLClG8ex7fzifSIimXNbU5M5VxB00YMS7jjNL0sMPP0z33HMPHXjggTzl9ymnnJK0Kh177LFu1zEr8Sa7XfQe+AbZ086y/MhZv7OK/jNxHf32g7nC8TlO/OglBUk6dxTIkHHKdV4cu5q+mLNZaN8IPjbRSAHubfG+nSPq+Nm/cT/CQcwDmcH1uBeXy9O7JmvjXDR6sNcxenGBfbJaSbrqqqto8+bNNHfuXG5Jkjj33HPpxRdfdLN+tGXLFrrpppv4IrWtW7emo48+mp83ihi5FChSgPv8KIZ54S95ytvcHPv1ZIGuRz0yikYt3WavHo3RGByBOSye7eXxa+jJH1cEXZVQkynKod/XEfepQL/cCDOkG2Q9mSC0xtxwUxUNQ6DoIpebHLmyxqLcCgEqSYzu3btzq9HWrVupqCgRo8GsSv369XOtcqWlpXTaaadRfn4+jRw5kpYvX86z6EmpxzMJ+QuPf/IkBXi0zcZ5DpSkJVvKiI0b7K8dmI9vJMEYl4aU8adGlvoYZCaxbHkcPLwwrXTTblfTmSAX7ok+K4i+ZrRkV6fybNyhkByGOyBUXUuv8jBclXUyIdtjpJWkpqYmevzxx6lDhw50wAEH8H8dO3akJ554gv/mFs899xz17t2b3nvvPa6AHXTQQTRkyBA65JBDKNPwo09H8cGRKyc5DpQkqRi76yKqF3GMCtEc4v15DqJ6T4E4abPGAdUjynwrczN2ihft76eChPFUH7jPhgevX21xgfIzZeLCVuKGBx98kN5991169tlnuaWHMXXqVHr00UeppqaGnnrqKVcq9/3339PQoUPp6quvpkmTJtH+++9Pt912G/3+97/XPYYtcsv+SZSXJ9YXqK+v5//sIB1n93iJhkb9mes6WdnMZ7YpnpLmnZ43Va52WfJ6uXUut9q5tq4u+bmxQT/bjVm9G5sS11jf0GDrGuX1YDQ1NgbaVnYGM3l93erTItQ3NtH8zXtoYK8O1DI/V2HR+WDmJjrj0H2pX/dEtkyrqBUdkeuRnjV2aF1dneZs6R1fLOL1+88NAxU+7Fbby6yd2aSSW/fA7XvJrtvL/iFv1/kbd9LR+3ewXZZeO6uvoaHe3vNvBflEoeLcjanxy6wO8n2bdETD+jrZO8NiP1KOBcZZxNi7yK2xg7W/4Tlkj6Jo+fF4k6X3JWsrM1gZjRr7Ndh8f4giOh6wRE9sP1Yfu/JH2rOicW72zpVv05MhpB/1ftNqS606KItLL08dT5ReX+V7mZ2Xfa+TpcFmz5ZiHx25rJHPqCrHfvmzwp6/+lyt49L7iNk9le6n0e+iZanbWz6WiBwv/z2mV76BLCt/LvXaIQyyk2gdbClJH3zwAb3zzjt0ySWXJLcdc8wxSSXGLSVp/fr1fHHau+++m/7+97/TnDlz6C9/+Qu1aNGCbr75Zs1jnnnmGXrsscfStrOkEm3atHFUn7Fjxzo6ftEO1uVytVM1T5qUvB17Svc0m40TXXTEiBGOziuVyxRYrbLk9XJ+LufI27msLlX/8ePG6XZZs3pv2sSMpjm0bv0GGjFineU67eF6d+rcixcvptbbF1HYqarKNexHVvs0ux//XZVLp3VvokH7iU1XfbMxhyZty6FjuzTRrw9LDd7jtsToh8259PzoNfTyKfbWchhdpHymRPpv8d7UvfxpxEhSGyhrG4lGLE38/um3I2l3qXEbipDezonymbvyiBHiKeWr6olWlcXo6M5xys9JlcOUdjee3cS7OFFmZWWlp+NBTU2qXe//bAbdfqRzL4RUOyeuoaqqikaNGp38PnnyJFrZmjxly5bEWMOQt9/S3eLjrHzfhCCcLq6MGp26rqKiLTRihNkCo6nxS35+1t+NRIHdu0ttjh3pZU6aPIlilEtx1fUUb9/Oz9HQIPqspcresGED7ebjc3qba+2/bt16UycaVsamjan7KDFz5gwqXkYuk6obi/UeMWKjqWhWXFLM67iOzwHnJRUEI1vXihUrkn2KKRuJdkqdRzkWJbYvXLiQcooWpJ6n6iqN9m2WL2prde+ZVlsy1HWQU11VnVZefV2qf6SOT9VhwcIFRIXx5PfVq1fRiOqVij4+Z85cql6benct2qUtl61bt45qa2OK/ih/d4wZO5ba8I/K+i9etJhabWOLuRr1ZeUxW7caP7/FJdpjSjrN94JPoCTOPXv2bGqoz9Goi7ksVadqb4mVq1bqyrIS27ZtoxEjtngiS7sBW8rIMyVp9+7dmrFHbBv7zc1ZlRNOOIGefvpp/p3FQC1dupSGDRumqyQ98MADXKmSW5KYyx5z07ObnpxpnOymDh48mMdH2aVh0Tb6aO0Szd/OPPMsenphYsHPTp06Uk4sRhsq9vDvBQUF5IQ7Zozhf1u2bEkFBWcb1svpuZyg1c5b9+wlmjeFfz5v8Hn097kTNY81q/eM75cTFRdRnwMOpIIC63FzW1g95ifqwTj6mGOo4Lj9Key8snYaFe+tSmsju336nq+X0MbKbbRxbS49evMQoWPueCjR/xbsyqEvC85Pbh/5OVMyi9PqZoWHn/6Z9eDkd5Fy1pRUEi2czj8PGXo+tcjLSVuf497ZrFyis885h37YucT2s6huZ2b5Ym1IlIjz6NmzJxUUHGNYxuKiMrrt04X0t6GH0WczNtGSLeX0y5N608MFRySf7ZzcXCooGEpO+XbhViai888tWrehgoLEouES28traNraXXTRMT2opazd2Foc+7TMo8NVFkFmQdx3nxbUp3P6BNUzyyYR1SWs/vvuuy8VFJxgu97qdpbapW3btnT++afQ32aP59/POussOmjftuQl479aQrRzW1p/abmyhN5etVCxnS302DIvNy0pTatVO+jtVUw4JcrLzaNajZnb84cOpXtmJa6LTVAWFBzNhV+9OBKpTdT1kvd3LTp37kQFBYOS38ura+iZzyfQ/11yOh2wr74FWH4+ibPOPIueWTQtzW+KxTgXFAykv88bn7xWVke2Fl5h6V7q23Uf3bIPPuggarFnLy3eXaL7jMr3P+SQg2n8VqaI6MPKmPvTSqLtygyYp5xyKh3XpyO5ibxuffr0oYKCIzXbTk7Xrl2poOA4mrOxlF5ZNic5BpAqA6ycI444gr7btJp/Zn2EXaP8PD1kY5G0feDAgVRwTI/U89SmLRUUnG5JvmBotSVDXQc5bdqmjz+PLZ7AzJGK4+V1OO7YY+mC/t2T3/v2PYwKzjlE0ceZTHnO4fulCl28lWh1YsyTc+ihh9DC8i1UUV+XPNe6HVVJOW3I4MHUvnVqrJE4ZsAxVHDs/nTP7LHJhE/qPqk+Rnp+9fh293xaVrpTsyytcnNycpOxBScNGkQfrV/EtGjNNlMjL//hhT8T7U2fwOx3eD/6cfMaMqJnj/R3m1uytBtIXmaeKEkDBgyg1157jV555RXFdraNWZTcokePHnTkkUemPej/+9//dI9hDyr7p4bdEKc3xWkZeXm5Qr/xl5zsRedWZ2Kzd1plyc8ddMeV6iDVIyc3NSDm5+nXzazesVizQBfTbgMzcnKUptnc3NxQtJUZTNmW0Kqv1T5dmZiS0y3PDPkx8hgzu22p9o0WKSc3NzXs5eTmUb7MBZDRIp6qV15enkLotFtPqZ3HLN5GPy5JBcKzRbjNyrzjy8VUXFHbrFwl+H7xdnri8tRYy5rBjf742ZyUVYtdt7rMS16fQKXV9VS0p5buGXo431ZcXkPXvZMQ1DY+e2Fy37UlFXTt27PTtsvLl8iJmbeDCOr+rL4Gdj/Z9xfGrKKflmyjb247jTq0dvc51uvXTNmRb2drvR33xM90VM/29NNflMJgLhNymtGz1+YpnqUcuvOrJbRiWzkNPqIbnXrovnTWYTJBUIW8XvlNxrED6nvz8oSV9PWGXBrz5hxa/Gi6Yj5yyTZ6d+oGnTrn6Y7Pq0qq+eKX8jpe9NoMWlVcQe/dciKdc3hX7TLzcnkdta5N81w55qHYrIxcjf3YueTls3itNyevpzdvOp76dHHmqSI6HjBym/dj/VmUPKZEyVCfR+vcuc3PiwR7ZPXqpzVeyOurhdG1apWnjnNR/y493+r3tLyPq9/d7LsWrD3kVpREe+cqnj+t+rP3C9sufzeV1Tbxkrrs01L4WuXLVUxYtVP3mrWQe6Hnq/qI2fHq8VOLnFzzZyiWo39NbsjjThE9vy0l6fnnn6cLL7yQxo0bl1wjacaMGVRYWOiqewaLd1q1apVi2+rVq3miiEzDn5wK0Qt7lCebcFL7uMNgfXV2u6iEJLqdwTNsyT/iDq9BK2uh/EXs9uVW1tbbiukKy5pnTEFiTFxdklSSikq5D0oay7Yaz9T5dQmK5RWaH4hXfl7L/34wfSP95dy+FAQTV5UItZMoPy1OWK/e3LGeC+5aiqkbTF27i/8tr9F2kf3jJ/Nt3fPHf0wsGi6HKUiSMqKnJMUsjnNsCQARPp65SedsKe78ImEZfPDbJTT4yG40dnkxvfnL46lNC1uiVeosMbHnQz4OWGkDLeFX63Arrw87z7PVccyNIcO1ccdCOSc8yUIFiNY+dQHlGSgY5TX1tHlXNTU0xWlArw78PrHlKkK3TlLcfB9Wd3Z/2fqWrVQTkRmf3Y65LDBl5fLLL6c9e/bwf1dccQUtW7aMPvroI9cqd9ddd9HMmTO5u93atWvp008/pbfeeotuv/12yjTUsrsXQlDI5Fsh3MpAJl273cEDmdASuNkKrmS/iTtUkkzuq9fPjEj5cmugHl4o7VEcL9Sox1H1dyaMuI0ba4vIixAqzcEp/b7NmsJ4jGhnRa17BRrwHXcpNUerb5SU19BZ/5xAb05SxrUyd66Hv1tGU9bspI9maClXwSPv+lryBXMpL2ueBMnkdXPcynj5uw8T1nM9tJqqut444cHxT4yli16dSpe9Po1+XpmYRDFS9n/3wRyasmZHKOWVGBH96r+zqd9Do6ikQmxiIqPWSWK+9CxBA3N9Y/+efPJJvq4Ry3rnFieeeCINHz6cPvvsM+rfvz9PMf7SSy/RjTfeSJmGemFAL7p48I9NgEpS89XbLS9sFhRR3E7DGYKxV4Gd6shvpTxrUKpM7y7STjfSUpK8qmEmCEGZRlykL3n5XKq6RNi6iJ+phl8ct5o27aqmZ0aywHVt5C6DXuPm88riCgc8bhwL5fbkrVFxWr9ZXUzWaXWNmpfFgxlh59z1skXrRy8zXp/sweFLaNyKEvrluwmXZi+IOTj2+0Vb+aQB48dFCSt3FHFmE/aBiy66iP/LBIwGtIjK4J7j1iKuWbtOksvyQ1BuXm7Wx8zdTjHj6vHUgsj90dxHbXl2rUbyMsN1r724Dm8scP4Jkm5g2gZpXg7e1MOoWFPh2Cc9aXVxpeZ2/z24Qqaphhw7fUvU5dEKbt61bYJuo1GyMmeUJQm4ix+yp97LO8yzx3LlxInwEXdYRlSVJLeJZ4ElSU4YbnuIH8/IKWFhHuuCIgRd3NHYHLpb6ssgaTy5E5XnIB4GF1wKHjv3w+iQMFxTmOtjBShJYXW386BXRbGjCqz7J1aOlLjBZsOGTTkIirBZF+zcF7klSSvuQOHFFHf3iu3IJn6624m6MWXKauohkRUj9Sw6bTPNpAEOyozwLXR8TV5b9q3dF+/7Y9xifbWekSDfYGFRTkWJRcSjJDTudiw5gxEsgQPQx+jxUPc5L7qg2ax5JrvbSQ3qVna7qOD2oOyW0uoWdmLF5F1Aqz94+QJIe85tJm5Q1zFar15/FS2rcQ/Zhr99x4tEGRQ4in7kQoXstJKV04qOcerd7L5P9M4XdmE7qu7qIW/WzFWSOnToYPr7r371K6d1ykrSOrUX2e10tofgHeND4oYEyG4XotnrgDqe/EWl1R/8iod38qJOGy4iaKnwwxIShvvnVADz/j6Eg7gDZTtTLJsQbo2xepe1+oVvSw9QOOBtEHBlYpQlStJ7773nXU2yHPmLMDFbA387N7PKOV0nKbrZ7dzFTV3RjbrZqY6ZJSls7izaliSP6uPDOcKEF1YI0WYTbV+9/bLh/kTSTcmFG2MuAcTS2sWLmKQ09zXbcWPa54u7PjkQEygjuAdH78xht6g5JcpXh5gkH8mVrcRudQ2DbKVBlhLTSatIx7qV3S4qL23Xqxmyruk0u52mJUntYkLBojVseGVdCNntdUzQ9y4jUKcAd7c4QbdI/R8jMhR7AmSFaOHm7RLt93y/LH5GnAIlyUdaGKy07I/7TDZbkpyVF8V4Li+IqkVNfzFZjR0UExYUOGF0JYqKYMpunyJcxIe2jfnUvh/NdGfR0qgL2jGDia3PZm+mtSXaabvdRN6CdbKJPT8J813Uj0nSP8bOs5lu+TI+v+8EUA1+6TbPW6qzuHBYmtMPQr9OUibRIs9ASZL1Omal8OKh1k8BTqHFrVigZHa7rEvc4G55YWsFO7dFfkyDRiYKuZXGwfvFcl0sxST54G7nBbsqa2nV9go65ZAutKOi1uOzheNlPmfjbvp5ZUm6giYck6TNswYLmoYVK/ejqrZBzHKv89vnczbTg8OXkt8XNmzSOvrrkMMo32BS1Pyd7MEiPSEkiAyNTprV6S3Ru97C0r1U1xCyrEgGxCl7gJLkIy0NlCS17O7F4BHFjo3EDeEibJakJqfudibvpTBcbmApwD3QmM59YRLtqa6nX596oC9rUG3eXe3pNW7eVU1vT1lPvz/jYOrTpU3a76VVdXT1sBma291Ucr5ZsIWijvqdN/DxMULH8VuocR8XbA4u225xeQ316pTeH+SMWrqdHhy+xFb541YU0wfTN1K/7u3IS2rrlQOkkbIqjZUfzthIn8zcTB/+dhB1a9/K8DhDF8sMdCnWu955m0rpmjdnWLKkiVra1O52X88roquO7yV0LIC7XWgsSb6sMRACgc/ZYrIOCmo+NvsSN8RC7FMdCz5xg0lMktcznUKJGwIapb3o8kxBYrw/fSP5hZFV3uk13vTuLO72dsM7M1Nlyn7fVaVtLbvvf4upuNx7S5oIfo5srL9r9Xk2TqnvRb3Mbc3oMVGXx2bkv5lfRNvLaihMfD57M/36vdlUXZewkP3fx/NoV1Wd7bvxyPfLaO2OSk+twH/9apHus1S4u5rKNNyxHv5uGa0qrqB/j1mleZycfg+N0j23HUtzzMN35/gVxXTzf2c7KtPo7i4sVCr1rr57ZEXdo7qntoqLU9YAS1Jo3O2Mv2dbzIPbbm7SgGNbSYqOJTwj1nnwazFZzXWSHJbvy/PpURCjvL+E4drDjmSpKirda+m4BSqByJB45owpdvuUlcPemryO/jVmNQWJ1nXe/03CavTulA3053P7ujrpwM9J/sEUpDOen0Ddmy1FWtQ6dB+rqW/i47NRwis/++BvP5jrwrm9uUu1DY3UMi9X87cwSHfxCL9MYEnyEb1OrCnzxDNnhfZQuNs5TNwQ1ZgktwlzKwjHeJhkt1PuS4Hja3a7gK43qLjIMMdjRnnc9hP1KkmTVu/wvQ5W7lB5jXYwfJT60ehl2/nf7eXeWuuY8O91OxhmTnT93N6MXR/NcCeJC0gHSlJIYpL8EE7CIPB5pSSZzVRIP9u3JEWw8TxZJyma7aBnFZSnmNfqS24LqHYmQ4TcEn0W9l0XHqLfrSKLadt74/VjqR5W3O2CwO3+6/UlOS3fqpXIryUz1OdxelscefgLLC/hloePqWtpCJ6RqAIlKTSJGxCT5KRdzHSYZHY7m22gtiRFZsxx+eXkVR9ywxwfc2udJEW9KJyWJB/c7TKFuMH1BXW5GdjMgbl3R60tjdeDclKwO7sar0klLWJrXmYQaz/qrsFldIyPg56VSTevYpLcKS5O2QKUpLDGJHlwfr2OHWbBSJG4waBVTC1JDi1CUc1u574lyeUCXSxX9GWnSNygFZOkeLl7+4IXStwQUHa7TCQMSm/k4kRj7tXN9pHWM4ADsnffovKM2CU9/tsbuUjzfeRi28ZCqARmIlCSwqIkWfCTzSYaBKVns90cu9tF9H6EOXFDLCAlVH4NZrFmbt93O7dDS0kC0cbslirW6vL60TApP+biLDI/0k53NnLFi8UiJQh6djst9Cnj/Qx+a+6MoVLiPWz/mNvudpbOHd42jkdTHLIFlCQfaWG0uBxikjQRtfyYvwDiDtdJokgSldiRJl/d7WSfNbPbya2X7s7E2bpKTXe7cD7MYaxXXPbshkWWttJMQbeoL+cPyX2JtPuRpXgXg2IEOqfI9XrRImbPr5vPtyfJszzqJhF/fEINlCQfyTNQkvwYYuMRfMBEs8qZ7ZatiRuiIgy4YUkStbiYpQCXX2IYLIja2e2AKA0RzN8f5llkr+pmKJxnkLtdCIYUQzLqVaeZPCGeGe/PADt+nLIHKEkhwZ/EDdHr2gohNq4tMAqlcpbKs9kGYRCW7eC2G4qbL1B51VxJsR7zYp2k4O97UO52Ybh2rxVwpB43F9z8qmo8gxRKp49OkP3DqD8kEzdotLkX44X6PGanCNNz5Wviowi3SdiBkhTChyfm2TpJ0XuI1AKOntBv1l6SYGw7cUNEBcaopABvtJt20AbySzC7r2G47ZqJG4Kul83nMAjqZc+8HwK1220QtLLq9tnt3AGj+xaG95dbtygMz08Y6hCG6/WiX2VK08Yoe4CSFBIUs9dh8XEOo5Kks5/ooqC2LUkZ5YPggHgwyopXKcDNstuF4baLvKzdGi/cVCLCImzJFXB1O0Uh4D8kzRhonzC0bkRMaIvyu31HRS2VVWsvhhvUsyQUQxVAk8d9nPAwXEfMg/PFKXuAkhQS1A9PlIIGvUQtxOq5HomlbVAuJOqkHhGQrTypp5uWJMV6RS5oI6LXqkjcoJmBSFaveDzwmfzAhA+fjsnGmKSgXcQUCyZbvGledccovp/M6r6zslZ4X69dcZ8esdLxGF9Z20ADHh+j+ZsX42RpdR3N3bg7lVVPYM242z6ZF9p+FoS7nTcnjFO2ACUpJMi7XETkb19IszDEzDNYaf4uLSZr293O1mEZh5vNoLDouGJJspO4gUzXSQoavTi8MAndToVpL/XAYNc405vUEa+T3T44Zc0OevLH5VTXkN7Jrxo2w7ZQu6q4MvmZlf/SuNX88+hl2+lvXy0iL/Db3W5PdZ3pPoW7q5Ofl28rT/v9rcnr6IQnx9GwSesoShYqdbe48/MF9qzbsoI+mLHJVl3O/tdE3lfHrygR2n9RYRmNWLLduF7q5VbIPiXlNbq/aTXRlDU7ySmsX533wiTapaGAA/eBkhQWVE9qCGSzUCC3MMQNBEbRF4Rb7nZhEJ5FcFt4dtOSJBdeA1snycTK4PbsqJ3ismGdJC+fJ/laa/4rk8ENFL98dza9M3UDfThjY9pv8zaV0tYyfQFP7xLK9ipdrVj5L41bw5/fWz+aR1/NKzItTq872xXy2T11+xF5cPhS033OeH6C7m/sWiTLzbMjxSw40nFBT3rc9cVCxfdvF25N20fvmopKU4qjxLodKaXaKpKCP25Fse44Id9Up5r1cvr0mfWrQU+P1/1N69x/H77EYY0SFsG1JZVUVLo3uW39jsrAPR4yFShJIUEtfPrb4cMrhKln+vVeHqKLyWZb4ga3b62bzSC/t254RNlxt9O0JOnsG2ZLkhdxDnYyMjtx48pMS5I2fgrBcmFKWYcEVlqnokY7HsUpTlrDizmEuZt2U7YyZnlCIbHDA9+kKwHlKsXabeRjTkwjhuqNietod1Wd5XHJqwRaXjBh1Q76ZNZm4f2N5MsHvllsfjxlD1CSQoLRw3jFf6bxmb9sRD3TrzsLaTKaSUqoXWUnjIJWELj50pBPDLgRN2IrcYPJOhpuKx92BDpfY5JimRFgrmdJigzhnbcCDsnkGf9dleZuinawOwR+PqeQnhu1kv74cSpOSd38mXI/9Nw6ReK45Hw2u5A27KwyPFfcYpNFuYmhJIUEoz40f/MeuvKN6Z6d2ysZjAV5Mr/4Bq3pekHUQqx+djtvF5NVD6RR8YByu5puvlDk98LPdagUiRuikN1OaJ+IdEgdvHyenIw/XhGV8UON08fUSPGOsiAVFGHqR3Ef6qMp8Ot8lrNye4VXVYokZo+aVhxjtgIlKazZ7Sj63PTOLO4X7yRwVS7fsCbSzW5nuphs3Jm7XUTHDPez27lZlnECBa8sLsqYJDELZNhjkryw+thRvBQJaGLhi0nyX8gMkRSrg+jYGWS/MrpPUUjj7hVhu/IgboV6jUk3ydSu5XSyMxbLnnaEkhQS0rpsQFqSm5aChYV7+N+vBYJ5HbvbmZTjdJ2kyMYkuYybApPbiRuE3e0sWLDC4IoR1AvG6b0OQdOFwFU2JI0QcpiiY7elordOUuYiV4C9uE6zMUVsTTnj71HF0qSU6e9m70WK5LvADlCSQkIYhLFIJG7QGQlMhV1pP5sWi6guJut+djsKr7udjcQNWlaGsKUA99MVUY6d09qtqqfudvLsdlGSpj0mBF3blfdfGO+p40dW8JoUrmZhuqEhnszxS9YKz/2Ihbhu4QdKUkhI67RBzR578PA4cYdQC4j6iRsE10nKMkuSUdNvq04s1heOxA3+tW/cxMqgXEyWAicMdYiCYKqHWZp3twnh7fK8vkFO8kWoK2b0tbMuYBYzFMZxJ6Kvdkc4tRTFIzfK2QdKUkgIssuFaaBVoxZi9RM3iD30dl1vompJ0mNNSSU9uyiPTnp2YigSN/jpbie/BrP76rUVR6R4PwVQeRv62eM9jUkKdCXo8I6usRAJ0tzdLoOGWKNLyaTrDENvtez6Rdk1kWQ1u50I8Szqw1CSQkJYOl1IqqFpYWCzF/qJG4zLiTtUeKKaAlxvoJ69sTTwF4wiy5wLD0COyIJCQinAtT8HRRjqIIp8hjEsQoLRsxtUVsCQNI2l/seU9ds/ne/lmWy1VyYlbojSs66G3QatOxG6uxOPxr20nBzBSJF0VpWsBkpSSAhSuJC/ZMIWG6VWaJy629l1nYusu53OwNki196j76ZlRZndzsfEDXLlTNPdTvbZ4/su8qz7GZMUVy3EOH3dTvtlWaj21LX2z2NGvUsTHEWl1bxNzJDf0pv/O5uCRq8Px5ufuzXFlULlsAU5FxeVaf4m6i6bQfqMIbGQuyp55rYWwRusezcCvpYgRY6IijueACXJZ046qLPmdvU7JnpDjTekKycxez628jJtCE2iylpUaJGXE/jgqUjc4KOlzsySpNw3+Fk40abZVraX/vzZApq/2b2Fp294e5bpPbzziwXkB9PX7qQlOkK6RH1jE41aul03JmnV9goas0z5+5dzCmmBSZuV7a2n05+bQCc+NY7+9tUiuvjVqWlriXw1t5DKa+oVCyNv2bPXlvXDj+Hlt+/PoXu/XkzXvz3TcT987ee1QmVs2GG8SKVd3LYmObUw+pS3IXTvIUV1JAukx+eEQG9OLOA2iwf+FrVPXtAVyDYevvhIuvCVqYazfQm/7WBGv7B1ZbVCo+dRJbqYrPqzKBH1ttN9ibbIVVoPRftbk1cxSS6UK75Okll2O6WLZ9CI1uDuLxbRjPW76IdFW2njsxeSH0xYWUKFu/d6/vItLq+hG95JKGxG1zZs0gZ6ZcI63QyZv/twruI3ZimbsiZhxVr71AWUp2Nh3bQrJdx/1bykwbKtSoXtb18v5v/cWZvIe9gCm24tsvnTkm1C+/3xE213vZiDvuOFtXd7eY2r5d36kbLfuUV1XWPys5VW8OI59dLqziYk2OSPerhev6OSundolfxeWl1vWpbomP7K+DUUJF/MLaRnrzzacTn82VJt21VlbBG/+LWp9N3tp+n+vr3M3ecjzMCS5DMt83JtH1tV20DvTFlPhburKUrEXBKk9YJ+ra53k03udiKWJCuZ5cKc3c7WOkkm7nZeK8duJm7Y7MK4YPVZraxtID/YqmORUfPjEqWViNFgsFLxepll4xUDa4jWLWjXKl+oTsCc7xdtpV1VdbbG30d/WE4/LRZT0vyCWRXljF5WnPzMLmVnpbaQanW4eWlcsIK8Gs2kHC6U+7/5RXTFf6Zzl085v/j3JIXA/umszaZlPfbDci5HHfXwKPqS3acQv9snrd7hSbnXvTXTVO76lYGr8DcLtlg6X1Cxn24AJclnRGJq9PZ5ZuQKevKnFVTw8hRvKufVTLCD50P9cnQjcYMb7nZRRx6TVKtyGwrCkuSvu528DmZWR3frZccyJdrmfhqfYyGytJm1gagCrhZsze6Bk/YOg7udVYK812ZCVp2BIhwE/5motGbK+XxOIZ3w5DjXz2nlvebFWBGU98vQlyZbtr4xOaqqrpG7m45ZUeJqfe75ahFNbbZOO8XKEh1Gza+ezCoqNZ902mNxeRAjwvaesAKUpJAg0olmrt/N/1a4PHsbxheyRKMqfW/MrvuKSbC+aT0iqiTpvbjy5UpSfcplw19LErmbuEF4MVmZcibQb7x8PoRWiBeyNrkj+FgtI8STsK72rXhErx2Ej6i+S8zgbtta2z0+b73DFP9T1+4it7npXeNYTlGC1P0zs5daB0qSz+iu89Nkvp9csPWKsGn8akuSntAft3BdLG7DqoUg09zt5O0RCkuSK+WKxiTFTQQWt+vlzO1AtA56VlYv8UveE52ljukkc3BKhj3+lhC5dK+zQIbtvQQyJx27n9lDreKGh0UU70mYgJLkM6JCvtZu+bJge3frlPoskuI2qEGCfbIfk5T6fNsn8+kHiz7sUXW307e8pT7XaFiSZq3fpZklzc1WUC4mSz5akswSNyj3DfrOi3Y9N5Qky+tmqQ7wSt5wIoSLztwbt17QvcA+0a159gK51j/C/GoPswKXLUBJCgkiQkCe4GKZTnhdlRkqfJYku+skKb+PWmpNSXJo0Q8M3faSfVZbkli642vfmskDZdVB727OGFtJxe0mCnc7n9dJUs+Iu5W4gS/kGIBgFbZ3uFYbuNG3tIsI2cUDEDBR1O3Ctjak2wpcFO9JmICSFJaZfYFj3XC3Y+uEGGUCshKfEkwK8JitGRf172r3RsvrJEV86JG3h1pJKpVlEFILmF6tkyRfy8bPxWTNBOgwvD+FY5IogJgknxQFJy4j6rjGTJttNiPaI1UzEW5/K4RhvHGC/DGNiotkmNvcygSPE9kyau3iJ1gnyWd03/Vx7xYA1coE07HNSXTaofum/V7rQaSgWynAjcqy+kBbnV2Oqtlbt+3j9hTjJq8sST6628XNLElx/+67SJ3DGJMkKS3qqoVRMKp3I3FDRJ9/RjyLrx34B3eHj6BKHuZ3e6Y8e/EIXwYsSSF8UNlAozXYuOlut2SL9sr16lXkgyZNSbKbAlwtzFlN3BDRqWS99jKyJMlJF4IptCnARV/QZm5+ckE/DLfdz5gkq0JOCJrHtP5uWCk103uE7eIzGDQ1yMa+ZeW9qPeuj57aGi6gJPmMnhCiiIPQeWz1VoO3w7MjV9IPi7ZGSknSSzEqlLhB1aZWhd8wzzbZwSgmyfA4r9ztfI1J0q6D5jpJIXiFitbADUOS1etVPxdhazu3Fip2u3ua3auoZaQKx53OHLy2yHhWfrS6LSfMr/aoxkJnElCSfEY08YDWfvIFQI2obWhUrEKtx58/WxAKJYnFSZ327M+aqzgLJ24wOYe6fa1ahiJrSRJoD9ZfFL/pCMFaWfCivk6S1nlZ4orUvuQpThI3/LyyWPF95fYK8pswCxgiMUlb9pgvqhgmhS9byRS3o7D0M/Tn7On3EZtvCR1QkkKCyKAlmgL84len0snPjKflW8uFzLkvj18jvKbI8AVFdP5Lk2nTrioSxWxW9O4vF3Jh5b5vlmnWz43EDXGHlqFMm9FRuNvVm7vbMWXimEfHeFYHV5Qkwf3kt17rvG9OWqd4SQUtn+n11d+8P5eCJu7TbLVoSVrDg6glyXCc8qEPjFq6nW58ZyYVl5tPcAVCho2BwH0gj7tLpnmwRBEoSSFB/izoCRei7nariyv53x8Wp7vTqRm5dDstLioTfijv+mIRn7H+x7dLyYnlaG1Joo6MvQYWCrdSgKdltzM4oLqugapqG5T7R9WSJJAoxMjdTmqnPdV1VOdyUg9ldjs3ZsysxyRp9QO5UO31O0qkyn6+Jy3HJKnd7Vyuj9VytWpvZUJHTuHuarrri4V8skmre/JAdZtSodZx//fxPJq2dhc9+n36ZFGQlFanLKt6bNpV7UtdFhft4ffFiCAsqoCooqaBZm3YnfwO+d45NQYTmFbkraDZImixDyNQknzGrruYncVkRfYuLLX3cpuyZidt1nkxTl2zk8YuL9asR0VNPc+wd94Lk5KCsdFg2iAz4STSHOslbjDL3KD8qhfLzZShox8dQ0c9MlrhehhVdzu9XtBk5G4na8u4hzFDZsqKV5hZsAYf2U2xb9DuCiJdL6jeaXTbAnHp0bhZE1btsFXUHz6aR8MXbKGCV6boXovdrlG4W19oKK1OpeB3gw9nbKJv5hfZPn7Dzir6ck4hXfTqVAoK1vrsfXPJa9PojOcnmArrwBi/stCxdfbMlFqgzwtjVwvvq3dH//b1YgqaD2dsoqiCFOAhQSmYxl1ZJ0lERHEyVN7z9SL68tZTFNtYLNRN787SPWZnZUoAaGhqotycXE1BdfyKYh6jtEc1i2k7Jkn1XS2UM0tJh9b5VNPQmKwPc3vp3bmN74kF/EDex0Sy23lx+e5bkuyskyS+b1CEMR4jppu4wZu6BqGnrilOzcDqXRa3Xobw/qi5+8tFjo6/93/BC1rLt5m7j2cKRt4VUeLQB0cGXYWsYf1OexZzv3h/2gY66cCOFDVgSfIZPZegjTvNZ1vycty/XU5e72XV9fTW5HU86cLWPXuppLyGx0JZRUtA/u0Hc/mit9tV/vm6Ka1NpNk0tyDZ10mrd9DAx8fS/f9booh5Urpdibn9hQ0R90R1TJL8SqXrdtuSxsq1sqirn+sk6e3rBump6M2PEbGyBdUdI6AfuLQwZnZde9hAW7uLH1beGet3eX4OEB0e/WE5XfDqdIoaUJJCwn+nbTA1hXvhbicKy2z2+ezNyvJjRE+PWMn9TZ8btZLmbirVPFYvlkV68VlxtbKzFu+YZdtpo8o1UC6USybtL+YWprkKJPdXCdNReWmLpExXu9vpJW5wE3VxfsZ8yV0tmTVTjSKNdQjus1AGPLfOZbGkEDSPL8qinrLsxfnC0OfCSFQmphyRQfde7QUCQBSBu53PiGdpihm62zGhNdeFxWVjgmP0K+PX0H8mprJ+WUkdrhfUa0tJ0rlkozJYbIHR/nrNWC/zxcq07HZyRBI3uC24qZWuhoAWkzVbZ5Tt66XQKiL4hTnDkV+JG4Ig0Z+M+39WCO4g4/ArJgmAqANLUkjRGsLkSpJZqm5R1O9+PWFg8hrj4Gc7Qq40a23lUvRSgFuVzuTV1StTLshnWnY748QNss/J/d22JCnLawosJsnE3Y7cRa+OE1aV0C/+NZHmb05YYzfurKJ/jV5Fu6vqQm1ZCFvdvFJatCxsXrkssWuACAsAAMEDJSlC5Mnc7UTSMbspMOSaFGbHHavJVUuS/RlwvSurl5kZ1Nfn1wwyE5L/OXolzzBlB5FsgOo0o4okIpK7ncvSsLo9XYlJEtxPfn1a/VYRs+RxTJLELe/N4YG3N787m38//+XJ9NqEtXTcE2NDaZ2R+n8QGex8S2Qhj0ny+TLDeM+DhLUHFEcAgN9ASfIZJ8J1nswvrN7ARcoLckxc+5iwaVWQsJMUQDdxg9XFYWXnVARox3UsSYLls2v65buz+D83hLl7v15Er09YR5e85m763biBu538dkjX4LZgqlaK3FqCaeX2cnp6xAqerdBq6vFtZXt5+no5XgvH6vKrm7NayRXXcLvbGX/3e9z0zJKk527ngege4tsdGGHM8AgAyHwQkxQh9DKvuYleqVouaXKFxZElyYqSpLPd6tnlp9QTdOQujaLXx1KcszWkJCtQl31akhOkxfnsrv0h5G6nSjcrtw5In1xeRzbtnruhCLD+eP5LU5Kp6F+5/ljtc8e11+H686cLePKRvl330a2n12hZbEOtJPl1HlUyDS+UIaMy43p18kgpg9UEAACCJ1KWpGeffZYLQnfeeSdlOmZCgFGihGQZdl61OgKZlvAm36KVJcz8XFatNPYSN2iXpdCSZFXSDuoXdQdTuPG5IMkZCelVtQ10/kuTeWZBPXSrIKun2nVTft1Su9rNbjd3Y2oFdkN3u+bvK7aVc+sZSylvFfmlLttaZtmSJGVnXFNSmdxm9aqXbinTXWRZ5P5o3S8/dSS9c7HrendqKgOn7nMXsD7npmUnFhFFFQAAQJYrSXPmzKE333yTjjnmGIoyQi9x3dwEcUuJG9yMFzBbosmeJalZAHchBbj1xA2pA/Q8CeX1ErUoyPdyQ1wzapuv5hbSyu0V9IZB1kE95JeTlo5bds6Fm/dQZW2DsJDIUsWzlOvsmKLSarpq2AxBd7vE949nbqIv5xbRdwu3JhMaPD9qpaJ/sfW4mIJohFHmR/mZWfsxBYDRMi+9k1sRjpn16qJXp9KZ/5xA1745Q5FCXhTm+vjpLGWq/TDI5+y6nvhxedp2dd1Wl1TQ3V8spE27nC1sWF5Tz+9z2LPIhbRaGQc32oW1E7hICB51AEDU3O0qKyvpxhtvpLfffpuefPJJw31ra2v5P4ny8sQq3fX19fyfHaTj7B4vp6GhXsgaobV4aaNM6KqpNb+epsYm030aG9WZzeKax2i9nuR1ZAJhQ4O+4CqVKb/+On5PYmkKll6d6xvqdYWSuoYGS/eHuVkl95dbVerU9avXTlnd0Kh5PnZMah9WJ2cvdvlp1eerk2Wl07v2uKwA+T4Njal71dSk7Cf19anf/vjJfLp0QA+6+ZQ+aWVrnfOR75bTF3OL6IxDu9BffnGI7jG1snbm25vbc29d4twVe+v4d5bQgHFwl9Z06cCeVFJRS6c9P4la5OXQskfOU19t8tPq4kravLOCenRolVYH+XMkKQBrnhjC3eyWbk2MF8l2amhU9HOjPrZme5nCTfLjGRtoYeEeOjKWOk79vKnbnvH34UsU30sN4qv0sDpWsbXOrhg2k3ZX1QuVJY0TrH3kXN2sFC8sLKXbzjrYUn3k+xzz6Bj+d+b9Z1Ph7mr6at4WxTOmVoKlYx3FrqjGPrlMrjW2sW1uye3y87JrkD+fgI1jTdRo8H7JFLTGAy9gE6h+nAekg3anULSBaB0ioSTdfvvtdOGFF9J5551nqiQ988wz9Nhjj6VtHzNmDLVp08ZRPcaOHUtOKaszb/bdu3ZTLZfjlBkFVq5cwebI+dcJkyfTmrZ6JSTKX7duHY2oX2N4vlUrVybLZOzZU0YjRozQqBObZVfOtFdUlCfruGv3Hpq/YLeiLDlSmSXciypRn7HjxlG7fCY45iquNdHO6XWeOHEi7SlV7isxd85cqlmnJyCll1VRWZms0y7ZtbF+Iu0/e/Zcql6bKLOqWnnehQsXUt6WBWnl7uH6eeL4cePGUhuHT1iDrG3U92XltliyvbXuGWPb9tS1yfdZWpI6tmTHDsVvm7m3WariyzZspSmNbKFd5cVonfOLuYl9pqzdRce3KtY9ZresnRgbNm2iESM2UGFhor4r16ylEXWrk/tMmL2I8rcupIW7EvVm7qaJslJlVFVVKe7R7e9OpN/1S7fmbN2W3pdZWWVl6X1rzZq1tKcspnsP5Kzl+lWqPo/+mHCDnJCfS91aJ8aOpdtT7c7YsmUrjRhRZPiMVtfpL/YrFyLldZfXk7UZe+4G7x/XFepfX55Du6u0zcXqdmZs21HKt68qUl6PxPqd1bRw0aLkby9+OpJGFrHy9bWKvg+Nob8e3UB9eEhY4nzvfTue3lypLH/kyJGa1l+W6yIxKWZPc9lVsZd+/GlEsmz5uDR33vy063zo82lUU++OM8b3P6baePfu3TRn9k7dsTQb2bptG82r35rxbbJlyxYaMSJ9rPVCGdN6roH3oN3JFVnaKdXVYm7xob9Tn3/+Oc2fP5+724nwwAMP0N133538zl6avXv3piFDhlD79u1ta5zspg4ePJjy8/PJCcXlNfTwvMmG+3Tq3ImqahuJqiqS23Jycqhfv8Ppu01McCQadPKpNLB3R83j75iRmIU95NBDqOC8vsnvWhzerx/RZqZIJejQsQMVFJyctt//ds6jVWW7FNt4ezbXcZ/27enYYw+iD9Ys1jxPQUEB/8tSWT+1cBr/fO6559K++7RMqx9rZ5oxIa2Ms88+m0aVLqN1FYnYETnHHX88nXdEV81za11/6zZtqKDgDP75i5K5tKY8ETszeMgQotk/88/HHnc8DT4yUeYzyyYxM2Xy+IEDB1LBgB5p5W4rq6FH5ifu75DBg6l9a2f95a6ZY9LaUGL3rM30zcaVmr9JjK5YRAt3FaftUz57M9G6xLH7dtmXCgpOSP62qKiMaMms5PeOnTrRKaccRi8uTaSn1quPuq1POvkUoqVzNI8pKt1Lj81PJFlg9OrVmwoKjqJxXy0m2rmd9u9zIBUU9EuW1/eww6ng7IMptnQ7vbd6cbIs+fn22WcfKt6bcvNq1aELFRScmFbHH/csJNpdklavtzbNUDxzjIMPPYS2r9tNmyrLDNuZMW9TKb26LH2cKquPJceO0tmF9NUGNtmRoGfPnlRQcIzhMypCjPnDyqyG8nre8VCi7BuGnECDDuysefzLa1j2RO2XxgUXXEB3zFC+1PZp144KCk6l9RPWERVqu3sOHDCAPl67lH/+zwox4fbfS/K4VU9qj0W1+zJbWlp91JakR75fRp/O2aLrOivC3sYY/bSnB71xYyLhx31zxyWXATj22GOT/U5iIZ9ccYe/zkq9ijt37kwzKtl59ePqsg3W1v83dCC9vWohZTL7778/FRQc7Xg8MIPJEwUFQz0/D0hH/d7KRga7IEs7RfIyi7SSVFhYSHfccQdXUFq1Sneb0aJly5b8nxp2Q5zeFDfKaJHfKDSAUUw5Ax6TtjcTj+Wa1iUv13yf3Fyl8ML8vrWOYWWl1zMlkTD5TF2WHKnMnNxUl8vNzdM8l16d8/LydBd+zRG4VjlMnJT2z5W1q7wMJnhK39VxO3l52ufLzUu5hOS3cN5f5OdVl8XaQ+83CXmfke+TK1uYOE7Ke87aUl2HmMa9Nbu2WI7+MTm5ShcyqQ7sL4PlJVHci1jiXuQbXLNWzIJWHaVzqPfTOp6dV77d6JpbtMg3HTvUzwi7D268LNRuZlpl7tnbpHsuWZK/NLSOkcYJrpzpkJtnb9Zffr6ZG9InRFi/z5P1XwZTkBhOkxGOW7kjeX55/Cgbq/xi3Y4q2lVl3cUy01lZ4izOLQqw8doP4ZH17aCF1GwF7U6uyNJu1CHyStK8efOopKSEjjvuuOQ25tM/efJkeu2113jskZFgHmXMfOvtBIWLnVd7u9kMLV8nSewMGp/E0XMXshqLoJeMT7HQqI1FRUUWqXULkVlz/XWlSPfa1G3JBGjRxBzsdNLhRsku9BaTlepSq4p1kXpX3EJ76N0yvb6itTnu4oLLjLCGntvNXhiGpBJeoVg/zceQepb0BKSjXvQaAAC8JtRKEnPHWrJEGcR8yy23UL9+/ei+++7LWAVJS/hQy1/qtM1eo2fBUS4may5IGAnnTuphVcaTn1tPkZALjqJCpGI9F/IWJ0K5UT3Vt4UpO6L3KiZfW8ngmHTFTNnO6hT3IqdXZ47UO8RKv7Oyr9kzolUnt5QM3ocdFGZ0qOFvlB34qQxmQRI3oAMWzQUgXIRaSWrXrh31799fsa1t27bUpUuXtO2RQfAFqJ65ZAKgfEu9kX+MtVMJoZVSWS6UssVt5Qtzii4K6Z4lyf0U4PJ97M60e4mIUK7bXnKLnqrx1JfKrt3OMlhGbabW8aV9pUNYKmxFfZvraHSf1deqp+BYuZWsiLhLafLDLFzZWucscWI7PzkiiCfRz3WS3FzrCQBN0MUAyKx1krKNtHdyzCd3Ox0RRMSSZGQ5kIQ4vYU85ei5afHFZHVGd6tCjPwU8hLlpcibWFSwjsqMs+g6SdJ30bWs5FY5o3ui626nZ0ki6+idvsmKu52FG2q0NlPYMVJojVoghHMHrhHdu5mZRPjxCh8Z/NwCkDWWJC1YGugoIzpLaKIj+e9up2VJkq8jwtaxMJCYeGKHmFJA1ZM/jQRyfcuINRSxQ3oufE02YpIUFhryFLlQzuqqeY/0Dlbch3SlKM2SZONijLpomiLW3NbSvVcrSXbObyX2SL+e7ro/htW1ynZMksGTF5ZrcwN4QQVPJvUnAEA0gCUppKiFQvULQsTdzk1hgCk4ZgKxkaAlufOIuNsZlaOn0Fh1N5KfQ65byIuRK2t2YpK8Rm7dY+6O9hM3qH5Uu9tpLG7s3N0uXRGT/01L3BAXEcqdxSTFncYkZaolKQCXOiMCOaePU+9QBrLXDRG6OADhAkpSCOGvAk3Xn9Tn+hBYkuQ0mliSpN+UCQO09zdSAHNci0mSfzNP3CBuSdL74q0wZdUSIN/bLCaJJ24Q7G7yljR0t9OxXkl/1ZZSP9ztrJShRSzCFgr7lqTwX5td5Eq3r260/p0qUkB5dBG0JQBCQEkK4UAf13S3i/kSk6SHVkySfAuzZBhbkpqVJNmVNdmxJOlstx6TJHe3k/2gsLDoW5Lcsmi55W6nF3ivn91O5m6n+i3N3c5CTJLiOCP3SzNLkirdr1Qno9lk9S9WEzdo3btsyTZlGE8YkoQGQVh1siH2KipArgcA+A2UpJCiFs7SU4DrxVvItoukJBZ8+Yusk2RoSWqur3wXPQGUWaW0iBsqJ8b1M9pf79pS1i8WkyNYruJz3DfFVbftFa6E2gqqVqIGxfcm4zWP9LCWuCF1Lk1LkpC7nfr82vtZUXz4QrqC+wYpRzs9t2VLpHQ/Arjo8StKfD+nn8pyVZ35guNZSRaYkqCMAxAuoCSFlHRLklJA1HO303qXW3m36MYkmWhJ3JIUF7Ak6QjqWvt6aUmSC4Vy64S8jdVpqcMXkyTWZmZ1U29X75ZI3GC9foZKs07ihuRisipLkoiQqu7nesdYuRZWn3gWyH3GMUnp21YVV/C4MaP74tW13fbJfLrqjelUUlFDXqKX9RIEQ0geFQBAFgElKYQDfUwzcYPyyHpV9i8jZSFmRbDU2U8zBbjKkiESkyRmSTISvNyxJOm622nso1UffeFQ5sbmsWSlSDKhl7hBoQCmUKZiV5dr391ONE5KbSxMutvpxCTZUdJciUly4XxRwE77vv7zWsNrfnrESvKKuZtK6baP53tS9m/fn0PfLdyiGDgnr97hybmAu+vCRZ05G3YHXQUAgAwoST6jJ+SrUQsf6qPqdaQarfV/jM4pKthpLyZLwkpSKmZGPxYmta+NxA0W53qVi8lqB2hLcrpXgf5OkTeTmCVJW4FLS9zQpJW4QbmPSCI3K4kb1Osk1dbrZLczuEx1vJJen7BmGfT2hrpVvJfV1GvHiat3GD51Oypq7Z1P8GKYouQF41eW0B2fL1Rs+3HxNk/OBcSJcPJIYbaXe2sdlWDj7B8+nOvLuYA742Km0OhvOL1joCSFECYimMkJeu52Vi1Jbs7iNVi0JOkJ0XrKFhOe9K0+ptXT39/EkqTZpnoWLfIPRWIJnRg1eTXjgus5aSZuEExcIVdUDNdJajJZJyktu50ddzvn6yeJZvWLgrnJ7Yl4dileJG4Io0XunMP3C7oKALgGe1ePWV4cdDWykhOfGkfZzOTt0ZrtgJIUEZiAo0gBruNup3es6G96AqRmdjt1oLxIdjuFBcN4X836kgfudvJy5PuoMq6JoExx7i3y8kWy28nrJt9dLehqxSSpLT+6s7pydzuDm6KliCXOlUoDL+9PqcQN4uhnt7PibmfJ4Y7CjNvKB4/X8uCSw9KK8i7es2PrAGsCAACZwfoKKEnAh5gkPUVC25LkhrsduWRJksfC2IlJ0t5udUZbmd1OZ52kpAuYhXJ9FPHkCq2IIqfvfqZSkjSSKqgVYJGFHY2UZnV9k4kbZNvl1iShxA2q73pH6N1PrfZxPduUqq9FIcxCP7bLq/PFI+UaDfwBtwMA4DdQkkKKmZygdkcyFFxi/rjb6aXuZjQ0mluSpLgnI4Ffrx5OxCq9S1MnExDBKNbHbeTKjZ6CqnC303F1VB+pLkorcYOIwGKYuEHPkiTbXiuzlsbtdGVd4V78vvB9BfcPiWzvo7sdsySF/KJBxgClFQDgN1CSQop6Vlv9fhDJbicd40pMkkniBrMYFPmaQxJq+Uo6hV68leZJk2XZF9ZiJtYZLWHfrVTkfma30zvWLCZJa50kPXklJrxOkvZ3+TEsxbS6LKPWTVf2xGOPhAt1SprVzuXyxU/tGNa+XliTwqh2hbFOAAAQNeIRG0yhJIUU0+x2euskeZQ5JNepJan5t7iBIihZiXQTNxgoJ04evJiZu51G4XGfY5K0sgtaz24n+6wox1hw10rcIGZZNFCSNFz65H8ZdbKJAFspwHW2W1Ge/FR6owY3snmgPoSlyWG4AACA7AZKUkhfvGo5IW2dJCsxSS4sJqtlSVIjEqhvtD6PpAgYCfxWBV8R9DLA2Unc4BVaSqrS6tUkcG3a8WCm2e00FpMV6VKG/aG5wDzJxdLM3c7GLXAjcYOldOEUbuwK/bpZAj2KS/Izri9qihsAAAD/gJLkMyIB71ruY2mWJEuLyTqfEtXSkdSKm+E6SY3mi8maWZKMcCKs6bVPg9Psdi4KVjkaT6q8fKl9RWOS5HKomSWJYceSJJK4Ib85I0hSiZZ1a7klSeorVtwq9VOA62zX2+ahSSHK1grPsttBIQEaIP4NAOA3UJJ8Zp9WebRPyzzr7nY8BXhcYJ2k9DKMBDH1rK3eLK6WIpEek2QuFMcNLUnm5ejhKCZJL7mBRka+5DE6ZXnlnqWllDRZzm5HtixJWolCdGOSYoIxas3nyM+N6VrtrFqS1PvoZ2WzYklyrpRFHb0xIXG9GXrRac945l5nVMjU5wsAEF6gJPkMcymb99B59N3tp+nuwxUik3LYOjJaKBMjJD7HXHjxiLjANFhcJ0l9lZIioFeOUV2dvED1PAlTMUniZcX9dLcTavuYdt+QlyNgSVIr5SKZpkTc7SRLkpa7ncKSRO4pzpbup8eSWZQFP564oSlz2wTZ1MJFSLoFACCLgJIUAC3zcpPCoRaJrMPqV0JMLHGDxmc3XvZagouVxWSTliRFXIz1FOC69XPwCpVbyeTlGGW300OZWtu917pWTJiIJUkv3kqZDly/XL3+JhCiZtwf4ip3Oym7XZNedjvz86Wd36IlSUsh4vUKi9QeEEZui54kbgihOJzlXSAU4B4AAPzG3O8LeIKZIJAWKK9OAa7rbpc68NWf19LeukZDS5JakHXyIhKxJMlnntXnkqwlhpnadAVf8mydpDC4XGkpJY6y2xkoc9qWJOVGPcVbrnA2iViS8pSKsfwYZUySblG65zN2E3NfYA+jcB/FmKQwki3XGWY27qoKugoAAIdEbSiFJSmkaCVukG/Sc7dTy8rvTN1g6G8nqlzo7SZlJ0uUZWRJSk8Brt5fkrvtxSRZPkR2Xm1zi73EDXJNhFxDM1GCSHY7xf7aVROxJMkVlrRybbjbNeq52+nFJAk0pvo+WbYkae5LnhIFjy69JkhYkjw4X0jeohG4NVnF8AVbKBtYUlQWdBUAAM1ASQoII0FAKyZJxJJUVdug6eJkGJOkOtOakkqat6lUqMLMaiBfv0cvwxr/TcNSELeRApw8TgGuKNOOkkTeoO1uZ9GSpJsCXG2BSUfd3+ICbWnsbpf42yLpbif1D3LPkmTgJiYKMmoZt40XiUrQ4iCbufi1qUFXAQDQDJSksKJ2tzOJSXpnyno66pHR9M389Nk2o5gkLTn2yjemm1XHhiUpbujypUjcoJsWzRvxKaZzBi3Fzgy5YhD3OHGD5ZikuPlndblm7p1p55N9NjpEN3GDTkySiLKS3gZ61lY97cmpQiWwj4PywwZvbg/qHxbFVG+NMQAAANkBlKSAMMvUZiaYq93tnvxpBf/74rjVGuXFbQsk63ZUUll1veZvszfuVliS6owsSc2/6WVYE03coCesGFktzNBb80e6B2GwJMnbOXkukXWSFEkpSPOzuq9pXa66v4kIsoZKc/Nvec0pwJNJMnRikqQ6GZ023W1QbD8jvErprjhHCBYrtpclMHssSSHR2wAAAPgIEjcEhNnMpPpXJiPHbczsm7liGb381xRX0OAXJ3MB/Y9nHaK5T3lNQ/JzbX1q5l8/u10KtYAl6QH23O3INnrWFqPEDbouegbuhE7QOp/ldZJ0XOzUh8YF1kkSwahOTWnZ7ZrbWjcmyZwGVVyWlSx2+vUUF9rt3G92X41it8KMR4akECkkiEoCAIBsBpaksMYkqd3tVFKyXuIGLdRB93KMZoKnrt2ZFHZF3E3kQq1oTJJcKJYsOv6nANcmpSRZqkgwliQHKcCF1klS3Vu9y5T3U5F1kloYrJOkXEw2vSz1NnXuirgLiRvcvp1afc1Of/cTvdqx9vdEoYlHK7EFAACAzARKUkDEHQr9blmSDLNtWxSAjJSkZHa7uFJYlQvFZokbrLhaWUEvZsveOknexDFoLyYrtyTprJsV1/5sZPFyEpMkvm5W4m9+s7sdq75a6NZK3GDUpur75NZism7K6fGAXPq8wLPsdrJSg9SR9CYYAAAA2CNqYymUpIAwc/nR+lmZAtydpe6NhE49y4Me8kB7IUuSSrB1YklyMqWtF6CdWttJvGyvAry13e3sZ7dT3FuDcvVjkkxPZ3gf1YvJsu/q3eVKt5Yiod6ktlxZtiRpbLe0RpaNe8+K98uSZFfhMGpHT2KSFJYkmJIAACBTiEdMS4KSFFZLkskORum2LdXD0JKkLVTrUVtvZEnSdpeSC1lCiRt0BTa9/c1rrs4cmCoz3QXMDK/kXa3kElZjkkjAqpT4zaWYJAF3u/y8ZiWpKZ52DWYpwNX1TrMk6Zzb7Yx1TtExArpOPCLZ7cJI1F7sAAAQRuIULaAkhRT1rHROTrrQ6kaqXFEriVNLklYSBCYcKixJOfYTN+jN4ovUWy9xg6SI2l1M1k3Bym5Mkq71SJG4wdwCk7ZOks7FyWtpvE6SMiaJb1Ptr0gBrnF/1cWLu9vptZX4vprHZ2riBoMJCC8sp/ISA3W3C/DcAACQicRD/rpTAyUppB0lLXGDxivbjjKRdh4LdXBiSZLqqoiRUQm2UtyNXnyNEfrpnkUsScbHei0o27UkxS1nt5N91tmud712LJdGh6TWSZKnkFfed3UKcHa928tqdeupVsr0Tm9p3SsfBvSwu9vpkUi84nKhFrMPAgAAiA5xihZIAR7SrqL1q3rWls3uSzEddjESGJXxQ3GHiRskhUNZvlZMkr5VhFxzw5OTI7PSxDUTN5iXkTremouiKGpLovrahJQkWY2MEzcIWJIcJ26QlKQc3XMos9sRPfL9MvpwxibdeqstMk0uJW7wclDnioZPSoHds+iuTeaDJcmM8SuK6eOZqT7hFVhMFgAAnBO1kRSWpIAwEtSY1UgtOGnFL1tJA24rJkn3izb1TdZTgDe6ZLWw6lolJ2ZinbGU3c6j+BLN7HYi7nZx889p7nbkICYpZi9xg5aSpIxJiisUJK16q89nNU7NLFmKV/idAnxb2V66/q2ZNHrZdkflsFp7UfW/fLZA2Fr+2w/m0oRVO9yvhHrMjdqbHQAAQkg8YmMplKSAMFZO0tcf0XKVcSPDnZESYbUzG+2fdKFTCOpxTaXCXuIGccFXjTyDlnx/SZDXEqr1kj0o3djcGw3k1i7txA3mfSEu8Jl/F7Ak6QmN8loKrZPUnLhBSzlWxiRplGFmOXJgXdQt0yFaxfntbvfQt0tpxvpddOtH85K/tcq3/irgliQPqj593S4KA/JnPGLvdQAACCVxihZQkiKCVipcN5QkUSHHacfWSwHeIBPupV9sJW6wqDzJkTetfP9k4gZLMSxxHy1JsroKuCgqk0pou97x7xpl1TdYvy6RxA3ymKQ0S5Lsu3Z6bjKxJFmzLookh/AicYPf6yTtrKxL2yZPoGHNlTVqrzwAAABBEY9HKyUOlKSAsGplYN1KfYgdwdWSJUkeX+NQkGtsVjji6nVWLFiSjKrgVuIGdcyUXn1Esum5KftqJm7QaF8jRFzvnMYkyZV5I+UytZis3N0urpsIRKtO6j6p3kfr7OoFa81wWwXQcpv1291OC3tLk3ljSQIAAJCZNFG0gJIUEEayhZbgsX5nlaUYIDeEIzcFfksxSS6mABdK3CCTXBWWJI06m9bDRalRXpb2YrLmliQ90hQKkyQdttZJMqhTKrudQUyS7LvWPTC7ZK17YejmKqCIOSXNI5AnbqDAkVt01cRDkHQiCJRLA2TudQIAANAGSlJAWBXWtGBCZXVdg8OZaANLkouCgVRHdcIAed2l89m5nriTxWR1hCFJkNfSD0RikpyiSI+uGZOkva+Q9UhVU6UFzf46Scoyzd3tmIIqXZpRCnCr5Sd+t36Mk/3tZkALg6JhZ74lkd0OAAAAECMErztLIAV4QBiJF7quXKrvOyvq6PyXplC/7u08EY6UQrUzUuskKUvSEu6NkhDou7nZtyTpudtJgrzogruJ411ULGVl2V1MVt99Ul0W2xDTbUs7mRRFLEnMkMSurakxTvUN+inAtS1J1utkVf+WNYtn+O1up3U2I9dIo2crai88u2TJZQIAAJABS1JAnHhgZzq06z40oFeHtN9EBY+Jq0r435XbKzyKSbJeJz0kxUdeTJolyTQJgYHQ7Shxg7a7XaONxA1uCo1yXVErcUfcanY7hVXJyJKkpbgqt8VFkmAYVKlJZkmSrk2tiClTgLvT1lazObqduEF9G9n3oGOSWF+wW4dMVh6iFV4MAADhJ07RAkpSQLBYjDF3nkkf/uYk251IKy20VeI+CfzJ+B6Fe52YQO50wUvdY5p/0xPsJeXI0jpJqpgr1yxJtmOS0pVQrbq5WW+hxA3NPzElScrcl76YbKPrSpLVY7yOSQrE3c4k4UXa7oZFRe2VZ48suUwAAPCUeMTGUihJAcKUnJYa65OICk1uzHQKZ7dzqP8nY5IU51YqIFJV7CRu0F841PwYeXyRcu2hZsVOoxCtRApuYxaTJK+WiCKnTPutv59I84t0UTF3u1jy2tKVJGN3OysWPqNyghzQefKSgC1JTs4ftRceAACA4IhTtICSFDAtZYtpWpVI3py83vH59YScipp6xW9mQfRmpDLFyc8d11SI1IuKiqAfN2FgzWg+t1z/0FI8tGKS9IpVrgPlbDiQn1crBXiT5Zgk+We1NUGurNqvd8xq2+ekEjekpQCXu9tplGElVkykTk73t9tqQSduMDu/8URD1F554igWmQ60JgAAAIIASlLAaMea+Hf+4Qu2aG5/Y+I6hWBQWLrX2Yni6QL4/M2lmkqF0cy2fhY77e3GFhMNdzsNFzYrOpub905uKdGyXMkVHb11knSz26W528k/iyhc5vsY3Ufp2pirndqSJH1XKOYutatVvcoPJcCFNaEtob4iO5bbZFlZoj1ki1shAAB4SZyiBZSkEBKGF/KuyjqFBLR5V/o6TVaQhGr5pX02u5BKq+rS9tVN3GBjRtvI2pBSkrTd7aRjrWW3E6uvWFkyJYmcZ7dTxCcZrZPkUvezkt1OngI8XyMAy7XYNYtZ3OIW2sPOc8uO+GHRVgoSs3a0k4kTAAAAUBMC8dYSUJJCSBj6EBNY5fUocmpJ0hGqistr5D8KZ2qz4/6W/pvxtmTiBgsxSW4quGbN0OQku53FdZKMypIjVzjVMUb66yQpLUl5OenDUlyjzZ2mAH/04iP530EHdQ5sQGcK0kczN1GQ2HFbTB4bhsEKAAAA8AAoSSFE16XMxzowVyex7GliSEWpi5HHnTg5l34KcGsz6FqJG6xYLJSKiDPkypnWjL0ifkrADVG+i/qSlEkd7Nc8JngfG7USNzT3Be2Fc+M8I6Rym/X6ya+tfet8RVxgPMtiblx5tjO4ebSSygAAALCPz97ljoGSFELC4MLC0i9X1DS4Vt7Ipds1hQ0tJUmtlMiTW8Q9SAGu2F92bqPEDX7cO7PzOsnUpr52o9/sYpSAQ6o7U4hSlqTUNjVs93zVdjv1lMehiWQodDtxQxhcaY3Sv2sfYPRT8NfjFdtlVu6a+lQ6egAAADaJ2CsjL+gKgHRCIEfRuBWJhWrdRi2QyZWkxVvKaWX7WJqS1LZlHtU21Bm2i35CB3NrhrJ+ys98oU0LN8RN9yMzC5Y6U6CZEKtMkqEuS/837XLNMXS3S2YWlFmSml0GNZUkFqvElOW6RkdtLV2mVrZAvbWY/Ej3HiRIAW5OpvcBAADwg7qImZJgSQohdtb88Zr92rV0pRy1MC9fMJTxxorcNPefPIFFc/VTgOsfo/WbuhwmQFqyJLlokTFXzpxYkvRLcuRuFxNz45JCqJTuds2WJE0FJp4Wq2QvJklSzrSTYaSfV7xskX21sln6hd6pzRM36JMN7oiMLLlMAADwlF210ZpxgpIUQsLgkqPmwqN7OC6DKRtp7nb15u52Eu9MWU9jlxdr/vbtwq20dEuZxcQNxpYkSdC3MtHuptAoV860irWa30KxOLCqQEVWP5dMSeKJG5T768UktVBlvXOSuEGxBo6hIp3eZ6OK3nU4siRRdpAt1wkAAF6SE4vWaAolCQjRwsqitzowhWP4QuW6TFLaZznqRUUlvtFZ00niqZ9WWFIkzBI3SN+tuNvJ97Q7FHw5p5Bu/3Q+1WgokOq62bUepSdu8DcmSTNxg4GSxKqUp0rcYKeacbklSXUas+QYmTIBor5Os/5tx80108gWixkAAHhJPGJDKWKSIpXdLtjedfXxveireUWG+7RtkUvHH9iZOrbOp+9V67/M3rCb1u+osm1JsqPIiViSjDK7WXe3s1f3bWV76Ykfl9Mtpx1E9/5vMd/WvlW+8blsnUk6Ni7siidyfIqU5tFgoKGmEjek4oMkhTlPV0lybknSikkyeq6snSPco790yWmJG2BJyrgXOwAAhJG4gJt7mIAlKQS8e/MJiu96QpuB95LnsG79xGX96c1fHm+4X5uWefThbwbRnef1Tftt5fbytG3qmCS76yQxjujRPm2boSuVxmnUChr7bjcF+MadVVS2t55/Zq6Aq4sraNLqHXTVG9Pphrdn0mezNyf3veerRTRiyXa6etiM5LY91ekL7Srqb3EB2Fd/XkM/Lt5qmuHMrVlzPYugXuIGyfKk526nTrbgJAW4aOKGqK8DJKK0NzhZTDZLtAdYkgAAIPuAkhQCzj2iG115XC+B2IFg04K0ys+loUd1N9ynRbNLlFaAula6b7N1kph1SDTWXWs/I+Fm6EuTqaq2wbA+XEnSKOO2T+bTW5PXGZ7vtx/Mpd+8P4fKa+rpolen0pAXJ9MH0zfS3E2lNH3dLnp6RMo9cOPOauN1WjTqL2bxSTF6WTH96dMFNHLJNhMlSaBc3X3EhEnpHIrsdgbudvwYVcXspQBP/BXPn2BPQY4Siwr32D4WygMAAIBMBUpSCNETPJwu6OoIQaEyv9klKqazQK0ao3WSfnf6QTT+7rOEq6htCdBvs731jfTl3ELDOhq5230xp9C0DkWl1bS7MmURqpQpZdLaK98t3EJb9uxNK2uMTpKK1Lns9Yc/fjLf0N3OjuC7YWcV/fLdWbRTdq1GSG0quk4Sq5NWvJgbliSpGK3Som5JEuH+b5YY/o6YpOy5TgAAACmgJIUQvfexk9gBv1AH15tlO6vTcLeTlMFrT+xNvTu3cZSe3KzJWHIEuQCkdv9jViS9wHaRxA/qfWpli1IypYC51N31xUKywpuT1tH5L01WKCSS0rNsaxk99sMyKq2q4wrfxFU7NMswStwgYjxh92jYpHVUXZdQ+v748Tyasman8DXIs9uJJm5Q17mkvFb4fNqJG8w1f1FFjGVevErmKhkW9NZ+8rL8TAQWMwAAyD6QuCEkiLj/BGlJEllThpGfdLcTU5KMLEl6bldqpEB/7exkxm3G6hQzqA+Lk9GLBRPJeseuRW61UGes21Ndb9m97ZmRK5s/VSS3MU/M4vIauvCVqfz7e9M2CpdntOisEc+OXEkfTt9Io+46kzbtSncXFLUkSesiSf1DM15Io17MImbGRzM38f5x/aA+ifNqJW4wsZTI24ZZ/Pbv2Dptvyc1Miuqr7dwt7U2cpv/+3g+bXz2QlfLzBbVAUoSAABkH6G2JD3zzDN04oknUrt27ahr16502WWX0apVqyjT8WI9E79Qr2VjFshvlN1OWjzUTEFLCrw2Au8bVBqQ2t0usU5OohC17N7YKGZJkh/HXPzkVDVbYpwyY/0uOunp8cL7qxVKeTuZtVnvzq3p31cPoNb5ubS1rIY27KjSTOUuIU/i8e7UDVxhaJRnt2seheoNsttxdzsb/f+hb5fSA98soZfGreZJK6T7o2VFEnHXPP25n3k91LFsZnw+t4jOeH4CPT/an/GL9buHv1tKv/9wrmJ7SUWN5bKMWn3FtvRkLJlIRY07zykAAIDoEGoladKkSXT77bfTzJkzaezYsVRfX09DhgyhqiplGulMICYwaxmkkiQa6J60JJFo4gZ9d7tcA4VLjmRx0o4pMbEksQVuDeooz26nFt61LEnpCRGU39VK0t669Ov3AyfZ7dg9vvL4XtStfcukcmPUN1m8kgRLc/7C2NWa2e3qDGKStNztrPDSuDU8aYWU+4S72wkcx84r78vs++8+nEsnPjWOtpeJKxyP/JCwNFX7dL+/mltIH87YRONXlii2l1Ylsi0Cayzbmh3KIAAAgIi4240aNUrx/f333+cWpXnz5tGZZ55JWWdJioDLh7SWjZZSZTVxg5ZFQfOcBvuZKkkNTdwikqyPSomRZ7djwrvcGqZlPFEL8mytIHkValRCclVgSpJ+4gazXhZTrUtlZEVitMpLtS9j+bby5D1mClcycUNzX9BWktITN9hBM3FD8orNLYOMn5sVj4WFe+j8DsbZHoNibUml5nbWtFZbMVvSfAMAAACRUZLUlJWV8b+dO3fW3ae2tpb/kygvT8wAMisU+2cH6Ti7x4vQFG8yFUrqNawufhFvahK6fqaw8LZuSN+3pj7dZUWtlMgtSfHGBl6W2SK6kkzd2NiYVsd6jXMqzt/QSI2NKYPqXpX7W21dPTVIwrtK82Mp2dXnY3VQ7hOnOtk+Nap7WF4tlnygSbD9RVFbflgdpfIbTZQe1gpsX0k5rak1rtfvTu9Du6tqucIxfuUO3m6Sm2O8qZFizfdXSuKhpfOyY92wpEr9gd3KpuZ7xZ433s80imfn1Hse82Lu3hM3icvGEznVtXWK62H1792pNRWWpmdXlGhogKsZAAAAdwjDe1O0DpFRkpiQeOedd9Jpp51G/fv3N4xjeuyxx9K2jxkzhtq0Mc+UZgRz+fOKokImqCeE9epqFuCdLikWbdkamIfkunXraET9GtNuU7prB40YMYJ21aTvV6hR/6q9TEnQtgT9PH48tc0nqqlhlgh9a1FVFZs1j9G69RtoxAjl2kUr97DjcvWva8NG2pkfT+6zau16RR0nTZlCRVsS96apsUFRj9raOn6tclYUKc/HFI6fJ05MtoU6LmvmnPmG9ZMoKSmWncv5Y7t7d6niWiZNnkxrmh+PrdtSfVGLqspKXpeqisR9mT5rjuE1zJ02iS7qSDSrJNE2JSUlVF3DPsdo+tQptHNH4nw7m+u0e+eO9H5SVU01XKdJ7we5MWbtE7M6TpnGElvkUW3NXlqwYAGvz65du/n11Nam97OGxsbmyZn08mfNmUtVa+OhHEo3btigeQ8nTZlKFeWp62TX3SmWQ4UG9/vnnyeE7voAAABEk7EeytKiJORscyLz5mOxSUuXLqWpUxPZu/R44IEH6O6771ZYknr37s1jmdq3b29b42Q3dfDgwZSfn09eMGX4Mpq1Ywv/3Kp1a6La9HiHrt26E+1Sxhj4xaGHHEIFgxMB+HfMGKO73/49ulNBwUAqKt1Ljy+Yovit875diXYr00Q35eRq+60R0flDh1C7Vnn0zLJJVFanb3Hp2L49bauuoIMPOogKLjhc8ds+LC31Cv0saD337009O7aikUUJ5apn7z5E24uSv59y6mm0dMpGol3F1LpVC9ori+nIycungoKhivI2TlxPPxWuTV0fxeiMM84kWjhd8/x9jziKaJ2UrU6frl27UUHBsabtL0rHTh2JKhKWWcYZp59Bh3dvxz//uGch0W79fta+fTsqKDiVPto6mzZV7qFjBh5LtGqx7v7sPu7TMo/2zt9Cn65bRvvttx9tqSljJgo65+yzaPbo1bR8zw5qs097osoK6t6tG/8up3Xr1tRY20ikYaHMz8ulRo0EIFqccsqpREtm8wmTY4/tS++vWcwt0wUFJ9Jjiyeklc/uX4cO7amwKj0m5bjjjqfzjujq2j1xk76HHkLjtzJFScmgk06hESUriKoT7ngFBQWm9/ucc85Je5YBAMApx/buQAsKU+8hkB0M9lCWFkXyMssIJelPf/oT/fjjjzR58mTq1auX4b4tW7bk/9SwG+L0prhRhh65UoovjvasuDJZtb/k5uYKXXuLvMR++fnpwqxG+JFmTJJEm1YtKD8/13Q9m/zm2JhYTk5aHXOYEmYAM+zkyvZJ8/7LyaV4c7tL2faSxzbF087H6pCGQR0S1hFzcnJiLvc9ZZvm5Oalyjdp75zmdm6Vnxg+4jFj62arFon7mJeX2D8Wy0m6zrHfpLW1JDdLrbW22D3Qi8lL3BcxJYldpxT3lKpPom21ko0kUoBro9XfwkJernafa2L3SnZ/+XWb3G+pnQAAwC26t29FZx3eFUpSFpLvoSxtpQ4ihPrtx3zn//znP9Pw4cNp4sSJdNBBB1E2oBcDEY0U4NI6STGhxA1GMeGi6yQls9sJpHBWwzKzyWOe1Nn2lOmqrWe3k86hR7VgKmm3Y+fjBu1kFqgvNUN+c5IOrfuq2L9Z55FaL67KYKheTFZK/qGoL0/F7qyfSOWkJ25Q/hV97sL8ODKlWjQNf4gvAwCQobAhWHT9RQCCIi/sLnaffvopfffdd3ytpO3bt/PtHTp04O43mYpVYS2MKcC1MMuCpkadKMHOfmZNplZg1AI/a3NpfR71Iqda6/ZoKWVaSlKr/By+sGxQ2e2MlEezNpOaQbrXZvdVuj/J5axkSRhY8odkdrtkCnAtS5J+nUWzIMqvjb+gBQ/Te+7CPGmh90xIGQStgOR2AAAvMEvKBEDQhHqdpDfeeIMHTZ999tnUo0eP5L8vvviCMg25TBPlxWTz85oFYrJmUVHD5F5pNtxMlpX20xpwzSxJDaqZda11kqQy1BYOTUuS4Ox92xZ5vq6b4+Y6SZJSI7k5mgneWpaepCUpR75OkpRFkLQXk9WplxVLklYKcOmmWbXgupGS3Cv0mkTrGQzxZQAAMpRE6h5YkkC4CbUlKVvX59ATvtiaO0EhOpSp43bkmLlliZaTvq++u51ZH2KCuXwXtbsdU4QkHUctjPMFTpviCtcmrfNpCaZtWubSriqmJAWTXlmtUCrWSTK1JCWut2WzJUlLCUztm9pf0kvkSge7d5LVQ2onTUsSb2tywZKUOLeVV7NeLFSYJy303O20rX7G14HZXgCA25jFQgIQBkJtScom5BYMPZEkQB1JGGmBUa3xz4olyYp1wGhfMzlWbUlSK3LM4iG51Wm5MKkFaNGYpLbNlqQqlrFNgHiILElSK4i428nbTJo1lLc5u3eSQC9t1/LYZLdA15KkZXrSQSqCWZJEj4qiu50erI2zdO4JAAAAsASUpJAwYsk2c3e7IKUbwVkfKZhfSwS1ZkkSF3zVsUJWEzfIUQv8PHGDzDXMTFDWOl9dQ/q21i0S2ccCsySlKUn6v+kmbmh2rTS6r3KLhnSb6mXaPrMYSopU0t1O894buNvFbFiSFN52zYsX6x0TSXc7vcQNcLcDAIQDGJNA2IGSFBKUsTB67nb6wnpYME7cIC6NWbEOpNzttGKSjI+tb1I6E2lZkiTlVCvrmlpQjgu4SbL6SlkAg4pJShfwLViSpJikpLudmCVJQt+SpK8kJSxJ+vURfSSkMowU67T66lqSKCNiksyAEgUAcBsoSCAKQEkKIXprBzU2C9tWZs7dQvSMkuCsVcU6VbyPqCXJzHdZL/5CJCZJnXRA3fZNZu52ApYktWDK2khyS4yyJUm6BiPBW+vWNKhjkppHIWmzSDvLYbuLThwkEzfIlguSrtdqwpRALbsm6CmBWhMVZldRUqG/kDMAAACQqUBJCiGVOmvnSLJouC1J+hnprKQAt3KNSUuSxm+m2e1UVp7a+iaNxA2SYK1h4VBfklZMksrdjrWRpEwKxyQ110HP9csq6lLk5YpakiRrWK2wu53SYsS+st/VSpFWOxsqSRYsQ1rrJJmhpwy5dS+84MVxq4XWBROZSPjHt0tcrRsAAMCSBKIAlKQQoj+jbRSzEYF1kjzKbpdMAR63nuyCu37JDlQrcvJ1krTipNQCtGZMkqpMZoGRytpbb83dzi3rhVowln8zzW6nuteVNfrWMHlfjaksSVIbqJUi65akVBpxM6T+kFDY1NkKdSxGOm6i0nWEMQunnhsns5xare7WPTXuVAoAAJpB+m8QBaAkRQijBAJhIakkaa51I16OVvyPvcVkTdzt0ixJjRrrJBmt99NkObsdayNpjaEqHauhHm5lVFO3i611kprvdYXBNWjdm1Sq75jmPiIJMpT1EbcMpdZJSm2LO7QkRSnLnWbiBpNjwqgEAhAmvrz1lKCrEDlgSQJRAEpSSBh203HJzwN6ddDcRxLGrGR+83vWR3K3c4o9dzuNeAuzxA0qVzi11Ycnbki2e46ppUpLXlanGWeWJBFXNS8zqqkFe8U6SSbHSs0gxSQZWZK0sttJ7SG1p/pea7nbGa0Rxvqml4kbzGKSwhybpJWoRI1Z9aNzdQAEQ69OrYOuAgCR4MoDg0lWZRcoSSHh/P496PdnHGToKmMUGxMWkokbHJrSrSiCuUbudhZjktQLo/LEDc1laFo40tzWzN3tWBtZVXSlUt2yWqhdH+WXYb5OkhSTlPhbUVtvbZ0klUVU3Z+1msbosq0kbkjFJKXPZMZtrpMUKUuSRaU87KnOAQgDsIpYJ93hGWQDJ3eN1vsESlKIkALbd1fVGcZG5EUgJsnpSyPXQkySk8VkmbJgtIvckqSZmtrAIiPibmcV15SkRiN3O+NjpXubdLcTjUmKKRXTPD13O4udJ5ECXNTdLnWMqDtZQyYpSTxxgxKz2kfo8gAAEcEsay3ITFokloiMDFCSQkS39q343106SlLU10mygqXFZB1lt4sbnp8dL1mLRGJltARutZLELDCSu51VPLMkyT9bjEkydrdL3ya52+lakiz2b57dzmoKcGZJUv9osWkbIqgkWVmrLEl0Lg+AQEASAgAyEyhJIaJv130Mfzdy+wrPOkn6KcA9j0mK21gnSScteav83LTsdppZ19ISIJjHJHFLks3YLbfiX9QugHJl0jS7nWqdJNHEDTFVm7tnSRI/JqUkySxJls4mKytTEjeY3HC42wFgDIwi1kGTgSgAJSlE9O1mrCRlqyXJ7AVk5GplJsCyGCQtGbBVfk7y+KQlKVfAkiQak2SxnaQ6mqU0tx+TZD+7nVFqd63EDUn3xeb2VDeFVUsSq4/oIdKlafUZq6pAMnFDxJUkM6JzdQAEQ3jfyCEGjQYiAJSkENG9fSvap2We7u+BZrezHJPkrI5WFMHUvuninF35VWlJIv11klQnaBKJScpjliSb7nYuzeqr3QyViRuMj5WaoUWe+T1SWniUiRuk7HbqvmJ1EkBalFYE6X6xY5z20WRMUjxiMUkW6wtLEgDAbaAjgSgAJSlEMKHtUJnLXbtWeZpCmZ7lJAwWJklwdloTK0qEkbudXQFPUpIazLLbiSRuUKUZT8Qk2WshdaIIt5AXay5EKy1JRmglblD/pm5XO4kbRPt+MkOkInGDpdOlyoqku52NFODRuTwAgiH4Vy8AwAOgJIU4LqlTmxaK35Iz8DoCtltrFGkhOuuutZaQX5Yk7Zgk8+O1XOQkdzumlBhZ8NRKmEjihkRMkkV3O5NEE3aR2s5KTFLSkiRwDUaukHoxSVYNPDxxQ8xGCnCd3zJbSXLJXxMAkASJG+zJFIjlAmEHSlKI45I6tslX/GaUQMDNeCAnuJUC3EpMknEKcHsCbGtNS1KOLUuSGzFJeudzitR0VtZJSsYk5Vm0JOn8pnaVs+VuJ3iIdCvcSNyQOSnAo1N/AMIIhH3roMlAFNAPgAGB0Ldru+TnDq3zLSVusJtW2k1E4lREsCIoSwJv3IOYJJ4CPNnu6fupFYomQUuSbXc7l32fWDsnkleIJ26IWbEkKZTdmI4lKb1OVsix4W4Xy9bEDSrXzyv+M43mb94TWH0AAACAsBK8VA0UyGOSOqrc7cxc2vTc8AJJ3OBwnsjKtTiNSdLObpdK3JByt8sxTe+tdTb1PkyRtJ24wW13u+Ybq4hJMjlGnd3OuHwytSSpFRxR1znH7nYOHxdpcecoJW7gVk1ZdaEgAeAcWEWsA+sbiAKwJIWM/Tu2pv77t+dplffdR1tJ0gv7sSpcekHSjcxhVbRc2/QwymwmEmcSN8tuZ5A2On2dJLEU4JZjkjyyWqQW4rW+TpJIDJyRhUdSOt1xt7OW3U6xf/MFW9V1pHuvVoLDDGKSAHAfp5kysxE2kYp2A2EHlqSQwQTG728/nUb85Qzd2CO3kiNYQdQy5FbyiDxb7nbpiOgUWopHa/k6SQYJM3717mxauqUstUEkBTiPSQqJu52GJcnc3S6mWEzWCLkyopvdzvFishbc7SQlKccFS1JzWVFKkQ0lCUSNqfedQ2EHor49rCbLAcBvoCSFVFFiFhk9IS4Mqb71kOJUnAqgyoB/48Kkc9l1t9NaDFWeAlwrbbQE+/26t2Yank+ddjkRk2Tv0XM7u52kb1tbTDbxt4XDFOCSoqi2JNnLbie2r3Rp8j7lNHGD2/fES6Jk9QJAKzYXZAZurFUHgNdASYogQShJ1mOS/LMkGe0pIr+q3eHUiRukrIJ6daqsbTCJSVKWz5I22I1JcnudJMlqI9eLzFOA21wnSXWndC1JXi4mm0zckP6b1SxvUllerV3lBayvR6e2AECQBgAEB5SkCGJFiPT7/eJW8gj5NdY2NAodoyXkipjz600sSUaLyarRkpfrNCxJdtvJq5gkK+skSTUXSQEutE6Sw5gknt3ORkyS0+QiUuKGKFmS4G4HokYUVKTojADhAcoviAJQkiI4iFixsri1dpLoGfOb/becDoDyeheX1xrXTTqVXXc7leDImldK0c2sBJIMLNLuQovJ5tl3t3M7k5qWJUk4JsmiJUndifTWSbKc3c5C4gbJ6iM/pXS5dhM3RMmSpHb9BCDsQJYGAAQFlKQIoudapCXk+b12kqjbk6vWMgMVTkR+VSsxLB5Myq4nV6BErk3rHqjLZ/dExAqjRZPLhgAtS5LoOkkiSToUiRt0EpA4drejmG7GRzWKTIUuJW6IlCWpoSlS6zoBADIT6L4gCkBJiuAgomfR0LIyuOX+ZieY3glWrGUS2tntRBI3qNYx4kpS+sy7Xp3kyoKWy5/anY8pSPkhtiSZxySlLEpmipL8MtXWxdQ6SeTYkuRkMVmrsUjJspqiuU4SXO5AlHDqFgvCCSyEIApASYogevEXWjPEQaQLdzu7nei5tFzdROTX9HWMYilLkiweSq9OcoVHy9JTr7ovzJXPqhIoXYfriRty0hUFs1PIlRgzZc94naRmdzuHlqTW+bmO3O0krLaspIBLsUlRgClIUJJAlIiCMI1U1gBkJlCSQozeOjR6QqSW1cSORSYMs3lu1VtEqUiz9DBLUizdkiSiJGlakjTWSRJZY8iXFOAa6ySZvfDlQovZdRi526UsSeqYJLLEPi3zxJUkWTr3mEvptKNkSWL3uaYeShIAIFiioPwCACUpxEgZ1kRd6DQtSS6521nFqQgqWXKsYHcxWS0lRhLc5Wso6SlJZXvraVHhHt3zaSlhtt3tXLck2YlJSrVD2xZ5theT1VsnyWpc2z6t8iy728m7V/JybSZuiFqMT3VdKmU9AGEnCsI0MrVZB26UIApASQoxLXVm6fVmzbWsJq5ltwtxKnHpBWV3Mdm0xAp5OokbDBrhmjdn6NZBazFZkaQHWohcjxVyNLPbmR2T+ty5bQv310my2NksWZKaL471GaeCTTImKWJKUsSqC7IcCNMAgKCAkhRi2rbMs+SKpuWKZVcYj1RMksFvYinA4xoxSekKlFGdaputRZopwFWBSi3yrC8mK7nxeWVJktfbzEVRLrR0bJPvYJ2kHFfWSWKWJNFDUtntNFKAW11MtrkwtxVXAEB4OO+Irqb7ICbJOjC+gSgAJSnEXDZwfzqyR/s0AVDPFU1rnGaz7FHEz+x22u52iTa2GuSudTZ1FZy427luSUombhA/hzVLkv5LMblOkuoHq9nt2rW04G4nW0zWKckU4BFK3ABA1LDyqLo9KXj9oN5C+7VrlU8PXNDP1XNnOtCRQBSAkhRiWrfIpRF3nEGv3XCc0EtDK4C8fWvjmf6wYie73Q+LttLC5tgg5zFJzb81pwcXrY+IEuPE3c51S5KUuEFWrlkiArmbWqc2VtzttBVhVyxJOf4nbohiCnAA3KZru5a6v713y4mOy1dPaNx5Xl+6dGDPtP02Pnshffibk9K2dzGZyFHz18GHJT/37drOdP/JfzuHu2gf1t1430P2a0tn9N2XnNKrU2sKmjvO7eu4jPP793ClPcLAhUf3CLoKkeCMQ7tQ1ICSFAH6dG6j+L6jolZYgGYzXG5gNX7D6UQ9W9BVFLmM+uXcQtVvIuskpS/2qo5JEo2TEZGXnViSGjxL3JDaZnYKeVOYKUkKAUfXkqTeTpZo20I8Jkl6RuS7J/M2xG2mAEeQD8hijJ69kw7qnLbtomOsCZTq8YF5R7x83bHUT0Mp0Rrvbz3rYPrHhUeYnufCY3rwd+1vTj/IUv32bSemhH38u5Po/VsGGS5lMPSobrq/D+zdkTY8U0Dj7j7LE1e15686hg7s0oaevKw//e+Ppyp+G9CrA7183UBa+cT5tPrJC+gumSJplauP78XP8fszDqL+PTskt195XC967sqjTY+/4aQ+ls7Hyvzu9tM0f2vbQjs5FuP1G44T6jfd27eiV64/lmY+cC65wY2C19etfUs6t5/SFfTT36dPEjiZ5FBz3YnGltX3fn2i4fP/8rUDKGpASYoAfboolaTj+nTkA+UBqu1atG+V+e52xx3QKfl5d2Wd4jetdYtMLUl5saRSJClQTGcSEaJFLElMCbMck+TROknJxA2ybWbnkAtFndrmO18nSbWPVYWcZ7ezHJPkXMqQFFYoSSCbMXqU3HjO1OOBNBZqjRNajyKrQ7/u7U3Pw4TiSX87WzcW2AlMoevRobXheLj40SE07KbjdX9n3gfsmlnW29+eZk2RE+GaE3rTxL+dQzedfAAdL3un/u70g+i7P51Olw7cn5/b7vIVEv+8egA/B5sIld/CG0/uQ6cdam5ZYorB6DvPpP07GlvURt5xBrcuXntiHxrQuyP9/Nez0vZZ8uhQQ6W5p8k57ju/H0297xx+X7t3aGVadxGuH9SHFj0yhCulrfK125ptZ0rZy9cfq9gu949gyhZrA6PwCyZLTr//F/Tq9cfS5384mbeXEb8+7UBDWfOcfl25si3xxa2nJD+ze9AugvIolKQI0F5lDbpuUB86tOs+dITAwO+aJcn3FODix7MZNjaTw9hVVWs9cYPWOknNT4ZkSWIvWquB/XpwJSwnZnk9IC9cu/K0EjdYiElS9830fY2y2+W4kt2uXct8cXc72WKy6kWILS8mCyUJgMBiS7TOqzVGc9faWPhTebP3jtH5g/LqDWOChcO7t9NVIPQUdC0lxuy9Yb4chjWvF1E6tM7nSmkbgyU2eIZWjfpItMzLTfNCUltae3Vqw+t/8YCedPLB5q5wOQadwUzWDGE3EgJKUsRgpl1p/SS1InHywemuDUFp7o7d7SxqEKxdtFwRReRXeZpvvcQNTHB3y5IkWZHsuNy5bklSrZPEBlFzd7vUvWlj4K6QFpOks06SO9ntLK6TBEsSAK5gJNhrPWduKSJaxWg9imy/qApocpBF03/MmjzoW2L2KJm956xWP0fgQYpFSNkWAUpSxNheXqPZ6Zif7pOXHe1Z4gaRDu7mQ2BVUN6v2a9WrSSJxCTV1GvFJCkXghW1VIgMmqx8u0qS2wK5dFnJNNhxa/fZaKbLLHGDW9ntmAtBzKKgkZiFU7vxKC/e7JZHdZ0kANzEaN1vO9ZyMyRrkdYwoTXe8918ENC8PoX8yjJlxFErzCIKtJ+KSTzCiiufHIi5m7o+5kDIi6iOBCUpKvzx7EP43/tlaUblAujTlx/NXfDUHN7NPDuPawkJZG9Ly+55aiuD0ZvXQEmqqmukqtoGR4NYYp0kyZKUym4nUpI1S5J4K0nFup1tWlJIJDlfxJ1PrsSozflG+5JX2e1a5gkLDXJ3OzPM+mAycUOIX5QAeI2Ra7WX7mta59V6EtkEl133b6HJweayjUYBN9oh0+di3B5G3eh6ZkqE254dVjHr1+o2cFrbHCdKUkRNSVCSIsI9Qw6nsXedSbeeebBQh2XBjRPvOZt6dnQnmHDa2p2m+0juU3ZQW1XsCMqS65fcmmRnDGM+usnEDbKYJLNRnFkUxLLbxRxYkqyt2ySe3U58YdSYKqkICzC9rVmJTy9fdpw69iipJOkfI4KZb7rdxA1mfRDudgCYJW5w/3ypxA3iliRn8llIhDtMxoQOr4f+mMWuEAvQ3S4WM1aGQvIUWQZKUkRgAlvfbu0UHZCtVcBct1j2GTUsK8uB+7Y1DaYTTTe5s1I77bgcudBvddYgX/X02VlMNulyJ6urPUsSc7dTC/TmA8re+kYxJak5O5A9JSnx161JGfV1iuhg6oGXBZgW6KwTIU/CkG4t1Ha3s55uXnz/1DpJ8sQNzX8tKklI3ADe/tUJlO0YCWJezB5LT5tWyVrjFwtgd+eMwRKOWniLSG9JLtlgtp8LDWZWhhfudlYeGfW+ae6LZgXE/bMk5cCSBPyGKUHLHx9K/7joyOS2uwcfxlNj/ukXh2qmfLzpZKVSdH7/7kILw1XXNZruI3cfs/o4qGN+cm1YpfbbJ6EklZSnlCQ7Y1gL7m6nqo/AA15d2yCUAa+FHXe75nKlQbmlwzSseovJigz6WrqDXpa7HMOYpObsdjbaOlVGzNJ9nrRqh+WyzSxJbq9dBaKDep2SbCQo0Uc7BXj6s3jJwJ6+1NHzmKR4phuVwndRZu/zMMckeaGYxJwUF00dCUpS1FGnn/zLuX153v5uzdne1IKelg/r7eckFCozK4kWr91wrO04IqOH2Y4lqWt7KXlDjQuWJFX9WExS3FyRFJGXnWS3k6wWzmdHtddJEoqv0Rgp27fWTuBgpPDoWZKsuFoaLQaoRUVzvNqY5cVpT4L60s36YFKxhJIEshmfhR9DdzvV90sH9uTZYJ1ZtKzFfXiFW0tQZAvuxCRRpJWktJikuLM+lSPQqBHVhXSBkpSBGL0QtH4SWRyO5e3X4qJjemrGJFkdoNSCsR2FS7IkSe52K7aV08il2y2Xw9zhJCuHBF8nyWRArKprMN2HXad0rU6UJKcL+snro4hJEhD4tXQHtcUyua9BCvBUTJLyB9FMgkbnNWPrnr2mLwozZU1SKGFJyl4i6kES6Gx1zK3sdlq/6Yy/zu5TOJ5vl8NRMz7g3g3MlSRvz6/X9EmX05ize2dVx8uxKFsqfqdoAiUpy1B38qN6dhA6jmXPE3UjszOwplmS7LjbqdKAX/DyFLIDtyRpWDdMY5IELElyFzsr7nYSkjIjb2snSMVI9RYZ9LUGSr0F9ZSKhvY9duJu16ZZSbI6IybSP80sSZJyFPbZRADs0rFNPp112H6G++g9JT00Fu+UOKPvvsnPv7Dpsqj1DKsfxZgfMTI+Pf7ZMMqIjKVW01ZnUwpwq/qsdSWJsi4mKZiVRoGvsLThz45cSe1b5dFt5xzCV1eetWEXXX18b+rctoVQGQd2aetpdjv1w2c0i8/icWqb1y+S07Vd4qVcoloryY2YJJHBgbnbmY05cuuRFUuSNJhJgnlLCxndhAQNKZ21gJZk5S4bJW7QXSfJwqW1tWlJ4qdWJW5QYxYXh8QNINPp2DqfHrzwCJq0eodl4WfS387RPeaDWwbR6pIKmrx6B11zQm8a+PhYy3XTTNygVpKa6+ZMPAuHcCdXDjLR9Y5dnps6h/qu2fFOMVPIenUyXgLDOSaunj73zZiRJam5Lnq7RFRHgiUpG/i/sw6hjc9eSIsfHcoVieMP6ES3nX1o0vKi5p4hh6VtE0mkwBJG2MVKHIrc1ezCY1JZ1aTrmbhqB53yzHjbddHKbsfazTwmydzdTm4BsuNu1+RyTFLK3U58ls6KO5zRvrrrJFkYTfdpmWvrZSGUAtxkH6QAB0G4IvXfv71v5xKKQdDZxcglmI0L/bq3pz+ceQh1bCM2USchDVHyuv3y5AMMlYdMcLdzqkCweGU3ufr4Xmnbrh8kli3XD+Ia/XHYTcc5KkO9duV1J/amIHE6/Fj3wCBX9okSUJIAZ8I9Z9MJB3Si9359Iv3pF31pyr3n0AOyhWvlrkd9mxetlV7Wv21OQX6tgwFDvv4To7pWP5ueXEF49bpU4gi50retLJW8wQ0l6crje5kOJ9ySZLLT/p1ap6UCt5e4wd6je0yvDjqLyTYL/CLrJFkYBOW6tW52O7UlycIJ2rbIsy3cyhUrLeVQRHFnSiuUJOAnbW32eVsICUUWY5LcEqJk5TxxWX9tS5LWzhHFqfXI7RbQUoKvPG5/GtC7o63y4oKKoJNWOL9/D+qqMzls9WT3nd/P1kSnl8Qs9iFfY5JiFEnCdYdBYBy0b1v6+o+n0jnN/uG9O7fhyk+nNvnct1wulH/wm0H0p3MOpXdvPpF//8eFR9Dsv5/LByAj/nNj+izO5cfuT9/efhrdfOqBQtn0GMxtUMtScUCXNnxBWVbXw7olFDk7MOWlRnX+C4/uIZC4gcUkxQ0teu/fMih1nqS7mXjdJCXGSEm68rhemrN87Vrm0csypZIhjfFSrc3k/S5tW9B1J4rPFsoVDbUwlcxup5FJ0GriBiczYnpHirhnsPuBxA3AT/wWNswEqaBkH/8SN5gEv/tkaXKaAjzu8tV7cdV+xPhYOUNo3RqlDI9WD3N4OTEHxyImCWQcLBh/1t/Pa154M6ZYqPaeoYcnv7PfujanHNdj5B1n0BE92tOiR4ZQaVUdbS3bSwfvuw91lwX3ntdvPxq3cgdPaHDqIV10y2KC/u2fzqc7z1O6D7CFc8fefRa1zk8oSkc9Mlq3jEsG9ORpqz+euVkzk9/B+6VisAb06kCtBVJNP/TtUsPfmQVOHgMmzUKxGbma+iahzHmSu52RK4tRwgH1b5L7n0h2uyuO3Z/+efUAXQsLK1utMBivk6TjbmclBbiTmCSTl4eIssasSOt2VNqqAwB28DMOIYyCjaQIaVUtTchu3ieWAa6XjsX1kCUZ0MLNGuoqd/GMajJH1hyrl5cjlAI8fGOGE2BJAoYwYVwvc5kZf2le0PaC/t25giQpIGwR3FMP2VehIDHeuPFYevHkBlrwj3M1hd9bTjuQ3vnVCXR0rw40+d5z6IrjemnGRTFFhB3/4W9SVhvJHU9SLpiCde4R3TTrPejAztSmRR79bejhXLF57QZrfswSakVG/V1ytzvhgM6mZS3dUk5vTFonZEniazppDH9xVR1yY/G0xViNZvLk6cu12Edm4RNJ3KC7TlLMeyWJO9slEzdoX7PIWl3MxXL2ht226gCAHRwsR2cZkScxKD1KS2DTG77sKjAix/klSIctk5oWTmsoEhOb3MX2ycQPDLrFnab4NsNyl4rZ+inxewgnXESAJQl4xh3nHUZn9+tKR/UUDzRmcqlaAWCL467bUWWailZvcVkpsPcPZx5MHdrkc0vWAV3a8n8stflL41YrMuJJyhtbZFe+0K7VAaVVXg7VNWfhY4rb6Yem0t7Kkw6wFLg9O7aiL+cWaZbDshH+sGgrPT9qFbVqzmpnlLiB6bQNOt6Kch9qFi8kDVxVtQ00be1OWlNcYVBuzNT1bU91vbA1Rn+dJMPTqM7Z3A4epDIVsST9tGSbtRMD4BA/Z2rDKNcYLiabZkjy7wKMBHxXahG0xC5ILOSXmEmWJKfudlbTqec4uLkhHEqEgCUJeAYTfo/r08lxJjaWZtOqgiRPCc74x0VH8Dir9q3yuXIk1e+Gk/rQlPvOSa7bYRR0KheaX7/hOH4sW9H9zV8ez7Ps/e+Pp9L1g1LJK+SudY9cfCR1UqVbZzFfvzv9ILpkYE/FWiFXHd+L/nnVMdS22cXv6cv7J5NjSG557XUW9+XXxRa+1djOBkT1gr9MkWN8Mmsz3fjOLHr0h+WOlCStuiTPp7dOkkeWpO9uP80kcUOKsr1K5Y7BlGkzXhm/htyAxYuBzOD5K4/JGMWFPSVhi8uI27C2BC2gudGC4boL7isQbqcAz2TrXVDPZMwwcUNmpgDHmxlkLExJYckimHBvpKix39646XgasWQbDT2yu+5+15zQi96Zsp4O796OK0Xy9ONDj0ocx9Krn3hgZxq5dDv95Rd96Yo3pvHfWAyUmkO7tqN/XHQk/7xLJpA/c8XR3OLDLEhsPSgWa/X3giP4b+9O3cD/ssQUt519CP28soRWbldaf1rl53KFUKJXp9ZUVLqXzjxsP0UKcvbpuhN70abSGhq9bHvS6sU4ZL+2XCErOLo7vT1lg5CSxNwZ1XWRW4XS10nK0bTYuBWTZFSOvC7Mivir/85Oumtu2bOXf94ukCFRWrjYCUwBZtbWu79c5LgsEDxqN2K38dNtxYuUv7FA3O0o8jgV2MMp7qsJW+KGcJPer611dOsxSWSbqD6CUJJARlNwtHHGPbkVhC1qaARTVmY8cK5pWSxWSoqXYokqWCIJM8GGKVJfzS3iypTkEseUHfZPEvgfuuhI/vuEVSU8KyBbX+SeIYfzWKXFRXto9LJiLmwzC1ePDq15hr4z+u7H3Q6Zu961J/bhZTMLFcvEd3D7OHVr34pevf5YKq+pp0mrdtCfP1vAz/fwxUfRmX335fWWlCSz9Uyeuuxo+vX7s+mwru1o1LLtfNvaEv2kBixBhxZ6bcWsLSwL4vzNpTR93a5kjBvDsmt1jKjLPonrqahpoCVbypIKpaQk1TUaJ9NgnHxwZ5q53nlMEnN3BMBrQcUqYYwjMNIVdNdJ8lBEi/uVuCHsErtDeGIioWt0qCyqGnLsnafRLW9PpaKq8PV1t2ukbjmr7nYxgxohJgkAYBmWAEKEffdpyVOhm8HcAeUugcwKw+Km2GDHhHtmCZEGI7belQRbtFHivVsG0c7yvVSzYW5yG3NDvOiYHrR5dzXPcCcpSIznrjyafly8jcd0GdGnSxv6+a9n04adVUkliblbSsjdDZni2LdrOxKBWc2euLQ/t9JJSUQe/2E5Ld9WlnRT1Fur6LRDu9C0tQmFSg6LUWOWvI9+O4hWbCunp0esTN6Hw7u1o1XFFTyBx+yN2goQc5NkCuavTzuQ+j440rD+lx3QSN9u0rdkrimp5O1vxHlHdKNZ63dRBZSp0MOWIfCSsIka7Nm8/D/TfTufpAhpCV1p6yRJ2e3C1mgBuFi5r2TFXT+H0DpJLl/HgV3a0sAuTVRUlRsKzdSKQm95jTLVdyn0QPx8ZJuoPoKRUJJef/11+uc//0nbt2+nAQMG0KuvvkqDBikzlwGQzbDBksVuiTDooM5UX19PIzamlyFPVCHBLFDsn5U1t16+biDtrqqjcw5PxVoxBe7dm0+gl8ev4QsPyzPtMQvYsq3l1LFNQll48doB9N60jdxdUuu6Hr444aYocWTP9vT9oq3J9bI6tWlBfbvtQ2/+8gTqr5EK/lenJNblYpY29k9SkpjLIFuYctLqEhp8ZHd6c9I6mrxmJy0q3EMPFhzBU9cz5ekCQQslQ8dglqSipp6O7pWe3IQpgMydknHWYfvSxQN60B2fL6QwIt0/wFxV7a/RFra03CJWq2NlEyF+ovVcqV3SvGipe88/nNbvqKKv5xUJZ8GMub5Oko/Ce8ynmCSXY230HhMrZwjrEnhuuJUyj5O/DjnMA/fbmO1jw0jolaQvvviC7r77bho2bBiddNJJ9NJLL9HQoUNp1apV1LVrSgADAISHSwfur7mdpV3XSr3+zW2n0o+LtvGFixmXH9uL/xPlxpP6UH1DE1deDu2aElJZyNK0+39Bf/50Pv329IP52ljsBSO5MUqwrIEsBuv8/t15LJt07r8OOZz/M+K1G46l96dtpOeuOoaWFJVxi9eQFycnF0Q+omOc/lFwOD05YhV1b9+KrwH2zYItScWRuSmyODcW8L9saxl9MGMTffq7k+jUQ/el/0xcSyXltXTDSQdQZU26FYkpnZ/N3kzjViSUKTXH9OpAi4sSroTsvMwN9MmflnNBm60837dbO+6KqQVLIMJcIj+bXUiXDexJlbWNNG5Fsea+TCmVkNw57XDTyX001y5zC+ZWW6myxrH+0r9ne/p2oXY7WEWdoMVt7hp8GI1vVp5FGNi7Iy0s3GPrXId1ayds8RW1pmkJUSy+8j8T16Vt79c9/dw3DOqjm7yGLfr95I8rDBcjd8ptZx+atJKz5DPSWNLTIBaNTUy5KRi3FvRQMFuiwQucCMN+6H7WstsFqyXJ23Lc3WfSeS9MdlSe/GpYZl/L9SEHOcAjaksKvZL0wgsv0O9//3u65ZZb+HemLP3000/03//+l+6///6gqwcAcAGWPOPK48WVIq14sT+fq1xcWIIpIt/cZuzKOPaus2jTrmo6+WD9RYz1uOiYnvyf3Iow5q4z+cu4sbGBFs+YQAWnHEC/OzNlpbv6hN60rWyvYq2va05kMXG96bFL+6cJZAyWvn7lE+dz6xJLDPLsFUfzxBVM6dxZWcsTPxzUpQ1NW7eLryl240kH8ONKymvof/O38MQjXfZpyZUfOX8v6MeVB6Zs/bRkO3Vp24K27tnLY+BYzNf1g/pwt4zyvfVU39hEk1bvUAix798yiG8/4/kJXEhlVkSmiDCLIbMGymPKLj9uf37NLOX9Kc/8TI9echS3mP20eCtde0Ifvg6YXEliCu6CzaV8oWYm7LPFilnd2JIAjMcuOYoe+X5Zcn+m1NU3xumlawdy91GmrF375gyu/DIXS3Y9n87eTM+NXEn9erSnotJqGn7bqbz/MGX4js8X0PzNexRujpJiOOXec6i0uo4ueW0a//5B8zpsbD21L+cW0sH7tk32gyuP60X/m5+wNDCLKUuKcmyfjnydN1ZGcXktV8Zv/Wged3FlsHvGJglY3OCHMzbReUd0TcYDsu3MlZUp83Ilo1ObfN6GkoXx31cP4PGJzLJ63/+WcIWVufGOXV7Mk7NMXr0judwBSzzz0+L0FPY///Us+sW/JyWzcrJ4yDVPXUCXvjaNW2n/fPbB9OP4KTTg+BNo33at+X5Mqb/hnVn8M7O0sr4jwayz8gQnR/RIV3zuPb8fV/5Yhk1p3THWPl//8VT++R8XHsEtN6zNpYXL2bP6nUqxZXGTLA70sH8kXGBPan6epaUTrMLGDtaPtCYH2Ey8HDbhoAV7vm46OfEs2oVZ2NlkjMQfzzqEhk1KKZUsqypzH37ix+W6kyQn2VTURMZENvmzvbyGW5QvHdCTFsieIVEFij278oywerAxTC8xD8tSO2XNTsMYWq0EGO10vJ3PsJhVl40B63cmxiY17VvlUbnGRJeaXp0Tz5QUU83GULZeI7u/ZshbRGofNglkFBvsF7Fo6kgUiwetKhtQV1dHbdq0oa+//pouu+yy5Pabb76Z9uzZQ999913aMbW1tfyfRHl5OfXu3Zt27txJ7duLr9cjh7kmjR07lgYPHkz5+caxA8A+aGf/QFv7Qya2M1OImIuRiD88Sx7C1j3bXl5L3du3FDpmxvpd1CovlysVRuVKM/jM8jZmWTFdut9OGnLeOdS+dSuhNa4YLP5Ovi97HTKLWTvZrPveukZqLbOMsOuXrzemBYuRY4IJyxLJXrCzN5bSCQew5RCUx7GymXB5YJc2mm3DziXFGsrPyZTEN6dsoNvPOpgrLlr1YsoeK1cteDIlbUtpDY/1e/iH5XTGofty5fHh75fTfUMPo6FHdeP1Z80irxNrG/Zdr0+z83Vum89jPNTXwBZdZhk2p67dRbecekDawtpyTn52Is/2+fRlR9HVx2tbpKV799ncIjqhT0duiZVTWFpNiwrLqKB/98Ti2vE4PfjdcurcpgUd2rUt/bB4G/3pnENo9oZS+nr+Frr1zIPoquNS55qydict21LOtzPmbd7D68/a7MjmhdG1YNf6+Zwirgg+M3IVXX5sT7pJpUyxiYg7v1zMP996xkH07rSNdNd5h9Ifzkic68o3Z9LiooTr6tBeTfTL846nQQenYkQl2KTOeS9N5YL56DtOSzuWMev+s7lC3rdrWx7POXzBVvpg5iZatjWRhXTIkV1pzPIS+vg3J6QpUdvKamjtjko6/ZAumn2TKULXvD2bjunVnj7/XWKihMXgsr4za8Nufk+YwjtpzU763/yEMsueh1F/UU5YsXbatLua/nP9QH6v+j40hoxY/fhgXh/m3vv7j+Zzy/2oZcV079C+9PvTD+LnZpbEs3UUnDu+WEQjlhZzy9+ke87k/XnUmLE0o64PfdVczwv7d6eXrk2k8r/t04U0VmWpv/Do7vTSNemp/hsam+jtqRvphXFr036bfM+ZdOa/EpagEw7oSH8bchhd+3Yiqyrj+9tOoQ6t86hnx5SSVFvfSKOXl9Dph3bhz/GRj47lk0BHdG9H399+Ct9H3l5LHj6X3py8gb5dtI2+vvUkPuHFJreOf3oCt+5+eMsJdNWbs/gz+PcLtD0kvpq3hf7+bWLiqXv7lnTzKQfwRElsTHz52gG69+fcfvvRsBuP5c/Obz6Yz7eteWII/WvMGt7H2fUd2LllaN6HTDfYd999qayszFA3CLWStHXrVtp///1p+vTpdMopiQ7BuPfee2nSpEk0a1Zi5krOo48+So899lja9k8//ZQrXAAAAAAIJ5X1RIVVMTq8Q0JRy1RqG4nYWths6Tu5oausjujHzTl0Vo8m6mUSV19RT9QmN7GAuBRDw8pj8Vp1TURtNHyF2EoP68pjtF/rOHVOrbdui9Jaovb5qfPrsWMv0ZgtOXTe/k3ULaUDaLKhgmhteYyO3zdO329KtEOHFkQ1jUQ9VSIck16Z/qZuQ7M6T92eQ2d0b6KOquvfXk00d2cO/aJnU7Lt2H0aU5TDkzt0apmoG3OhltYxV9MYJ5pdEqND2iey9Q3fmENXH9xE+7ZKlN86L9FmrN5bqoimFefQ+b2aqL2Aly7bf+K2xP5dmr07N1awtonRoe3jpDf3wL0a4ix+jk3gmN8v6TpyNZ4/ZgyrjxO1zCGavyvG22nJ7hhd3CdxDexc/9uYQz3bxOnUbgn1QvScflJdXU033HBD9ilJsCRFF7Szf6Ct/QHt7A9oZ/9AW/sD2tkf0M7Z2dblgpakUMcksQvIzc2l4mKlPzD73r279qKfLVu25P/UsBvi9Ka4UQYwB+3sH2hrf0A7+wPa2T/Q1v6AdvYHtHN2tXW+4PlDZgBT0qJFCzr++ONp/PjxyW1NTU38u9yyBAAAAAAAAABuEWpLEoOl/2aJGk444QS+NhJLAV5VVZXMdgcAAAAAAAAAWaUkXXvttbRjxw56+OGH+WKyAwcOpFGjRlG3bulrrQAAAAAAAABAxitJjD/96U/8HwAAAAAAAAB4TahjkgAAAAAAAADAb6AkAQAAAAAAAIAMKEkAAAAAAAAAIANKEgAAAAAAAADIgJIEAAAAAAAAADKgJAEAAAAAAACADChJAAAAAAAAACADShIAAAAAAAAAyICSBAAAAAAAAAAyoCQBAAAAAAAAgAwoSQAAAAAAAAAgA0oSAAAAAAAAAMiAkgQAAAAAAAAAMvIow4nH4/xveXm57TLq6+upurqal5Gfn+9i7YActLN/oK39Ae3sD2hn/0Bb+wPa2R/QztnZ1uXNOoGkI2StklRRUcH/9u7dO+iqAAAAAAAAAEKiI3To0EH391jcTI2KOE1NTbR161Zq164dxWIx2xonU7IKCwupffv2rtcRJEA7+wfa2h/Qzv6AdvYPtLU/oJ39Ae2cnW0dj8e5gtSzZ0/KycnJXksSu/hevXq5Uha7qUHf2GwA7ewfaGt/QDv7A9rZP9DW/oB29ge0c/a1dQcDC5IEEjcAAAAAAAAAgAwoSQAAAAAAAAAgA0qSAC1btqRHHnmE/wXegXb2D7S1P6Cd/QHt7B9oa39AO/sD2tk/WkawrTM+cQMAAAAAAAAAWAGWJAAAAAAAAACQASUJAAAAAAAAAGRASQIAAAAAAAAAGVCSAAAAAAAAAEBG1ipJr7/+Oh144IHUqlUrOumkk2j27NmG+3/11VfUr18/vv/RRx9NI0aMUPzO8l88/PDD1KNHD2rdujWdd955tGbNGsp2rLTz22+/TWeccQZ16tSJ/2NtqN7/17/+NcViMcW/888/n7IdK+38/vvvp7UhO04O+rM7bX322WentTX7d+GFFyb3QZ9OZ/LkyXTxxRfz1dBZe3z77bemx0ycOJGOO+44njnp0EMP5f3c6bif6Vht52+++YYGDx5M++23H18M8pRTTqHRo0cr9nn00UfT+jN7d2YzVtuZ9WWtcWP79u2K/dCfnbe11vjL/h111FHJfdCn03nmmWfoxBNPpHbt2lHXrl3psssuo1WrVpEZUZOls1JJ+uKLL+juu+/mqQjnz59PAwYMoKFDh1JJSYnm/tOnT6frr7+efvvb39KCBQt4Z2D/li5dmtzn+eefp1deeYWGDRtGs2bNorZt2/Iya2pqKFux2s7sxcDaecKECTRjxgzq3bs3DRkyhLZs2aLYjwmQ27ZtS/777LPPKJux2s4MJuDI23DTpk2K39Gf3WlrJlTK25mNGbm5uXT11Vcr9kOfVlJVVcXblgmBImzYsIErnueccw4tXLiQ7rzzTvrd736nEODtPCeZjtV2ZgIoU5KYYDNv3jze3kwgZe9FOUzAlPfnqVOnUjZjtZ0lmNApb0cmjEqgP7vT1i+//LKijQsLC6lz585pYzT6tJJJkybR7bffTjNnzqSxY8dSfX09l9dY++sRSVk6noUMGjQofvvttye/NzY2xnv27Bl/5plnNPe/5ppr4hdeeKFi20knnRS/9dZb+eempqZ49+7d4//85z+Tv+/ZsyfesmXL+GeffRbPVqy2s5qGhoZ4u3bt4h988EFy28033xy/9NJLPalvtrTze++9F+/QoYNueejP3vXpF198kffpysrK5Db0aWPYa2r48OGG+9x7773xo446SrHt2muvjQ8dOtS1e5fpiLSzFkceeWT8scceS35/5JFH4gMGDHC5dtnVzhMmTOD7lZaW6u6D/uxNn2b7x2Kx+MaNG5Pb0KfNKSkp4e09adIk3X2iKEtnnSWprq6Oz4AxE55ETk4O/86sF1qw7fL9GUyzlfZns5jMDC7fp0OHDtz8rVdmpmOnndVUV1fz2Qk2q6O2OLEZtcMPP5z++Mc/0q5duyhbsdvOlZWVdMABB3Br3aWXXkrLli1L/ob+7F2ffvfdd+m6667js2Ny0KedYTZGu3HvQDpNTU1UUVGRNkYz9xjm7nTwwQfTjTfeSJs3bw6sjlFm4MCB3O2IWe+mTZuW3I7+7B1sjGbtyN6PctCnjSkrK+N/1WNB1GXprFOSdu7cSY2NjdStWzfFdvZd7e8rwbYb7S/9tVJmpmOnndXcd999fFCSPzDMLenDDz+k8ePH03PPPcdNvhdccAE/VzZip52ZIP7f//6XvvvuO/r444+5oHPqqadSUVER/x392Zs+zeIFmFsBcwOTgz7tHL0xury8nPbu3evKeATS+de//sUnXK655prkNibQsHiwUaNG0RtvvMEFHxZrypQpIAZTjJi70f/+9z/+j01msfhG5lbHQH/2hq1bt9LIkSPTxmj0aWOYDMFcnE877TTq37+/7n5RlKXzAjkrACY8++yz9Pnnn/MZdnlSATYLL8GC/o455hg65JBD+H7nnntuQLWNFizYmv2TYArSEUccQW+++SY98cQTgdYt02coWZ8dNGiQYjv6NIgin376KT322GN8skUeK8MUfAnWl5mAyWblv/zySx6LAMxhE1nsn3yMXrduHb344ov00UcfBVq3TOaDDz6gjh078jgZOejTxrDYJDYBmIlxWllnSdp333154HRxcbFiO/vevXt3zWPYdqP9pb9Wysx07LSzfHaSKUljxozhA5IRzPTNzrV27VrKRpy0s0R+fj4de+yxyTZEf3a/rVkwK1P6RV6o2d6n7aA3RrMEJSxDkhvPCUjB+jKbbWdCotp9Rg0TOg877DD0Z4ewyRWpDdGf3YeFMDEPi1/+8pfUokULw33Rp1P86U9/oh9//JEn3OrVqxcZEUVZOuuUJNb5jz/+eO7aIjcVsu/y2XU5bLt8fwbL5iHtf9BBB/EbKN+HuXmwzBx6ZWY6dtpZymzCrBnMrH3CCSeYnoe5iLH4DeaekI3YbWc5zG1jyZIlyTZEf3a/rVna09raWrrppptMz5PtfdoO/9/enQfbXP9xHH/jElKWSBKyt1GJZpK6N1vSaEGbQmo0KWJCMaVSFCXTkJkmLZZMKtla6ZKSpQXlliVb8oeWmUrdbMXnN6/3b77n98W9596ji373PB8zp7uc7/2e08e53895f97vz/sWdI0uit8T/Jc6L/bq1cs/xlvZ50fleMqC8Hr+Z9S1MRpDXs9FT2XOCnoKs5DFa9o8qFSANGvWLFu4cKG/byjI/+V76ZCGpk+f7t0yJk2aFNasWRPuuOOOUKlSpfDDDz/4/d27dw9DhgxJHL9kyZKQkZERxowZE9auXeudTkqXLh1ycnISx4waNcrPMWfOnLB69WrvVlW3bt2wa9eukK5SHWeNYZkyZcKMGTPC9u3bE7c//vjD79fHQYMGhWXLloUtW7aE7Ozs0KxZs9CwYcOwe/fukK5SHWd1opo3b17YtGlTWLFiRbjxxhtD2bJlwzfffJM4htdz0Yx1pFWrVt5t7WC8pvOmcVm1apXfNE2NHTvWP9+6davfrzHWWEc2b94cypcvHwYPHuzX6AkTJoRSpUqF999/v9D/duko1XGeNm2az4Ua3/g1Wh2oIgMHDgyLFi3y17PmzrZt24aqVat696t0leo4qwvm7Nmzw4YNG/x9Rv/+/UPJkiX9+hDh9Vw0Yx255ZZbvNNaXnhNH6pPnz7eJVfjEr8W7Ny5M3FMcXgvnZZBkowfPz7Url3b35Srleby5csT92VmZnpb3rjXX389NGrUyI9Xq9l33nnngPvVunDYsGGhevXqfuFq06ZNWL9+fUh3qYxznTp1/KJ28E2/SKJfvvbt24dq1ar5L5aO7927d9pPCqmO84ABAxLH6vXasWPHsHLlygPOx+u56K4d69at89fx/PnzDzkXr+nkLZAPvkVjq48a64N/5rzzzvN/l3r16nmr+1T+7dJRquOsz5MdL1oMqFGjho9xzZo1/euNGzeGdJbqOI8ePTrUr1/fF6+qVKkSsrKywsKFCw85L6/norl2KMgvV65ceP755/M8J6/pQ+U1xrrFr7vF4b10Cf3n2OSwAAAAAODfJ+32JAEAAABAMgRJAAAAABBDkAQAAAAAMQRJAAAAABBDkAQAAAAAMQRJAAAAABBDkAQAAAAAMQRJAAAAAP4VPv74Y+vUqZOdeuqpVqJECZs9e3bK59CfgR0zZow1atTIjjvuOKtZs6aNHDkypXMQJAEAjpnTTz/dnnnmmUIfv2jRIp80f/vttyP6vAAAx8aff/5p5557rk2YMOGwz9G/f3974YUXPFBat26dzZ071y688MKUzlEiKNQCACAJBSbJPPzww/bII4+kfN6ff/7Zjj/+eCtfvnyhjt+7d6/98ssvVr169QKf0z81ceJEe/bZZ23Tpk2WkZFhdevWteuvv96GDh3q9996660erB3OKicAoGC6zs+aNcuuueaaxPf27NljDzzwgL366qt+DT7nnHNs9OjRlpWV5fevXbvWmjZtal9//bU1btzYDlfGYf8kACBtbN++PfH5a6+9Zg899JCtX78+8b0KFSokPtfa2759+zywKEi1atVSeh5lypSxU045xY60l156yQYMGGDjxo2zzMxMn5RXr17tky4A4Njp27evrVmzxqZPn+4leQqiOnToYDk5OdawYUN76623rF69evb222/79zUntW3b1p588kmrUqVKoR+HcjsAQIEUmES3ihUr+upe9LVKGU444QR777337IILLvD6708++cQzMFdffbVnfRREtWjRwrKzs5OW2+m8KpG49tprPbukCU9lEvmV202aNMkqVapk8+bNszPPPNMfR5NiPKj7+++/7Z577vHjTjrpJLv//vutZ8+eB6xMHkyPqazR7bffbg0aNLCzzz7bbrrppkRNu7JmkydPtjlz5vjz0U3PTbZt2+Y/q8fThKwx+O677xLnVgZKjz18+HAPEk888US78847PUsWmTFjhjVp0sTKlSvnz1kTvEpQACCdff/99/byyy/bG2+8YZdcconVr1/fBg0aZK1atfLvy+bNm23r1q1+zJQpU3yeWLFihXXt2jWlxyJIAgAUiSFDhtioUaMSpQ65ubnWsWNHW7Bgga1atcqDF23G1SSXjIIHBRnK3Ojnb775Zi+xy8/OnTu97nzq1Km+4Vfn16QZURnGtGnTfAJdsmSJ/f777wWWyCn4W758uU+0edH59RyjgEy3li1b2l9//WWXX365B42LFy/2x4sCt3gQpDHROCmwUsnIzJkz/f9bdC4FZLfddlvimM6dO/tqKACks5ycHK9UUEMGXVuj20cffeQLc7J//37P/itAUiClMrwXX3zRPvzwwwMqIApCuR0AoEg8+uij1q5du8TXyqJo823kscce87IIZWlULpEfZVoUJMjjjz/uJW+fffaZBxp5UWDy3HPP+Yqi6Nx6LpHx48f7PiJlp0T7jN59990C91gpMFGmS5PxRRdd5AGbViJLlizpk7KyPJqI4+V/r7zyik/QyoZFe6YUnCmrpGCnffv2ibJBlfQpW6YslZ7v4MGDfYwUJCn7pcevU6eOH6+sEgCku9zcXCtVqpRnhvQxLir7rlGjhpd769odUaWBaBGtsPuUyCQBAIpE8+bND5nMlHHR5KQgQROYMiMFZZKUhYqoqYPK0X766ad8j1egEQVI0QQZHb9jxw778ccfD+hqpIlVZYHJ6BzLli3zVUt1SVLQohI9BWoKgvLz1Vdf2caNGz2TFK1wKljcvXt3YpVTFDzGm1UoCNN4qVRP97Vp08YDo+uuu84bSPz6669Jny8ApIPzzz/fM0m6xqsUOn6LFqwuvvhiv2bHr7nffvutf4wWngqDTBIAoEgooIlTgPTBBx94KZwmMGVelImJl53lpXTp0gd8rYxMssAkr+OLqjRNXZN0u+uuu3zfkEo3VNZx2WWX5Xm8Ah0FYCrvO9wmFQriNG5Lly61+fPneyZMnZw+/fRT77AHAMVZbm6uLzZFtmzZYl9++aUvOCk7pBLsHj162NNPP+1Bk7qkqoRZC2xXXnml7+Fs1qyZlyxrz6vmj7vvvtsrHeLZpYKQSQIAHBHaj6PSOZW5KSuiVb54A4OjQU0m1Dji888/T3xPq5ArV65M+VxnnXWWf4waKKhkTueK08S8YcMGO/nkkw9Z5dRziWecdu3alfha+5+UdapVq1Yi0NNqqPYpaT+XHkuligBQ3H3xxRce/Ogm9957r3+urqpRCbOCpIEDB3rpnBrh6Bpfu3Ztv18l0epwV7VqVbv00ks9cFJFg7rhpYJMEgDgiFBnOjUkULMGvekfNmxY0ozQkdKvXz974oknPFA544wzPDOj8rVkf2epT58+3lq2devWdtppp/k+oREjRng2SKVxov1K6qqnjcDqQKcgSCucTz31lHe00z4j/ayaP2gc7rvvPv9alE1T57wHH3zQA0ftgdJeKk3uyhhpVVT7lxRs6WutlEY19QBQnGVlZSWtBlD1gBaQomY3edH1+8033/xHz4NMEgDgiBg7dqxVrlzZu74pUFLXN2Vajja1/FYjCK08KsBRxkbPpWzZsvn+jMo1lN3RniCVZ3Tp0sWPV/CigEh69+7tq5jai6XgSZkz7TNShz2taKrxggIbBUPak6S9VRHtOVIQqVXOG264wa666qrEH+PVcTqHGkXosRVIqazkiiuuOAqjBQCQEoGeogCANKJsloIXtfBWN7mjTSWI+jtPBbUhBwAcO5TbAQCKNZW7qQFCZmamt+xWC3BtBO7WrduxfmoAgH8pyu0AAMWa9vnoL663aNHCmyGorXd2djZ7fAAA+aLcDgAAAABiyCQBAAAAQAxBEgAAAADEECQBAAAAQAxBEgAAAADEECQBAAAAQAxBEgAAAADEECQBAAAAQAxBEgAAAADY//wHqHCYZnegO4UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 指定日志文件路径\n",
    "log_dir = r\"C:\\Users\\raced\\Autonomous-Fighter-Jet-Navigation-and-Combat\\fighter_jet_dqn_2\\DQN_0\"\n",
    "event_acc = EventAccumulator(log_dir)\n",
    "event_acc.Reload()\n",
    "\n",
    "# 获取所有标量标签\n",
    "tags = event_acc.Tags()[\"scalars\"]\n",
    "print(\"Available scalar tags:\", tags)\n",
    "\n",
    "# 提取某个标量（例如奖励）\n",
    "if \"main/ep_rew_total\" in tags:\n",
    "    rewards = event_acc.Scalars(\"main/ep_rew_total\")\n",
    "    steps = [x.step for x in rewards]\n",
    "    values = [x.value for x in rewards]\n",
    "\n",
    "    # 绘制奖励曲线\n",
    "    plt.plot(steps, values, label=\"Episode Reward\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Training Reward Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制探索率 (Epsilon)\n",
    "if \"exploration/epsilon\" in tags:\n",
    "    epsilon = event_acc.Scalars(\"exploration/epsilon\")\n",
    "    steps = [x.step for x in epsilon]\n",
    "    values = [x.value for x in epsilon]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(steps, values, label=\"Epsilon\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Epsilon\")\n",
    "    plt.title(\"Epsilon Decay Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制平均奖励\n",
    "if \"main/ep_rew_total\" in tags:\n",
    "    rewards = event_acc.Scalars(\"main/ep_rew_total\")\n",
    "    steps = [x.step for x in rewards]\n",
    "    values = [x.value for x in rewards]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(steps, values, label=\"Mean Reward\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Mean Reward Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制 Q 值\n",
    "if \"q_values/mean\" in tags:\n",
    "    q_values = event_acc.Scalars(\"q_values/mean\")\n",
    "    steps = [x.step for x in q_values]\n",
    "    values = [x.value for x in q_values]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(steps, values, label=\"Mean Q Value\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Q Value\")\n",
    "    plt.title(\"Mean Q Value Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制 Q 值分布\n",
    "if \"q_values/max\" in tags and \"q_values/min\" in tags and \"q_values/mean\" in tags:\n",
    "    q_max = event_acc.Scalars(\"q_values/max\")\n",
    "    q_min = event_acc.Scalars(\"q_values/min\")\n",
    "    q_mean = event_acc.Scalars(\"q_values/mean\")\n",
    "\n",
    "    steps = [x.step for x in q_max]\n",
    "    max_values = [x.value for x in q_max]\n",
    "    min_values = [x.value for x in q_min]\n",
    "    mean_values = [x.value for x in q_mean]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(steps, max_values, label=\"Max Q Value\", color=\"red\")\n",
    "    plt.plot(steps, min_values, label=\"Min Q Value\", color=\"blue\")\n",
    "    plt.plot(steps, mean_values, label=\"Mean Q Value\", color=\"green\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Q Value\")\n",
    "    plt.title(\"Q Value Distribution Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制动作分布\n",
    "action_tags = [tag for tag in tags if tag.startswith(\"q_values/action_\")]\n",
    "if action_tags:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for action_tag in action_tags:\n",
    "        action_values = event_acc.Scalars(action_tag)\n",
    "        steps = [x.step for x in action_values]\n",
    "        values = [x.value for x in action_values]\n",
    "        plt.plot(steps, values, label=action_tag)\n",
    "\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Q Value\")\n",
    "    plt.title(\"Action Q Value Distribution Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制损失\n",
    "if \"train/loss\" in tags:\n",
    "    losses = event_acc.Scalars(\"train/loss\")\n",
    "    steps = [x.step for x in losses]\n",
    "    values = [x.value for x in losses]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(steps, values, label=\"Loss\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 提取 Mean Episode Length 數據\n",
    "if \"main/ep_len_mean\" in tags:\n",
    "    ep_len_mean = event_acc.Scalars(\"main/ep_len_mean\")\n",
    "    steps = [x.step for x in ep_len_mean]\n",
    "    values = [x.value for x in ep_len_mean]\n",
    "\n",
    "    # 繪製 Mean Episode Length vs Steps 圖表\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(steps, values, label=\"Mean Episode Length\", color=\"purple\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Mean Episode Length\")\n",
    "    plt.title(\"Mean Episode Length vs Training Steps\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tag 'main/ep_len_mean' not found in TensorBoard logs.\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jestfight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
